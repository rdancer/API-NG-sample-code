{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "mount_file_id": "1OogBSJ3G5Obnf3LGUYY7o9FErLUFrwDD",
      "authorship_tag": "ABX9TyPFtE8H8LhH2HA2PlpEFG26",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rdancer/API-NG-sample-code/blob/master/needs_work_Experiment_TS_transformer_nonlinear_head.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# access the secret GITHUB_PAT_TOKEN\n",
        "from google.colab import userdata\n",
        "\n",
        "GITHUB_PAT_TOKEN = userdata.get('GITHUB_PAT_TOKEN')"
      ],
      "metadata": {
        "id": "yWpmrumVwYSv"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install ipython-autotime\n",
        "%load_ext autotime"
      ],
      "metadata": {
        "id": "xOXYV1sIJAQb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b9ab0d8-95b2-4254-f188-2e07cd08cb97"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25htime: 339 µs (started: 2025-11-23 03:23:52 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "qFYRgGbuCfXR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8d8968e-eeb7-440b-9ad7-6c64c595388e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "time: 27.5 s (started: 2025-11-23 03:23:52 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "upT42_lqwIwe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15609ce1-5be5-4628-f094-c6e769c5b3f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'aziz-mrh-final'...\n",
            "remote: Enumerating objects: 48, done.\u001b[K\n",
            "remote: Counting objects: 100% (48/48), done.\u001b[K\n",
            "remote: Compressing objects: 100% (40/40), done.\u001b[K\n",
            "remote: Total 48 (delta 17), reused 23 (delta 5), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (48/48), 95.16 KiB | 15.86 MiB/s, done.\n",
            "Resolving deltas: 100% (17/17), done.\n",
            "time: 1.41 s (started: 2025-11-23 03:24:19 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Clone the repository using HTTPS with the PAT for authentication, explicitly including the username\n",
        "!git clone https://rdancer:{GITHUB_PAT_TOKEN}@github.com/rdancer/aziz-mrh-final.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.cs.ucr.edu/%7Eeamonn/time_series_data_2018/UCRArchive_2018.zip\n"
      ],
      "metadata": {
        "id": "_DAAL0LJzgBf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7ef161c-3ae2-43bc-81df-2bedecf0b0af"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-11-23 03:24:21--  https://www.cs.ucr.edu/%7Eeamonn/time_series_data_2018/UCRArchive_2018.zip\n",
            "Resolving www.cs.ucr.edu (www.cs.ucr.edu)... 169.235.30.15\n",
            "Connecting to www.cs.ucr.edu (www.cs.ucr.edu)|169.235.30.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 316175400 (302M) [application/zip]\n",
            "Saving to: ‘UCRArchive_2018.zip’\n",
            "\n",
            "UCRArchive_2018.zip 100%[===================>] 301.53M  19.9MB/s    in 16s     \n",
            "\n",
            "2025-11-23 03:24:38 (18.3 MB/s) - ‘UCRArchive_2018.zip’ saved [316175400/316175400]\n",
            "\n",
            "time: 18.1 s (started: 2025-11-23 03:24:21 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf UCRArchive_2018\n",
        "!unzip -P someone UCRArchive_2018.zip\n",
        "!rm -rf aziz-mrh-final/datasets\n",
        "!mv UCRArchive_2018 aziz-mrh-final/datasets"
      ],
      "metadata": {
        "id": "HR-eZEANzh6-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab35ead5-2f66-49e0-8645-f7ea2962ac38"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  UCRArchive_2018.zip\n",
            "   creating: UCRArchive_2018/\n",
            "   creating: UCRArchive_2018/MixedShapesSmallTrain/\n",
            "  inflating: UCRArchive_2018/MixedShapesSmallTrain/README.md  \n",
            "  inflating: UCRArchive_2018/MixedShapesSmallTrain/MixedShapesSmallTrain_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/MixedShapesSmallTrain/MixedShapesSmallTrain_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/Beef/\n",
            "  inflating: UCRArchive_2018/Beef/README.md  \n",
            "  inflating: UCRArchive_2018/Beef/Beef_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/Beef/Beef_TEST.tsv  \n",
            "   creating: UCRArchive_2018/ShapesAll/\n",
            "  inflating: UCRArchive_2018/ShapesAll/README.md  \n",
            "  inflating: UCRArchive_2018/ShapesAll/ShapesAll_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/ShapesAll/ShapesAll_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/RefrigerationDevices/\n",
            "  inflating: UCRArchive_2018/RefrigerationDevices/RefrigerationDevices_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/RefrigerationDevices/README.md  \n",
            "  inflating: UCRArchive_2018/RefrigerationDevices/RefrigerationDevices_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/BeetleFly/\n",
            "  inflating: UCRArchive_2018/BeetleFly/BeetleFly_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/BeetleFly/README.md  \n",
            "  inflating: UCRArchive_2018/BeetleFly/BeetleFly_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/Ham/\n",
            "  inflating: UCRArchive_2018/Ham/Ham_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/Ham/README.md  \n",
            "  inflating: UCRArchive_2018/Ham/Ham_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/ShakeGestureWiimoteZ/\n",
            "  inflating: UCRArchive_2018/ShakeGestureWiimoteZ/ShakeGestureWiimoteZ_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/ShakeGestureWiimoteZ/README.md  \n",
            "  inflating: UCRArchive_2018/ShakeGestureWiimoteZ/ShakeGestureWiimoteZ_TEST.tsv  \n",
            "   creating: UCRArchive_2018/UMD/\n",
            "  inflating: UCRArchive_2018/UMD/README.md  \n",
            "  inflating: UCRArchive_2018/UMD/UMD_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/UMD/UMD_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/WordSynonyms/\n",
            "  inflating: UCRArchive_2018/WordSynonyms/WordSynonyms_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/WordSynonyms/README.md  \n",
            "  inflating: UCRArchive_2018/WordSynonyms/WordSynonyms_TEST.tsv  \n",
            "   creating: UCRArchive_2018/AllGestureWiimoteZ/\n",
            "  inflating: UCRArchive_2018/AllGestureWiimoteZ/README.md  \n",
            "  inflating: UCRArchive_2018/AllGestureWiimoteZ/AllGestureWiimoteZ_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/AllGestureWiimoteZ/AllGestureWiimoteZ_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/SemgHandGenderCh2/\n",
            "  inflating: UCRArchive_2018/SemgHandGenderCh2/SemgHandGenderCh2_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/SemgHandGenderCh2/README.md  \n",
            "  inflating: UCRArchive_2018/SemgHandGenderCh2/SemgHandGenderCh2_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/SmoothSubspace/\n",
            "  inflating: UCRArchive_2018/SmoothSubspace/SmoothSubspace_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/SmoothSubspace/README.md  \n",
            "  inflating: UCRArchive_2018/SmoothSubspace/SmoothSubspace_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/HouseTwenty/\n",
            "  inflating: UCRArchive_2018/HouseTwenty/README.md  \n",
            "  inflating: UCRArchive_2018/HouseTwenty/HouseTwenty_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/HouseTwenty/HouseTwenty_TEST.tsv  \n",
            "   creating: UCRArchive_2018/SwedishLeaf/\n",
            "  inflating: UCRArchive_2018/SwedishLeaf/README.md  \n",
            "  inflating: UCRArchive_2018/SwedishLeaf/SwedishLeaf_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/SwedishLeaf/SwedishLeaf_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/ElectricDevices/\n",
            "  inflating: UCRArchive_2018/ElectricDevices/README.md  \n",
            "  inflating: UCRArchive_2018/ElectricDevices/ElectricDevices_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/ElectricDevices/ElectricDevices_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/FordA/\n",
            "  inflating: UCRArchive_2018/FordA/FordA_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/FordA/README.md  \n",
            "  inflating: UCRArchive_2018/FordA/FordA_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/EOGVerticalSignal/\n",
            "  inflating: UCRArchive_2018/EOGVerticalSignal/README.md  \n",
            "  inflating: UCRArchive_2018/EOGVerticalSignal/EOGVerticalSignal_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/EOGVerticalSignal/EOGVerticalSignal_TEST.tsv  \n",
            "   creating: UCRArchive_2018/SemgHandMovementCh2/\n",
            "  inflating: UCRArchive_2018/SemgHandMovementCh2/README.md  \n",
            "  inflating: UCRArchive_2018/SemgHandMovementCh2/SemgHandMovementCh2_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/SemgHandMovementCh2/SemgHandMovementCh2_TEST.tsv  \n",
            "   creating: UCRArchive_2018/FordB/\n",
            "  inflating: UCRArchive_2018/FordB/README.md  \n",
            "  inflating: UCRArchive_2018/FordB/FordB_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/FordB/FordB_TEST.tsv  \n",
            "   creating: UCRArchive_2018/Haptics/\n",
            "  inflating: UCRArchive_2018/Haptics/README.md  \n",
            "  inflating: UCRArchive_2018/Haptics/Haptics_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/Haptics/Haptics_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/PowerCons/\n",
            "  inflating: UCRArchive_2018/PowerCons/PowerCons_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/PowerCons/README.md  \n",
            "  inflating: UCRArchive_2018/PowerCons/PowerCons_TEST.tsv  \n",
            "   creating: UCRArchive_2018/GunPointMaleVersusFemale/\n",
            "  inflating: UCRArchive_2018/GunPointMaleVersusFemale/GunPointMaleVersusFemale_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/GunPointMaleVersusFemale/README.md  \n",
            "  inflating: UCRArchive_2018/GunPointMaleVersusFemale/GunPointMaleVersusFemale_TEST.tsv  \n",
            "   creating: UCRArchive_2018/Chinatown/\n",
            "  inflating: UCRArchive_2018/Chinatown/README.md  \n",
            "  inflating: UCRArchive_2018/Chinatown/Chinatown_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/Chinatown/Chinatown_TEST.tsv  \n",
            "   creating: UCRArchive_2018/Symbols/\n",
            "  inflating: UCRArchive_2018/Symbols/Symbols_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/Symbols/Symbols_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/Symbols/README.md  \n",
            "   creating: UCRArchive_2018/ItalyPowerDemand/\n",
            "  inflating: UCRArchive_2018/ItalyPowerDemand/README.md  \n",
            "  inflating: UCRArchive_2018/ItalyPowerDemand/ItalyPowerDemand_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/ItalyPowerDemand/ItalyPowerDemand_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/ECG200/\n",
            "  inflating: UCRArchive_2018/ECG200/README.md  \n",
            "  inflating: UCRArchive_2018/ECG200/ECG200_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/ECG200/ECG200_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/WormsTwoClass/\n",
            "  inflating: UCRArchive_2018/WormsTwoClass/README.md  \n",
            "  inflating: UCRArchive_2018/WormsTwoClass/WormsTwoClass_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/WormsTwoClass/WormsTwoClass_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/Yoga/\n",
            "  inflating: UCRArchive_2018/Yoga/README.md  \n",
            "  inflating: UCRArchive_2018/Yoga/Yoga_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/Yoga/Yoga_TEST.tsv  \n",
            "   creating: UCRArchive_2018/MixedShapesRegularTrain/\n",
            "  inflating: UCRArchive_2018/MixedShapesRegularTrain/README.md  \n",
            "  inflating: UCRArchive_2018/MixedShapesRegularTrain/MixedShapesRegularTrain_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/MixedShapesRegularTrain/MixedShapesRegularTrain_TEST.tsv  \n",
            "   creating: UCRArchive_2018/MiddlePhalanxOutlineCorrect/\n",
            "  inflating: UCRArchive_2018/MiddlePhalanxOutlineCorrect/MiddlePhalanxOutlineCorrect_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/MiddlePhalanxOutlineCorrect/README.md  \n",
            "  inflating: UCRArchive_2018/MiddlePhalanxOutlineCorrect/MiddlePhalanxOutlineCorrect_TEST.tsv  \n",
            "   creating: UCRArchive_2018/MedicalImages/\n",
            "  inflating: UCRArchive_2018/MedicalImages/MedicalImages_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/MedicalImages/README.md  \n",
            "  inflating: UCRArchive_2018/MedicalImages/MedicalImages_TEST.tsv  \n",
            "   creating: UCRArchive_2018/InsectEPGSmallTrain/\n",
            "  inflating: UCRArchive_2018/InsectEPGSmallTrain/README.md  \n",
            "  inflating: UCRArchive_2018/InsectEPGSmallTrain/InsectEPGSmallTrain_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/InsectEPGSmallTrain/InsectEPGSmallTrain_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/InsectEPGRegularTrain/\n",
            "  inflating: UCRArchive_2018/InsectEPGRegularTrain/README.md  \n",
            "  inflating: UCRArchive_2018/InsectEPGRegularTrain/InsectEPGRegularTrain_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/InsectEPGRegularTrain/InsectEPGRegularTrain_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/GunPoint/\n",
            "  inflating: UCRArchive_2018/GunPoint/README.md  \n",
            "  inflating: UCRArchive_2018/GunPoint/GunPoint_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/GunPoint/GunPoint_TEST.tsv  \n",
            "   creating: UCRArchive_2018/ToeSegmentation2/\n",
            "  inflating: UCRArchive_2018/ToeSegmentation2/ToeSegmentation2_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/ToeSegmentation2/ToeSegmentation2_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/ToeSegmentation2/README.md  \n",
            "   creating: UCRArchive_2018/NonInvasiveFetalECGThorax1/\n",
            "  inflating: UCRArchive_2018/NonInvasiveFetalECGThorax1/README.md  \n",
            "  inflating: UCRArchive_2018/NonInvasiveFetalECGThorax1/NonInvasiveFetalECGThorax1_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/NonInvasiveFetalECGThorax1/NonInvasiveFetalECGThorax1_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/OliveOil/\n",
            "  inflating: UCRArchive_2018/OliveOil/OliveOil_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/OliveOil/README.md  \n",
            "  inflating: UCRArchive_2018/OliveOil/OliveOil_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/ECGFiveDays/\n",
            "  inflating: UCRArchive_2018/ECGFiveDays/README.md  \n",
            "  inflating: UCRArchive_2018/ECGFiveDays/ECGFiveDays_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/ECGFiveDays/ECGFiveDays_TEST.tsv  \n",
            "   creating: UCRArchive_2018/HandOutlines/\n",
            "  inflating: UCRArchive_2018/HandOutlines/HandOutlines_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/HandOutlines/README.md  \n",
            "  inflating: UCRArchive_2018/HandOutlines/HandOutlines_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/TwoLeadECG/\n",
            "  inflating: UCRArchive_2018/TwoLeadECG/TwoLeadECG_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/TwoLeadECG/README.md  \n",
            "  inflating: UCRArchive_2018/TwoLeadECG/TwoLeadECG_TEST.tsv  \n",
            "   creating: UCRArchive_2018/DistalPhalanxTW/\n",
            "  inflating: UCRArchive_2018/DistalPhalanxTW/README.md  \n",
            "  inflating: UCRArchive_2018/DistalPhalanxTW/DistalPhalanxTW_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/DistalPhalanxTW/DistalPhalanxTW_TEST.tsv  \n",
            "   creating: UCRArchive_2018/Adiac/\n",
            "  inflating: UCRArchive_2018/Adiac/Adiac_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/Adiac/README.md  \n",
            "  inflating: UCRArchive_2018/Adiac/Adiac_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/DistalPhalanxOutlineCorrect/\n",
            "  inflating: UCRArchive_2018/DistalPhalanxOutlineCorrect/README.md  \n",
            "  inflating: UCRArchive_2018/DistalPhalanxOutlineCorrect/DistalPhalanxOutlineCorrect_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/DistalPhalanxOutlineCorrect/DistalPhalanxOutlineCorrect_TEST.tsv  \n",
            "   creating: UCRArchive_2018/UWaveGestureLibraryX/\n",
            "  inflating: UCRArchive_2018/UWaveGestureLibraryX/UWaveGestureLibraryX_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/UWaveGestureLibraryX/UWaveGestureLibraryX_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/UWaveGestureLibraryX/README.md  \n",
            "   creating: UCRArchive_2018/GunPointAgeSpan/\n",
            "  inflating: UCRArchive_2018/GunPointAgeSpan/README.md  \n",
            "  inflating: UCRArchive_2018/GunPointAgeSpan/GunPointAgeSpan_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/GunPointAgeSpan/GunPointAgeSpan_TEST.tsv  \n",
            "   creating: UCRArchive_2018/CinCECGTorso/\n",
            "  inflating: UCRArchive_2018/CinCECGTorso/CinCECGTorso_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/CinCECGTorso/README.md  \n",
            "  inflating: UCRArchive_2018/CinCECGTorso/CinCECGTorso_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/Fish/\n",
            "  inflating: UCRArchive_2018/Fish/Fish_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/Fish/README.md  \n",
            "  inflating: UCRArchive_2018/Fish/Fish_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/PhalangesOutlinesCorrect/\n",
            "  inflating: UCRArchive_2018/PhalangesOutlinesCorrect/PhalangesOutlinesCorrect_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/PhalangesOutlinesCorrect/README.md  \n",
            "  inflating: UCRArchive_2018/PhalangesOutlinesCorrect/PhalangesOutlinesCorrect_TEST.tsv  \n",
            "   creating: UCRArchive_2018/Phoneme/\n",
            "  inflating: UCRArchive_2018/Phoneme/README.md  \n",
            "  inflating: UCRArchive_2018/Phoneme/Phoneme_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/Phoneme/Phoneme_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/Missing_value_and_variable_length_datasets_adjusted/\n",
            "   creating: UCRArchive_2018/Missing_value_and_variable_length_datasets_adjusted/ShakeGestureWiimoteZ/\n",
            "  inflating: UCRArchive_2018/Missing_value_and_variable_length_datasets_adjusted/ShakeGestureWiimoteZ/ShakeGestureWiimoteZ_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/Missing_value_and_variable_length_datasets_adjusted/ShakeGestureWiimoteZ/ShakeGestureWiimoteZ_TEST.tsv  \n",
            "   creating: UCRArchive_2018/Missing_value_and_variable_length_datasets_adjusted/AllGestureWiimoteZ/\n",
            "  inflating: UCRArchive_2018/Missing_value_and_variable_length_datasets_adjusted/AllGestureWiimoteZ/AllGestureWiimoteZ_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/Missing_value_and_variable_length_datasets_adjusted/AllGestureWiimoteZ/AllGestureWiimoteZ_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/Missing_value_and_variable_length_datasets_adjusted/REAME.md  \n",
            "   creating: UCRArchive_2018/Missing_value_and_variable_length_datasets_adjusted/PLAID/\n",
            "  inflating: UCRArchive_2018/Missing_value_and_variable_length_datasets_adjusted/PLAID/PLAID_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/Missing_value_and_variable_length_datasets_adjusted/PLAID/PLAID_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/Missing_value_and_variable_length_datasets_adjusted/PickupGestureWiimoteZ/\n",
            "  inflating: UCRArchive_2018/Missing_value_and_variable_length_datasets_adjusted/PickupGestureWiimoteZ/PickupGestureWiimoteZ_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/Missing_value_and_variable_length_datasets_adjusted/PickupGestureWiimoteZ/PickupGestureWiimoteZ_TEST.tsv  \n",
            "   creating: UCRArchive_2018/Missing_value_and_variable_length_datasets_adjusted/MelbournePedestrian/\n",
            "  inflating: UCRArchive_2018/Missing_value_and_variable_length_datasets_adjusted/MelbournePedestrian/MelbournePedestrian_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/Missing_value_and_variable_length_datasets_adjusted/MelbournePedestrian/MelbournePedestrian_TEST.tsv  \n",
            "   creating: UCRArchive_2018/Missing_value_and_variable_length_datasets_adjusted/DodgerLoopWeekend/\n",
            "  inflating: UCRArchive_2018/Missing_value_and_variable_length_datasets_adjusted/DodgerLoopWeekend/DodgerLoopWeekend_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/Missing_value_and_variable_length_datasets_adjusted/DodgerLoopWeekend/DodgerLoopWeekend_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/Missing_value_and_variable_length_datasets_adjusted/AllGestureWiimoteX/\n",
            "  inflating: UCRArchive_2018/Missing_value_and_variable_length_datasets_adjusted/AllGestureWiimoteX/AllGestureWiimoteX_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/Missing_value_and_variable_length_datasets_adjusted/AllGestureWiimoteX/AllGestureWiimoteX_TEST.tsv  \n",
            "   creating: UCRArchive_2018/Missing_value_and_variable_length_datasets_adjusted/DodgerLoopGame/\n",
            "  inflating: UCRArchive_2018/Missing_value_and_variable_length_datasets_adjusted/DodgerLoopGame/DodgerLoopGame_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/Missing_value_and_variable_length_datasets_adjusted/DodgerLoopGame/DodgerLoopGame_TEST.tsv  \n",
            "   creating: UCRArchive_2018/Missing_value_and_variable_length_datasets_adjusted/GesturePebbleZ1/\n",
            "  inflating: UCRArchive_2018/Missing_value_and_variable_length_datasets_adjusted/GesturePebbleZ1/GesturePebbleZ1_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/Missing_value_and_variable_length_datasets_adjusted/GesturePebbleZ1/GesturePebbleZ1_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/Missing_value_and_variable_length_datasets_adjusted/missing_value_and_variable_length_datasets_info.csv  \n",
            "   creating: UCRArchive_2018/Missing_value_and_variable_length_datasets_adjusted/GestureMidAirD3/\n",
            "  inflating: UCRArchive_2018/Missing_value_and_variable_length_datasets_adjusted/GestureMidAirD3/GestureMidAirD3_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/Missing_value_and_variable_length_datasets_adjusted/GestureMidAirD3/GestureMidAirD3_TEST.tsv  \n",
            "   creating: UCRArchive_2018/Missing_value_and_variable_length_datasets_adjusted/GestureMidAirD2/\n",
            "  inflating: UCRArchive_2018/Missing_value_and_variable_length_datasets_adjusted/GestureMidAirD2/GestureMidAirD2_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/Missing_value_and_variable_length_datasets_adjusted/GestureMidAirD2/GestureMidAirD2_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/Missing_value_and_variable_length_datasets_adjusted/DodgerLoopDay/\n",
            "  inflating: UCRArchive_2018/Missing_value_and_variable_length_datasets_adjusted/DodgerLoopDay/DodgerLoopDay_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/Missing_value_and_variable_length_datasets_adjusted/DodgerLoopDay/DodgerLoopDay_TEST.tsv  \n",
            "   creating: UCRArchive_2018/Missing_value_and_variable_length_datasets_adjusted/AllGestureWiimoteY/\n",
            "  inflating: UCRArchive_2018/Missing_value_and_variable_length_datasets_adjusted/AllGestureWiimoteY/AllGestureWiimoteY_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/Missing_value_and_variable_length_datasets_adjusted/AllGestureWiimoteY/AllGestureWiimoteY_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/Missing_value_and_variable_length_datasets_adjusted/GesturePebbleZ2/\n",
            "  inflating: UCRArchive_2018/Missing_value_and_variable_length_datasets_adjusted/GesturePebbleZ2/GesturePebbleZ2_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/Missing_value_and_variable_length_datasets_adjusted/GesturePebbleZ2/GesturePebbleZ2_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/Missing_value_and_variable_length_datasets_adjusted/GestureMidAirD1/\n",
            "  inflating: UCRArchive_2018/Missing_value_and_variable_length_datasets_adjusted/GestureMidAirD1/GestureMidAirD1_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/Missing_value_and_variable_length_datasets_adjusted/GestureMidAirD1/GestureMidAirD1_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/Strawberry/\n",
            "  inflating: UCRArchive_2018/Strawberry/Strawberry_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/Strawberry/README.md  \n",
            "  inflating: UCRArchive_2018/Strawberry/Strawberry_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/Computers/\n",
            "  inflating: UCRArchive_2018/Computers/README.md  \n",
            "  inflating: UCRArchive_2018/Computers/Computers_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/Computers/Computers_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/SonyAIBORobotSurface2/\n",
            "  inflating: UCRArchive_2018/SonyAIBORobotSurface2/README.md  \n",
            "  inflating: UCRArchive_2018/SonyAIBORobotSurface2/SonyAIBORobotSurface2_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/SonyAIBORobotSurface2/SonyAIBORobotSurface2_TEST.tsv  \n",
            "   creating: UCRArchive_2018/ToeSegmentation1/\n",
            "  inflating: UCRArchive_2018/ToeSegmentation1/README.md  \n",
            "  inflating: UCRArchive_2018/ToeSegmentation1/ToeSegmentation1_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/ToeSegmentation1/ToeSegmentation1_TEST.tsv  \n",
            "   creating: UCRArchive_2018/PLAID/\n",
            "  inflating: UCRArchive_2018/PLAID/README.md  \n",
            "  inflating: UCRArchive_2018/PLAID/PLAID_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/PLAID/PLAID_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/PickupGestureWiimoteZ/\n",
            "  inflating: UCRArchive_2018/PickupGestureWiimoteZ/PickupGestureWiimoteZ_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/PickupGestureWiimoteZ/README.md  \n",
            "  inflating: UCRArchive_2018/PickupGestureWiimoteZ/PickupGestureWiimoteZ_TEST.tsv  \n",
            "   creating: UCRArchive_2018/ArrowHead/\n",
            "  inflating: UCRArchive_2018/ArrowHead/README.md  \n",
            "  inflating: UCRArchive_2018/ArrowHead/ArrowHead_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/ArrowHead/ArrowHead_TEST.tsv  \n",
            "   creating: UCRArchive_2018/UWaveGestureLibraryY/\n",
            "  inflating: UCRArchive_2018/UWaveGestureLibraryY/UWaveGestureLibraryY_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/UWaveGestureLibraryY/README.md  \n",
            "  inflating: UCRArchive_2018/UWaveGestureLibraryY/UWaveGestureLibraryY_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/InsectWingbeatSound/\n",
            "  inflating: UCRArchive_2018/InsectWingbeatSound/InsectWingbeatSound_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/InsectWingbeatSound/README.md  \n",
            "  inflating: UCRArchive_2018/InsectWingbeatSound/InsectWingbeatSound_TEST.tsv  \n",
            "   creating: UCRArchive_2018/Wine/\n",
            "  inflating: UCRArchive_2018/Wine/Wine_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/Wine/README.md  \n",
            "  inflating: UCRArchive_2018/Wine/Wine_TEST.tsv  \n",
            "   creating: UCRArchive_2018/MelbournePedestrian/\n",
            "  inflating: UCRArchive_2018/MelbournePedestrian/MelbournePedestrian_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/MelbournePedestrian/README.md  \n",
            "  inflating: UCRArchive_2018/MelbournePedestrian/MelbournePedestrian_TEST.tsv  \n",
            "   creating: UCRArchive_2018/StarLightCurves/\n",
            "  inflating: UCRArchive_2018/StarLightCurves/README.md  \n",
            "  inflating: UCRArchive_2018/StarLightCurves/StarLightCurves_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/StarLightCurves/StarLightCurves_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/FreezerSmallTrain/\n",
            "  inflating: UCRArchive_2018/FreezerSmallTrain/FreezerSmallTrain_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/FreezerSmallTrain/README.md  \n",
            "  inflating: UCRArchive_2018/FreezerSmallTrain/FreezerSmallTrain_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/FaceAll/\n",
            "  inflating: UCRArchive_2018/FaceAll/README.md  \n",
            "  inflating: UCRArchive_2018/FaceAll/FaceAll_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/FaceAll/FaceAll_TEST.tsv  \n",
            "   creating: UCRArchive_2018/Lightning2/\n",
            "  inflating: UCRArchive_2018/Lightning2/README.md  \n",
            "  inflating: UCRArchive_2018/Lightning2/Lightning2_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/Lightning2/Lightning2_TEST.tsv  \n",
            "   creating: UCRArchive_2018/LargeKitchenAppliances/\n",
            "  inflating: UCRArchive_2018/LargeKitchenAppliances/README.md  \n",
            "  inflating: UCRArchive_2018/LargeKitchenAppliances/LargeKitchenAppliances_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/LargeKitchenAppliances/LargeKitchenAppliances_TEST.tsv  \n",
            "   creating: UCRArchive_2018/CricketX/\n",
            "  inflating: UCRArchive_2018/CricketX/README.md  \n",
            "  inflating: UCRArchive_2018/CricketX/CricketX_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/CricketX/CricketX_TEST.tsv  \n",
            "   creating: UCRArchive_2018/SemgHandSubjectCh2/\n",
            "  inflating: UCRArchive_2018/SemgHandSubjectCh2/README.md  \n",
            "  inflating: UCRArchive_2018/SemgHandSubjectCh2/SemgHandSubjectCh2_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/SemgHandSubjectCh2/SemgHandSubjectCh2_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/OSULeaf/\n",
            "  inflating: UCRArchive_2018/OSULeaf/OSULeaf_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/OSULeaf/README.md  \n",
            "  inflating: UCRArchive_2018/OSULeaf/OSULeaf_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/GunPointOldVersusYoung/\n",
            "  inflating: UCRArchive_2018/GunPointOldVersusYoung/README.md  \n",
            "  inflating: UCRArchive_2018/GunPointOldVersusYoung/GunPointOldVersusYoung_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/GunPointOldVersusYoung/GunPointOldVersusYoung_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/DistalPhalanxOutlineAgeGroup/\n",
            "  inflating: UCRArchive_2018/DistalPhalanxOutlineAgeGroup/DistalPhalanxOutlineAgeGroup_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/DistalPhalanxOutlineAgeGroup/README.md  \n",
            "  inflating: UCRArchive_2018/DistalPhalanxOutlineAgeGroup/DistalPhalanxOutlineAgeGroup_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/ProximalPhalanxOutlineCorrect/\n",
            "  inflating: UCRArchive_2018/ProximalPhalanxOutlineCorrect/ProximalPhalanxOutlineCorrect_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/ProximalPhalanxOutlineCorrect/README.md  \n",
            "  inflating: UCRArchive_2018/ProximalPhalanxOutlineCorrect/ProximalPhalanxOutlineCorrect_TEST.tsv  \n",
            "   creating: UCRArchive_2018/DodgerLoopWeekend/\n",
            "  inflating: UCRArchive_2018/DodgerLoopWeekend/DodgerLoopWeekend_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/DodgerLoopWeekend/README.md  \n",
            "  inflating: UCRArchive_2018/DodgerLoopWeekend/DodgerLoopWeekend_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/Rock/\n",
            "  inflating: UCRArchive_2018/Rock/README.md  \n",
            "  inflating: UCRArchive_2018/Rock/Rock_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/Rock/Rock_TEST.tsv  \n",
            "   creating: UCRArchive_2018/SmallKitchenAppliances/\n",
            "  inflating: UCRArchive_2018/SmallKitchenAppliances/README.md  \n",
            "  inflating: UCRArchive_2018/SmallKitchenAppliances/SmallKitchenAppliances_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/SmallKitchenAppliances/SmallKitchenAppliances_TEST.tsv  \n",
            "   creating: UCRArchive_2018/AllGestureWiimoteX/\n",
            "  inflating: UCRArchive_2018/AllGestureWiimoteX/README.md  \n",
            "  inflating: UCRArchive_2018/AllGestureWiimoteX/AllGestureWiimoteX_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/AllGestureWiimoteX/AllGestureWiimoteX_TEST.tsv  \n",
            "   creating: UCRArchive_2018/ScreenType/\n",
            "  inflating: UCRArchive_2018/ScreenType/README.md  \n",
            "  inflating: UCRArchive_2018/ScreenType/ScreenType_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/ScreenType/ScreenType_TEST.tsv  \n",
            "   creating: UCRArchive_2018/ProximalPhalanxTW/\n",
            "  inflating: UCRArchive_2018/ProximalPhalanxTW/README.md  \n",
            "  inflating: UCRArchive_2018/ProximalPhalanxTW/ProximalPhalanxTW_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/ProximalPhalanxTW/ProximalPhalanxTW_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/DodgerLoopGame/\n",
            "  inflating: UCRArchive_2018/DodgerLoopGame/DodgerLoopGame_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/DodgerLoopGame/README.md  \n",
            "  inflating: UCRArchive_2018/DodgerLoopGame/DodgerLoopGame_TEST.tsv  \n",
            "   creating: UCRArchive_2018/GesturePebbleZ1/\n",
            "  inflating: UCRArchive_2018/GesturePebbleZ1/GesturePebbleZ1_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/GesturePebbleZ1/README.md  \n",
            "  inflating: UCRArchive_2018/GesturePebbleZ1/GesturePebbleZ1_TEST.tsv  \n",
            "   creating: UCRArchive_2018/MoteStrain/\n",
            "  inflating: UCRArchive_2018/MoteStrain/README.md  \n",
            "  inflating: UCRArchive_2018/MoteStrain/MoteStrain_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/MoteStrain/MoteStrain_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/Plane/\n",
            "  inflating: UCRArchive_2018/Plane/Plane_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/Plane/README.md  \n",
            "  inflating: UCRArchive_2018/Plane/Plane_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/Wafer/\n",
            "  inflating: UCRArchive_2018/Wafer/README.md  \n",
            "  inflating: UCRArchive_2018/Wafer/Wafer_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/Wafer/Wafer_TEST.tsv  \n",
            "   creating: UCRArchive_2018/GestureMidAirD3/\n",
            "  inflating: UCRArchive_2018/GestureMidAirD3/README.md  \n",
            "  inflating: UCRArchive_2018/GestureMidAirD3/GestureMidAirD3_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/GestureMidAirD3/GestureMidAirD3_TEST.tsv  \n",
            "   creating: UCRArchive_2018/SonyAIBORobotSurface1/\n",
            "  inflating: UCRArchive_2018/SonyAIBORobotSurface1/SonyAIBORobotSurface1_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/SonyAIBORobotSurface1/README.md  \n",
            "  inflating: UCRArchive_2018/SonyAIBORobotSurface1/SonyAIBORobotSurface1_TEST.tsv  \n",
            "   creating: UCRArchive_2018/SyntheticControl/\n",
            "  inflating: UCRArchive_2018/SyntheticControl/README.md  \n",
            "  inflating: UCRArchive_2018/SyntheticControl/SyntheticControl_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/SyntheticControl/SyntheticControl_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/MiddlePhalanxOutlineAgeGroup/\n",
            "  inflating: UCRArchive_2018/MiddlePhalanxOutlineAgeGroup/README.md  \n",
            "  inflating: UCRArchive_2018/MiddlePhalanxOutlineAgeGroup/MiddlePhalanxOutlineAgeGroup_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/MiddlePhalanxOutlineAgeGroup/MiddlePhalanxOutlineAgeGroup_TEST.tsv  \n",
            "   creating: UCRArchive_2018/CBF/\n",
            "  inflating: UCRArchive_2018/CBF/CBF_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/CBF/README.md  \n",
            "  inflating: UCRArchive_2018/CBF/CBF_TEST.tsv  \n",
            "   creating: UCRArchive_2018/GestureMidAirD2/\n",
            "  inflating: UCRArchive_2018/GestureMidAirD2/README.md  \n",
            "  inflating: UCRArchive_2018/GestureMidAirD2/GestureMidAirD2_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/GestureMidAirD2/GestureMidAirD2_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/CricketZ/\n",
            "  inflating: UCRArchive_2018/CricketZ/README.md  \n",
            "  inflating: UCRArchive_2018/CricketZ/CricketZ_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/CricketZ/CricketZ_TEST.tsv  \n",
            "   creating: UCRArchive_2018/Fungi/\n",
            "  inflating: UCRArchive_2018/Fungi/README.md  \n",
            "  inflating: UCRArchive_2018/Fungi/Fungi_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/Fungi/Fungi_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/Car/\n",
            "  inflating: UCRArchive_2018/Car/Car_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/Car/README.md  \n",
            "  inflating: UCRArchive_2018/Car/Car_TEST.tsv  \n",
            "   creating: UCRArchive_2018/Herring/\n",
            "  inflating: UCRArchive_2018/Herring/Herring_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/Herring/README.md  \n",
            "  inflating: UCRArchive_2018/Herring/Herring_TEST.tsv  \n",
            "   creating: UCRArchive_2018/PigArtPressure/\n",
            "  inflating: UCRArchive_2018/PigArtPressure/PigArtPressure_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/PigArtPressure/README.md  \n",
            "  inflating: UCRArchive_2018/PigArtPressure/PigArtPressure_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/DodgerLoopDay/\n",
            "  inflating: UCRArchive_2018/DodgerLoopDay/README.md  \n",
            "  inflating: UCRArchive_2018/DodgerLoopDay/DodgerLoopDay_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/DodgerLoopDay/DodgerLoopDay_TEST.tsv  \n",
            "   creating: UCRArchive_2018/ChlorineConcentration/\n",
            "  inflating: UCRArchive_2018/ChlorineConcentration/README.md  \n",
            "  inflating: UCRArchive_2018/ChlorineConcentration/ChlorineConcentration_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/ChlorineConcentration/ChlorineConcentration_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/AllGestureWiimoteY/\n",
            "  inflating: UCRArchive_2018/AllGestureWiimoteY/README.md  \n",
            "  inflating: UCRArchive_2018/AllGestureWiimoteY/AllGestureWiimoteY_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/AllGestureWiimoteY/AllGestureWiimoteY_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/CricketY/\n",
            "  inflating: UCRArchive_2018/CricketY/CricketY_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/CricketY/README.md  \n",
            "  inflating: UCRArchive_2018/CricketY/CricketY_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/BME/\n",
            "  inflating: UCRArchive_2018/BME/BME_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/BME/README.md  \n",
            "  inflating: UCRArchive_2018/BME/BME_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/BirdChicken/\n",
            "  inflating: UCRArchive_2018/BirdChicken/BirdChicken_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/BirdChicken/README.md  \n",
            "  inflating: UCRArchive_2018/BirdChicken/BirdChicken_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/MiddlePhalanxTW/\n",
            "  inflating: UCRArchive_2018/MiddlePhalanxTW/README.md  \n",
            "  inflating: UCRArchive_2018/MiddlePhalanxTW/MiddlePhalanxTW_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/MiddlePhalanxTW/MiddlePhalanxTW_TEST.tsv  \n",
            "   creating: UCRArchive_2018/UWaveGestureLibraryAll/\n",
            "  inflating: UCRArchive_2018/UWaveGestureLibraryAll/README.md  \n",
            "  inflating: UCRArchive_2018/UWaveGestureLibraryAll/UWaveGestureLibraryAll_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/UWaveGestureLibraryAll/UWaveGestureLibraryAll_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/Meat/\n",
            "  inflating: UCRArchive_2018/Meat/Meat_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/Meat/README.md  \n",
            "  inflating: UCRArchive_2018/Meat/Meat_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/PigAirwayPressure/\n",
            "  inflating: UCRArchive_2018/PigAirwayPressure/README.md  \n",
            "  inflating: UCRArchive_2018/PigAirwayPressure/PigAirwayPressure_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/PigAirwayPressure/PigAirwayPressure_TEST.tsv  \n",
            "   creating: UCRArchive_2018/EthanolLevel/\n",
            "  inflating: UCRArchive_2018/EthanolLevel/EthanolLevel_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/EthanolLevel/README.md  \n",
            "  inflating: UCRArchive_2018/EthanolLevel/EthanolLevel_TEST.tsv  \n",
            "   creating: UCRArchive_2018/Trace/\n",
            "  inflating: UCRArchive_2018/Trace/Trace_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/Trace/README.md  \n",
            "  inflating: UCRArchive_2018/Trace/Trace_TEST.tsv  \n",
            "   creating: UCRArchive_2018/Mallat/\n",
            "  inflating: UCRArchive_2018/Mallat/Mallat_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/Mallat/README.md  \n",
            "  inflating: UCRArchive_2018/Mallat/Mallat_TEST.tsv  \n",
            "   creating: UCRArchive_2018/Coffee/\n",
            "  inflating: UCRArchive_2018/Coffee/README.md  \n",
            "  inflating: UCRArchive_2018/Coffee/Coffee_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/Coffee/Coffee_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/DiatomSizeReduction/\n",
            "  inflating: UCRArchive_2018/DiatomSizeReduction/DiatomSizeReduction_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/DiatomSizeReduction/README.md  \n",
            "  inflating: UCRArchive_2018/DiatomSizeReduction/DiatomSizeReduction_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/EOGHorizontalSignal/\n",
            "  inflating: UCRArchive_2018/EOGHorizontalSignal/README.md  \n",
            "  inflating: UCRArchive_2018/EOGHorizontalSignal/EOGHorizontalSignal_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/EOGHorizontalSignal/EOGHorizontalSignal_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/GesturePebbleZ2/\n",
            "  inflating: UCRArchive_2018/GesturePebbleZ2/README.md  \n",
            "  inflating: UCRArchive_2018/GesturePebbleZ2/GesturePebbleZ2_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/GesturePebbleZ2/GesturePebbleZ2_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/ShapeletSim/\n",
            "  inflating: UCRArchive_2018/ShapeletSim/ShapeletSim_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/ShapeletSim/README.md  \n",
            "  inflating: UCRArchive_2018/ShapeletSim/ShapeletSim_TEST.tsv  \n",
            "   creating: UCRArchive_2018/Earthquakes/\n",
            "  inflating: UCRArchive_2018/Earthquakes/Earthquakes_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/Earthquakes/README.md  \n",
            "  inflating: UCRArchive_2018/Earthquakes/Earthquakes_TEST.tsv  \n",
            "   creating: UCRArchive_2018/TwoPatterns/\n",
            "  inflating: UCRArchive_2018/TwoPatterns/README.md  \n",
            "  inflating: UCRArchive_2018/TwoPatterns/TwoPatterns_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/TwoPatterns/TwoPatterns_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/FaceFour/\n",
            "  inflating: UCRArchive_2018/FaceFour/README.md  \n",
            "  inflating: UCRArchive_2018/FaceFour/FaceFour_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/FaceFour/FaceFour_TEST.tsv  \n",
            "   creating: UCRArchive_2018/Lightning7/\n",
            "  inflating: UCRArchive_2018/Lightning7/README.md  \n",
            "  inflating: UCRArchive_2018/Lightning7/Lightning7_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/Lightning7/Lightning7_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/Worms/\n",
            "  inflating: UCRArchive_2018/Worms/Worms_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/Worms/README.md  \n",
            "  inflating: UCRArchive_2018/Worms/Worms_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/UWaveGestureLibraryZ/\n",
            "  inflating: UCRArchive_2018/UWaveGestureLibraryZ/README.md  \n",
            "  inflating: UCRArchive_2018/UWaveGestureLibraryZ/UWaveGestureLibraryZ_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/UWaveGestureLibraryZ/UWaveGestureLibraryZ_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/ECG5000/\n",
            "  inflating: UCRArchive_2018/ECG5000/ECG5000_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/ECG5000/README.md  \n",
            "  inflating: UCRArchive_2018/ECG5000/ECG5000_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/ProximalPhalanxOutlineAgeGroup/\n",
            "  inflating: UCRArchive_2018/ProximalPhalanxOutlineAgeGroup/README.md  \n",
            "  inflating: UCRArchive_2018/ProximalPhalanxOutlineAgeGroup/ProximalPhalanxOutlineAgeGroup_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/ProximalPhalanxOutlineAgeGroup/ProximalPhalanxOutlineAgeGroup_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/GestureMidAirD1/\n",
            "  inflating: UCRArchive_2018/GestureMidAirD1/GestureMidAirD1_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/GestureMidAirD1/README.md  \n",
            "  inflating: UCRArchive_2018/GestureMidAirD1/GestureMidAirD1_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/Crop/\n",
            "  inflating: UCRArchive_2018/Crop/README.md  \n",
            "  inflating: UCRArchive_2018/Crop/Crop_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/Crop/Crop_TEST.tsv  \n",
            "   creating: UCRArchive_2018/PigCVP/\n",
            "  inflating: UCRArchive_2018/PigCVP/PigCVP_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/PigCVP/README.md  \n",
            "  inflating: UCRArchive_2018/PigCVP/PigCVP_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/NonInvasiveFetalECGThorax2/\n",
            "  inflating: UCRArchive_2018/NonInvasiveFetalECGThorax2/README.md  \n",
            "  inflating: UCRArchive_2018/NonInvasiveFetalECGThorax2/NonInvasiveFetalECGThorax2_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/NonInvasiveFetalECGThorax2/NonInvasiveFetalECGThorax2_TEST.tsv  \n",
            "   creating: UCRArchive_2018/InlineSkate/\n",
            "  inflating: UCRArchive_2018/InlineSkate/README.md  \n",
            "  inflating: UCRArchive_2018/InlineSkate/InlineSkate_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/InlineSkate/InlineSkate_TEST.tsv  \n",
            "   creating: UCRArchive_2018/FreezerRegularTrain/\n",
            "  inflating: UCRArchive_2018/FreezerRegularTrain/README.md  \n",
            "  inflating: UCRArchive_2018/FreezerRegularTrain/FreezerRegularTrain_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/FreezerRegularTrain/FreezerRegularTrain_TEST.tsv  \n",
            "   creating: UCRArchive_2018/FacesUCR/\n",
            "  inflating: UCRArchive_2018/FacesUCR/README.md  \n",
            "  inflating: UCRArchive_2018/FacesUCR/FacesUCR_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/FacesUCR/FacesUCR_TEST.tsv  \n",
            "   creating: UCRArchive_2018/ACSF1/\n",
            "  inflating: UCRArchive_2018/ACSF1/README.md  \n",
            "  inflating: UCRArchive_2018/ACSF1/ACSF1_TEST.tsv  \n",
            "  inflating: UCRArchive_2018/ACSF1/ACSF1_TRAIN.tsv  \n",
            "   creating: UCRArchive_2018/FiftyWords/\n",
            "  inflating: UCRArchive_2018/FiftyWords/FiftyWords_TRAIN.tsv  \n",
            "  inflating: UCRArchive_2018/FiftyWords/README.md  \n",
            "  inflating: UCRArchive_2018/FiftyWords/FiftyWords_TEST.tsv  \n",
            "time: 12.2 s (started: 2025-11-23 03:24:39 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd aziz-mrh-final/\n",
        "!ls datasets/ | head"
      ],
      "metadata": {
        "id": "090D4tNa1myS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "839ac269-6f6e-4719-b397-385e0c082323"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/aziz-mrh-final\n",
            "ACSF1\n",
            "Adiac\n",
            "AllGestureWiimoteX\n",
            "AllGestureWiimoteY\n",
            "AllGestureWiimoteZ\n",
            "ArrowHead\n",
            "Beef\n",
            "BeetleFly\n",
            "BirdChicken\n",
            "BME\n",
            "time: 105 ms (started: 2025-11-23 03:24:51 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "LSaG53qyyZ1k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8251b892-ec4b-46ea-a498-c5d51bf4d839"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\u001b[31m\n",
            "\u001b[0mtime: 2.37 s (started: 2025-11-23 03:24:51 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !env NUM_RESAMPLES=0 python run_3trans_loss_gate.py"
      ],
      "metadata": {
        "id": "zRNVeKZgydVt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48fe682a-9d72-4aae-d4eb-fc8ebd8a660f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 227 µs (started: 2025-11-23 03:24:54 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helpers\n"
      ],
      "metadata": {
        "id": "AKhLKSOIggws"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['NUM_RESAMPLES'] = '1'"
      ],
      "metadata": {
        "id": "CtZ9y1wsgp_M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57e77655-bdad-482d-f1e3-42ffcc55dc1f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 442 µs (started: 2025-11-23 03:24:54 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install aeon"
      ],
      "metadata": {
        "id": "d9hz6piiPg7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dd28a37-2aa3-4f77-febf-e4351d604e36"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/62.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m110.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25htime: 12.8 s (started: 2025-11-23 03:24:54 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from aeon.transformations.collection.convolution_based import MultiRocket\n",
        "import numpy as np\n",
        "from typing import Tuple, Optional\n",
        "\n",
        "def extract_mr_features(\n",
        "        X_train: np.ndarray,\n",
        "        X_test: np.ndarray,\n",
        "        seed: int,\n",
        "        n_jobs: int = -1,\n",
        ") -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"Extract MultiRocket features.\"\"\"\n",
        "    mr_model = MultiRocket(\n",
        "        random_state=seed,\n",
        "        n_jobs=n_jobs,\n",
        "    )\n",
        "    mr_model.fit(X_train)\n",
        "    X_train_mr: np.ndarray = mr_model.transform(X_train) # type: ignore\n",
        "    X_test_mr: np.ndarray = mr_model.transform(X_test) # type: ignore\n",
        "\n",
        "    return X_train_mr, X_test_mr\n"
      ],
      "metadata": {
        "id": "G9QYnk8YUCBC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "020e3bce-f47f-4abb-ae94-015d38edc48b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 7.1 s (started: 2025-11-23 03:25:06 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment: TimeSeries Transformer nonlinear head"
      ],
      "metadata": {
        "id": "6lHAqFnnmn4a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6iitgk7zzaf",
        "outputId": "8e64c720-eecd-4d35-d360-499d66bc20d5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n",
            "time: 5.22 s (started: 2025-11-23 03:43:34 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import (\n",
        "    AutoConfig,\n",
        "    AutoModel,\n",
        "    get_linear_schedule_with_warmup,\n",
        "    TimesFmModelForPrediction,   # <-- add this\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3n8xjiPz4aN",
        "outputId": "d42b1fa0-8977-4489-c5a2-887b66ddcda2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 488 µs (started: 2025-11-23 03:43:49 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "os.environ['HF_TOKEN'] = userdata.get('HF_TOKEN')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8c6ENXepZ64",
        "outputId": "314845ab-a60c-4e0e-8426-582569efae0c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 557 ms (started: 2025-11-23 03:25:14 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYtCfx1pz99C",
        "outputId": "1e8ba352-d8a8-4e7b-fd7b-151bd66736ef"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.1 ms (started: 2025-11-23 03:44:13 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Optional, Dict, Any, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from transformers import AutoConfig, AutoModel, get_linear_schedule_with_warmup\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "HF_TOKEN = os.environ.get(\"HF_TOKEN\", None)  # optional\n",
        "\n",
        "\n",
        "# ------------------------\n",
        "# Model candidates\n",
        "# ------------------------\n",
        "\n",
        "MODEL_CANDIDATES = [\n",
        "    # Google TimesFM\n",
        "    \"google/timesfm-2.5-200m-pytorch\",\n",
        "    # \"google/timesfm-1.0-200m\",\n",
        "\n",
        "    # # Amazon Chronos\n",
        "    # \"amazon/chronos-t5-small\",\n",
        "    # \"amazon/chronos-t5-base\",\n",
        "\n",
        "    # # Lag-Llama\n",
        "    # \"time-series-foundation-models/Lag-Llama\",\n",
        "\n",
        "    # # IBM Granite TS\n",
        "    # \"ibm-granite/granite-timeseries-patchtst\",\n",
        "    # \"ibm-granite/granite-timeseries-ttm-r2\",\n",
        "\n",
        "    # # THUML Timer / Sundial\n",
        "    # \"thuml/timer-base-84m\",\n",
        "    # \"thuml/sundial-base-128m\",\n",
        "\n",
        "    # # Salesforce Moirai\n",
        "    # \"Salesforce/moirai-1.1-R-small\",\n",
        "    # \"Salesforce/moirai-1.1-R-base\",\n",
        "]\n",
        "\n",
        "\n",
        "# ------------------------\n",
        "# Dataset wrapper\n",
        "# ------------------------\n",
        "\n",
        "class ArrayTSDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Wraps numpy arrays:\n",
        "      ts: (N, T) or (N, T, D)\n",
        "      extra: (N, F) or None\n",
        "      y: (N,)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        ts: np.ndarray,\n",
        "        y: np.ndarray,\n",
        "        extra: Optional[np.ndarray] = None,\n",
        "    ):\n",
        "        # ensure 3D: (N, T, D)\n",
        "        if ts.ndim == 2:\n",
        "            ts = ts[:, :, None]  # (N, T, 1)\n",
        "        elif ts.ndim != 3:\n",
        "            raise ValueError(f\"Expected ts shape (N,T) or (N,T,D), got {ts.shape}\")\n",
        "        self.ts = ts.astype(np.float32)\n",
        "        self.y = y.astype(np.int64)\n",
        "        self.extra = extra.astype(np.float32) if extra is not None else None\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return self.ts.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx: int):\n",
        "        ts = torch.from_numpy(self.ts[idx])          # (T,D)\n",
        "        y = torch.tensor(self.y[idx], dtype=torch.long)\n",
        "        if self.extra is not None:\n",
        "            extra = torch.from_numpy(self.extra[idx])  # (F,)\n",
        "        else:\n",
        "            extra = None\n",
        "        return ts, y, extra\n",
        "\n",
        "\n",
        "def ts_collate_fn(\n",
        "    batch: List[Tuple[torch.Tensor, torch.Tensor, Optional[torch.Tensor]]]\n",
        "):\n",
        "    # batch: list of (ts[T,D], y, extra[F] or None)\n",
        "    series, labels, extras = zip(*batch)\n",
        "    lengths = [s.shape[0] for s in series]\n",
        "    max_len = max(lengths)\n",
        "\n",
        "    padded = []\n",
        "    attn_masks = []\n",
        "    for s in series:\n",
        "        T, D = s.shape\n",
        "        pad_len = max_len - T\n",
        "        if pad_len > 0:\n",
        "            pad = torch.zeros(pad_len, D, dtype=torch.float32)\n",
        "            s_padded = torch.cat([s, pad], dim=0)\n",
        "        else:\n",
        "            s_padded = s\n",
        "        padded.append(s_padded)\n",
        "        attn_masks.append(\n",
        "            torch.tensor([1] * T + [0] * pad_len, dtype=torch.long)\n",
        "        )\n",
        "\n",
        "    padded = torch.stack(padded, dim=0)       # (B, T, D)\n",
        "    attn_masks = torch.stack(attn_masks, 0)   # (B, T)\n",
        "    labels = torch.stack(labels, 0)           # (B,)\n",
        "\n",
        "    if any(e is not None for e in extras):\n",
        "        feat_dim = next(e for e in extras if e is not None).shape[-1]\n",
        "        extra_tensor = []\n",
        "        for e in extras:\n",
        "            if e is None:\n",
        "                extra_tensor.append(torch.zeros(feat_dim, dtype=torch.float32))\n",
        "            else:\n",
        "                extra_tensor.append(e)\n",
        "        extra_tensor = torch.stack(extra_tensor, 0)   # (B,F)\n",
        "    else:\n",
        "        extra_tensor = None\n",
        "\n",
        "    return padded, attn_masks, labels, extra_tensor\n",
        "\n",
        "\n",
        "# ------------------------\n",
        "# Model with nonlinear head\n",
        "# ------------------------\n",
        "\n",
        "class TimeSeriesClassifier(nn.Module):\n",
        "    \"\"\"\n",
        "    backbone: HF transformer providing last_hidden_state (B,T,H)\n",
        "    input:  ts: (B,T,D)\n",
        "    extra:  (B,F) -> projected and concatenated with pooled TS representation\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        backbone: nn.Module,\n",
        "        input_dim: int,\n",
        "        num_labels: int,\n",
        "        extra_feat_dim: int = 0,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.backbone = backbone\n",
        "\n",
        "        if hasattr(backbone, \"config\") and hasattr(backbone.config, \"hidden_size\"):\n",
        "            hidden_size = backbone.config.hidden_size\n",
        "        elif hasattr(backbone, \"config\") and hasattr(backbone.config, \"d_model\"):\n",
        "            hidden_size = backbone.config.d_model\n",
        "        else:\n",
        "            raise RuntimeError(\"Cannot infer hidden dimension from backbone config.\")\n",
        "\n",
        "        self.input_embed = nn.Linear(input_dim, hidden_size)\n",
        "\n",
        "        self.extra_feat_dim = extra_feat_dim\n",
        "        if extra_feat_dim > 0:\n",
        "            self.extra_proj = nn.Linear(extra_feat_dim, hidden_size)\n",
        "            head_dim = hidden_size * 2\n",
        "        else:\n",
        "            self.extra_proj = None\n",
        "            head_dim = hidden_size\n",
        "\n",
        "        self.norm = nn.LayerNorm(head_dim)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.fc1 = nn.Linear(head_dim, head_dim)\n",
        "        self.act = nn.GELU()\n",
        "        self.fc_out = nn.Linear(head_dim, num_labels)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        ts: torch.Tensor,              # (B,T,D)\n",
        "        attention_mask: torch.Tensor,  # (B,T)\n",
        "        extra_feats: Optional[torch.Tensor] = None,  # (B,F)\n",
        "    ):\n",
        "        \"\"\"\n",
        "        ts: (batch, seq_len, D)\n",
        "        attention_mask: (batch, seq_len) with 1 for valid, 0 for pad\n",
        "        extra_feats: (batch, F) or None\n",
        "        \"\"\"\n",
        "        model_type = getattr(self.backbone.config, \"model_type\", None)\n",
        "\n",
        "        # --------------------------------------------------\n",
        "        # TimesFM special case (TimesFmModelForPrediction)\n",
        "        # --------------------------------------------------\n",
        "        if model_type == \"timesfm\":\n",
        "            # ts: (B,T,D) already on DEVICE\n",
        "            B, T, D = ts.shape\n",
        "\n",
        "            # derive valid lengths from attention_mask, or use full length\n",
        "            if attention_mask is None:\n",
        "                valid_lengths = [T] * B\n",
        "            else:\n",
        "                # 1=valid, 0=pad -> sum over time\n",
        "                valid_lengths = attention_mask.sum(dim=1).tolist()\n",
        "\n",
        "            past_values_list = []\n",
        "            for i in range(B):\n",
        "                L = int(valid_lengths[i])\n",
        "                if L <= 0:\n",
        "                    # degenerate case: everything padded; keep a single step 0\n",
        "                    series_i = ts[i, :1, :]\n",
        "                else:\n",
        "                    series_i = ts[i, :L, :]  # (L,D)\n",
        "\n",
        "                # collapse multivariate to univariate; change this if you prefer first channel\n",
        "                if D > 1:\n",
        "                    series_i = series_i.mean(dim=-1)  # (L,)\n",
        "                else:\n",
        "                    series_i = series_i.squeeze(-1)   # (L,)\n",
        "\n",
        "                past_values_list.append(series_i.to(self.backbone.device))\n",
        "\n",
        "            # dummy frequency indices\n",
        "            freq = torch.zeros(\n",
        "                B,\n",
        "                dtype=torch.long,\n",
        "                device=self.backbone.device,\n",
        "            )\n",
        "\n",
        "            # TimesFmModelForPrediction API – no past_values_padding here\n",
        "            outputs = self.backbone(\n",
        "                past_values=past_values_list,\n",
        "                freq=freq,\n",
        "                return_dict=True,\n",
        "                output_hidden_states=False,\n",
        "            )\n",
        "            hidden = outputs.last_hidden_state  # (B, S, H) S = internal patch sequence\n",
        "\n",
        "        # --------------------------------------------------\n",
        "        # Generic path for other HF time-series models\n",
        "        # --------------------------------------------------\n",
        "        else:\n",
        "            x = self.input_embed(ts)  # (B,T,H)\n",
        "\n",
        "            if \"inputs_embeds\" in self.backbone.forward.__code__.co_varnames:\n",
        "                outputs = self.backbone(\n",
        "                    inputs_embeds=x,\n",
        "                    attention_mask=attention_mask,\n",
        "                )\n",
        "            else:\n",
        "                if attention_mask is not None and \"attention_mask\" in self.backbone.forward.__code__.co_varnames:\n",
        "                    outputs = self.backbone(x, attention_mask=attention_mask)\n",
        "                else:\n",
        "                    outputs = self.backbone(x)\n",
        "\n",
        "            hidden = outputs.last_hidden_state  # (B,T,H)\n",
        "\n",
        "        # --------------------------------------------------\n",
        "        # Shared nonlinear head\n",
        "        # --------------------------------------------------\n",
        "        pooled = hidden.mean(dim=1)  # (B,H)\n",
        "\n",
        "        if self.extra_feat_dim > 0 and extra_feats is not None:\n",
        "            proj_extra = self.extra_proj(extra_feats)  # (B,H)\n",
        "            pooled = torch.cat([pooled, proj_extra], dim=-1)\n",
        "\n",
        "        h = self.norm(pooled)\n",
        "        h = self.dropout(h)\n",
        "        h = self.fc1(h)\n",
        "        h = self.act(h)\n",
        "        logits = self.fc_out(h)\n",
        "        return logits\n",
        "\n",
        "\n",
        "# ------------------------\n",
        "# Benchmark driver\n",
        "# ------------------------\n",
        "\n",
        "@dataclass\n",
        "class BenchResult:\n",
        "    model_name: str\n",
        "    train_loss: float\n",
        "    train_acc: float\n",
        "    eval_loss: float\n",
        "    eval_acc: float\n",
        "\n",
        "\n",
        "class TransformerBench:\n",
        "    def __init__(\n",
        "        self,\n",
        "        model_names: List[str],\n",
        "        X_train_ts: np.ndarray,\n",
        "        y_train: np.ndarray,\n",
        "        X_test_ts: np.ndarray,\n",
        "        y_test: np.ndarray,\n",
        "        X_train_extra: Optional[np.ndarray] = None,\n",
        "        X_test_extra: Optional[np.ndarray] = None,\n",
        "        num_labels: Optional[int] = None,\n",
        "        epochs: int = 3,\n",
        "        batch_size: int = 32,\n",
        "        eval_batch_size: int = 64,\n",
        "        lr: float = 3e-4,\n",
        "        weight_decay: float = 1e-2,\n",
        "        max_grad_norm: float = 1.0,\n",
        "        patience: int = 5,\n",
        "    ):\n",
        "        self.model_names = model_names\n",
        "        self.epochs = epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.eval_batch_size = eval_batch_size\n",
        "        self.lr = lr\n",
        "        self.weight_decay = weight_decay\n",
        "        self.max_grad_norm = max_grad_norm\n",
        "        self.patience = patience\n",
        "\n",
        "        # infer num_labels if needed\n",
        "        if num_labels is None:\n",
        "            num_labels = int(np.max(y_train)) + 1\n",
        "        self.num_labels = num_labels\n",
        "\n",
        "        self.train_ds = ArrayTSDataset(X_train_ts, y_train, X_train_extra)\n",
        "        self.test_ds = ArrayTSDataset(X_test_ts, y_test, X_test_extra)\n",
        "\n",
        "        self.results: List[BenchResult] = []\n",
        "\n",
        "    def _build_backbone(self, model_name: str) -> nn.Module:\n",
        "        # Load config (to inspect model_type)\n",
        "        if HF_TOKEN is not None:\n",
        "            config = AutoConfig.from_pretrained(model_name, token=HF_TOKEN)\n",
        "        else:\n",
        "            config = AutoConfig.from_pretrained(model_name)\n",
        "\n",
        "        model_type = getattr(config, \"model_type\", None)\n",
        "\n",
        "        if model_type == \"timesfm\":\n",
        "            # IMPORTANT: use TimesFmModelForPrediction, NOT AutoModel\n",
        "            if HF_TOKEN is not None:\n",
        "                backbone = TimesFmModelForPrediction.from_pretrained(\n",
        "                    model_name,\n",
        "                    config=config,\n",
        "                    token=HF_TOKEN,\n",
        "                )\n",
        "            else:\n",
        "                backbone = TimesFmModelForPrediction.from_pretrained(\n",
        "                    model_name,\n",
        "                    config=config,\n",
        "                )\n",
        "        else:\n",
        "            # Generic path for Chronos, PatchTST, etc.\n",
        "            if HF_TOKEN is not None:\n",
        "                backbone = AutoModel.from_pretrained(\n",
        "                    model_name,\n",
        "                    config=config,\n",
        "                    token=HF_TOKEN,\n",
        "                )\n",
        "            else:\n",
        "                backbone = AutoModel.from_pretrained(\n",
        "                    model_name,\n",
        "                    config=config,\n",
        "                )\n",
        "\n",
        "        backbone.to(DEVICE)\n",
        "        return backbone\n",
        "\n",
        "    def _train_one(self, model_name: str) -> BenchResult:\n",
        "        print(f\"\\n=== Transformer bench: {model_name} ===\")\n",
        "\n",
        "        backbone = self._build_backbone(model_name)\n",
        "\n",
        "        # deduce D and extra_feat_dim\n",
        "        X_train_ts = self.train_ds.ts\n",
        "        if X_train_ts.ndim != 3:\n",
        "            raise ValueError(\"Internal TS storage must be (N,T,D)\")\n",
        "        _, _, D = X_train_ts.shape\n",
        "\n",
        "        extra_feat_dim = 0\n",
        "        if self.train_ds.extra is not None:\n",
        "            extra_feat_dim = self.train_ds.extra.shape[1]\n",
        "\n",
        "        model = TimeSeriesClassifier(\n",
        "            backbone=backbone,\n",
        "            input_dim=D,\n",
        "            num_labels=self.num_labels,\n",
        "            extra_feat_dim=extra_feat_dim,\n",
        "        ).to(DEVICE)\n",
        "\n",
        "        train_loader = DataLoader(\n",
        "            self.train_ds,\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle=True,\n",
        "            collate_fn=ts_collate_fn,\n",
        "        )\n",
        "        test_loader = DataLoader(\n",
        "            self.test_ds,\n",
        "            batch_size=self.eval_batch_size,\n",
        "            shuffle=False,\n",
        "            collate_fn=ts_collate_fn,\n",
        "        )\n",
        "\n",
        "        params = list(model.parameters())\n",
        "        optimizer = torch.optim.AdamW(params, lr=self.lr, weight_decay=self.weight_decay)\n",
        "\n",
        "        total_steps = self.epochs * len(train_loader)\n",
        "        scheduler = get_linear_schedule_with_warmup(\n",
        "            optimizer,\n",
        "            num_warmup_steps=max(10, total_steps // 10),\n",
        "            num_training_steps=total_steps,\n",
        "        )\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        def train_epoch(epoch_idx: int) -> Tuple[float, float]:\n",
        "            model.train()\n",
        "            total_loss = 0.0\n",
        "            total_correct = 0\n",
        "            total_count = 0\n",
        "\n",
        "            for step, (ts_batch, attn_mask, labels, extras) in enumerate(train_loader):\n",
        "                ts_batch = ts_batch.to(DEVICE)\n",
        "                attn_mask = attn_mask.to(DEVICE)\n",
        "                labels = labels.to(DEVICE)\n",
        "                if extras is not None:\n",
        "                    extras = extras.to(DEVICE)\n",
        "\n",
        "                logits = model(ts_batch, attention_mask=attn_mask, extra_feats=extras)\n",
        "                loss = criterion(logits, labels)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(params, self.max_grad_norm)\n",
        "                optimizer.step()\n",
        "                scheduler.step()\n",
        "\n",
        "                B = ts_batch.size(0)\n",
        "                total_loss += loss.item() * B\n",
        "                preds = logits.argmax(dim=-1)\n",
        "                total_correct += (preds == labels).sum().item()\n",
        "                total_count += B\n",
        "\n",
        "            return total_loss / total_count, total_correct / total_count\n",
        "\n",
        "        def eval_model() -> Tuple[float, float]:\n",
        "            model.eval()\n",
        "            total_loss = 0.0\n",
        "            total_correct = 0\n",
        "            total_count = 0\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for ts_batch, attn_mask, labels, extras in test_loader:\n",
        "                    ts_batch = ts_batch.to(DEVICE)\n",
        "                    attn_mask = attn_mask.to(DEVICE)\n",
        "                    labels = labels.to(DEVICE)\n",
        "                    if extras is not None:\n",
        "                        extras = extras.to(DEVICE)\n",
        "\n",
        "                    logits = model(ts_batch, attention_mask=attn_mask, extra_feats=extras)\n",
        "                    loss = criterion(logits, labels)\n",
        "\n",
        "                    B = ts_batch.size(0)\n",
        "                    total_loss += loss.item() * B\n",
        "                    preds = logits.argmax(dim=-1)\n",
        "                    total_correct += (preds == labels).sum().item()\n",
        "                    total_count += B\n",
        "\n",
        "            return total_loss / total_count, total_correct / total_count\n",
        "\n",
        "        print(f\"\\n== Transformer bench: {model_name} ===\")\n",
        "\n",
        "        # Early stopping state\n",
        "        best_eval_loss = float(\"inf\")\n",
        "        best_eval_acc = 0.0\n",
        "        best_train_loss = float(\"inf\")\n",
        "        best_train_acc = 0.0\n",
        "        best_epoch = -1\n",
        "        no_improve = 0\n",
        "\n",
        "        best_state = None  # <--- NEW\n",
        "\n",
        "        for epoch in range(self.epochs):\n",
        "            train_loss, train_acc = train_epoch(epoch)\n",
        "            eval_loss, eval_acc = eval_model()\n",
        "\n",
        "            improved = eval_loss < best_eval_loss  # or eval_acc > best_eval_acc\n",
        "            if improved:\n",
        "                best_eval_loss = eval_loss\n",
        "                best_eval_acc = eval_acc\n",
        "                best_train_loss = train_loss\n",
        "                best_train_acc = train_acc\n",
        "                best_epoch = epoch\n",
        "                no_improve = 0\n",
        "\n",
        "                # snapshot model weights at best epoch\n",
        "                # best_state = copy.deepcopy(model.state_dict())  # <--- NEW\n",
        "            else:\n",
        "                no_improve += 1\n",
        "\n",
        "            print(\n",
        "                f\"  Epoch {epoch+1}/{self.epochs} \"\n",
        "                f\"train_loss={train_loss:.4f} train_acc={train_acc:.4f} \"\n",
        "                f\"eval_loss={eval_loss:.4f} eval_acc={eval_acc:.4f} \"\n",
        "                f\"{'(best)' if improved else ''}\"\n",
        "            )\n",
        "\n",
        "            if no_improve >= self.patience:\n",
        "                print(\n",
        "                    f\"  Early stopping on {model_name}: \"\n",
        "                    f\"no improvement for {self.patience} epochs \"\n",
        "                    f\"(best epoch = {best_epoch+1})\"\n",
        "                )\n",
        "                break\n",
        "\n",
        "        # Restore best weights before final use\n",
        "        if best_state is not None:\n",
        "            model.load_state_dict(best_state)  # <--- NEW\n",
        "\n",
        "        # Optionally recompute eval metrics with restored best weights\n",
        "        eval_loss, eval_acc = eval_model()\n",
        "\n",
        "        return BenchResult(\n",
        "            model_name=model_name,\n",
        "            train_loss=best_train_loss,\n",
        "            train_acc=best_train_acc,\n",
        "            eval_loss=eval_loss,\n",
        "            eval_acc=eval_acc,\n",
        "        )\n",
        "\n",
        "    def run_all(self) -> List[BenchResult]:\n",
        "        self.results.clear()\n",
        "        for name in self.model_names:\n",
        "            try:\n",
        "                res = self._train_one(name)\n",
        "                self.results.append(res)\n",
        "            except Exception as e:\n",
        "                print(f\"!! ERROR for model {name}: {e}\")\n",
        "        return self.results\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iBjB0_znAxP",
        "outputId": "fc7741ed-33e2-4380-89da-5a7a563fe07e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 13.1 ms (started: 2025-11-23 04:18:18 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entry point\n"
      ],
      "metadata": {
        "id": "GijYhHw4m5Ri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Run KG-MTP (3 transforms) with a per-split loss-based adaptive Savitzky-Golay gate.\n",
        "\n",
        "This script is an alternative to `run_3trans.py`:\n",
        "  - It proposes adaptive Savitzky-Golay parameters per dataset via\n",
        "    `get_adaptive_savgol_for_dataset` (noise/length heuristics).\n",
        "  - Instead of validating with accuracy on full train-only resamples, it runs\n",
        "    small loss-driven simulations on *subsampled* per-class training slices.\n",
        "  - Uses a custom margin hinge-like loss on the classifier decision function.\n",
        "  - Chooses the adaptive filter if the average validation loss does NOT exceed\n",
        "    the baseline (no filter) loss by more than a tolerance.\n",
        "\n",
        "Why loss? The classifier (RidgeClassifierCV) optimizes a regression objective;\n",
        "direct access to its internal loss is not exposed, so we approximate with a\n",
        "margin-based hinge surrogate:\n",
        "  Binary: margin = y * decision; loss = max(0, 1 - margin)\n",
        "  Multiclass: margin = f_correct - max(f_other); loss = max(0, 1 - margin)\n",
        "\n",
        "Subset sampling rationale: Using only a small number of samples per class for\n",
        "the validation simulations reduces overfitting in the decision gate and speeds\n",
        "up filtering choice. The main evaluation still uses the full data.\n",
        "\n",
        "Parameters you can tune below:\n",
        "  SUBSET_PER_CLASS       -> Max samples per class for gate simulations\n",
        "  VALIDATION_RESAMPLES   -> How many subset splits to average\n",
        "  LOSS_TOLERANCE         -> Allowed *increase* in loss to still keep adaptive\n",
        "\n",
        "Decision rule:\n",
        "  Keep adaptive filter if adaptive_loss <= baseline_loss + LOSS_TOLERANCE\n",
        "  Else fall back to baseline (no filtering).\n",
        "\n",
        "\n",
        "\n",
        "The adaptive Savitzky-Golay filter determination is performed separately for\n",
        "each resample split.\n",
        "\n",
        "The results are logged in two formats:\n",
        "1. Wide format (Main): Datasets as rows, Splits as columns + aggregates.\n",
        "2. Long format (Details): Detailed per-split metadata (time, window, poly).\n",
        "\n",
        "The CSVs are written incrementally to: results/kgtmp_3_trans_loss_gate*.csv\n",
        "\n",
        "For each dataset and for each split, the script writes out arithmetic mean,\n",
        "minimum, maximum, and standard deviation.\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import time\n",
        "import csv\n",
        "from pathlib import Path\n",
        "from typing import List, Tuple, Dict, Optional, Iterator\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.linear_model import RidgeClassifierCV\n",
        "\n",
        "from reference.kg_mtp_rebuild import (\n",
        "    HydraEnsembleConfig,\n",
        "    find_dataset_files,\n",
        "    load_ucr_split,\n",
        "    KGMTPRebuild,\n",
        "    split_feature_blocks,\n",
        "    prepare_resample_indices,\n",
        "    extract_hydra_features,\n",
        ")\n",
        "from libs.hydra_basic import SparseScaler\n",
        "from libs.adaptive_savgol import get_adaptive_savgol_for_dataset, apply_savgol_filter\n",
        "\n",
        "\n",
        "PROJECT_ROOT = Path('.').resolve()\n",
        "DATASETS_DIR = PROJECT_ROOT / \"datasets\"\n",
        "DATASETS_FILE = PROJECT_ROOT / \"datasets_to_run.txt\"\n",
        "OUTPUT_CSV = PROJECT_ROOT / \"results\" / \"kgtmp_3_trans_loss_gate.csv\"\n",
        "DETAILS_CSV = PROJECT_ROOT / \"results\" / \"kgtmp_3_trans_loss_gate_details.csv\"\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# Configuration\n",
        "# ---------------------------------------------------------------------------\n",
        "SUBSET_PER_CLASS = 25         # Max samples per class used in each validation simulation\n",
        "VALIDATION_RESAMPLES = 5      # Number of subset splits to evaluate for gate\n",
        "LOSS_TOLERANCE = 0.02         # Allowed loss increase vs baseline to keep adaptive\n",
        "RANDOM_STATE = 1337\n",
        "\n",
        "# Main evaluation configuration\n",
        "NUM_FEATURES = 50_000\n",
        "NUM_RESAMPLES = int(os.environ.get('NUM_RESAMPLES', '1'))\n",
        "N_JOBS = -1                  # Number of processes to run in parallel, or -1 to use all CPU cores\n",
        "\n",
        "HYDRA_CFG = HydraEnsembleConfig(\n",
        "    k=16,\n",
        "    g=64,\n",
        "    batch_size=256,\n",
        "    device=\"auto\",\n",
        "    weight_short=0.6,\n",
        "    weight_long=0.3,\n",
        "    length_threshold=400,\n",
        "    sample_threshold=400,\n",
        "    class_threshold=3,\n",
        ")\n",
        "\n",
        "\n",
        "def compute_margin_loss(decisions: np.ndarray, y_true: np.ndarray, classes: np.ndarray) -> float:\n",
        "    \"\"\"Compute hinge-like margin loss from decision function outputs.\n",
        "\n",
        "    Args:\n",
        "        decisions: (n_samples,) for binary or (n_samples, n_classes) for multiclass.\n",
        "        y_true: Encoded integer labels matching indices in classes.\n",
        "        classes: Array of class labels in the same order as classifier output.\n",
        "\n",
        "    Returns:\n",
        "        Mean hinge-like loss (float).\n",
        "    \"\"\"\n",
        "    if decisions.ndim == 1:  # binary case\n",
        "        # Map y_true integers to +/-1 according to classes ordering\n",
        "        positive_class = classes[1]\n",
        "        signs = np.where(y_true == np.where(classes == positive_class)[0][0], 1.0, -1.0)\n",
        "        margin = signs * decisions\n",
        "        loss = np.maximum(0.0, 1.0 - margin)\n",
        "        return float(np.mean(loss))\n",
        "    else:  # multiclass hinge: f_correct - max(f_other)\n",
        "        correct_scores = decisions[np.arange(len(y_true)), y_true]\n",
        "        mask = np.ones_like(decisions, dtype=bool)\n",
        "        mask[np.arange(len(y_true)), y_true] = False\n",
        "        other_max = np.max(np.where(mask, decisions, -np.inf), axis=1)\n",
        "        margin = correct_scores - other_max\n",
        "        loss = np.maximum(0.0, 1.0 - margin)\n",
        "        return float(np.mean(loss))\n",
        "\n",
        "\n",
        "def _compute_pipeline_loss(\n",
        "    X_train: np.ndarray,\n",
        "    y_train: np.ndarray,\n",
        "    X_val: np.ndarray,\n",
        "    y_val: np.ndarray,\n",
        "    window: int,\n",
        "    poly: int,\n",
        ") -> float:\n",
        "    \"\"\"Apply filtering -> KG-MTP extraction -> Ridge classifier -> Return margin loss.\"\"\"\n",
        "    if window > 0 and poly > 0:\n",
        "        X_train_f = apply_savgol_filter(X_train, window, poly)\n",
        "        X_val_f = apply_savgol_filter(X_val, window, poly)\n",
        "    else:\n",
        "        X_train_f = X_train\n",
        "        X_val_f = X_val\n",
        "\n",
        "    kgmtp = KGMTPRebuild(num_features=NUM_FEATURES, random_state=None, n_jobs=N_JOBS)\n",
        "    X_train_feats = kgmtp.fit_transform(X_train_f)\n",
        "    X_val_feats = kgmtp.transform(X_val_f)\n",
        "\n",
        "    layout = kgmtp.layout\n",
        "    X_train_pool, X_train_hydra = split_feature_blocks(X_train_feats, layout)\n",
        "    X_val_pool, X_val_hydra = split_feature_blocks(X_val_feats, layout)\n",
        "\n",
        "    pool_scaler = StandardScaler()\n",
        "    X_train_pool_scaled = pool_scaler.fit_transform(X_train_pool)\n",
        "    X_val_pool_scaled = pool_scaler.transform(X_val_pool)\n",
        "\n",
        "    hydra_block_scaler = SparseScaler()\n",
        "    X_train_hydra_scaled = hydra_block_scaler.fit_transform(\n",
        "        torch.from_numpy(X_train_hydra.astype(np.float32))\n",
        "    ).numpy()\n",
        "    X_val_hydra_scaled = hydra_block_scaler.transform(\n",
        "        torch.from_numpy(X_val_hydra.astype(np.float32))\n",
        "    ).numpy()\n",
        "\n",
        "    X_train_all = np.c_[X_train_pool_scaled, X_train_hydra_scaled]\n",
        "    X_val_all = np.c_[X_val_pool_scaled, X_val_hydra_scaled]\n",
        "\n",
        "    clf = RidgeClassifierCV(alphas=np.logspace(-3, 3, 10))\n",
        "    clf.fit(X_train_all, y_train)\n",
        "    decisions = clf.decision_function(X_val_all)\n",
        "    return compute_margin_loss(decisions, y_val, clf.classes_)\n",
        "\n",
        "\n",
        "def run_loss_gate_on_split(\n",
        "    X_train: np.ndarray,\n",
        "    y_train: np.ndarray,\n",
        "    prop_window: int,\n",
        "    prop_poly: int,\n",
        "    heuristic_expl: str,\n",
        "    seed: int\n",
        ") -> Tuple[int, int, str]:\n",
        "    \"\"\"Determine (window, poly) using loss-based validation gate on a specific split.\"\"\"\n",
        "    rng = np.random.default_rng(seed)\n",
        "    unique_classes = np.unique(y_train)\n",
        "\n",
        "    baseline_losses: List[float] = []\n",
        "    adaptive_losses: List[float] = []\n",
        "\n",
        "    print(\"  [Loss Gate] Running subset simulations...\", flush=True)\n",
        "\n",
        "    for split_idx in range(VALIDATION_RESAMPLES):\n",
        "        # Build subset indices per class\n",
        "        subset_indices = []\n",
        "        min_class_size = float('inf')\n",
        "        for c in unique_classes:\n",
        "            cls_indices = np.where(y_train == c)[0]\n",
        "            if len(cls_indices) > SUBSET_PER_CLASS:\n",
        "                chosen = rng.choice(cls_indices, SUBSET_PER_CLASS, replace=False)\n",
        "            else:\n",
        "                chosen = cls_indices\n",
        "            subset_indices.append(chosen)\n",
        "            min_class_size = min(min_class_size, len(chosen))\n",
        "\n",
        "        if min_class_size < 2:\n",
        "            msg = f\"Gate skipped (min class size {min_class_size} < 2); {heuristic_expl}\"\n",
        "            print(f\"    {msg}\", flush=True)\n",
        "            return 0, 0, msg\n",
        "\n",
        "        subset_indices = np.concatenate(subset_indices)\n",
        "        rng.shuffle(subset_indices)\n",
        "\n",
        "        subset_X = X_train[subset_indices]\n",
        "        subset_y = y_train[subset_indices]\n",
        "        n_classes = len(unique_classes)\n",
        "        subset_n = len(subset_y)\n",
        "\n",
        "        val_count = max(int(0.3 * subset_n), n_classes)\n",
        "        max_val_count = subset_n - n_classes\n",
        "        if max_val_count < n_classes:\n",
        "            msg = f\"Gate skipped (subset too small for stratified split); {heuristic_expl}\"\n",
        "            print(f\"    {msg}\", flush=True)\n",
        "            return 0, 0, msg\n",
        "        val_count = min(val_count, max_val_count)\n",
        "\n",
        "        inner_split = StratifiedShuffleSplit(\n",
        "            n_splits=1,\n",
        "            test_size=val_count,\n",
        "            random_state=seed + split_idx,\n",
        "        )\n",
        "        try:\n",
        "            (train_idx_sub, val_idx_sub) = next(inner_split.split(np.zeros((subset_n, 1)), subset_y))\n",
        "        except ValueError:\n",
        "             return 0, 0, f\"Gate skipped (stratified split failed); {heuristic_expl}\"\n",
        "\n",
        "        X_sub_train = subset_X[train_idx_sub]\n",
        "        y_sub_train = subset_y[train_idx_sub]\n",
        "        X_sub_val = subset_X[val_idx_sub]\n",
        "        y_sub_val = subset_y[val_idx_sub]\n",
        "\n",
        "        base_loss = _compute_pipeline_loss(X_sub_train, y_sub_train, X_sub_val, y_sub_val, 0, 0)\n",
        "        baseline_losses.append(base_loss)\n",
        "\n",
        "        adapt_loss = _compute_pipeline_loss(\n",
        "            X_sub_train, y_sub_train, X_sub_val, y_sub_val, prop_window, prop_poly\n",
        "        )\n",
        "        adaptive_losses.append(adapt_loss)\n",
        "\n",
        "        print(\n",
        "            f\"    Gate split {split_idx+1}/{VALIDATION_RESAMPLES}: baseline_loss={base_loss:.4f} adaptive_loss={adapt_loss:.4f}\",\n",
        "            flush=True,\n",
        "        )\n",
        "\n",
        "    base_avg = float(np.mean(baseline_losses))\n",
        "    adapt_avg = float(np.mean(adaptive_losses))\n",
        "    delta = adapt_avg - base_avg\n",
        "\n",
        "    if adapt_avg <= base_avg + LOSS_TOLERANCE:\n",
        "        msg = f\"Adaptive kept (loss {adapt_avg:.4f} vs baseline {base_avg:.4f}, delta={delta:+.4f} <= +{LOSS_TOLERANCE:.4f}); {heuristic_expl}\"\n",
        "        print(f\"  Decision: {msg}\", flush=True)\n",
        "        return prop_window, prop_poly, msg\n",
        "    else:\n",
        "        msg = f\"Adaptive rejected (loss {adapt_avg:.4f} vs baseline {base_avg:.4f}, delta={delta:+.4f} > +{LOSS_TOLERANCE:.4f}); {heuristic_expl}\"\n",
        "        print(f\"  Decision: {msg}\", flush=True)\n",
        "        return 0, 0, msg\n",
        "\n",
        "\n",
        "def evaluate_dataset_per_split(\n",
        "    dataset_dir: Path,\n",
        "    num_features: int,\n",
        "    num_resamples: int,\n",
        "    random_state: int,\n",
        "    n_jobs: int,\n",
        "    hydra_cfg: HydraEnsembleConfig,\n",
        ") -> List[Dict]:\n",
        "    \"\"\"Evaluate dataset with per-split gating.\"\"\"\n",
        "    train_path, test_path = find_dataset_files(dataset_dir)\n",
        "    X_train_raw, y_train_raw = load_ucr_split(train_path)\n",
        "    X_test_raw, y_test_raw = load_ucr_split(test_path)\n",
        "\n",
        "    encoder = LabelEncoder()\n",
        "    y_train = encoder.fit_transform(y_train_raw)\n",
        "    y_test = encoder.transform(y_test_raw)\n",
        "\n",
        "    X_all = np.vstack([X_train_raw, X_test_raw])\n",
        "    y_all = np.hstack([y_train, y_test])\n",
        "\n",
        "    apply_f, prop_w, prop_p, heuristic_expl = get_adaptive_savgol_for_dataset(\n",
        "        dataset_dir.name, DATASETS_DIR, baseline_accuracy=None\n",
        "    )\n",
        "\n",
        "    base_hydra_weight = hydra_cfg.ensemble_weight(\n",
        "        n_samples=X_train_raw.shape[0],\n",
        "        length=X_train_raw.shape[1],\n",
        "        num_classes=len(np.unique(y_train)),\n",
        "    )\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for split_idx, (train_idx, test_idx) in enumerate(\n",
        "        prepare_resample_indices(y_train, y_test, num_resamples, random_state)\n",
        "    ):\n",
        "        # Adjust split display index to be 1-based\n",
        "        current_split_num = split_idx + 1\n",
        "        # Calculate total splits for display\n",
        "        total_splits = num_resamples if num_resamples > 0 else 1\n",
        "\n",
        "        print(f\"\\n--- Split {current_split_num}/{total_splits} ---\", flush=True)\n",
        "        start = time.time()\n",
        "\n",
        "        X_train_split = X_all[train_idx]\n",
        "        y_train_split = y_all[train_idx]\n",
        "        X_test_split = X_all[test_idx]\n",
        "        y_test_split = y_all[test_idx]\n",
        "\n",
        "        chosen_w, chosen_p = 0, 0\n",
        "        decision_expl = \"Disabled (heuristic)\"\n",
        "\n",
        "        if apply_f:\n",
        "            gate_seed = (random_state if random_state is not None else 0) + (split_idx * 100)\n",
        "            chosen_w, chosen_p, decision_expl = run_loss_gate_on_split(\n",
        "                X_train_split, y_train_split, prop_w, prop_p, heuristic_expl, gate_seed\n",
        "            )\n",
        "        else:\n",
        "            print(f\"  Decision: Heuristic says no filter ({heuristic_expl})\", flush=True)\n",
        "\n",
        "        if chosen_w > 0 and chosen_p > 0:\n",
        "            X_train_proc = apply_savgol_filter(X_train_split, chosen_w, chosen_p)\n",
        "            X_test_proc = apply_savgol_filter(X_test_split, chosen_w, chosen_p)\n",
        "        else:\n",
        "            X_train_proc = X_train_split\n",
        "            X_test_proc = X_test_split\n",
        "\n",
        "        kgmtp = KGMTPRebuild(\n",
        "            num_features=num_features,\n",
        "            random_state=None if random_state is None else random_state + split_idx,\n",
        "            n_jobs=n_jobs,\n",
        "        )\n",
        "        X_train_features = kgmtp.fit_transform(X_train_proc)\n",
        "        X_test_features = kgmtp.transform(X_test_proc)\n",
        "\n",
        "        layout = kgmtp.layout\n",
        "        X_train_pool, X_train_hydra = split_feature_blocks(X_train_features, layout)\n",
        "        X_test_pool, X_test_hydra = split_feature_blocks(X_test_features, layout)\n",
        "\n",
        "        pool_scaler = StandardScaler()\n",
        "        X_train_pool_scaled = pool_scaler.fit_transform(X_train_pool)\n",
        "        X_test_pool_scaled = pool_scaler.transform(X_test_pool)\n",
        "\n",
        "        hydra_block_scaler = SparseScaler()\n",
        "        X_train_hydra_scaled = hydra_block_scaler.fit_transform(\n",
        "            torch.from_numpy(X_train_hydra.astype(np.float32))\n",
        "        ).numpy()\n",
        "        X_test_hydra_scaled = hydra_block_scaler.transform(\n",
        "            torch.from_numpy(X_test_hydra.astype(np.float32))\n",
        "        ).numpy()\n",
        "\n",
        "        X_train_final = np.c_[X_train_pool_scaled, X_train_hydra_scaled]\n",
        "        X_test_final = np.c_[X_test_pool_scaled, X_test_hydra_scaled]\n",
        "\n",
        "        kg_clf = RidgeClassifierCV(alphas=np.logspace(-3, 3, 10))\n",
        "        kg_clf.fit(X_train_final, y_train_split)\n",
        "        kg_dec = kg_clf.decision_function(X_test_final)\n",
        "        kg_accuracy = float(kg_clf.score(X_test_final, y_test_split))\n",
        "\n",
        "        ensemble_accuracy = kg_accuracy\n",
        "        mrh_accuracy = 0.0\n",
        "        weight = 0.0\n",
        "\n",
        "        if base_hydra_weight > 0:\n",
        "            # Hydra\n",
        "\n",
        "            hydra_seed = None if random_state is None else random_state + split_idx\n",
        "\n",
        "            X_train_h_raw, X_test_h_raw = extract_hydra_features(\n",
        "                X_train_split, X_test_split, hydra_cfg, hydra_seed\n",
        "            )\n",
        "\n",
        "            h_scaler = SparseScaler()\n",
        "            X_train_h_only = h_scaler.fit_transform(\n",
        "                torch.from_numpy(X_train_h_raw.astype(np.float32))\n",
        "            ).numpy()\n",
        "            X_test_h_only = h_scaler.transform(\n",
        "                torch.from_numpy(X_test_h_raw.astype(np.float32))\n",
        "            ).numpy()\n",
        "\n",
        "            # MultiRocket\n",
        "\n",
        "            mr_seed = hydra_seed\n",
        "            X_train_mr_raw, X_test_mr_raw = extract_mr_features(\n",
        "                X_train_split,\n",
        "                X_test_split,\n",
        "                seed=mr_seed,  # type: ignore\n",
        "                n_jobs=N_JOBS,\n",
        "            )\n",
        "\n",
        "            mr_scaler = StandardScaler()\n",
        "            X_train_mr = mr_scaler.fit_transform(X_train_mr_raw)\n",
        "            X_test_mr = mr_scaler.transform(X_test_mr_raw)\n",
        "\n",
        "            # MR + Hydra\n",
        "\n",
        "            X_train_mrh = np.concatenate((X_train_mr, X_train_h_only), axis=1)\n",
        "            X_test_mrh = np.concatenate((X_test_mr, X_test_h_only), axis=1)\n",
        "\n",
        "            mrh_clf = RidgeClassifierCV(alphas=np.logspace(-3, 3, 10))\n",
        "            mrh_clf.fit(X_train_mrh, y_train_split)\n",
        "            mrh_dec = mrh_clf.decision_function(X_test_mrh)\n",
        "            mrh_accuracy = float(mrh_clf.score(X_test_mrh, y_test_split))\n",
        "\n",
        "            # KG + Hydra + Multirocket\n",
        "\n",
        "            X_train_all = np.concatenate((X_train_mr, X_train_h_only, X_train_pool_scaled), axis=1)\n",
        "            X_test_all = np.concatenate((X_test_mr, X_test_h_only, X_test_pool_scaled), axis=1)\n",
        "\n",
        "            all_clf = RidgeClassifierCV(alphas=np.logspace(-3, 3, 10))\n",
        "            all_clf.fit(X_train_all, y_train_split)\n",
        "            all_dec = all_clf.decision_function(X_test_all)\n",
        "            all_accuracy = float(all_clf.score(X_test_all, y_test_split))\n",
        "\n",
        "            # Time Series transformer / non-linear head\n",
        "\n",
        "            # First get train-side decision values:\n",
        "            all_dec_train = all_clf.decision_function(X_train_all)  # shape (N_train, n_classes)\n",
        "            all_dec_test = all_dec                                 # already computed for test\n",
        "\n",
        "            # Stack Hydra+MR features + Ridge decs into one extra feature vector\n",
        "            X_train_extra = np.concatenate([X_train_all, all_dec_train], axis=1)\n",
        "            X_test_extra = np.concatenate([X_test_all, all_dec_test], axis=1)\n",
        "\n",
        "            # Time-series arrays are X_train_split / X_test_split:\n",
        "            #  - If they are (N,T), bench will add a singleton channel.\n",
        "            #  - If they are (N,T,D), it will use D channels directly.\n",
        "\n",
        "            bench = TransformerBench(\n",
        "                model_names=MODEL_CANDIDATES,\n",
        "                X_train_ts=X_train_split,\n",
        "                y_train=y_train_split,\n",
        "                X_test_ts=X_test_split,\n",
        "                y_test=y_test_split,\n",
        "                X_train_extra=X_train_extra,\n",
        "                X_test_extra=X_test_extra,\n",
        "                num_labels=None,       # infer from y_train_split\n",
        "                epochs=100,            # generous ceiling...\n",
        "                patience=10,           # ... with early stopping\n",
        "                batch_size=32,\n",
        "                eval_batch_size=64,\n",
        "                lr=3e-4,\n",
        "                weight_decay=1e-2,\n",
        "                max_grad_norm=1.0,\n",
        "            )\n",
        "\n",
        "            bench_results = bench.run_all()\n",
        "\n",
        "            for r in bench_results:\n",
        "                print(\n",
        "                    f\"    tfm[{r.model_name}] \"\n",
        "                    f\"train_acc={r.train_acc:.4f} eval_acc={r.eval_acc:.44f}\"\n",
        "                )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            weight = float(np.clip(base_hydra_weight, 0.0, 1.0))\n",
        "\n",
        "            if kg_dec.ndim == 1:\n",
        "                ensemble_dec = (1.0 - weight) * kg_dec + weight * mrh_dec\n",
        "                classes = kg_clf.classes_\n",
        "                ensemble_pred = np.where(ensemble_dec >= 0, classes[1], classes[0])\n",
        "            else:\n",
        "                ensemble_dec = (1.0 - weight) * kg_dec + weight * mrh_dec\n",
        "                ensemble_pred = kg_clf.classes_[np.argmax(ensemble_dec, axis=1)]\n",
        "\n",
        "            ensemble_accuracy = float(np.mean(ensemble_pred == y_test_split))\n",
        "            print(\n",
        "                f\"    mrh_acc={mrh_accuracy:.4f} mr+h+kg_acc={all_accuracy:.4f} kg_acc={kg_accuracy:.4f} ensemble={ensemble_accuracy:.4f} (w={weight:.2f})\",\n",
        "                flush=True,\n",
        "            )\n",
        "        else:\n",
        "            print(\n",
        "                f\"    hydra skipped (weight={base_hydra_weight:.2f}); kg_acc={kg_accuracy:.4f}\",\n",
        "                flush=True,\n",
        "            )\n",
        "\n",
        "        durations = time.time() - start\n",
        "\n",
        "        results.append({\n",
        "            \"split_idx\": current_split_num,\n",
        "            \"accuracy\": ensemble_accuracy,\n",
        "            \"time\": durations,\n",
        "            \"window\": chosen_w,\n",
        "            \"poly\": chosen_p,\n",
        "            \"notes\": decision_expl\n",
        "        })\n",
        "\n",
        "        print(\n",
        "            f\"  Split {current_split_num}/{total_splits} \"\n",
        "            f\"- accuracy={ensemble_accuracy:.4f} time={durations:.1f}s\",\n",
        "            flush=True,\n",
        "        )\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "def main():\n",
        "    if not DATASETS_DIR.exists():\n",
        "        print(f\"Datasets directory not found: {DATASETS_DIR}\")\n",
        "        return\n",
        "\n",
        "    if DATASETS_FILE.exists():\n",
        "        with open(DATASETS_FILE, \"r\") as f:\n",
        "            datasets_to_run = [line.strip() for line in f if line.strip()]\n",
        "    else:\n",
        "        # Fallback: list directories in DATASETS_DIR\n",
        "        datasets_to_run = [d.name for d in DATASETS_DIR.iterdir() if d.is_dir()]\n",
        "        datasets_to_run.sort()\n",
        "\n",
        "    OUTPUT_CSV.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Determine columns based on NUM_RESAMPLES (0 -> 1 original split, N -> N resamples)\n",
        "    n_cols = NUM_RESAMPLES if NUM_RESAMPLES > 0 else 1\n",
        "\n",
        "    # Initialize CSV files\n",
        "    split_cols = [f\"split_{i+1}\" for i in range(n_cols)]\n",
        "    stat_cols = [\"min\", \"max\", \"mean\", \"std\"]\n",
        "    csv_headers = [\"dataset\"] + split_cols + stat_cols\n",
        "\n",
        "    if not OUTPUT_CSV.exists():\n",
        "        with open(OUTPUT_CSV, \"w\", newline=\"\") as f:\n",
        "            writer = csv.writer(f)\n",
        "            writer.writerow(csv_headers)\n",
        "\n",
        "    details_headers = [\"dataset\", \"split\", \"accuracy\", \"time\", \"window\", \"poly\", \"notes\"]\n",
        "    if not DETAILS_CSV.exists():\n",
        "        with open(DETAILS_CSV, \"w\", newline=\"\") as f:\n",
        "            writer = csv.writer(f)\n",
        "            writer.writerow(details_headers)\n",
        "\n",
        "    print(f\"Starting evaluation on {len(datasets_to_run)} datasets...\")\n",
        "    print(f\"Results will be saved to {OUTPUT_CSV}\")\n",
        "\n",
        "    for ds_idx, ds_name in enumerate(datasets_to_run, 1):\n",
        "        dataset_path = DATASETS_DIR / ds_name\n",
        "        if not dataset_path.exists():\n",
        "            print(f\"Dataset path not found: {dataset_path}, skipping.\")\n",
        "            continue\n",
        "\n",
        "        print(f\"\\n=== {ds_idx}/{len(datasets_to_run)} {ds_name} ===\", flush=True)\n",
        "        try:\n",
        "            results = evaluate_dataset_per_split(\n",
        "                dataset_path,\n",
        "                NUM_FEATURES,\n",
        "                NUM_RESAMPLES,\n",
        "                RANDOM_STATE,\n",
        "                N_JOBS,\n",
        "                HYDRA_CFG\n",
        "            )\n",
        "\n",
        "            # 1. Write Details\n",
        "            with open(DETAILS_CSV, \"a\", newline=\"\") as f:\n",
        "                writer = csv.writer(f)\n",
        "                for res in results:\n",
        "                    writer.writerow([\n",
        "                        ds_name,\n",
        "                        res['split_idx'],\n",
        "                        f\"{res['accuracy']:.4f}\",\n",
        "                        f\"{res['time']:.4f}\",\n",
        "                        res['window'],\n",
        "                        res['poly'],\n",
        "                        res['notes']\n",
        "                    ])\n",
        "\n",
        "            # 2. Write Wide Row (Main)\n",
        "            accuracies = [r['accuracy'] for r in results]\n",
        "            row_stats = [\n",
        "                np.min(accuracies) if accuracies else \"\",\n",
        "                np.max(accuracies) if accuracies else \"\",\n",
        "                np.mean(accuracies) if accuracies else \"\",\n",
        "                np.std(accuracies) if accuracies else \"\"\n",
        "            ]\n",
        "\n",
        "            # Pad if fewer results than expected (e.g. error)\n",
        "            acc_cells = [\"\"] * n_cols\n",
        "            for i, acc in enumerate(accuracies):\n",
        "                if i < n_cols:\n",
        "                    acc_cells[i] = f\"{acc:.4f}\"\n",
        "\n",
        "            final_row = [ds_name] + acc_cells + [f\"{v:.4f}\" if isinstance(v, float) else v for v in row_stats]\n",
        "\n",
        "            with open(OUTPUT_CSV, \"a\", newline=\"\") as f:\n",
        "                writer = csv.writer(f)\n",
        "                writer.writerow(final_row)\n",
        "\n",
        "            print(f\"Completed {ds_name}: Mean Acc={np.mean(accuracies):.4f}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {ds_name}: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "    # --- Final Aggregation (Column-wise) ---\n",
        "    print(\"\\nRunning final aggregation...\")\n",
        "    try:\n",
        "        df = pd.read_csv(OUTPUT_CSV)\n",
        "        # Filter out existing aggregate rows if re-running\n",
        "        df = df[~df['dataset'].isin(['MEAN', 'MIN', 'MAX', 'STD'])]\n",
        "\n",
        "        # Columns to aggregate: split_1..split_N + stats\n",
        "        numeric_cols = split_cols + stat_cols\n",
        "\n",
        "        aggs = {}\n",
        "        aggs['MEAN'] = df[numeric_cols].mean()\n",
        "        aggs['MIN'] = df[numeric_cols].min()\n",
        "        aggs['MAX'] = df[numeric_cols].max()\n",
        "        aggs['STD'] = df[numeric_cols].std()\n",
        "\n",
        "        with open(OUTPUT_CSV, \"a\", newline=\"\") as f:\n",
        "            writer = csv.writer(f)\n",
        "            for label, series in aggs.items():\n",
        "                # Construct row: [label, val_split1, ..., val_stat]\n",
        "                row = [label]\n",
        "                for col in numeric_cols:\n",
        "                    val = series.get(col, np.nan)\n",
        "                    row.append(f\"{val:.4f}\")\n",
        "                writer.writerow(row)\n",
        "\n",
        "        print(\"Aggregation complete.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during aggregation: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\" or True:\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "ozebqekBVyo5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f003b5ab-ee1e-483b-eda6-664dae441df2"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting evaluation on 109 datasets...\n",
            "Results will be saved to /content/aziz-mrh-final/results/kgtmp_3_trans_loss_gate.csv\n",
            "\n",
            "=== 1/109 ACSF1 ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n",
            "    Gate split 1/5: baseline_loss=0.5775 adaptive_loss=0.6921\n",
            "    Gate split 2/5: baseline_loss=0.5435 adaptive_loss=0.6083\n",
            "    Gate split 3/5: baseline_loss=0.4202 adaptive_loss=0.5461\n",
            "    Gate split 4/5: baseline_loss=0.4701 adaptive_loss=0.5158\n",
            "    Gate split 5/5: baseline_loss=0.4540 adaptive_loss=0.4660\n",
            "  Decision: Adaptive rejected (loss 0.5656 vs baseline 0.4931, delta=+0.0726 > +0.0200); savgol(window=21, poly=3) - high noise (std_diff)\n",
            "\n",
            "=== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at google/timesfm-2.5-200m-pytorch were not used when initializing TimesFmModelForPrediction: ['output_projection_point.hidden_layer.weight', 'output_projection_point.output_layer.weight', 'output_projection_point.residual_layer.weight', 'output_projection_quantiles.hidden_layer.weight', 'output_projection_quantiles.output_layer.weight', 'output_projection_quantiles.residual_layer.weight', 'stacked_xf.0.attn.key_ln.scale', 'stacked_xf.0.attn.out.weight', 'stacked_xf.0.attn.per_dim_scale.per_dim_scale', 'stacked_xf.0.attn.qkv_proj.weight', 'stacked_xf.0.attn.query_ln.scale', 'stacked_xf.0.ff0.weight', 'stacked_xf.0.ff1.weight', 'stacked_xf.0.post_attn_ln.scale', 'stacked_xf.0.post_ff_ln.scale', 'stacked_xf.0.pre_attn_ln.scale', 'stacked_xf.0.pre_ff_ln.scale', 'stacked_xf.1.attn.key_ln.scale', 'stacked_xf.1.attn.out.weight', 'stacked_xf.1.attn.per_dim_scale.per_dim_scale', 'stacked_xf.1.attn.qkv_proj.weight', 'stacked_xf.1.attn.query_ln.scale', 'stacked_xf.1.ff0.weight', 'stacked_xf.1.ff1.weight', 'stacked_xf.1.post_attn_ln.scale', 'stacked_xf.1.post_ff_ln.scale', 'stacked_xf.1.pre_attn_ln.scale', 'stacked_xf.1.pre_ff_ln.scale', 'stacked_xf.10.attn.key_ln.scale', 'stacked_xf.10.attn.out.weight', 'stacked_xf.10.attn.per_dim_scale.per_dim_scale', 'stacked_xf.10.attn.qkv_proj.weight', 'stacked_xf.10.attn.query_ln.scale', 'stacked_xf.10.ff0.weight', 'stacked_xf.10.ff1.weight', 'stacked_xf.10.post_attn_ln.scale', 'stacked_xf.10.post_ff_ln.scale', 'stacked_xf.10.pre_attn_ln.scale', 'stacked_xf.10.pre_ff_ln.scale', 'stacked_xf.11.attn.key_ln.scale', 'stacked_xf.11.attn.out.weight', 'stacked_xf.11.attn.per_dim_scale.per_dim_scale', 'stacked_xf.11.attn.qkv_proj.weight', 'stacked_xf.11.attn.query_ln.scale', 'stacked_xf.11.ff0.weight', 'stacked_xf.11.ff1.weight', 'stacked_xf.11.post_attn_ln.scale', 'stacked_xf.11.post_ff_ln.scale', 'stacked_xf.11.pre_attn_ln.scale', 'stacked_xf.11.pre_ff_ln.scale', 'stacked_xf.12.attn.key_ln.scale', 'stacked_xf.12.attn.out.weight', 'stacked_xf.12.attn.per_dim_scale.per_dim_scale', 'stacked_xf.12.attn.qkv_proj.weight', 'stacked_xf.12.attn.query_ln.scale', 'stacked_xf.12.ff0.weight', 'stacked_xf.12.ff1.weight', 'stacked_xf.12.post_attn_ln.scale', 'stacked_xf.12.post_ff_ln.scale', 'stacked_xf.12.pre_attn_ln.scale', 'stacked_xf.12.pre_ff_ln.scale', 'stacked_xf.13.attn.key_ln.scale', 'stacked_xf.13.attn.out.weight', 'stacked_xf.13.attn.per_dim_scale.per_dim_scale', 'stacked_xf.13.attn.qkv_proj.weight', 'stacked_xf.13.attn.query_ln.scale', 'stacked_xf.13.ff0.weight', 'stacked_xf.13.ff1.weight', 'stacked_xf.13.post_attn_ln.scale', 'stacked_xf.13.post_ff_ln.scale', 'stacked_xf.13.pre_attn_ln.scale', 'stacked_xf.13.pre_ff_ln.scale', 'stacked_xf.14.attn.key_ln.scale', 'stacked_xf.14.attn.out.weight', 'stacked_xf.14.attn.per_dim_scale.per_dim_scale', 'stacked_xf.14.attn.qkv_proj.weight', 'stacked_xf.14.attn.query_ln.scale', 'stacked_xf.14.ff0.weight', 'stacked_xf.14.ff1.weight', 'stacked_xf.14.post_attn_ln.scale', 'stacked_xf.14.post_ff_ln.scale', 'stacked_xf.14.pre_attn_ln.scale', 'stacked_xf.14.pre_ff_ln.scale', 'stacked_xf.15.attn.key_ln.scale', 'stacked_xf.15.attn.out.weight', 'stacked_xf.15.attn.per_dim_scale.per_dim_scale', 'stacked_xf.15.attn.qkv_proj.weight', 'stacked_xf.15.attn.query_ln.scale', 'stacked_xf.15.ff0.weight', 'stacked_xf.15.ff1.weight', 'stacked_xf.15.post_attn_ln.scale', 'stacked_xf.15.post_ff_ln.scale', 'stacked_xf.15.pre_attn_ln.scale', 'stacked_xf.15.pre_ff_ln.scale', 'stacked_xf.16.attn.key_ln.scale', 'stacked_xf.16.attn.out.weight', 'stacked_xf.16.attn.per_dim_scale.per_dim_scale', 'stacked_xf.16.attn.qkv_proj.weight', 'stacked_xf.16.attn.query_ln.scale', 'stacked_xf.16.ff0.weight', 'stacked_xf.16.ff1.weight', 'stacked_xf.16.post_attn_ln.scale', 'stacked_xf.16.post_ff_ln.scale', 'stacked_xf.16.pre_attn_ln.scale', 'stacked_xf.16.pre_ff_ln.scale', 'stacked_xf.17.attn.key_ln.scale', 'stacked_xf.17.attn.out.weight', 'stacked_xf.17.attn.per_dim_scale.per_dim_scale', 'stacked_xf.17.attn.qkv_proj.weight', 'stacked_xf.17.attn.query_ln.scale', 'stacked_xf.17.ff0.weight', 'stacked_xf.17.ff1.weight', 'stacked_xf.17.post_attn_ln.scale', 'stacked_xf.17.post_ff_ln.scale', 'stacked_xf.17.pre_attn_ln.scale', 'stacked_xf.17.pre_ff_ln.scale', 'stacked_xf.18.attn.key_ln.scale', 'stacked_xf.18.attn.out.weight', 'stacked_xf.18.attn.per_dim_scale.per_dim_scale', 'stacked_xf.18.attn.qkv_proj.weight', 'stacked_xf.18.attn.query_ln.scale', 'stacked_xf.18.ff0.weight', 'stacked_xf.18.ff1.weight', 'stacked_xf.18.post_attn_ln.scale', 'stacked_xf.18.post_ff_ln.scale', 'stacked_xf.18.pre_attn_ln.scale', 'stacked_xf.18.pre_ff_ln.scale', 'stacked_xf.19.attn.key_ln.scale', 'stacked_xf.19.attn.out.weight', 'stacked_xf.19.attn.per_dim_scale.per_dim_scale', 'stacked_xf.19.attn.qkv_proj.weight', 'stacked_xf.19.attn.query_ln.scale', 'stacked_xf.19.ff0.weight', 'stacked_xf.19.ff1.weight', 'stacked_xf.19.post_attn_ln.scale', 'stacked_xf.19.post_ff_ln.scale', 'stacked_xf.19.pre_attn_ln.scale', 'stacked_xf.19.pre_ff_ln.scale', 'stacked_xf.2.attn.key_ln.scale', 'stacked_xf.2.attn.out.weight', 'stacked_xf.2.attn.per_dim_scale.per_dim_scale', 'stacked_xf.2.attn.qkv_proj.weight', 'stacked_xf.2.attn.query_ln.scale', 'stacked_xf.2.ff0.weight', 'stacked_xf.2.ff1.weight', 'stacked_xf.2.post_attn_ln.scale', 'stacked_xf.2.post_ff_ln.scale', 'stacked_xf.2.pre_attn_ln.scale', 'stacked_xf.2.pre_ff_ln.scale', 'stacked_xf.3.attn.key_ln.scale', 'stacked_xf.3.attn.out.weight', 'stacked_xf.3.attn.per_dim_scale.per_dim_scale', 'stacked_xf.3.attn.qkv_proj.weight', 'stacked_xf.3.attn.query_ln.scale', 'stacked_xf.3.ff0.weight', 'stacked_xf.3.ff1.weight', 'stacked_xf.3.post_attn_ln.scale', 'stacked_xf.3.post_ff_ln.scale', 'stacked_xf.3.pre_attn_ln.scale', 'stacked_xf.3.pre_ff_ln.scale', 'stacked_xf.4.attn.key_ln.scale', 'stacked_xf.4.attn.out.weight', 'stacked_xf.4.attn.per_dim_scale.per_dim_scale', 'stacked_xf.4.attn.qkv_proj.weight', 'stacked_xf.4.attn.query_ln.scale', 'stacked_xf.4.ff0.weight', 'stacked_xf.4.ff1.weight', 'stacked_xf.4.post_attn_ln.scale', 'stacked_xf.4.post_ff_ln.scale', 'stacked_xf.4.pre_attn_ln.scale', 'stacked_xf.4.pre_ff_ln.scale', 'stacked_xf.5.attn.key_ln.scale', 'stacked_xf.5.attn.out.weight', 'stacked_xf.5.attn.per_dim_scale.per_dim_scale', 'stacked_xf.5.attn.qkv_proj.weight', 'stacked_xf.5.attn.query_ln.scale', 'stacked_xf.5.ff0.weight', 'stacked_xf.5.ff1.weight', 'stacked_xf.5.post_attn_ln.scale', 'stacked_xf.5.post_ff_ln.scale', 'stacked_xf.5.pre_attn_ln.scale', 'stacked_xf.5.pre_ff_ln.scale', 'stacked_xf.6.attn.key_ln.scale', 'stacked_xf.6.attn.out.weight', 'stacked_xf.6.attn.per_dim_scale.per_dim_scale', 'stacked_xf.6.attn.qkv_proj.weight', 'stacked_xf.6.attn.query_ln.scale', 'stacked_xf.6.ff0.weight', 'stacked_xf.6.ff1.weight', 'stacked_xf.6.post_attn_ln.scale', 'stacked_xf.6.post_ff_ln.scale', 'stacked_xf.6.pre_attn_ln.scale', 'stacked_xf.6.pre_ff_ln.scale', 'stacked_xf.7.attn.key_ln.scale', 'stacked_xf.7.attn.out.weight', 'stacked_xf.7.attn.per_dim_scale.per_dim_scale', 'stacked_xf.7.attn.qkv_proj.weight', 'stacked_xf.7.attn.query_ln.scale', 'stacked_xf.7.ff0.weight', 'stacked_xf.7.ff1.weight', 'stacked_xf.7.post_attn_ln.scale', 'stacked_xf.7.post_ff_ln.scale', 'stacked_xf.7.pre_attn_ln.scale', 'stacked_xf.7.pre_ff_ln.scale', 'stacked_xf.8.attn.key_ln.scale', 'stacked_xf.8.attn.out.weight', 'stacked_xf.8.attn.per_dim_scale.per_dim_scale', 'stacked_xf.8.attn.qkv_proj.weight', 'stacked_xf.8.attn.query_ln.scale', 'stacked_xf.8.ff0.weight', 'stacked_xf.8.ff1.weight', 'stacked_xf.8.post_attn_ln.scale', 'stacked_xf.8.post_ff_ln.scale', 'stacked_xf.8.pre_attn_ln.scale', 'stacked_xf.8.pre_ff_ln.scale', 'stacked_xf.9.attn.key_ln.scale', 'stacked_xf.9.attn.out.weight', 'stacked_xf.9.attn.per_dim_scale.per_dim_scale', 'stacked_xf.9.attn.qkv_proj.weight', 'stacked_xf.9.attn.query_ln.scale', 'stacked_xf.9.ff0.weight', 'stacked_xf.9.ff1.weight', 'stacked_xf.9.post_attn_ln.scale', 'stacked_xf.9.post_ff_ln.scale', 'stacked_xf.9.pre_attn_ln.scale', 'stacked_xf.9.pre_ff_ln.scale', 'tokenizer.hidden_layer.bias', 'tokenizer.hidden_layer.weight', 'tokenizer.output_layer.bias', 'tokenizer.output_layer.weight', 'tokenizer.residual_layer.bias', 'tokenizer.residual_layer.weight']\n",
            "- This IS expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of TimesFmModelForPrediction were not initialized from the model checkpoint at google/timesfm-2.5-200m-pytorch and are newly initialized: ['decoder.freq_emb.weight', 'decoder.input_ff_layer.input_layer.bias', 'decoder.input_ff_layer.input_layer.weight', 'decoder.input_ff_layer.output_layer.bias', 'decoder.input_ff_layer.output_layer.weight', 'decoder.input_ff_layer.residual_layer.bias', 'decoder.input_ff_layer.residual_layer.weight', 'decoder.layers.0.input_layernorm.weight', 'decoder.layers.0.mlp.down_proj.bias', 'decoder.layers.0.mlp.down_proj.weight', 'decoder.layers.0.mlp.gate_proj.bias', 'decoder.layers.0.mlp.gate_proj.weight', 'decoder.layers.0.mlp.layer_norm.bias', 'decoder.layers.0.mlp.layer_norm.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.o_proj.bias', 'decoder.layers.0.self_attn.o_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.scaling', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.1.input_layernorm.weight', 'decoder.layers.1.mlp.down_proj.bias', 'decoder.layers.1.mlp.down_proj.weight', 'decoder.layers.1.mlp.gate_proj.bias', 'decoder.layers.1.mlp.gate_proj.weight', 'decoder.layers.1.mlp.layer_norm.bias', 'decoder.layers.1.mlp.layer_norm.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.o_proj.bias', 'decoder.layers.1.self_attn.o_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.scaling', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.10.input_layernorm.weight', 'decoder.layers.10.mlp.down_proj.bias', 'decoder.layers.10.mlp.down_proj.weight', 'decoder.layers.10.mlp.gate_proj.bias', 'decoder.layers.10.mlp.gate_proj.weight', 'decoder.layers.10.mlp.layer_norm.bias', 'decoder.layers.10.mlp.layer_norm.weight', 'decoder.layers.10.self_attn.k_proj.bias', 'decoder.layers.10.self_attn.k_proj.weight', 'decoder.layers.10.self_attn.o_proj.bias', 'decoder.layers.10.self_attn.o_proj.weight', 'decoder.layers.10.self_attn.q_proj.bias', 'decoder.layers.10.self_attn.q_proj.weight', 'decoder.layers.10.self_attn.scaling', 'decoder.layers.10.self_attn.v_proj.bias', 'decoder.layers.10.self_attn.v_proj.weight', 'decoder.layers.11.input_layernorm.weight', 'decoder.layers.11.mlp.down_proj.bias', 'decoder.layers.11.mlp.down_proj.weight', 'decoder.layers.11.mlp.gate_proj.bias', 'decoder.layers.11.mlp.gate_proj.weight', 'decoder.layers.11.mlp.layer_norm.bias', 'decoder.layers.11.mlp.layer_norm.weight', 'decoder.layers.11.self_attn.k_proj.bias', 'decoder.layers.11.self_attn.k_proj.weight', 'decoder.layers.11.self_attn.o_proj.bias', 'decoder.layers.11.self_attn.o_proj.weight', 'decoder.layers.11.self_attn.q_proj.bias', 'decoder.layers.11.self_attn.q_proj.weight', 'decoder.layers.11.self_attn.scaling', 'decoder.layers.11.self_attn.v_proj.bias', 'decoder.layers.11.self_attn.v_proj.weight', 'decoder.layers.12.input_layernorm.weight', 'decoder.layers.12.mlp.down_proj.bias', 'decoder.layers.12.mlp.down_proj.weight', 'decoder.layers.12.mlp.gate_proj.bias', 'decoder.layers.12.mlp.gate_proj.weight', 'decoder.layers.12.mlp.layer_norm.bias', 'decoder.layers.12.mlp.layer_norm.weight', 'decoder.layers.12.self_attn.k_proj.bias', 'decoder.layers.12.self_attn.k_proj.weight', 'decoder.layers.12.self_attn.o_proj.bias', 'decoder.layers.12.self_attn.o_proj.weight', 'decoder.layers.12.self_attn.q_proj.bias', 'decoder.layers.12.self_attn.q_proj.weight', 'decoder.layers.12.self_attn.scaling', 'decoder.layers.12.self_attn.v_proj.bias', 'decoder.layers.12.self_attn.v_proj.weight', 'decoder.layers.13.input_layernorm.weight', 'decoder.layers.13.mlp.down_proj.bias', 'decoder.layers.13.mlp.down_proj.weight', 'decoder.layers.13.mlp.gate_proj.bias', 'decoder.layers.13.mlp.gate_proj.weight', 'decoder.layers.13.mlp.layer_norm.bias', 'decoder.layers.13.mlp.layer_norm.weight', 'decoder.layers.13.self_attn.k_proj.bias', 'decoder.layers.13.self_attn.k_proj.weight', 'decoder.layers.13.self_attn.o_proj.bias', 'decoder.layers.13.self_attn.o_proj.weight', 'decoder.layers.13.self_attn.q_proj.bias', 'decoder.layers.13.self_attn.q_proj.weight', 'decoder.layers.13.self_attn.scaling', 'decoder.layers.13.self_attn.v_proj.bias', 'decoder.layers.13.self_attn.v_proj.weight', 'decoder.layers.14.input_layernorm.weight', 'decoder.layers.14.mlp.down_proj.bias', 'decoder.layers.14.mlp.down_proj.weight', 'decoder.layers.14.mlp.gate_proj.bias', 'decoder.layers.14.mlp.gate_proj.weight', 'decoder.layers.14.mlp.layer_norm.bias', 'decoder.layers.14.mlp.layer_norm.weight', 'decoder.layers.14.self_attn.k_proj.bias', 'decoder.layers.14.self_attn.k_proj.weight', 'decoder.layers.14.self_attn.o_proj.bias', 'decoder.layers.14.self_attn.o_proj.weight', 'decoder.layers.14.self_attn.q_proj.bias', 'decoder.layers.14.self_attn.q_proj.weight', 'decoder.layers.14.self_attn.scaling', 'decoder.layers.14.self_attn.v_proj.bias', 'decoder.layers.14.self_attn.v_proj.weight', 'decoder.layers.15.input_layernorm.weight', 'decoder.layers.15.mlp.down_proj.bias', 'decoder.layers.15.mlp.down_proj.weight', 'decoder.layers.15.mlp.gate_proj.bias', 'decoder.layers.15.mlp.gate_proj.weight', 'decoder.layers.15.mlp.layer_norm.bias', 'decoder.layers.15.mlp.layer_norm.weight', 'decoder.layers.15.self_attn.k_proj.bias', 'decoder.layers.15.self_attn.k_proj.weight', 'decoder.layers.15.self_attn.o_proj.bias', 'decoder.layers.15.self_attn.o_proj.weight', 'decoder.layers.15.self_attn.q_proj.bias', 'decoder.layers.15.self_attn.q_proj.weight', 'decoder.layers.15.self_attn.scaling', 'decoder.layers.15.self_attn.v_proj.bias', 'decoder.layers.15.self_attn.v_proj.weight', 'decoder.layers.16.input_layernorm.weight', 'decoder.layers.16.mlp.down_proj.bias', 'decoder.layers.16.mlp.down_proj.weight', 'decoder.layers.16.mlp.gate_proj.bias', 'decoder.layers.16.mlp.gate_proj.weight', 'decoder.layers.16.mlp.layer_norm.bias', 'decoder.layers.16.mlp.layer_norm.weight', 'decoder.layers.16.self_attn.k_proj.bias', 'decoder.layers.16.self_attn.k_proj.weight', 'decoder.layers.16.self_attn.o_proj.bias', 'decoder.layers.16.self_attn.o_proj.weight', 'decoder.layers.16.self_attn.q_proj.bias', 'decoder.layers.16.self_attn.q_proj.weight', 'decoder.layers.16.self_attn.scaling', 'decoder.layers.16.self_attn.v_proj.bias', 'decoder.layers.16.self_attn.v_proj.weight', 'decoder.layers.17.input_layernorm.weight', 'decoder.layers.17.mlp.down_proj.bias', 'decoder.layers.17.mlp.down_proj.weight', 'decoder.layers.17.mlp.gate_proj.bias', 'decoder.layers.17.mlp.gate_proj.weight', 'decoder.layers.17.mlp.layer_norm.bias', 'decoder.layers.17.mlp.layer_norm.weight', 'decoder.layers.17.self_attn.k_proj.bias', 'decoder.layers.17.self_attn.k_proj.weight', 'decoder.layers.17.self_attn.o_proj.bias', 'decoder.layers.17.self_attn.o_proj.weight', 'decoder.layers.17.self_attn.q_proj.bias', 'decoder.layers.17.self_attn.q_proj.weight', 'decoder.layers.17.self_attn.scaling', 'decoder.layers.17.self_attn.v_proj.bias', 'decoder.layers.17.self_attn.v_proj.weight', 'decoder.layers.18.input_layernorm.weight', 'decoder.layers.18.mlp.down_proj.bias', 'decoder.layers.18.mlp.down_proj.weight', 'decoder.layers.18.mlp.gate_proj.bias', 'decoder.layers.18.mlp.gate_proj.weight', 'decoder.layers.18.mlp.layer_norm.bias', 'decoder.layers.18.mlp.layer_norm.weight', 'decoder.layers.18.self_attn.k_proj.bias', 'decoder.layers.18.self_attn.k_proj.weight', 'decoder.layers.18.self_attn.o_proj.bias', 'decoder.layers.18.self_attn.o_proj.weight', 'decoder.layers.18.self_attn.q_proj.bias', 'decoder.layers.18.self_attn.q_proj.weight', 'decoder.layers.18.self_attn.scaling', 'decoder.layers.18.self_attn.v_proj.bias', 'decoder.layers.18.self_attn.v_proj.weight', 'decoder.layers.19.input_layernorm.weight', 'decoder.layers.19.mlp.down_proj.bias', 'decoder.layers.19.mlp.down_proj.weight', 'decoder.layers.19.mlp.gate_proj.bias', 'decoder.layers.19.mlp.gate_proj.weight', 'decoder.layers.19.mlp.layer_norm.bias', 'decoder.layers.19.mlp.layer_norm.weight', 'decoder.layers.19.self_attn.k_proj.bias', 'decoder.layers.19.self_attn.k_proj.weight', 'decoder.layers.19.self_attn.o_proj.bias', 'decoder.layers.19.self_attn.o_proj.weight', 'decoder.layers.19.self_attn.q_proj.bias', 'decoder.layers.19.self_attn.q_proj.weight', 'decoder.layers.19.self_attn.scaling', 'decoder.layers.19.self_attn.v_proj.bias', 'decoder.layers.19.self_attn.v_proj.weight', 'decoder.layers.2.input_layernorm.weight', 'decoder.layers.2.mlp.down_proj.bias', 'decoder.layers.2.mlp.down_proj.weight', 'decoder.layers.2.mlp.gate_proj.bias', 'decoder.layers.2.mlp.gate_proj.weight', 'decoder.layers.2.mlp.layer_norm.bias', 'decoder.layers.2.mlp.layer_norm.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.o_proj.bias', 'decoder.layers.2.self_attn.o_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.scaling', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.3.input_layernorm.weight', 'decoder.layers.3.mlp.down_proj.bias', 'decoder.layers.3.mlp.down_proj.weight', 'decoder.layers.3.mlp.gate_proj.bias', 'decoder.layers.3.mlp.gate_proj.weight', 'decoder.layers.3.mlp.layer_norm.bias', 'decoder.layers.3.mlp.layer_norm.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.o_proj.bias', 'decoder.layers.3.self_attn.o_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.scaling', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.4.input_layernorm.weight', 'decoder.layers.4.mlp.down_proj.bias', 'decoder.layers.4.mlp.down_proj.weight', 'decoder.layers.4.mlp.gate_proj.bias', 'decoder.layers.4.mlp.gate_proj.weight', 'decoder.layers.4.mlp.layer_norm.bias', 'decoder.layers.4.mlp.layer_norm.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.o_proj.bias', 'decoder.layers.4.self_attn.o_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.scaling', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.5.input_layernorm.weight', 'decoder.layers.5.mlp.down_proj.bias', 'decoder.layers.5.mlp.down_proj.weight', 'decoder.layers.5.mlp.gate_proj.bias', 'decoder.layers.5.mlp.gate_proj.weight', 'decoder.layers.5.mlp.layer_norm.bias', 'decoder.layers.5.mlp.layer_norm.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.o_proj.bias', 'decoder.layers.5.self_attn.o_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.scaling', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.6.input_layernorm.weight', 'decoder.layers.6.mlp.down_proj.bias', 'decoder.layers.6.mlp.down_proj.weight', 'decoder.layers.6.mlp.gate_proj.bias', 'decoder.layers.6.mlp.gate_proj.weight', 'decoder.layers.6.mlp.layer_norm.bias', 'decoder.layers.6.mlp.layer_norm.weight', 'decoder.layers.6.self_attn.k_proj.bias', 'decoder.layers.6.self_attn.k_proj.weight', 'decoder.layers.6.self_attn.o_proj.bias', 'decoder.layers.6.self_attn.o_proj.weight', 'decoder.layers.6.self_attn.q_proj.bias', 'decoder.layers.6.self_attn.q_proj.weight', 'decoder.layers.6.self_attn.scaling', 'decoder.layers.6.self_attn.v_proj.bias', 'decoder.layers.6.self_attn.v_proj.weight', 'decoder.layers.7.input_layernorm.weight', 'decoder.layers.7.mlp.down_proj.bias', 'decoder.layers.7.mlp.down_proj.weight', 'decoder.layers.7.mlp.gate_proj.bias', 'decoder.layers.7.mlp.gate_proj.weight', 'decoder.layers.7.mlp.layer_norm.bias', 'decoder.layers.7.mlp.layer_norm.weight', 'decoder.layers.7.self_attn.k_proj.bias', 'decoder.layers.7.self_attn.k_proj.weight', 'decoder.layers.7.self_attn.o_proj.bias', 'decoder.layers.7.self_attn.o_proj.weight', 'decoder.layers.7.self_attn.q_proj.bias', 'decoder.layers.7.self_attn.q_proj.weight', 'decoder.layers.7.self_attn.scaling', 'decoder.layers.7.self_attn.v_proj.bias', 'decoder.layers.7.self_attn.v_proj.weight', 'decoder.layers.8.input_layernorm.weight', 'decoder.layers.8.mlp.down_proj.bias', 'decoder.layers.8.mlp.down_proj.weight', 'decoder.layers.8.mlp.gate_proj.bias', 'decoder.layers.8.mlp.gate_proj.weight', 'decoder.layers.8.mlp.layer_norm.bias', 'decoder.layers.8.mlp.layer_norm.weight', 'decoder.layers.8.self_attn.k_proj.bias', 'decoder.layers.8.self_attn.k_proj.weight', 'decoder.layers.8.self_attn.o_proj.bias', 'decoder.layers.8.self_attn.o_proj.weight', 'decoder.layers.8.self_attn.q_proj.bias', 'decoder.layers.8.self_attn.q_proj.weight', 'decoder.layers.8.self_attn.scaling', 'decoder.layers.8.self_attn.v_proj.bias', 'decoder.layers.8.self_attn.v_proj.weight', 'decoder.layers.9.input_layernorm.weight', 'decoder.layers.9.mlp.down_proj.bias', 'decoder.layers.9.mlp.down_proj.weight', 'decoder.layers.9.mlp.gate_proj.bias', 'decoder.layers.9.mlp.gate_proj.weight', 'decoder.layers.9.mlp.layer_norm.bias', 'decoder.layers.9.mlp.layer_norm.weight', 'decoder.layers.9.self_attn.k_proj.bias', 'decoder.layers.9.self_attn.k_proj.weight', 'decoder.layers.9.self_attn.o_proj.bias', 'decoder.layers.9.self_attn.o_proj.weight', 'decoder.layers.9.self_attn.q_proj.bias', 'decoder.layers.9.self_attn.q_proj.weight', 'decoder.layers.9.self_attn.scaling', 'decoder.layers.9.self_attn.v_proj.bias', 'decoder.layers.9.self_attn.v_proj.weight', 'horizon_ff_layer.input_layer.bias', 'horizon_ff_layer.input_layer.weight', 'horizon_ff_layer.output_layer.bias', 'horizon_ff_layer.output_layer.weight', 'horizon_ff_layer.residual_layer.bias', 'horizon_ff_layer.residual_layer.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n",
            "  Epoch 1/100 train_loss=2.0408 train_acc=0.2500 eval_loss=0.9278 eval_acc=0.6700 (best)\n",
            "  Epoch 2/100 train_loss=0.7291 train_acc=0.8200 eval_loss=0.6928 eval_acc=0.7800 (best)\n",
            "  Epoch 3/100 train_loss=0.3458 train_acc=0.8800 eval_loss=0.5450 eval_acc=0.8200 (best)\n",
            "  Epoch 4/100 train_loss=0.2006 train_acc=0.9500 eval_loss=0.5184 eval_acc=0.8300 (best)\n",
            "  Epoch 5/100 train_loss=0.0720 train_acc=0.9800 eval_loss=0.4098 eval_acc=0.8700 (best)\n",
            "  Epoch 6/100 train_loss=0.0191 train_acc=1.0000 eval_loss=0.6036 eval_acc=0.8600 \n",
            "  Epoch 7/100 train_loss=0.0029 train_acc=1.0000 eval_loss=0.8327 eval_acc=0.8500 \n",
            "  Epoch 8/100 train_loss=0.0016 train_acc=1.0000 eval_loss=0.9427 eval_acc=0.8400 \n",
            "  Epoch 9/100 train_loss=0.0008 train_acc=1.0000 eval_loss=0.9835 eval_acc=0.8200 \n",
            "  Epoch 10/100 train_loss=0.0005 train_acc=1.0000 eval_loss=0.9748 eval_acc=0.8100 \n",
            "  Epoch 11/100 train_loss=0.0003 train_acc=1.0000 eval_loss=0.9489 eval_acc=0.8300 \n",
            "  Epoch 12/100 train_loss=0.0002 train_acc=1.0000 eval_loss=0.9272 eval_acc=0.8300 \n",
            "  Epoch 13/100 train_loss=0.0001 train_acc=1.0000 eval_loss=0.9121 eval_acc=0.8300 \n",
            "  Epoch 14/100 train_loss=0.0001 train_acc=1.0000 eval_loss=0.9014 eval_acc=0.8400 \n",
            "  Epoch 15/100 train_loss=0.0001 train_acc=1.0000 eval_loss=0.8952 eval_acc=0.8400 \n",
            "  Early stopping on google/timesfm-2.5-200m-pytorch: no improvement for 10 epochs (best epoch = 5)\n",
            "    tfm[google/timesfm-2.5-200m-pytorch] train_acc=0.9800 eval_acc=0.83999999999999996891375531049561686813831329\n",
            "    mrh_acc=0.8300 mr+h+kg_acc=0.8400 kg_acc=0.8600 ensemble=0.8400 (w=0.60)\n",
            "  Split 1/1 - accuracy=0.8400 time=120.6s\n",
            "Completed ACSF1: Mean Acc=0.8400\n",
            "\n",
            "=== 2/109 Adiac ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  Decision: Heuristic says no filter (clean signal (no filtering))\n",
            "\n",
            "=== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at google/timesfm-2.5-200m-pytorch were not used when initializing TimesFmModelForPrediction: ['output_projection_point.hidden_layer.weight', 'output_projection_point.output_layer.weight', 'output_projection_point.residual_layer.weight', 'output_projection_quantiles.hidden_layer.weight', 'output_projection_quantiles.output_layer.weight', 'output_projection_quantiles.residual_layer.weight', 'stacked_xf.0.attn.key_ln.scale', 'stacked_xf.0.attn.out.weight', 'stacked_xf.0.attn.per_dim_scale.per_dim_scale', 'stacked_xf.0.attn.qkv_proj.weight', 'stacked_xf.0.attn.query_ln.scale', 'stacked_xf.0.ff0.weight', 'stacked_xf.0.ff1.weight', 'stacked_xf.0.post_attn_ln.scale', 'stacked_xf.0.post_ff_ln.scale', 'stacked_xf.0.pre_attn_ln.scale', 'stacked_xf.0.pre_ff_ln.scale', 'stacked_xf.1.attn.key_ln.scale', 'stacked_xf.1.attn.out.weight', 'stacked_xf.1.attn.per_dim_scale.per_dim_scale', 'stacked_xf.1.attn.qkv_proj.weight', 'stacked_xf.1.attn.query_ln.scale', 'stacked_xf.1.ff0.weight', 'stacked_xf.1.ff1.weight', 'stacked_xf.1.post_attn_ln.scale', 'stacked_xf.1.post_ff_ln.scale', 'stacked_xf.1.pre_attn_ln.scale', 'stacked_xf.1.pre_ff_ln.scale', 'stacked_xf.10.attn.key_ln.scale', 'stacked_xf.10.attn.out.weight', 'stacked_xf.10.attn.per_dim_scale.per_dim_scale', 'stacked_xf.10.attn.qkv_proj.weight', 'stacked_xf.10.attn.query_ln.scale', 'stacked_xf.10.ff0.weight', 'stacked_xf.10.ff1.weight', 'stacked_xf.10.post_attn_ln.scale', 'stacked_xf.10.post_ff_ln.scale', 'stacked_xf.10.pre_attn_ln.scale', 'stacked_xf.10.pre_ff_ln.scale', 'stacked_xf.11.attn.key_ln.scale', 'stacked_xf.11.attn.out.weight', 'stacked_xf.11.attn.per_dim_scale.per_dim_scale', 'stacked_xf.11.attn.qkv_proj.weight', 'stacked_xf.11.attn.query_ln.scale', 'stacked_xf.11.ff0.weight', 'stacked_xf.11.ff1.weight', 'stacked_xf.11.post_attn_ln.scale', 'stacked_xf.11.post_ff_ln.scale', 'stacked_xf.11.pre_attn_ln.scale', 'stacked_xf.11.pre_ff_ln.scale', 'stacked_xf.12.attn.key_ln.scale', 'stacked_xf.12.attn.out.weight', 'stacked_xf.12.attn.per_dim_scale.per_dim_scale', 'stacked_xf.12.attn.qkv_proj.weight', 'stacked_xf.12.attn.query_ln.scale', 'stacked_xf.12.ff0.weight', 'stacked_xf.12.ff1.weight', 'stacked_xf.12.post_attn_ln.scale', 'stacked_xf.12.post_ff_ln.scale', 'stacked_xf.12.pre_attn_ln.scale', 'stacked_xf.12.pre_ff_ln.scale', 'stacked_xf.13.attn.key_ln.scale', 'stacked_xf.13.attn.out.weight', 'stacked_xf.13.attn.per_dim_scale.per_dim_scale', 'stacked_xf.13.attn.qkv_proj.weight', 'stacked_xf.13.attn.query_ln.scale', 'stacked_xf.13.ff0.weight', 'stacked_xf.13.ff1.weight', 'stacked_xf.13.post_attn_ln.scale', 'stacked_xf.13.post_ff_ln.scale', 'stacked_xf.13.pre_attn_ln.scale', 'stacked_xf.13.pre_ff_ln.scale', 'stacked_xf.14.attn.key_ln.scale', 'stacked_xf.14.attn.out.weight', 'stacked_xf.14.attn.per_dim_scale.per_dim_scale', 'stacked_xf.14.attn.qkv_proj.weight', 'stacked_xf.14.attn.query_ln.scale', 'stacked_xf.14.ff0.weight', 'stacked_xf.14.ff1.weight', 'stacked_xf.14.post_attn_ln.scale', 'stacked_xf.14.post_ff_ln.scale', 'stacked_xf.14.pre_attn_ln.scale', 'stacked_xf.14.pre_ff_ln.scale', 'stacked_xf.15.attn.key_ln.scale', 'stacked_xf.15.attn.out.weight', 'stacked_xf.15.attn.per_dim_scale.per_dim_scale', 'stacked_xf.15.attn.qkv_proj.weight', 'stacked_xf.15.attn.query_ln.scale', 'stacked_xf.15.ff0.weight', 'stacked_xf.15.ff1.weight', 'stacked_xf.15.post_attn_ln.scale', 'stacked_xf.15.post_ff_ln.scale', 'stacked_xf.15.pre_attn_ln.scale', 'stacked_xf.15.pre_ff_ln.scale', 'stacked_xf.16.attn.key_ln.scale', 'stacked_xf.16.attn.out.weight', 'stacked_xf.16.attn.per_dim_scale.per_dim_scale', 'stacked_xf.16.attn.qkv_proj.weight', 'stacked_xf.16.attn.query_ln.scale', 'stacked_xf.16.ff0.weight', 'stacked_xf.16.ff1.weight', 'stacked_xf.16.post_attn_ln.scale', 'stacked_xf.16.post_ff_ln.scale', 'stacked_xf.16.pre_attn_ln.scale', 'stacked_xf.16.pre_ff_ln.scale', 'stacked_xf.17.attn.key_ln.scale', 'stacked_xf.17.attn.out.weight', 'stacked_xf.17.attn.per_dim_scale.per_dim_scale', 'stacked_xf.17.attn.qkv_proj.weight', 'stacked_xf.17.attn.query_ln.scale', 'stacked_xf.17.ff0.weight', 'stacked_xf.17.ff1.weight', 'stacked_xf.17.post_attn_ln.scale', 'stacked_xf.17.post_ff_ln.scale', 'stacked_xf.17.pre_attn_ln.scale', 'stacked_xf.17.pre_ff_ln.scale', 'stacked_xf.18.attn.key_ln.scale', 'stacked_xf.18.attn.out.weight', 'stacked_xf.18.attn.per_dim_scale.per_dim_scale', 'stacked_xf.18.attn.qkv_proj.weight', 'stacked_xf.18.attn.query_ln.scale', 'stacked_xf.18.ff0.weight', 'stacked_xf.18.ff1.weight', 'stacked_xf.18.post_attn_ln.scale', 'stacked_xf.18.post_ff_ln.scale', 'stacked_xf.18.pre_attn_ln.scale', 'stacked_xf.18.pre_ff_ln.scale', 'stacked_xf.19.attn.key_ln.scale', 'stacked_xf.19.attn.out.weight', 'stacked_xf.19.attn.per_dim_scale.per_dim_scale', 'stacked_xf.19.attn.qkv_proj.weight', 'stacked_xf.19.attn.query_ln.scale', 'stacked_xf.19.ff0.weight', 'stacked_xf.19.ff1.weight', 'stacked_xf.19.post_attn_ln.scale', 'stacked_xf.19.post_ff_ln.scale', 'stacked_xf.19.pre_attn_ln.scale', 'stacked_xf.19.pre_ff_ln.scale', 'stacked_xf.2.attn.key_ln.scale', 'stacked_xf.2.attn.out.weight', 'stacked_xf.2.attn.per_dim_scale.per_dim_scale', 'stacked_xf.2.attn.qkv_proj.weight', 'stacked_xf.2.attn.query_ln.scale', 'stacked_xf.2.ff0.weight', 'stacked_xf.2.ff1.weight', 'stacked_xf.2.post_attn_ln.scale', 'stacked_xf.2.post_ff_ln.scale', 'stacked_xf.2.pre_attn_ln.scale', 'stacked_xf.2.pre_ff_ln.scale', 'stacked_xf.3.attn.key_ln.scale', 'stacked_xf.3.attn.out.weight', 'stacked_xf.3.attn.per_dim_scale.per_dim_scale', 'stacked_xf.3.attn.qkv_proj.weight', 'stacked_xf.3.attn.query_ln.scale', 'stacked_xf.3.ff0.weight', 'stacked_xf.3.ff1.weight', 'stacked_xf.3.post_attn_ln.scale', 'stacked_xf.3.post_ff_ln.scale', 'stacked_xf.3.pre_attn_ln.scale', 'stacked_xf.3.pre_ff_ln.scale', 'stacked_xf.4.attn.key_ln.scale', 'stacked_xf.4.attn.out.weight', 'stacked_xf.4.attn.per_dim_scale.per_dim_scale', 'stacked_xf.4.attn.qkv_proj.weight', 'stacked_xf.4.attn.query_ln.scale', 'stacked_xf.4.ff0.weight', 'stacked_xf.4.ff1.weight', 'stacked_xf.4.post_attn_ln.scale', 'stacked_xf.4.post_ff_ln.scale', 'stacked_xf.4.pre_attn_ln.scale', 'stacked_xf.4.pre_ff_ln.scale', 'stacked_xf.5.attn.key_ln.scale', 'stacked_xf.5.attn.out.weight', 'stacked_xf.5.attn.per_dim_scale.per_dim_scale', 'stacked_xf.5.attn.qkv_proj.weight', 'stacked_xf.5.attn.query_ln.scale', 'stacked_xf.5.ff0.weight', 'stacked_xf.5.ff1.weight', 'stacked_xf.5.post_attn_ln.scale', 'stacked_xf.5.post_ff_ln.scale', 'stacked_xf.5.pre_attn_ln.scale', 'stacked_xf.5.pre_ff_ln.scale', 'stacked_xf.6.attn.key_ln.scale', 'stacked_xf.6.attn.out.weight', 'stacked_xf.6.attn.per_dim_scale.per_dim_scale', 'stacked_xf.6.attn.qkv_proj.weight', 'stacked_xf.6.attn.query_ln.scale', 'stacked_xf.6.ff0.weight', 'stacked_xf.6.ff1.weight', 'stacked_xf.6.post_attn_ln.scale', 'stacked_xf.6.post_ff_ln.scale', 'stacked_xf.6.pre_attn_ln.scale', 'stacked_xf.6.pre_ff_ln.scale', 'stacked_xf.7.attn.key_ln.scale', 'stacked_xf.7.attn.out.weight', 'stacked_xf.7.attn.per_dim_scale.per_dim_scale', 'stacked_xf.7.attn.qkv_proj.weight', 'stacked_xf.7.attn.query_ln.scale', 'stacked_xf.7.ff0.weight', 'stacked_xf.7.ff1.weight', 'stacked_xf.7.post_attn_ln.scale', 'stacked_xf.7.post_ff_ln.scale', 'stacked_xf.7.pre_attn_ln.scale', 'stacked_xf.7.pre_ff_ln.scale', 'stacked_xf.8.attn.key_ln.scale', 'stacked_xf.8.attn.out.weight', 'stacked_xf.8.attn.per_dim_scale.per_dim_scale', 'stacked_xf.8.attn.qkv_proj.weight', 'stacked_xf.8.attn.query_ln.scale', 'stacked_xf.8.ff0.weight', 'stacked_xf.8.ff1.weight', 'stacked_xf.8.post_attn_ln.scale', 'stacked_xf.8.post_ff_ln.scale', 'stacked_xf.8.pre_attn_ln.scale', 'stacked_xf.8.pre_ff_ln.scale', 'stacked_xf.9.attn.key_ln.scale', 'stacked_xf.9.attn.out.weight', 'stacked_xf.9.attn.per_dim_scale.per_dim_scale', 'stacked_xf.9.attn.qkv_proj.weight', 'stacked_xf.9.attn.query_ln.scale', 'stacked_xf.9.ff0.weight', 'stacked_xf.9.ff1.weight', 'stacked_xf.9.post_attn_ln.scale', 'stacked_xf.9.post_ff_ln.scale', 'stacked_xf.9.pre_attn_ln.scale', 'stacked_xf.9.pre_ff_ln.scale', 'tokenizer.hidden_layer.bias', 'tokenizer.hidden_layer.weight', 'tokenizer.output_layer.bias', 'tokenizer.output_layer.weight', 'tokenizer.residual_layer.bias', 'tokenizer.residual_layer.weight']\n",
            "- This IS expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of TimesFmModelForPrediction were not initialized from the model checkpoint at google/timesfm-2.5-200m-pytorch and are newly initialized: ['decoder.freq_emb.weight', 'decoder.input_ff_layer.input_layer.bias', 'decoder.input_ff_layer.input_layer.weight', 'decoder.input_ff_layer.output_layer.bias', 'decoder.input_ff_layer.output_layer.weight', 'decoder.input_ff_layer.residual_layer.bias', 'decoder.input_ff_layer.residual_layer.weight', 'decoder.layers.0.input_layernorm.weight', 'decoder.layers.0.mlp.down_proj.bias', 'decoder.layers.0.mlp.down_proj.weight', 'decoder.layers.0.mlp.gate_proj.bias', 'decoder.layers.0.mlp.gate_proj.weight', 'decoder.layers.0.mlp.layer_norm.bias', 'decoder.layers.0.mlp.layer_norm.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.o_proj.bias', 'decoder.layers.0.self_attn.o_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.scaling', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.1.input_layernorm.weight', 'decoder.layers.1.mlp.down_proj.bias', 'decoder.layers.1.mlp.down_proj.weight', 'decoder.layers.1.mlp.gate_proj.bias', 'decoder.layers.1.mlp.gate_proj.weight', 'decoder.layers.1.mlp.layer_norm.bias', 'decoder.layers.1.mlp.layer_norm.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.o_proj.bias', 'decoder.layers.1.self_attn.o_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.scaling', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.10.input_layernorm.weight', 'decoder.layers.10.mlp.down_proj.bias', 'decoder.layers.10.mlp.down_proj.weight', 'decoder.layers.10.mlp.gate_proj.bias', 'decoder.layers.10.mlp.gate_proj.weight', 'decoder.layers.10.mlp.layer_norm.bias', 'decoder.layers.10.mlp.layer_norm.weight', 'decoder.layers.10.self_attn.k_proj.bias', 'decoder.layers.10.self_attn.k_proj.weight', 'decoder.layers.10.self_attn.o_proj.bias', 'decoder.layers.10.self_attn.o_proj.weight', 'decoder.layers.10.self_attn.q_proj.bias', 'decoder.layers.10.self_attn.q_proj.weight', 'decoder.layers.10.self_attn.scaling', 'decoder.layers.10.self_attn.v_proj.bias', 'decoder.layers.10.self_attn.v_proj.weight', 'decoder.layers.11.input_layernorm.weight', 'decoder.layers.11.mlp.down_proj.bias', 'decoder.layers.11.mlp.down_proj.weight', 'decoder.layers.11.mlp.gate_proj.bias', 'decoder.layers.11.mlp.gate_proj.weight', 'decoder.layers.11.mlp.layer_norm.bias', 'decoder.layers.11.mlp.layer_norm.weight', 'decoder.layers.11.self_attn.k_proj.bias', 'decoder.layers.11.self_attn.k_proj.weight', 'decoder.layers.11.self_attn.o_proj.bias', 'decoder.layers.11.self_attn.o_proj.weight', 'decoder.layers.11.self_attn.q_proj.bias', 'decoder.layers.11.self_attn.q_proj.weight', 'decoder.layers.11.self_attn.scaling', 'decoder.layers.11.self_attn.v_proj.bias', 'decoder.layers.11.self_attn.v_proj.weight', 'decoder.layers.12.input_layernorm.weight', 'decoder.layers.12.mlp.down_proj.bias', 'decoder.layers.12.mlp.down_proj.weight', 'decoder.layers.12.mlp.gate_proj.bias', 'decoder.layers.12.mlp.gate_proj.weight', 'decoder.layers.12.mlp.layer_norm.bias', 'decoder.layers.12.mlp.layer_norm.weight', 'decoder.layers.12.self_attn.k_proj.bias', 'decoder.layers.12.self_attn.k_proj.weight', 'decoder.layers.12.self_attn.o_proj.bias', 'decoder.layers.12.self_attn.o_proj.weight', 'decoder.layers.12.self_attn.q_proj.bias', 'decoder.layers.12.self_attn.q_proj.weight', 'decoder.layers.12.self_attn.scaling', 'decoder.layers.12.self_attn.v_proj.bias', 'decoder.layers.12.self_attn.v_proj.weight', 'decoder.layers.13.input_layernorm.weight', 'decoder.layers.13.mlp.down_proj.bias', 'decoder.layers.13.mlp.down_proj.weight', 'decoder.layers.13.mlp.gate_proj.bias', 'decoder.layers.13.mlp.gate_proj.weight', 'decoder.layers.13.mlp.layer_norm.bias', 'decoder.layers.13.mlp.layer_norm.weight', 'decoder.layers.13.self_attn.k_proj.bias', 'decoder.layers.13.self_attn.k_proj.weight', 'decoder.layers.13.self_attn.o_proj.bias', 'decoder.layers.13.self_attn.o_proj.weight', 'decoder.layers.13.self_attn.q_proj.bias', 'decoder.layers.13.self_attn.q_proj.weight', 'decoder.layers.13.self_attn.scaling', 'decoder.layers.13.self_attn.v_proj.bias', 'decoder.layers.13.self_attn.v_proj.weight', 'decoder.layers.14.input_layernorm.weight', 'decoder.layers.14.mlp.down_proj.bias', 'decoder.layers.14.mlp.down_proj.weight', 'decoder.layers.14.mlp.gate_proj.bias', 'decoder.layers.14.mlp.gate_proj.weight', 'decoder.layers.14.mlp.layer_norm.bias', 'decoder.layers.14.mlp.layer_norm.weight', 'decoder.layers.14.self_attn.k_proj.bias', 'decoder.layers.14.self_attn.k_proj.weight', 'decoder.layers.14.self_attn.o_proj.bias', 'decoder.layers.14.self_attn.o_proj.weight', 'decoder.layers.14.self_attn.q_proj.bias', 'decoder.layers.14.self_attn.q_proj.weight', 'decoder.layers.14.self_attn.scaling', 'decoder.layers.14.self_attn.v_proj.bias', 'decoder.layers.14.self_attn.v_proj.weight', 'decoder.layers.15.input_layernorm.weight', 'decoder.layers.15.mlp.down_proj.bias', 'decoder.layers.15.mlp.down_proj.weight', 'decoder.layers.15.mlp.gate_proj.bias', 'decoder.layers.15.mlp.gate_proj.weight', 'decoder.layers.15.mlp.layer_norm.bias', 'decoder.layers.15.mlp.layer_norm.weight', 'decoder.layers.15.self_attn.k_proj.bias', 'decoder.layers.15.self_attn.k_proj.weight', 'decoder.layers.15.self_attn.o_proj.bias', 'decoder.layers.15.self_attn.o_proj.weight', 'decoder.layers.15.self_attn.q_proj.bias', 'decoder.layers.15.self_attn.q_proj.weight', 'decoder.layers.15.self_attn.scaling', 'decoder.layers.15.self_attn.v_proj.bias', 'decoder.layers.15.self_attn.v_proj.weight', 'decoder.layers.16.input_layernorm.weight', 'decoder.layers.16.mlp.down_proj.bias', 'decoder.layers.16.mlp.down_proj.weight', 'decoder.layers.16.mlp.gate_proj.bias', 'decoder.layers.16.mlp.gate_proj.weight', 'decoder.layers.16.mlp.layer_norm.bias', 'decoder.layers.16.mlp.layer_norm.weight', 'decoder.layers.16.self_attn.k_proj.bias', 'decoder.layers.16.self_attn.k_proj.weight', 'decoder.layers.16.self_attn.o_proj.bias', 'decoder.layers.16.self_attn.o_proj.weight', 'decoder.layers.16.self_attn.q_proj.bias', 'decoder.layers.16.self_attn.q_proj.weight', 'decoder.layers.16.self_attn.scaling', 'decoder.layers.16.self_attn.v_proj.bias', 'decoder.layers.16.self_attn.v_proj.weight', 'decoder.layers.17.input_layernorm.weight', 'decoder.layers.17.mlp.down_proj.bias', 'decoder.layers.17.mlp.down_proj.weight', 'decoder.layers.17.mlp.gate_proj.bias', 'decoder.layers.17.mlp.gate_proj.weight', 'decoder.layers.17.mlp.layer_norm.bias', 'decoder.layers.17.mlp.layer_norm.weight', 'decoder.layers.17.self_attn.k_proj.bias', 'decoder.layers.17.self_attn.k_proj.weight', 'decoder.layers.17.self_attn.o_proj.bias', 'decoder.layers.17.self_attn.o_proj.weight', 'decoder.layers.17.self_attn.q_proj.bias', 'decoder.layers.17.self_attn.q_proj.weight', 'decoder.layers.17.self_attn.scaling', 'decoder.layers.17.self_attn.v_proj.bias', 'decoder.layers.17.self_attn.v_proj.weight', 'decoder.layers.18.input_layernorm.weight', 'decoder.layers.18.mlp.down_proj.bias', 'decoder.layers.18.mlp.down_proj.weight', 'decoder.layers.18.mlp.gate_proj.bias', 'decoder.layers.18.mlp.gate_proj.weight', 'decoder.layers.18.mlp.layer_norm.bias', 'decoder.layers.18.mlp.layer_norm.weight', 'decoder.layers.18.self_attn.k_proj.bias', 'decoder.layers.18.self_attn.k_proj.weight', 'decoder.layers.18.self_attn.o_proj.bias', 'decoder.layers.18.self_attn.o_proj.weight', 'decoder.layers.18.self_attn.q_proj.bias', 'decoder.layers.18.self_attn.q_proj.weight', 'decoder.layers.18.self_attn.scaling', 'decoder.layers.18.self_attn.v_proj.bias', 'decoder.layers.18.self_attn.v_proj.weight', 'decoder.layers.19.input_layernorm.weight', 'decoder.layers.19.mlp.down_proj.bias', 'decoder.layers.19.mlp.down_proj.weight', 'decoder.layers.19.mlp.gate_proj.bias', 'decoder.layers.19.mlp.gate_proj.weight', 'decoder.layers.19.mlp.layer_norm.bias', 'decoder.layers.19.mlp.layer_norm.weight', 'decoder.layers.19.self_attn.k_proj.bias', 'decoder.layers.19.self_attn.k_proj.weight', 'decoder.layers.19.self_attn.o_proj.bias', 'decoder.layers.19.self_attn.o_proj.weight', 'decoder.layers.19.self_attn.q_proj.bias', 'decoder.layers.19.self_attn.q_proj.weight', 'decoder.layers.19.self_attn.scaling', 'decoder.layers.19.self_attn.v_proj.bias', 'decoder.layers.19.self_attn.v_proj.weight', 'decoder.layers.2.input_layernorm.weight', 'decoder.layers.2.mlp.down_proj.bias', 'decoder.layers.2.mlp.down_proj.weight', 'decoder.layers.2.mlp.gate_proj.bias', 'decoder.layers.2.mlp.gate_proj.weight', 'decoder.layers.2.mlp.layer_norm.bias', 'decoder.layers.2.mlp.layer_norm.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.o_proj.bias', 'decoder.layers.2.self_attn.o_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.scaling', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.3.input_layernorm.weight', 'decoder.layers.3.mlp.down_proj.bias', 'decoder.layers.3.mlp.down_proj.weight', 'decoder.layers.3.mlp.gate_proj.bias', 'decoder.layers.3.mlp.gate_proj.weight', 'decoder.layers.3.mlp.layer_norm.bias', 'decoder.layers.3.mlp.layer_norm.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.o_proj.bias', 'decoder.layers.3.self_attn.o_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.scaling', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.4.input_layernorm.weight', 'decoder.layers.4.mlp.down_proj.bias', 'decoder.layers.4.mlp.down_proj.weight', 'decoder.layers.4.mlp.gate_proj.bias', 'decoder.layers.4.mlp.gate_proj.weight', 'decoder.layers.4.mlp.layer_norm.bias', 'decoder.layers.4.mlp.layer_norm.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.o_proj.bias', 'decoder.layers.4.self_attn.o_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.scaling', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.5.input_layernorm.weight', 'decoder.layers.5.mlp.down_proj.bias', 'decoder.layers.5.mlp.down_proj.weight', 'decoder.layers.5.mlp.gate_proj.bias', 'decoder.layers.5.mlp.gate_proj.weight', 'decoder.layers.5.mlp.layer_norm.bias', 'decoder.layers.5.mlp.layer_norm.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.o_proj.bias', 'decoder.layers.5.self_attn.o_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.scaling', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.6.input_layernorm.weight', 'decoder.layers.6.mlp.down_proj.bias', 'decoder.layers.6.mlp.down_proj.weight', 'decoder.layers.6.mlp.gate_proj.bias', 'decoder.layers.6.mlp.gate_proj.weight', 'decoder.layers.6.mlp.layer_norm.bias', 'decoder.layers.6.mlp.layer_norm.weight', 'decoder.layers.6.self_attn.k_proj.bias', 'decoder.layers.6.self_attn.k_proj.weight', 'decoder.layers.6.self_attn.o_proj.bias', 'decoder.layers.6.self_attn.o_proj.weight', 'decoder.layers.6.self_attn.q_proj.bias', 'decoder.layers.6.self_attn.q_proj.weight', 'decoder.layers.6.self_attn.scaling', 'decoder.layers.6.self_attn.v_proj.bias', 'decoder.layers.6.self_attn.v_proj.weight', 'decoder.layers.7.input_layernorm.weight', 'decoder.layers.7.mlp.down_proj.bias', 'decoder.layers.7.mlp.down_proj.weight', 'decoder.layers.7.mlp.gate_proj.bias', 'decoder.layers.7.mlp.gate_proj.weight', 'decoder.layers.7.mlp.layer_norm.bias', 'decoder.layers.7.mlp.layer_norm.weight', 'decoder.layers.7.self_attn.k_proj.bias', 'decoder.layers.7.self_attn.k_proj.weight', 'decoder.layers.7.self_attn.o_proj.bias', 'decoder.layers.7.self_attn.o_proj.weight', 'decoder.layers.7.self_attn.q_proj.bias', 'decoder.layers.7.self_attn.q_proj.weight', 'decoder.layers.7.self_attn.scaling', 'decoder.layers.7.self_attn.v_proj.bias', 'decoder.layers.7.self_attn.v_proj.weight', 'decoder.layers.8.input_layernorm.weight', 'decoder.layers.8.mlp.down_proj.bias', 'decoder.layers.8.mlp.down_proj.weight', 'decoder.layers.8.mlp.gate_proj.bias', 'decoder.layers.8.mlp.gate_proj.weight', 'decoder.layers.8.mlp.layer_norm.bias', 'decoder.layers.8.mlp.layer_norm.weight', 'decoder.layers.8.self_attn.k_proj.bias', 'decoder.layers.8.self_attn.k_proj.weight', 'decoder.layers.8.self_attn.o_proj.bias', 'decoder.layers.8.self_attn.o_proj.weight', 'decoder.layers.8.self_attn.q_proj.bias', 'decoder.layers.8.self_attn.q_proj.weight', 'decoder.layers.8.self_attn.scaling', 'decoder.layers.8.self_attn.v_proj.bias', 'decoder.layers.8.self_attn.v_proj.weight', 'decoder.layers.9.input_layernorm.weight', 'decoder.layers.9.mlp.down_proj.bias', 'decoder.layers.9.mlp.down_proj.weight', 'decoder.layers.9.mlp.gate_proj.bias', 'decoder.layers.9.mlp.gate_proj.weight', 'decoder.layers.9.mlp.layer_norm.bias', 'decoder.layers.9.mlp.layer_norm.weight', 'decoder.layers.9.self_attn.k_proj.bias', 'decoder.layers.9.self_attn.k_proj.weight', 'decoder.layers.9.self_attn.o_proj.bias', 'decoder.layers.9.self_attn.o_proj.weight', 'decoder.layers.9.self_attn.q_proj.bias', 'decoder.layers.9.self_attn.q_proj.weight', 'decoder.layers.9.self_attn.scaling', 'decoder.layers.9.self_attn.v_proj.bias', 'decoder.layers.9.self_attn.v_proj.weight', 'horizon_ff_layer.input_layer.bias', 'horizon_ff_layer.input_layer.weight', 'horizon_ff_layer.output_layer.bias', 'horizon_ff_layer.output_layer.weight', 'horizon_ff_layer.residual_layer.bias', 'horizon_ff_layer.residual_layer.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n",
            "  Epoch 1/100 train_loss=2.6537 train_acc=0.3564 eval_loss=1.5694 eval_acc=0.6547 (best)\n",
            "  Epoch 2/100 train_loss=1.1193 train_acc=0.7410 eval_loss=0.9079 eval_acc=0.7928 (best)\n",
            "  Epoch 3/100 train_loss=0.4497 train_acc=0.8744 eval_loss=0.7131 eval_acc=0.7749 (best)\n",
            "  Epoch 4/100 train_loss=0.2463 train_acc=0.9256 eval_loss=0.6595 eval_acc=0.8031 (best)\n",
            "  Epoch 5/100 train_loss=0.2315 train_acc=0.9333 eval_loss=0.6206 eval_acc=0.8005 (best)\n",
            "  Epoch 6/100 train_loss=0.1256 train_acc=0.9538 eval_loss=0.6454 eval_acc=0.8107 \n",
            "  Epoch 7/100 train_loss=0.1225 train_acc=0.9692 eval_loss=0.9166 eval_acc=0.7647 \n",
            "  Epoch 8/100 train_loss=0.2741 train_acc=0.9231 eval_loss=0.8148 eval_acc=0.7724 \n",
            "  Epoch 9/100 train_loss=0.1003 train_acc=0.9795 eval_loss=0.8239 eval_acc=0.7980 \n",
            "  Epoch 10/100 train_loss=0.1040 train_acc=0.9615 eval_loss=0.9930 eval_acc=0.7852 \n",
            "  Epoch 11/100 train_loss=0.2017 train_acc=0.9462 eval_loss=0.8558 eval_acc=0.7877 \n",
            "  Epoch 12/100 train_loss=0.1192 train_acc=0.9564 eval_loss=0.8176 eval_acc=0.8210 \n",
            "  Epoch 13/100 train_loss=0.0702 train_acc=0.9769 eval_loss=1.2009 eval_acc=0.7724 \n",
            "  Epoch 14/100 train_loss=0.0903 train_acc=0.9718 eval_loss=0.8111 eval_acc=0.8235 \n",
            "  Epoch 15/100 train_loss=0.0974 train_acc=0.9641 eval_loss=1.2515 eval_acc=0.8031 \n",
            "  Early stopping on google/timesfm-2.5-200m-pytorch: no improvement for 10 epochs (best epoch = 5)\n",
            "    tfm[google/timesfm-2.5-200m-pytorch] train_acc=0.9333 eval_acc=0.80306905370843995051188812794862315058708191\n",
            "    mrh_acc=0.8696 mr+h+kg_acc=0.8747 kg_acc=0.8798 ensemble=0.8721 (w=0.60)\n",
            "  Split 1/1 - accuracy=0.8721 time=357.6s\n",
            "Completed Adiac: Mean Acc=0.8721\n",
            "\n",
            "=== 3/109 ArrowHead ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  Decision: Heuristic says no filter (clean signal (no filtering))\n",
            "\n",
            "=== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at google/timesfm-2.5-200m-pytorch were not used when initializing TimesFmModelForPrediction: ['output_projection_point.hidden_layer.weight', 'output_projection_point.output_layer.weight', 'output_projection_point.residual_layer.weight', 'output_projection_quantiles.hidden_layer.weight', 'output_projection_quantiles.output_layer.weight', 'output_projection_quantiles.residual_layer.weight', 'stacked_xf.0.attn.key_ln.scale', 'stacked_xf.0.attn.out.weight', 'stacked_xf.0.attn.per_dim_scale.per_dim_scale', 'stacked_xf.0.attn.qkv_proj.weight', 'stacked_xf.0.attn.query_ln.scale', 'stacked_xf.0.ff0.weight', 'stacked_xf.0.ff1.weight', 'stacked_xf.0.post_attn_ln.scale', 'stacked_xf.0.post_ff_ln.scale', 'stacked_xf.0.pre_attn_ln.scale', 'stacked_xf.0.pre_ff_ln.scale', 'stacked_xf.1.attn.key_ln.scale', 'stacked_xf.1.attn.out.weight', 'stacked_xf.1.attn.per_dim_scale.per_dim_scale', 'stacked_xf.1.attn.qkv_proj.weight', 'stacked_xf.1.attn.query_ln.scale', 'stacked_xf.1.ff0.weight', 'stacked_xf.1.ff1.weight', 'stacked_xf.1.post_attn_ln.scale', 'stacked_xf.1.post_ff_ln.scale', 'stacked_xf.1.pre_attn_ln.scale', 'stacked_xf.1.pre_ff_ln.scale', 'stacked_xf.10.attn.key_ln.scale', 'stacked_xf.10.attn.out.weight', 'stacked_xf.10.attn.per_dim_scale.per_dim_scale', 'stacked_xf.10.attn.qkv_proj.weight', 'stacked_xf.10.attn.query_ln.scale', 'stacked_xf.10.ff0.weight', 'stacked_xf.10.ff1.weight', 'stacked_xf.10.post_attn_ln.scale', 'stacked_xf.10.post_ff_ln.scale', 'stacked_xf.10.pre_attn_ln.scale', 'stacked_xf.10.pre_ff_ln.scale', 'stacked_xf.11.attn.key_ln.scale', 'stacked_xf.11.attn.out.weight', 'stacked_xf.11.attn.per_dim_scale.per_dim_scale', 'stacked_xf.11.attn.qkv_proj.weight', 'stacked_xf.11.attn.query_ln.scale', 'stacked_xf.11.ff0.weight', 'stacked_xf.11.ff1.weight', 'stacked_xf.11.post_attn_ln.scale', 'stacked_xf.11.post_ff_ln.scale', 'stacked_xf.11.pre_attn_ln.scale', 'stacked_xf.11.pre_ff_ln.scale', 'stacked_xf.12.attn.key_ln.scale', 'stacked_xf.12.attn.out.weight', 'stacked_xf.12.attn.per_dim_scale.per_dim_scale', 'stacked_xf.12.attn.qkv_proj.weight', 'stacked_xf.12.attn.query_ln.scale', 'stacked_xf.12.ff0.weight', 'stacked_xf.12.ff1.weight', 'stacked_xf.12.post_attn_ln.scale', 'stacked_xf.12.post_ff_ln.scale', 'stacked_xf.12.pre_attn_ln.scale', 'stacked_xf.12.pre_ff_ln.scale', 'stacked_xf.13.attn.key_ln.scale', 'stacked_xf.13.attn.out.weight', 'stacked_xf.13.attn.per_dim_scale.per_dim_scale', 'stacked_xf.13.attn.qkv_proj.weight', 'stacked_xf.13.attn.query_ln.scale', 'stacked_xf.13.ff0.weight', 'stacked_xf.13.ff1.weight', 'stacked_xf.13.post_attn_ln.scale', 'stacked_xf.13.post_ff_ln.scale', 'stacked_xf.13.pre_attn_ln.scale', 'stacked_xf.13.pre_ff_ln.scale', 'stacked_xf.14.attn.key_ln.scale', 'stacked_xf.14.attn.out.weight', 'stacked_xf.14.attn.per_dim_scale.per_dim_scale', 'stacked_xf.14.attn.qkv_proj.weight', 'stacked_xf.14.attn.query_ln.scale', 'stacked_xf.14.ff0.weight', 'stacked_xf.14.ff1.weight', 'stacked_xf.14.post_attn_ln.scale', 'stacked_xf.14.post_ff_ln.scale', 'stacked_xf.14.pre_attn_ln.scale', 'stacked_xf.14.pre_ff_ln.scale', 'stacked_xf.15.attn.key_ln.scale', 'stacked_xf.15.attn.out.weight', 'stacked_xf.15.attn.per_dim_scale.per_dim_scale', 'stacked_xf.15.attn.qkv_proj.weight', 'stacked_xf.15.attn.query_ln.scale', 'stacked_xf.15.ff0.weight', 'stacked_xf.15.ff1.weight', 'stacked_xf.15.post_attn_ln.scale', 'stacked_xf.15.post_ff_ln.scale', 'stacked_xf.15.pre_attn_ln.scale', 'stacked_xf.15.pre_ff_ln.scale', 'stacked_xf.16.attn.key_ln.scale', 'stacked_xf.16.attn.out.weight', 'stacked_xf.16.attn.per_dim_scale.per_dim_scale', 'stacked_xf.16.attn.qkv_proj.weight', 'stacked_xf.16.attn.query_ln.scale', 'stacked_xf.16.ff0.weight', 'stacked_xf.16.ff1.weight', 'stacked_xf.16.post_attn_ln.scale', 'stacked_xf.16.post_ff_ln.scale', 'stacked_xf.16.pre_attn_ln.scale', 'stacked_xf.16.pre_ff_ln.scale', 'stacked_xf.17.attn.key_ln.scale', 'stacked_xf.17.attn.out.weight', 'stacked_xf.17.attn.per_dim_scale.per_dim_scale', 'stacked_xf.17.attn.qkv_proj.weight', 'stacked_xf.17.attn.query_ln.scale', 'stacked_xf.17.ff0.weight', 'stacked_xf.17.ff1.weight', 'stacked_xf.17.post_attn_ln.scale', 'stacked_xf.17.post_ff_ln.scale', 'stacked_xf.17.pre_attn_ln.scale', 'stacked_xf.17.pre_ff_ln.scale', 'stacked_xf.18.attn.key_ln.scale', 'stacked_xf.18.attn.out.weight', 'stacked_xf.18.attn.per_dim_scale.per_dim_scale', 'stacked_xf.18.attn.qkv_proj.weight', 'stacked_xf.18.attn.query_ln.scale', 'stacked_xf.18.ff0.weight', 'stacked_xf.18.ff1.weight', 'stacked_xf.18.post_attn_ln.scale', 'stacked_xf.18.post_ff_ln.scale', 'stacked_xf.18.pre_attn_ln.scale', 'stacked_xf.18.pre_ff_ln.scale', 'stacked_xf.19.attn.key_ln.scale', 'stacked_xf.19.attn.out.weight', 'stacked_xf.19.attn.per_dim_scale.per_dim_scale', 'stacked_xf.19.attn.qkv_proj.weight', 'stacked_xf.19.attn.query_ln.scale', 'stacked_xf.19.ff0.weight', 'stacked_xf.19.ff1.weight', 'stacked_xf.19.post_attn_ln.scale', 'stacked_xf.19.post_ff_ln.scale', 'stacked_xf.19.pre_attn_ln.scale', 'stacked_xf.19.pre_ff_ln.scale', 'stacked_xf.2.attn.key_ln.scale', 'stacked_xf.2.attn.out.weight', 'stacked_xf.2.attn.per_dim_scale.per_dim_scale', 'stacked_xf.2.attn.qkv_proj.weight', 'stacked_xf.2.attn.query_ln.scale', 'stacked_xf.2.ff0.weight', 'stacked_xf.2.ff1.weight', 'stacked_xf.2.post_attn_ln.scale', 'stacked_xf.2.post_ff_ln.scale', 'stacked_xf.2.pre_attn_ln.scale', 'stacked_xf.2.pre_ff_ln.scale', 'stacked_xf.3.attn.key_ln.scale', 'stacked_xf.3.attn.out.weight', 'stacked_xf.3.attn.per_dim_scale.per_dim_scale', 'stacked_xf.3.attn.qkv_proj.weight', 'stacked_xf.3.attn.query_ln.scale', 'stacked_xf.3.ff0.weight', 'stacked_xf.3.ff1.weight', 'stacked_xf.3.post_attn_ln.scale', 'stacked_xf.3.post_ff_ln.scale', 'stacked_xf.3.pre_attn_ln.scale', 'stacked_xf.3.pre_ff_ln.scale', 'stacked_xf.4.attn.key_ln.scale', 'stacked_xf.4.attn.out.weight', 'stacked_xf.4.attn.per_dim_scale.per_dim_scale', 'stacked_xf.4.attn.qkv_proj.weight', 'stacked_xf.4.attn.query_ln.scale', 'stacked_xf.4.ff0.weight', 'stacked_xf.4.ff1.weight', 'stacked_xf.4.post_attn_ln.scale', 'stacked_xf.4.post_ff_ln.scale', 'stacked_xf.4.pre_attn_ln.scale', 'stacked_xf.4.pre_ff_ln.scale', 'stacked_xf.5.attn.key_ln.scale', 'stacked_xf.5.attn.out.weight', 'stacked_xf.5.attn.per_dim_scale.per_dim_scale', 'stacked_xf.5.attn.qkv_proj.weight', 'stacked_xf.5.attn.query_ln.scale', 'stacked_xf.5.ff0.weight', 'stacked_xf.5.ff1.weight', 'stacked_xf.5.post_attn_ln.scale', 'stacked_xf.5.post_ff_ln.scale', 'stacked_xf.5.pre_attn_ln.scale', 'stacked_xf.5.pre_ff_ln.scale', 'stacked_xf.6.attn.key_ln.scale', 'stacked_xf.6.attn.out.weight', 'stacked_xf.6.attn.per_dim_scale.per_dim_scale', 'stacked_xf.6.attn.qkv_proj.weight', 'stacked_xf.6.attn.query_ln.scale', 'stacked_xf.6.ff0.weight', 'stacked_xf.6.ff1.weight', 'stacked_xf.6.post_attn_ln.scale', 'stacked_xf.6.post_ff_ln.scale', 'stacked_xf.6.pre_attn_ln.scale', 'stacked_xf.6.pre_ff_ln.scale', 'stacked_xf.7.attn.key_ln.scale', 'stacked_xf.7.attn.out.weight', 'stacked_xf.7.attn.per_dim_scale.per_dim_scale', 'stacked_xf.7.attn.qkv_proj.weight', 'stacked_xf.7.attn.query_ln.scale', 'stacked_xf.7.ff0.weight', 'stacked_xf.7.ff1.weight', 'stacked_xf.7.post_attn_ln.scale', 'stacked_xf.7.post_ff_ln.scale', 'stacked_xf.7.pre_attn_ln.scale', 'stacked_xf.7.pre_ff_ln.scale', 'stacked_xf.8.attn.key_ln.scale', 'stacked_xf.8.attn.out.weight', 'stacked_xf.8.attn.per_dim_scale.per_dim_scale', 'stacked_xf.8.attn.qkv_proj.weight', 'stacked_xf.8.attn.query_ln.scale', 'stacked_xf.8.ff0.weight', 'stacked_xf.8.ff1.weight', 'stacked_xf.8.post_attn_ln.scale', 'stacked_xf.8.post_ff_ln.scale', 'stacked_xf.8.pre_attn_ln.scale', 'stacked_xf.8.pre_ff_ln.scale', 'stacked_xf.9.attn.key_ln.scale', 'stacked_xf.9.attn.out.weight', 'stacked_xf.9.attn.per_dim_scale.per_dim_scale', 'stacked_xf.9.attn.qkv_proj.weight', 'stacked_xf.9.attn.query_ln.scale', 'stacked_xf.9.ff0.weight', 'stacked_xf.9.ff1.weight', 'stacked_xf.9.post_attn_ln.scale', 'stacked_xf.9.post_ff_ln.scale', 'stacked_xf.9.pre_attn_ln.scale', 'stacked_xf.9.pre_ff_ln.scale', 'tokenizer.hidden_layer.bias', 'tokenizer.hidden_layer.weight', 'tokenizer.output_layer.bias', 'tokenizer.output_layer.weight', 'tokenizer.residual_layer.bias', 'tokenizer.residual_layer.weight']\n",
            "- This IS expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of TimesFmModelForPrediction were not initialized from the model checkpoint at google/timesfm-2.5-200m-pytorch and are newly initialized: ['decoder.freq_emb.weight', 'decoder.input_ff_layer.input_layer.bias', 'decoder.input_ff_layer.input_layer.weight', 'decoder.input_ff_layer.output_layer.bias', 'decoder.input_ff_layer.output_layer.weight', 'decoder.input_ff_layer.residual_layer.bias', 'decoder.input_ff_layer.residual_layer.weight', 'decoder.layers.0.input_layernorm.weight', 'decoder.layers.0.mlp.down_proj.bias', 'decoder.layers.0.mlp.down_proj.weight', 'decoder.layers.0.mlp.gate_proj.bias', 'decoder.layers.0.mlp.gate_proj.weight', 'decoder.layers.0.mlp.layer_norm.bias', 'decoder.layers.0.mlp.layer_norm.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.o_proj.bias', 'decoder.layers.0.self_attn.o_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.scaling', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.1.input_layernorm.weight', 'decoder.layers.1.mlp.down_proj.bias', 'decoder.layers.1.mlp.down_proj.weight', 'decoder.layers.1.mlp.gate_proj.bias', 'decoder.layers.1.mlp.gate_proj.weight', 'decoder.layers.1.mlp.layer_norm.bias', 'decoder.layers.1.mlp.layer_norm.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.o_proj.bias', 'decoder.layers.1.self_attn.o_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.scaling', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.10.input_layernorm.weight', 'decoder.layers.10.mlp.down_proj.bias', 'decoder.layers.10.mlp.down_proj.weight', 'decoder.layers.10.mlp.gate_proj.bias', 'decoder.layers.10.mlp.gate_proj.weight', 'decoder.layers.10.mlp.layer_norm.bias', 'decoder.layers.10.mlp.layer_norm.weight', 'decoder.layers.10.self_attn.k_proj.bias', 'decoder.layers.10.self_attn.k_proj.weight', 'decoder.layers.10.self_attn.o_proj.bias', 'decoder.layers.10.self_attn.o_proj.weight', 'decoder.layers.10.self_attn.q_proj.bias', 'decoder.layers.10.self_attn.q_proj.weight', 'decoder.layers.10.self_attn.scaling', 'decoder.layers.10.self_attn.v_proj.bias', 'decoder.layers.10.self_attn.v_proj.weight', 'decoder.layers.11.input_layernorm.weight', 'decoder.layers.11.mlp.down_proj.bias', 'decoder.layers.11.mlp.down_proj.weight', 'decoder.layers.11.mlp.gate_proj.bias', 'decoder.layers.11.mlp.gate_proj.weight', 'decoder.layers.11.mlp.layer_norm.bias', 'decoder.layers.11.mlp.layer_norm.weight', 'decoder.layers.11.self_attn.k_proj.bias', 'decoder.layers.11.self_attn.k_proj.weight', 'decoder.layers.11.self_attn.o_proj.bias', 'decoder.layers.11.self_attn.o_proj.weight', 'decoder.layers.11.self_attn.q_proj.bias', 'decoder.layers.11.self_attn.q_proj.weight', 'decoder.layers.11.self_attn.scaling', 'decoder.layers.11.self_attn.v_proj.bias', 'decoder.layers.11.self_attn.v_proj.weight', 'decoder.layers.12.input_layernorm.weight', 'decoder.layers.12.mlp.down_proj.bias', 'decoder.layers.12.mlp.down_proj.weight', 'decoder.layers.12.mlp.gate_proj.bias', 'decoder.layers.12.mlp.gate_proj.weight', 'decoder.layers.12.mlp.layer_norm.bias', 'decoder.layers.12.mlp.layer_norm.weight', 'decoder.layers.12.self_attn.k_proj.bias', 'decoder.layers.12.self_attn.k_proj.weight', 'decoder.layers.12.self_attn.o_proj.bias', 'decoder.layers.12.self_attn.o_proj.weight', 'decoder.layers.12.self_attn.q_proj.bias', 'decoder.layers.12.self_attn.q_proj.weight', 'decoder.layers.12.self_attn.scaling', 'decoder.layers.12.self_attn.v_proj.bias', 'decoder.layers.12.self_attn.v_proj.weight', 'decoder.layers.13.input_layernorm.weight', 'decoder.layers.13.mlp.down_proj.bias', 'decoder.layers.13.mlp.down_proj.weight', 'decoder.layers.13.mlp.gate_proj.bias', 'decoder.layers.13.mlp.gate_proj.weight', 'decoder.layers.13.mlp.layer_norm.bias', 'decoder.layers.13.mlp.layer_norm.weight', 'decoder.layers.13.self_attn.k_proj.bias', 'decoder.layers.13.self_attn.k_proj.weight', 'decoder.layers.13.self_attn.o_proj.bias', 'decoder.layers.13.self_attn.o_proj.weight', 'decoder.layers.13.self_attn.q_proj.bias', 'decoder.layers.13.self_attn.q_proj.weight', 'decoder.layers.13.self_attn.scaling', 'decoder.layers.13.self_attn.v_proj.bias', 'decoder.layers.13.self_attn.v_proj.weight', 'decoder.layers.14.input_layernorm.weight', 'decoder.layers.14.mlp.down_proj.bias', 'decoder.layers.14.mlp.down_proj.weight', 'decoder.layers.14.mlp.gate_proj.bias', 'decoder.layers.14.mlp.gate_proj.weight', 'decoder.layers.14.mlp.layer_norm.bias', 'decoder.layers.14.mlp.layer_norm.weight', 'decoder.layers.14.self_attn.k_proj.bias', 'decoder.layers.14.self_attn.k_proj.weight', 'decoder.layers.14.self_attn.o_proj.bias', 'decoder.layers.14.self_attn.o_proj.weight', 'decoder.layers.14.self_attn.q_proj.bias', 'decoder.layers.14.self_attn.q_proj.weight', 'decoder.layers.14.self_attn.scaling', 'decoder.layers.14.self_attn.v_proj.bias', 'decoder.layers.14.self_attn.v_proj.weight', 'decoder.layers.15.input_layernorm.weight', 'decoder.layers.15.mlp.down_proj.bias', 'decoder.layers.15.mlp.down_proj.weight', 'decoder.layers.15.mlp.gate_proj.bias', 'decoder.layers.15.mlp.gate_proj.weight', 'decoder.layers.15.mlp.layer_norm.bias', 'decoder.layers.15.mlp.layer_norm.weight', 'decoder.layers.15.self_attn.k_proj.bias', 'decoder.layers.15.self_attn.k_proj.weight', 'decoder.layers.15.self_attn.o_proj.bias', 'decoder.layers.15.self_attn.o_proj.weight', 'decoder.layers.15.self_attn.q_proj.bias', 'decoder.layers.15.self_attn.q_proj.weight', 'decoder.layers.15.self_attn.scaling', 'decoder.layers.15.self_attn.v_proj.bias', 'decoder.layers.15.self_attn.v_proj.weight', 'decoder.layers.16.input_layernorm.weight', 'decoder.layers.16.mlp.down_proj.bias', 'decoder.layers.16.mlp.down_proj.weight', 'decoder.layers.16.mlp.gate_proj.bias', 'decoder.layers.16.mlp.gate_proj.weight', 'decoder.layers.16.mlp.layer_norm.bias', 'decoder.layers.16.mlp.layer_norm.weight', 'decoder.layers.16.self_attn.k_proj.bias', 'decoder.layers.16.self_attn.k_proj.weight', 'decoder.layers.16.self_attn.o_proj.bias', 'decoder.layers.16.self_attn.o_proj.weight', 'decoder.layers.16.self_attn.q_proj.bias', 'decoder.layers.16.self_attn.q_proj.weight', 'decoder.layers.16.self_attn.scaling', 'decoder.layers.16.self_attn.v_proj.bias', 'decoder.layers.16.self_attn.v_proj.weight', 'decoder.layers.17.input_layernorm.weight', 'decoder.layers.17.mlp.down_proj.bias', 'decoder.layers.17.mlp.down_proj.weight', 'decoder.layers.17.mlp.gate_proj.bias', 'decoder.layers.17.mlp.gate_proj.weight', 'decoder.layers.17.mlp.layer_norm.bias', 'decoder.layers.17.mlp.layer_norm.weight', 'decoder.layers.17.self_attn.k_proj.bias', 'decoder.layers.17.self_attn.k_proj.weight', 'decoder.layers.17.self_attn.o_proj.bias', 'decoder.layers.17.self_attn.o_proj.weight', 'decoder.layers.17.self_attn.q_proj.bias', 'decoder.layers.17.self_attn.q_proj.weight', 'decoder.layers.17.self_attn.scaling', 'decoder.layers.17.self_attn.v_proj.bias', 'decoder.layers.17.self_attn.v_proj.weight', 'decoder.layers.18.input_layernorm.weight', 'decoder.layers.18.mlp.down_proj.bias', 'decoder.layers.18.mlp.down_proj.weight', 'decoder.layers.18.mlp.gate_proj.bias', 'decoder.layers.18.mlp.gate_proj.weight', 'decoder.layers.18.mlp.layer_norm.bias', 'decoder.layers.18.mlp.layer_norm.weight', 'decoder.layers.18.self_attn.k_proj.bias', 'decoder.layers.18.self_attn.k_proj.weight', 'decoder.layers.18.self_attn.o_proj.bias', 'decoder.layers.18.self_attn.o_proj.weight', 'decoder.layers.18.self_attn.q_proj.bias', 'decoder.layers.18.self_attn.q_proj.weight', 'decoder.layers.18.self_attn.scaling', 'decoder.layers.18.self_attn.v_proj.bias', 'decoder.layers.18.self_attn.v_proj.weight', 'decoder.layers.19.input_layernorm.weight', 'decoder.layers.19.mlp.down_proj.bias', 'decoder.layers.19.mlp.down_proj.weight', 'decoder.layers.19.mlp.gate_proj.bias', 'decoder.layers.19.mlp.gate_proj.weight', 'decoder.layers.19.mlp.layer_norm.bias', 'decoder.layers.19.mlp.layer_norm.weight', 'decoder.layers.19.self_attn.k_proj.bias', 'decoder.layers.19.self_attn.k_proj.weight', 'decoder.layers.19.self_attn.o_proj.bias', 'decoder.layers.19.self_attn.o_proj.weight', 'decoder.layers.19.self_attn.q_proj.bias', 'decoder.layers.19.self_attn.q_proj.weight', 'decoder.layers.19.self_attn.scaling', 'decoder.layers.19.self_attn.v_proj.bias', 'decoder.layers.19.self_attn.v_proj.weight', 'decoder.layers.2.input_layernorm.weight', 'decoder.layers.2.mlp.down_proj.bias', 'decoder.layers.2.mlp.down_proj.weight', 'decoder.layers.2.mlp.gate_proj.bias', 'decoder.layers.2.mlp.gate_proj.weight', 'decoder.layers.2.mlp.layer_norm.bias', 'decoder.layers.2.mlp.layer_norm.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.o_proj.bias', 'decoder.layers.2.self_attn.o_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.scaling', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.3.input_layernorm.weight', 'decoder.layers.3.mlp.down_proj.bias', 'decoder.layers.3.mlp.down_proj.weight', 'decoder.layers.3.mlp.gate_proj.bias', 'decoder.layers.3.mlp.gate_proj.weight', 'decoder.layers.3.mlp.layer_norm.bias', 'decoder.layers.3.mlp.layer_norm.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.o_proj.bias', 'decoder.layers.3.self_attn.o_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.scaling', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.4.input_layernorm.weight', 'decoder.layers.4.mlp.down_proj.bias', 'decoder.layers.4.mlp.down_proj.weight', 'decoder.layers.4.mlp.gate_proj.bias', 'decoder.layers.4.mlp.gate_proj.weight', 'decoder.layers.4.mlp.layer_norm.bias', 'decoder.layers.4.mlp.layer_norm.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.o_proj.bias', 'decoder.layers.4.self_attn.o_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.scaling', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.5.input_layernorm.weight', 'decoder.layers.5.mlp.down_proj.bias', 'decoder.layers.5.mlp.down_proj.weight', 'decoder.layers.5.mlp.gate_proj.bias', 'decoder.layers.5.mlp.gate_proj.weight', 'decoder.layers.5.mlp.layer_norm.bias', 'decoder.layers.5.mlp.layer_norm.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.o_proj.bias', 'decoder.layers.5.self_attn.o_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.scaling', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.6.input_layernorm.weight', 'decoder.layers.6.mlp.down_proj.bias', 'decoder.layers.6.mlp.down_proj.weight', 'decoder.layers.6.mlp.gate_proj.bias', 'decoder.layers.6.mlp.gate_proj.weight', 'decoder.layers.6.mlp.layer_norm.bias', 'decoder.layers.6.mlp.layer_norm.weight', 'decoder.layers.6.self_attn.k_proj.bias', 'decoder.layers.6.self_attn.k_proj.weight', 'decoder.layers.6.self_attn.o_proj.bias', 'decoder.layers.6.self_attn.o_proj.weight', 'decoder.layers.6.self_attn.q_proj.bias', 'decoder.layers.6.self_attn.q_proj.weight', 'decoder.layers.6.self_attn.scaling', 'decoder.layers.6.self_attn.v_proj.bias', 'decoder.layers.6.self_attn.v_proj.weight', 'decoder.layers.7.input_layernorm.weight', 'decoder.layers.7.mlp.down_proj.bias', 'decoder.layers.7.mlp.down_proj.weight', 'decoder.layers.7.mlp.gate_proj.bias', 'decoder.layers.7.mlp.gate_proj.weight', 'decoder.layers.7.mlp.layer_norm.bias', 'decoder.layers.7.mlp.layer_norm.weight', 'decoder.layers.7.self_attn.k_proj.bias', 'decoder.layers.7.self_attn.k_proj.weight', 'decoder.layers.7.self_attn.o_proj.bias', 'decoder.layers.7.self_attn.o_proj.weight', 'decoder.layers.7.self_attn.q_proj.bias', 'decoder.layers.7.self_attn.q_proj.weight', 'decoder.layers.7.self_attn.scaling', 'decoder.layers.7.self_attn.v_proj.bias', 'decoder.layers.7.self_attn.v_proj.weight', 'decoder.layers.8.input_layernorm.weight', 'decoder.layers.8.mlp.down_proj.bias', 'decoder.layers.8.mlp.down_proj.weight', 'decoder.layers.8.mlp.gate_proj.bias', 'decoder.layers.8.mlp.gate_proj.weight', 'decoder.layers.8.mlp.layer_norm.bias', 'decoder.layers.8.mlp.layer_norm.weight', 'decoder.layers.8.self_attn.k_proj.bias', 'decoder.layers.8.self_attn.k_proj.weight', 'decoder.layers.8.self_attn.o_proj.bias', 'decoder.layers.8.self_attn.o_proj.weight', 'decoder.layers.8.self_attn.q_proj.bias', 'decoder.layers.8.self_attn.q_proj.weight', 'decoder.layers.8.self_attn.scaling', 'decoder.layers.8.self_attn.v_proj.bias', 'decoder.layers.8.self_attn.v_proj.weight', 'decoder.layers.9.input_layernorm.weight', 'decoder.layers.9.mlp.down_proj.bias', 'decoder.layers.9.mlp.down_proj.weight', 'decoder.layers.9.mlp.gate_proj.bias', 'decoder.layers.9.mlp.gate_proj.weight', 'decoder.layers.9.mlp.layer_norm.bias', 'decoder.layers.9.mlp.layer_norm.weight', 'decoder.layers.9.self_attn.k_proj.bias', 'decoder.layers.9.self_attn.k_proj.weight', 'decoder.layers.9.self_attn.o_proj.bias', 'decoder.layers.9.self_attn.o_proj.weight', 'decoder.layers.9.self_attn.q_proj.bias', 'decoder.layers.9.self_attn.q_proj.weight', 'decoder.layers.9.self_attn.scaling', 'decoder.layers.9.self_attn.v_proj.bias', 'decoder.layers.9.self_attn.v_proj.weight', 'horizon_ff_layer.input_layer.bias', 'horizon_ff_layer.input_layer.weight', 'horizon_ff_layer.output_layer.bias', 'horizon_ff_layer.output_layer.weight', 'horizon_ff_layer.residual_layer.bias', 'horizon_ff_layer.residual_layer.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n",
            "  Epoch 1/100 train_loss=1.0872 train_acc=0.3333 eval_loss=0.6903 eval_acc=0.7086 (best)\n",
            "  Epoch 2/100 train_loss=0.3811 train_acc=0.8333 eval_loss=0.7151 eval_acc=0.8000 \n",
            "  Epoch 3/100 train_loss=0.1282 train_acc=0.9722 eval_loss=0.5877 eval_acc=0.8514 (best)\n",
            "  Epoch 4/100 train_loss=0.0233 train_acc=1.0000 eval_loss=0.6536 eval_acc=0.8629 \n",
            "  Epoch 5/100 train_loss=0.0055 train_acc=1.0000 eval_loss=0.7508 eval_acc=0.8629 \n",
            "  Epoch 6/100 train_loss=0.0018 train_acc=1.0000 eval_loss=0.8415 eval_acc=0.8629 \n",
            "  Epoch 7/100 train_loss=0.0008 train_acc=1.0000 eval_loss=0.9261 eval_acc=0.8629 \n",
            "  Epoch 8/100 train_loss=0.0003 train_acc=1.0000 eval_loss=1.0132 eval_acc=0.8686 \n",
            "  Epoch 9/100 train_loss=0.0002 train_acc=1.0000 eval_loss=1.0984 eval_acc=0.8743 \n",
            "  Epoch 10/100 train_loss=0.0001 train_acc=1.0000 eval_loss=1.1802 eval_acc=0.8743 \n",
            "  Epoch 11/100 train_loss=0.0000 train_acc=1.0000 eval_loss=1.2552 eval_acc=0.8743 \n",
            "  Epoch 12/100 train_loss=0.0000 train_acc=1.0000 eval_loss=1.3179 eval_acc=0.8743 \n",
            "  Epoch 13/100 train_loss=0.0000 train_acc=1.0000 eval_loss=1.3702 eval_acc=0.8743 \n",
            "  Early stopping on google/timesfm-2.5-200m-pytorch: no improvement for 10 epochs (best epoch = 3)\n",
            "    tfm[google/timesfm-2.5-200m-pytorch] train_acc=0.9722 eval_acc=0.87428571428571433266085932700661942362785339\n",
            "    mrh_acc=0.8857 mr+h+kg_acc=0.8857 kg_acc=0.8800 ensemble=0.8857 (w=0.60)\n",
            "  Split 1/1 - accuracy=0.8857 time=60.9s\n",
            "Completed ArrowHead: Mean Acc=0.8857\n",
            "\n",
            "=== 4/109 Beef ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n",
            "    Gate split 1/5: baseline_loss=0.7581 adaptive_loss=0.7797\n",
            "    Gate split 2/5: baseline_loss=0.5902 adaptive_loss=0.6988\n",
            "    Gate split 3/5: baseline_loss=0.8962 adaptive_loss=0.7755\n",
            "    Gate split 4/5: baseline_loss=1.0219 adaptive_loss=0.9982\n",
            "    Gate split 5/5: baseline_loss=0.4929 adaptive_loss=0.7001\n",
            "  Decision: Adaptive rejected (loss 0.7905 vs baseline 0.7519, delta=+0.0386 > +0.0200); savgol(window=11, poly=2) - high noise (std_diff)\n",
            "\n",
            "=== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at google/timesfm-2.5-200m-pytorch were not used when initializing TimesFmModelForPrediction: ['output_projection_point.hidden_layer.weight', 'output_projection_point.output_layer.weight', 'output_projection_point.residual_layer.weight', 'output_projection_quantiles.hidden_layer.weight', 'output_projection_quantiles.output_layer.weight', 'output_projection_quantiles.residual_layer.weight', 'stacked_xf.0.attn.key_ln.scale', 'stacked_xf.0.attn.out.weight', 'stacked_xf.0.attn.per_dim_scale.per_dim_scale', 'stacked_xf.0.attn.qkv_proj.weight', 'stacked_xf.0.attn.query_ln.scale', 'stacked_xf.0.ff0.weight', 'stacked_xf.0.ff1.weight', 'stacked_xf.0.post_attn_ln.scale', 'stacked_xf.0.post_ff_ln.scale', 'stacked_xf.0.pre_attn_ln.scale', 'stacked_xf.0.pre_ff_ln.scale', 'stacked_xf.1.attn.key_ln.scale', 'stacked_xf.1.attn.out.weight', 'stacked_xf.1.attn.per_dim_scale.per_dim_scale', 'stacked_xf.1.attn.qkv_proj.weight', 'stacked_xf.1.attn.query_ln.scale', 'stacked_xf.1.ff0.weight', 'stacked_xf.1.ff1.weight', 'stacked_xf.1.post_attn_ln.scale', 'stacked_xf.1.post_ff_ln.scale', 'stacked_xf.1.pre_attn_ln.scale', 'stacked_xf.1.pre_ff_ln.scale', 'stacked_xf.10.attn.key_ln.scale', 'stacked_xf.10.attn.out.weight', 'stacked_xf.10.attn.per_dim_scale.per_dim_scale', 'stacked_xf.10.attn.qkv_proj.weight', 'stacked_xf.10.attn.query_ln.scale', 'stacked_xf.10.ff0.weight', 'stacked_xf.10.ff1.weight', 'stacked_xf.10.post_attn_ln.scale', 'stacked_xf.10.post_ff_ln.scale', 'stacked_xf.10.pre_attn_ln.scale', 'stacked_xf.10.pre_ff_ln.scale', 'stacked_xf.11.attn.key_ln.scale', 'stacked_xf.11.attn.out.weight', 'stacked_xf.11.attn.per_dim_scale.per_dim_scale', 'stacked_xf.11.attn.qkv_proj.weight', 'stacked_xf.11.attn.query_ln.scale', 'stacked_xf.11.ff0.weight', 'stacked_xf.11.ff1.weight', 'stacked_xf.11.post_attn_ln.scale', 'stacked_xf.11.post_ff_ln.scale', 'stacked_xf.11.pre_attn_ln.scale', 'stacked_xf.11.pre_ff_ln.scale', 'stacked_xf.12.attn.key_ln.scale', 'stacked_xf.12.attn.out.weight', 'stacked_xf.12.attn.per_dim_scale.per_dim_scale', 'stacked_xf.12.attn.qkv_proj.weight', 'stacked_xf.12.attn.query_ln.scale', 'stacked_xf.12.ff0.weight', 'stacked_xf.12.ff1.weight', 'stacked_xf.12.post_attn_ln.scale', 'stacked_xf.12.post_ff_ln.scale', 'stacked_xf.12.pre_attn_ln.scale', 'stacked_xf.12.pre_ff_ln.scale', 'stacked_xf.13.attn.key_ln.scale', 'stacked_xf.13.attn.out.weight', 'stacked_xf.13.attn.per_dim_scale.per_dim_scale', 'stacked_xf.13.attn.qkv_proj.weight', 'stacked_xf.13.attn.query_ln.scale', 'stacked_xf.13.ff0.weight', 'stacked_xf.13.ff1.weight', 'stacked_xf.13.post_attn_ln.scale', 'stacked_xf.13.post_ff_ln.scale', 'stacked_xf.13.pre_attn_ln.scale', 'stacked_xf.13.pre_ff_ln.scale', 'stacked_xf.14.attn.key_ln.scale', 'stacked_xf.14.attn.out.weight', 'stacked_xf.14.attn.per_dim_scale.per_dim_scale', 'stacked_xf.14.attn.qkv_proj.weight', 'stacked_xf.14.attn.query_ln.scale', 'stacked_xf.14.ff0.weight', 'stacked_xf.14.ff1.weight', 'stacked_xf.14.post_attn_ln.scale', 'stacked_xf.14.post_ff_ln.scale', 'stacked_xf.14.pre_attn_ln.scale', 'stacked_xf.14.pre_ff_ln.scale', 'stacked_xf.15.attn.key_ln.scale', 'stacked_xf.15.attn.out.weight', 'stacked_xf.15.attn.per_dim_scale.per_dim_scale', 'stacked_xf.15.attn.qkv_proj.weight', 'stacked_xf.15.attn.query_ln.scale', 'stacked_xf.15.ff0.weight', 'stacked_xf.15.ff1.weight', 'stacked_xf.15.post_attn_ln.scale', 'stacked_xf.15.post_ff_ln.scale', 'stacked_xf.15.pre_attn_ln.scale', 'stacked_xf.15.pre_ff_ln.scale', 'stacked_xf.16.attn.key_ln.scale', 'stacked_xf.16.attn.out.weight', 'stacked_xf.16.attn.per_dim_scale.per_dim_scale', 'stacked_xf.16.attn.qkv_proj.weight', 'stacked_xf.16.attn.query_ln.scale', 'stacked_xf.16.ff0.weight', 'stacked_xf.16.ff1.weight', 'stacked_xf.16.post_attn_ln.scale', 'stacked_xf.16.post_ff_ln.scale', 'stacked_xf.16.pre_attn_ln.scale', 'stacked_xf.16.pre_ff_ln.scale', 'stacked_xf.17.attn.key_ln.scale', 'stacked_xf.17.attn.out.weight', 'stacked_xf.17.attn.per_dim_scale.per_dim_scale', 'stacked_xf.17.attn.qkv_proj.weight', 'stacked_xf.17.attn.query_ln.scale', 'stacked_xf.17.ff0.weight', 'stacked_xf.17.ff1.weight', 'stacked_xf.17.post_attn_ln.scale', 'stacked_xf.17.post_ff_ln.scale', 'stacked_xf.17.pre_attn_ln.scale', 'stacked_xf.17.pre_ff_ln.scale', 'stacked_xf.18.attn.key_ln.scale', 'stacked_xf.18.attn.out.weight', 'stacked_xf.18.attn.per_dim_scale.per_dim_scale', 'stacked_xf.18.attn.qkv_proj.weight', 'stacked_xf.18.attn.query_ln.scale', 'stacked_xf.18.ff0.weight', 'stacked_xf.18.ff1.weight', 'stacked_xf.18.post_attn_ln.scale', 'stacked_xf.18.post_ff_ln.scale', 'stacked_xf.18.pre_attn_ln.scale', 'stacked_xf.18.pre_ff_ln.scale', 'stacked_xf.19.attn.key_ln.scale', 'stacked_xf.19.attn.out.weight', 'stacked_xf.19.attn.per_dim_scale.per_dim_scale', 'stacked_xf.19.attn.qkv_proj.weight', 'stacked_xf.19.attn.query_ln.scale', 'stacked_xf.19.ff0.weight', 'stacked_xf.19.ff1.weight', 'stacked_xf.19.post_attn_ln.scale', 'stacked_xf.19.post_ff_ln.scale', 'stacked_xf.19.pre_attn_ln.scale', 'stacked_xf.19.pre_ff_ln.scale', 'stacked_xf.2.attn.key_ln.scale', 'stacked_xf.2.attn.out.weight', 'stacked_xf.2.attn.per_dim_scale.per_dim_scale', 'stacked_xf.2.attn.qkv_proj.weight', 'stacked_xf.2.attn.query_ln.scale', 'stacked_xf.2.ff0.weight', 'stacked_xf.2.ff1.weight', 'stacked_xf.2.post_attn_ln.scale', 'stacked_xf.2.post_ff_ln.scale', 'stacked_xf.2.pre_attn_ln.scale', 'stacked_xf.2.pre_ff_ln.scale', 'stacked_xf.3.attn.key_ln.scale', 'stacked_xf.3.attn.out.weight', 'stacked_xf.3.attn.per_dim_scale.per_dim_scale', 'stacked_xf.3.attn.qkv_proj.weight', 'stacked_xf.3.attn.query_ln.scale', 'stacked_xf.3.ff0.weight', 'stacked_xf.3.ff1.weight', 'stacked_xf.3.post_attn_ln.scale', 'stacked_xf.3.post_ff_ln.scale', 'stacked_xf.3.pre_attn_ln.scale', 'stacked_xf.3.pre_ff_ln.scale', 'stacked_xf.4.attn.key_ln.scale', 'stacked_xf.4.attn.out.weight', 'stacked_xf.4.attn.per_dim_scale.per_dim_scale', 'stacked_xf.4.attn.qkv_proj.weight', 'stacked_xf.4.attn.query_ln.scale', 'stacked_xf.4.ff0.weight', 'stacked_xf.4.ff1.weight', 'stacked_xf.4.post_attn_ln.scale', 'stacked_xf.4.post_ff_ln.scale', 'stacked_xf.4.pre_attn_ln.scale', 'stacked_xf.4.pre_ff_ln.scale', 'stacked_xf.5.attn.key_ln.scale', 'stacked_xf.5.attn.out.weight', 'stacked_xf.5.attn.per_dim_scale.per_dim_scale', 'stacked_xf.5.attn.qkv_proj.weight', 'stacked_xf.5.attn.query_ln.scale', 'stacked_xf.5.ff0.weight', 'stacked_xf.5.ff1.weight', 'stacked_xf.5.post_attn_ln.scale', 'stacked_xf.5.post_ff_ln.scale', 'stacked_xf.5.pre_attn_ln.scale', 'stacked_xf.5.pre_ff_ln.scale', 'stacked_xf.6.attn.key_ln.scale', 'stacked_xf.6.attn.out.weight', 'stacked_xf.6.attn.per_dim_scale.per_dim_scale', 'stacked_xf.6.attn.qkv_proj.weight', 'stacked_xf.6.attn.query_ln.scale', 'stacked_xf.6.ff0.weight', 'stacked_xf.6.ff1.weight', 'stacked_xf.6.post_attn_ln.scale', 'stacked_xf.6.post_ff_ln.scale', 'stacked_xf.6.pre_attn_ln.scale', 'stacked_xf.6.pre_ff_ln.scale', 'stacked_xf.7.attn.key_ln.scale', 'stacked_xf.7.attn.out.weight', 'stacked_xf.7.attn.per_dim_scale.per_dim_scale', 'stacked_xf.7.attn.qkv_proj.weight', 'stacked_xf.7.attn.query_ln.scale', 'stacked_xf.7.ff0.weight', 'stacked_xf.7.ff1.weight', 'stacked_xf.7.post_attn_ln.scale', 'stacked_xf.7.post_ff_ln.scale', 'stacked_xf.7.pre_attn_ln.scale', 'stacked_xf.7.pre_ff_ln.scale', 'stacked_xf.8.attn.key_ln.scale', 'stacked_xf.8.attn.out.weight', 'stacked_xf.8.attn.per_dim_scale.per_dim_scale', 'stacked_xf.8.attn.qkv_proj.weight', 'stacked_xf.8.attn.query_ln.scale', 'stacked_xf.8.ff0.weight', 'stacked_xf.8.ff1.weight', 'stacked_xf.8.post_attn_ln.scale', 'stacked_xf.8.post_ff_ln.scale', 'stacked_xf.8.pre_attn_ln.scale', 'stacked_xf.8.pre_ff_ln.scale', 'stacked_xf.9.attn.key_ln.scale', 'stacked_xf.9.attn.out.weight', 'stacked_xf.9.attn.per_dim_scale.per_dim_scale', 'stacked_xf.9.attn.qkv_proj.weight', 'stacked_xf.9.attn.query_ln.scale', 'stacked_xf.9.ff0.weight', 'stacked_xf.9.ff1.weight', 'stacked_xf.9.post_attn_ln.scale', 'stacked_xf.9.post_ff_ln.scale', 'stacked_xf.9.pre_attn_ln.scale', 'stacked_xf.9.pre_ff_ln.scale', 'tokenizer.hidden_layer.bias', 'tokenizer.hidden_layer.weight', 'tokenizer.output_layer.bias', 'tokenizer.output_layer.weight', 'tokenizer.residual_layer.bias', 'tokenizer.residual_layer.weight']\n",
            "- This IS expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of TimesFmModelForPrediction were not initialized from the model checkpoint at google/timesfm-2.5-200m-pytorch and are newly initialized: ['decoder.freq_emb.weight', 'decoder.input_ff_layer.input_layer.bias', 'decoder.input_ff_layer.input_layer.weight', 'decoder.input_ff_layer.output_layer.bias', 'decoder.input_ff_layer.output_layer.weight', 'decoder.input_ff_layer.residual_layer.bias', 'decoder.input_ff_layer.residual_layer.weight', 'decoder.layers.0.input_layernorm.weight', 'decoder.layers.0.mlp.down_proj.bias', 'decoder.layers.0.mlp.down_proj.weight', 'decoder.layers.0.mlp.gate_proj.bias', 'decoder.layers.0.mlp.gate_proj.weight', 'decoder.layers.0.mlp.layer_norm.bias', 'decoder.layers.0.mlp.layer_norm.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.o_proj.bias', 'decoder.layers.0.self_attn.o_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.scaling', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.1.input_layernorm.weight', 'decoder.layers.1.mlp.down_proj.bias', 'decoder.layers.1.mlp.down_proj.weight', 'decoder.layers.1.mlp.gate_proj.bias', 'decoder.layers.1.mlp.gate_proj.weight', 'decoder.layers.1.mlp.layer_norm.bias', 'decoder.layers.1.mlp.layer_norm.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.o_proj.bias', 'decoder.layers.1.self_attn.o_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.scaling', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.10.input_layernorm.weight', 'decoder.layers.10.mlp.down_proj.bias', 'decoder.layers.10.mlp.down_proj.weight', 'decoder.layers.10.mlp.gate_proj.bias', 'decoder.layers.10.mlp.gate_proj.weight', 'decoder.layers.10.mlp.layer_norm.bias', 'decoder.layers.10.mlp.layer_norm.weight', 'decoder.layers.10.self_attn.k_proj.bias', 'decoder.layers.10.self_attn.k_proj.weight', 'decoder.layers.10.self_attn.o_proj.bias', 'decoder.layers.10.self_attn.o_proj.weight', 'decoder.layers.10.self_attn.q_proj.bias', 'decoder.layers.10.self_attn.q_proj.weight', 'decoder.layers.10.self_attn.scaling', 'decoder.layers.10.self_attn.v_proj.bias', 'decoder.layers.10.self_attn.v_proj.weight', 'decoder.layers.11.input_layernorm.weight', 'decoder.layers.11.mlp.down_proj.bias', 'decoder.layers.11.mlp.down_proj.weight', 'decoder.layers.11.mlp.gate_proj.bias', 'decoder.layers.11.mlp.gate_proj.weight', 'decoder.layers.11.mlp.layer_norm.bias', 'decoder.layers.11.mlp.layer_norm.weight', 'decoder.layers.11.self_attn.k_proj.bias', 'decoder.layers.11.self_attn.k_proj.weight', 'decoder.layers.11.self_attn.o_proj.bias', 'decoder.layers.11.self_attn.o_proj.weight', 'decoder.layers.11.self_attn.q_proj.bias', 'decoder.layers.11.self_attn.q_proj.weight', 'decoder.layers.11.self_attn.scaling', 'decoder.layers.11.self_attn.v_proj.bias', 'decoder.layers.11.self_attn.v_proj.weight', 'decoder.layers.12.input_layernorm.weight', 'decoder.layers.12.mlp.down_proj.bias', 'decoder.layers.12.mlp.down_proj.weight', 'decoder.layers.12.mlp.gate_proj.bias', 'decoder.layers.12.mlp.gate_proj.weight', 'decoder.layers.12.mlp.layer_norm.bias', 'decoder.layers.12.mlp.layer_norm.weight', 'decoder.layers.12.self_attn.k_proj.bias', 'decoder.layers.12.self_attn.k_proj.weight', 'decoder.layers.12.self_attn.o_proj.bias', 'decoder.layers.12.self_attn.o_proj.weight', 'decoder.layers.12.self_attn.q_proj.bias', 'decoder.layers.12.self_attn.q_proj.weight', 'decoder.layers.12.self_attn.scaling', 'decoder.layers.12.self_attn.v_proj.bias', 'decoder.layers.12.self_attn.v_proj.weight', 'decoder.layers.13.input_layernorm.weight', 'decoder.layers.13.mlp.down_proj.bias', 'decoder.layers.13.mlp.down_proj.weight', 'decoder.layers.13.mlp.gate_proj.bias', 'decoder.layers.13.mlp.gate_proj.weight', 'decoder.layers.13.mlp.layer_norm.bias', 'decoder.layers.13.mlp.layer_norm.weight', 'decoder.layers.13.self_attn.k_proj.bias', 'decoder.layers.13.self_attn.k_proj.weight', 'decoder.layers.13.self_attn.o_proj.bias', 'decoder.layers.13.self_attn.o_proj.weight', 'decoder.layers.13.self_attn.q_proj.bias', 'decoder.layers.13.self_attn.q_proj.weight', 'decoder.layers.13.self_attn.scaling', 'decoder.layers.13.self_attn.v_proj.bias', 'decoder.layers.13.self_attn.v_proj.weight', 'decoder.layers.14.input_layernorm.weight', 'decoder.layers.14.mlp.down_proj.bias', 'decoder.layers.14.mlp.down_proj.weight', 'decoder.layers.14.mlp.gate_proj.bias', 'decoder.layers.14.mlp.gate_proj.weight', 'decoder.layers.14.mlp.layer_norm.bias', 'decoder.layers.14.mlp.layer_norm.weight', 'decoder.layers.14.self_attn.k_proj.bias', 'decoder.layers.14.self_attn.k_proj.weight', 'decoder.layers.14.self_attn.o_proj.bias', 'decoder.layers.14.self_attn.o_proj.weight', 'decoder.layers.14.self_attn.q_proj.bias', 'decoder.layers.14.self_attn.q_proj.weight', 'decoder.layers.14.self_attn.scaling', 'decoder.layers.14.self_attn.v_proj.bias', 'decoder.layers.14.self_attn.v_proj.weight', 'decoder.layers.15.input_layernorm.weight', 'decoder.layers.15.mlp.down_proj.bias', 'decoder.layers.15.mlp.down_proj.weight', 'decoder.layers.15.mlp.gate_proj.bias', 'decoder.layers.15.mlp.gate_proj.weight', 'decoder.layers.15.mlp.layer_norm.bias', 'decoder.layers.15.mlp.layer_norm.weight', 'decoder.layers.15.self_attn.k_proj.bias', 'decoder.layers.15.self_attn.k_proj.weight', 'decoder.layers.15.self_attn.o_proj.bias', 'decoder.layers.15.self_attn.o_proj.weight', 'decoder.layers.15.self_attn.q_proj.bias', 'decoder.layers.15.self_attn.q_proj.weight', 'decoder.layers.15.self_attn.scaling', 'decoder.layers.15.self_attn.v_proj.bias', 'decoder.layers.15.self_attn.v_proj.weight', 'decoder.layers.16.input_layernorm.weight', 'decoder.layers.16.mlp.down_proj.bias', 'decoder.layers.16.mlp.down_proj.weight', 'decoder.layers.16.mlp.gate_proj.bias', 'decoder.layers.16.mlp.gate_proj.weight', 'decoder.layers.16.mlp.layer_norm.bias', 'decoder.layers.16.mlp.layer_norm.weight', 'decoder.layers.16.self_attn.k_proj.bias', 'decoder.layers.16.self_attn.k_proj.weight', 'decoder.layers.16.self_attn.o_proj.bias', 'decoder.layers.16.self_attn.o_proj.weight', 'decoder.layers.16.self_attn.q_proj.bias', 'decoder.layers.16.self_attn.q_proj.weight', 'decoder.layers.16.self_attn.scaling', 'decoder.layers.16.self_attn.v_proj.bias', 'decoder.layers.16.self_attn.v_proj.weight', 'decoder.layers.17.input_layernorm.weight', 'decoder.layers.17.mlp.down_proj.bias', 'decoder.layers.17.mlp.down_proj.weight', 'decoder.layers.17.mlp.gate_proj.bias', 'decoder.layers.17.mlp.gate_proj.weight', 'decoder.layers.17.mlp.layer_norm.bias', 'decoder.layers.17.mlp.layer_norm.weight', 'decoder.layers.17.self_attn.k_proj.bias', 'decoder.layers.17.self_attn.k_proj.weight', 'decoder.layers.17.self_attn.o_proj.bias', 'decoder.layers.17.self_attn.o_proj.weight', 'decoder.layers.17.self_attn.q_proj.bias', 'decoder.layers.17.self_attn.q_proj.weight', 'decoder.layers.17.self_attn.scaling', 'decoder.layers.17.self_attn.v_proj.bias', 'decoder.layers.17.self_attn.v_proj.weight', 'decoder.layers.18.input_layernorm.weight', 'decoder.layers.18.mlp.down_proj.bias', 'decoder.layers.18.mlp.down_proj.weight', 'decoder.layers.18.mlp.gate_proj.bias', 'decoder.layers.18.mlp.gate_proj.weight', 'decoder.layers.18.mlp.layer_norm.bias', 'decoder.layers.18.mlp.layer_norm.weight', 'decoder.layers.18.self_attn.k_proj.bias', 'decoder.layers.18.self_attn.k_proj.weight', 'decoder.layers.18.self_attn.o_proj.bias', 'decoder.layers.18.self_attn.o_proj.weight', 'decoder.layers.18.self_attn.q_proj.bias', 'decoder.layers.18.self_attn.q_proj.weight', 'decoder.layers.18.self_attn.scaling', 'decoder.layers.18.self_attn.v_proj.bias', 'decoder.layers.18.self_attn.v_proj.weight', 'decoder.layers.19.input_layernorm.weight', 'decoder.layers.19.mlp.down_proj.bias', 'decoder.layers.19.mlp.down_proj.weight', 'decoder.layers.19.mlp.gate_proj.bias', 'decoder.layers.19.mlp.gate_proj.weight', 'decoder.layers.19.mlp.layer_norm.bias', 'decoder.layers.19.mlp.layer_norm.weight', 'decoder.layers.19.self_attn.k_proj.bias', 'decoder.layers.19.self_attn.k_proj.weight', 'decoder.layers.19.self_attn.o_proj.bias', 'decoder.layers.19.self_attn.o_proj.weight', 'decoder.layers.19.self_attn.q_proj.bias', 'decoder.layers.19.self_attn.q_proj.weight', 'decoder.layers.19.self_attn.scaling', 'decoder.layers.19.self_attn.v_proj.bias', 'decoder.layers.19.self_attn.v_proj.weight', 'decoder.layers.2.input_layernorm.weight', 'decoder.layers.2.mlp.down_proj.bias', 'decoder.layers.2.mlp.down_proj.weight', 'decoder.layers.2.mlp.gate_proj.bias', 'decoder.layers.2.mlp.gate_proj.weight', 'decoder.layers.2.mlp.layer_norm.bias', 'decoder.layers.2.mlp.layer_norm.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.o_proj.bias', 'decoder.layers.2.self_attn.o_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.scaling', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.3.input_layernorm.weight', 'decoder.layers.3.mlp.down_proj.bias', 'decoder.layers.3.mlp.down_proj.weight', 'decoder.layers.3.mlp.gate_proj.bias', 'decoder.layers.3.mlp.gate_proj.weight', 'decoder.layers.3.mlp.layer_norm.bias', 'decoder.layers.3.mlp.layer_norm.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.o_proj.bias', 'decoder.layers.3.self_attn.o_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.scaling', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.4.input_layernorm.weight', 'decoder.layers.4.mlp.down_proj.bias', 'decoder.layers.4.mlp.down_proj.weight', 'decoder.layers.4.mlp.gate_proj.bias', 'decoder.layers.4.mlp.gate_proj.weight', 'decoder.layers.4.mlp.layer_norm.bias', 'decoder.layers.4.mlp.layer_norm.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.o_proj.bias', 'decoder.layers.4.self_attn.o_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.scaling', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.5.input_layernorm.weight', 'decoder.layers.5.mlp.down_proj.bias', 'decoder.layers.5.mlp.down_proj.weight', 'decoder.layers.5.mlp.gate_proj.bias', 'decoder.layers.5.mlp.gate_proj.weight', 'decoder.layers.5.mlp.layer_norm.bias', 'decoder.layers.5.mlp.layer_norm.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.o_proj.bias', 'decoder.layers.5.self_attn.o_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.scaling', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.6.input_layernorm.weight', 'decoder.layers.6.mlp.down_proj.bias', 'decoder.layers.6.mlp.down_proj.weight', 'decoder.layers.6.mlp.gate_proj.bias', 'decoder.layers.6.mlp.gate_proj.weight', 'decoder.layers.6.mlp.layer_norm.bias', 'decoder.layers.6.mlp.layer_norm.weight', 'decoder.layers.6.self_attn.k_proj.bias', 'decoder.layers.6.self_attn.k_proj.weight', 'decoder.layers.6.self_attn.o_proj.bias', 'decoder.layers.6.self_attn.o_proj.weight', 'decoder.layers.6.self_attn.q_proj.bias', 'decoder.layers.6.self_attn.q_proj.weight', 'decoder.layers.6.self_attn.scaling', 'decoder.layers.6.self_attn.v_proj.bias', 'decoder.layers.6.self_attn.v_proj.weight', 'decoder.layers.7.input_layernorm.weight', 'decoder.layers.7.mlp.down_proj.bias', 'decoder.layers.7.mlp.down_proj.weight', 'decoder.layers.7.mlp.gate_proj.bias', 'decoder.layers.7.mlp.gate_proj.weight', 'decoder.layers.7.mlp.layer_norm.bias', 'decoder.layers.7.mlp.layer_norm.weight', 'decoder.layers.7.self_attn.k_proj.bias', 'decoder.layers.7.self_attn.k_proj.weight', 'decoder.layers.7.self_attn.o_proj.bias', 'decoder.layers.7.self_attn.o_proj.weight', 'decoder.layers.7.self_attn.q_proj.bias', 'decoder.layers.7.self_attn.q_proj.weight', 'decoder.layers.7.self_attn.scaling', 'decoder.layers.7.self_attn.v_proj.bias', 'decoder.layers.7.self_attn.v_proj.weight', 'decoder.layers.8.input_layernorm.weight', 'decoder.layers.8.mlp.down_proj.bias', 'decoder.layers.8.mlp.down_proj.weight', 'decoder.layers.8.mlp.gate_proj.bias', 'decoder.layers.8.mlp.gate_proj.weight', 'decoder.layers.8.mlp.layer_norm.bias', 'decoder.layers.8.mlp.layer_norm.weight', 'decoder.layers.8.self_attn.k_proj.bias', 'decoder.layers.8.self_attn.k_proj.weight', 'decoder.layers.8.self_attn.o_proj.bias', 'decoder.layers.8.self_attn.o_proj.weight', 'decoder.layers.8.self_attn.q_proj.bias', 'decoder.layers.8.self_attn.q_proj.weight', 'decoder.layers.8.self_attn.scaling', 'decoder.layers.8.self_attn.v_proj.bias', 'decoder.layers.8.self_attn.v_proj.weight', 'decoder.layers.9.input_layernorm.weight', 'decoder.layers.9.mlp.down_proj.bias', 'decoder.layers.9.mlp.down_proj.weight', 'decoder.layers.9.mlp.gate_proj.bias', 'decoder.layers.9.mlp.gate_proj.weight', 'decoder.layers.9.mlp.layer_norm.bias', 'decoder.layers.9.mlp.layer_norm.weight', 'decoder.layers.9.self_attn.k_proj.bias', 'decoder.layers.9.self_attn.k_proj.weight', 'decoder.layers.9.self_attn.o_proj.bias', 'decoder.layers.9.self_attn.o_proj.weight', 'decoder.layers.9.self_attn.q_proj.bias', 'decoder.layers.9.self_attn.q_proj.weight', 'decoder.layers.9.self_attn.scaling', 'decoder.layers.9.self_attn.v_proj.bias', 'decoder.layers.9.self_attn.v_proj.weight', 'horizon_ff_layer.input_layer.bias', 'horizon_ff_layer.input_layer.weight', 'horizon_ff_layer.output_layer.bias', 'horizon_ff_layer.output_layer.weight', 'horizon_ff_layer.residual_layer.bias', 'horizon_ff_layer.residual_layer.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n",
            "  Epoch 1/100 train_loss=1.6937 train_acc=0.1333 eval_loss=1.6788 eval_acc=0.1667 (best)\n",
            "  Epoch 2/100 train_loss=1.6985 train_acc=0.1000 eval_loss=1.3286 eval_acc=0.4667 (best)\n",
            "  Epoch 3/100 train_loss=0.7179 train_acc=0.7000 eval_loss=0.9544 eval_acc=0.5000 (best)\n",
            "  Epoch 4/100 train_loss=0.4072 train_acc=0.8667 eval_loss=0.7554 eval_acc=0.7333 (best)\n",
            "  Epoch 5/100 train_loss=0.2120 train_acc=0.9667 eval_loss=0.9775 eval_acc=0.6333 \n",
            "  Epoch 6/100 train_loss=0.1088 train_acc=1.0000 eval_loss=0.7975 eval_acc=0.7333 \n",
            "  Epoch 7/100 train_loss=0.0333 train_acc=1.0000 eval_loss=0.7567 eval_acc=0.7667 \n",
            "  Epoch 8/100 train_loss=0.0112 train_acc=1.0000 eval_loss=0.8127 eval_acc=0.8000 \n",
            "  Epoch 9/100 train_loss=0.0038 train_acc=1.0000 eval_loss=0.9279 eval_acc=0.7333 \n",
            "  Epoch 10/100 train_loss=0.0021 train_acc=1.0000 eval_loss=1.0632 eval_acc=0.7333 \n",
            "  Epoch 11/100 train_loss=0.0014 train_acc=1.0000 eval_loss=1.1933 eval_acc=0.7333 \n",
            "  Epoch 12/100 train_loss=0.0009 train_acc=1.0000 eval_loss=1.2962 eval_acc=0.7333 \n",
            "  Epoch 13/100 train_loss=0.0005 train_acc=1.0000 eval_loss=1.3780 eval_acc=0.7000 \n",
            "  Epoch 14/100 train_loss=0.0003 train_acc=1.0000 eval_loss=1.4448 eval_acc=0.7000 \n",
            "  Early stopping on google/timesfm-2.5-200m-pytorch: no improvement for 10 epochs (best epoch = 4)\n",
            "    tfm[google/timesfm-2.5-200m-pytorch] train_acc=0.8667 eval_acc=0.69999999999999995559107901499373838305473328\n",
            "    mrh_acc=0.8333 mr+h+kg_acc=0.8333 kg_acc=0.8667 ensemble=0.8333 (w=0.60)\n",
            "  Split 1/1 - accuracy=0.8333 time=33.8s\n",
            "Completed Beef: Mean Acc=0.8333\n",
            "\n",
            "=== 5/109 BeetleFly ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  Decision: Heuristic says no filter (clean signal (no filtering))\n",
            "Error processing BeetleFly: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n",
            "\n",
            "=== 6/109 BirdChicken ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  Decision: Heuristic says no filter (clean signal (no filtering))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 556, in main\n",
            "    results = evaluate_dataset_per_split(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 429, in evaluate_dataset_per_split\n",
            "    X_train_extra = np.concatenate([X_train_all, all_dec_train], axis=1)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "ValueError: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing BirdChicken: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n",
            "\n",
            "=== 7/109 BME ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 556, in main\n",
            "    results = evaluate_dataset_per_split(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 429, in evaluate_dataset_per_split\n",
            "    X_train_extra = np.concatenate([X_train_all, all_dec_train], axis=1)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "ValueError: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Gate split 1/5: baseline_loss=0.0000 adaptive_loss=0.0000\n",
            "    Gate split 2/5: baseline_loss=0.0000 adaptive_loss=0.0000\n",
            "    Gate split 3/5: baseline_loss=0.0000 adaptive_loss=0.0000\n",
            "    Gate split 4/5: baseline_loss=0.0000 adaptive_loss=0.0000\n",
            "    Gate split 5/5: baseline_loss=0.0000 adaptive_loss=0.0000\n",
            "  Decision: Adaptive kept (loss 0.0000 vs baseline 0.0000, delta=+0.0000 <= +0.0200); savgol(window=7, poly=2) - high noise (std_diff)\n",
            "\n",
            "=== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at google/timesfm-2.5-200m-pytorch were not used when initializing TimesFmModelForPrediction: ['output_projection_point.hidden_layer.weight', 'output_projection_point.output_layer.weight', 'output_projection_point.residual_layer.weight', 'output_projection_quantiles.hidden_layer.weight', 'output_projection_quantiles.output_layer.weight', 'output_projection_quantiles.residual_layer.weight', 'stacked_xf.0.attn.key_ln.scale', 'stacked_xf.0.attn.out.weight', 'stacked_xf.0.attn.per_dim_scale.per_dim_scale', 'stacked_xf.0.attn.qkv_proj.weight', 'stacked_xf.0.attn.query_ln.scale', 'stacked_xf.0.ff0.weight', 'stacked_xf.0.ff1.weight', 'stacked_xf.0.post_attn_ln.scale', 'stacked_xf.0.post_ff_ln.scale', 'stacked_xf.0.pre_attn_ln.scale', 'stacked_xf.0.pre_ff_ln.scale', 'stacked_xf.1.attn.key_ln.scale', 'stacked_xf.1.attn.out.weight', 'stacked_xf.1.attn.per_dim_scale.per_dim_scale', 'stacked_xf.1.attn.qkv_proj.weight', 'stacked_xf.1.attn.query_ln.scale', 'stacked_xf.1.ff0.weight', 'stacked_xf.1.ff1.weight', 'stacked_xf.1.post_attn_ln.scale', 'stacked_xf.1.post_ff_ln.scale', 'stacked_xf.1.pre_attn_ln.scale', 'stacked_xf.1.pre_ff_ln.scale', 'stacked_xf.10.attn.key_ln.scale', 'stacked_xf.10.attn.out.weight', 'stacked_xf.10.attn.per_dim_scale.per_dim_scale', 'stacked_xf.10.attn.qkv_proj.weight', 'stacked_xf.10.attn.query_ln.scale', 'stacked_xf.10.ff0.weight', 'stacked_xf.10.ff1.weight', 'stacked_xf.10.post_attn_ln.scale', 'stacked_xf.10.post_ff_ln.scale', 'stacked_xf.10.pre_attn_ln.scale', 'stacked_xf.10.pre_ff_ln.scale', 'stacked_xf.11.attn.key_ln.scale', 'stacked_xf.11.attn.out.weight', 'stacked_xf.11.attn.per_dim_scale.per_dim_scale', 'stacked_xf.11.attn.qkv_proj.weight', 'stacked_xf.11.attn.query_ln.scale', 'stacked_xf.11.ff0.weight', 'stacked_xf.11.ff1.weight', 'stacked_xf.11.post_attn_ln.scale', 'stacked_xf.11.post_ff_ln.scale', 'stacked_xf.11.pre_attn_ln.scale', 'stacked_xf.11.pre_ff_ln.scale', 'stacked_xf.12.attn.key_ln.scale', 'stacked_xf.12.attn.out.weight', 'stacked_xf.12.attn.per_dim_scale.per_dim_scale', 'stacked_xf.12.attn.qkv_proj.weight', 'stacked_xf.12.attn.query_ln.scale', 'stacked_xf.12.ff0.weight', 'stacked_xf.12.ff1.weight', 'stacked_xf.12.post_attn_ln.scale', 'stacked_xf.12.post_ff_ln.scale', 'stacked_xf.12.pre_attn_ln.scale', 'stacked_xf.12.pre_ff_ln.scale', 'stacked_xf.13.attn.key_ln.scale', 'stacked_xf.13.attn.out.weight', 'stacked_xf.13.attn.per_dim_scale.per_dim_scale', 'stacked_xf.13.attn.qkv_proj.weight', 'stacked_xf.13.attn.query_ln.scale', 'stacked_xf.13.ff0.weight', 'stacked_xf.13.ff1.weight', 'stacked_xf.13.post_attn_ln.scale', 'stacked_xf.13.post_ff_ln.scale', 'stacked_xf.13.pre_attn_ln.scale', 'stacked_xf.13.pre_ff_ln.scale', 'stacked_xf.14.attn.key_ln.scale', 'stacked_xf.14.attn.out.weight', 'stacked_xf.14.attn.per_dim_scale.per_dim_scale', 'stacked_xf.14.attn.qkv_proj.weight', 'stacked_xf.14.attn.query_ln.scale', 'stacked_xf.14.ff0.weight', 'stacked_xf.14.ff1.weight', 'stacked_xf.14.post_attn_ln.scale', 'stacked_xf.14.post_ff_ln.scale', 'stacked_xf.14.pre_attn_ln.scale', 'stacked_xf.14.pre_ff_ln.scale', 'stacked_xf.15.attn.key_ln.scale', 'stacked_xf.15.attn.out.weight', 'stacked_xf.15.attn.per_dim_scale.per_dim_scale', 'stacked_xf.15.attn.qkv_proj.weight', 'stacked_xf.15.attn.query_ln.scale', 'stacked_xf.15.ff0.weight', 'stacked_xf.15.ff1.weight', 'stacked_xf.15.post_attn_ln.scale', 'stacked_xf.15.post_ff_ln.scale', 'stacked_xf.15.pre_attn_ln.scale', 'stacked_xf.15.pre_ff_ln.scale', 'stacked_xf.16.attn.key_ln.scale', 'stacked_xf.16.attn.out.weight', 'stacked_xf.16.attn.per_dim_scale.per_dim_scale', 'stacked_xf.16.attn.qkv_proj.weight', 'stacked_xf.16.attn.query_ln.scale', 'stacked_xf.16.ff0.weight', 'stacked_xf.16.ff1.weight', 'stacked_xf.16.post_attn_ln.scale', 'stacked_xf.16.post_ff_ln.scale', 'stacked_xf.16.pre_attn_ln.scale', 'stacked_xf.16.pre_ff_ln.scale', 'stacked_xf.17.attn.key_ln.scale', 'stacked_xf.17.attn.out.weight', 'stacked_xf.17.attn.per_dim_scale.per_dim_scale', 'stacked_xf.17.attn.qkv_proj.weight', 'stacked_xf.17.attn.query_ln.scale', 'stacked_xf.17.ff0.weight', 'stacked_xf.17.ff1.weight', 'stacked_xf.17.post_attn_ln.scale', 'stacked_xf.17.post_ff_ln.scale', 'stacked_xf.17.pre_attn_ln.scale', 'stacked_xf.17.pre_ff_ln.scale', 'stacked_xf.18.attn.key_ln.scale', 'stacked_xf.18.attn.out.weight', 'stacked_xf.18.attn.per_dim_scale.per_dim_scale', 'stacked_xf.18.attn.qkv_proj.weight', 'stacked_xf.18.attn.query_ln.scale', 'stacked_xf.18.ff0.weight', 'stacked_xf.18.ff1.weight', 'stacked_xf.18.post_attn_ln.scale', 'stacked_xf.18.post_ff_ln.scale', 'stacked_xf.18.pre_attn_ln.scale', 'stacked_xf.18.pre_ff_ln.scale', 'stacked_xf.19.attn.key_ln.scale', 'stacked_xf.19.attn.out.weight', 'stacked_xf.19.attn.per_dim_scale.per_dim_scale', 'stacked_xf.19.attn.qkv_proj.weight', 'stacked_xf.19.attn.query_ln.scale', 'stacked_xf.19.ff0.weight', 'stacked_xf.19.ff1.weight', 'stacked_xf.19.post_attn_ln.scale', 'stacked_xf.19.post_ff_ln.scale', 'stacked_xf.19.pre_attn_ln.scale', 'stacked_xf.19.pre_ff_ln.scale', 'stacked_xf.2.attn.key_ln.scale', 'stacked_xf.2.attn.out.weight', 'stacked_xf.2.attn.per_dim_scale.per_dim_scale', 'stacked_xf.2.attn.qkv_proj.weight', 'stacked_xf.2.attn.query_ln.scale', 'stacked_xf.2.ff0.weight', 'stacked_xf.2.ff1.weight', 'stacked_xf.2.post_attn_ln.scale', 'stacked_xf.2.post_ff_ln.scale', 'stacked_xf.2.pre_attn_ln.scale', 'stacked_xf.2.pre_ff_ln.scale', 'stacked_xf.3.attn.key_ln.scale', 'stacked_xf.3.attn.out.weight', 'stacked_xf.3.attn.per_dim_scale.per_dim_scale', 'stacked_xf.3.attn.qkv_proj.weight', 'stacked_xf.3.attn.query_ln.scale', 'stacked_xf.3.ff0.weight', 'stacked_xf.3.ff1.weight', 'stacked_xf.3.post_attn_ln.scale', 'stacked_xf.3.post_ff_ln.scale', 'stacked_xf.3.pre_attn_ln.scale', 'stacked_xf.3.pre_ff_ln.scale', 'stacked_xf.4.attn.key_ln.scale', 'stacked_xf.4.attn.out.weight', 'stacked_xf.4.attn.per_dim_scale.per_dim_scale', 'stacked_xf.4.attn.qkv_proj.weight', 'stacked_xf.4.attn.query_ln.scale', 'stacked_xf.4.ff0.weight', 'stacked_xf.4.ff1.weight', 'stacked_xf.4.post_attn_ln.scale', 'stacked_xf.4.post_ff_ln.scale', 'stacked_xf.4.pre_attn_ln.scale', 'stacked_xf.4.pre_ff_ln.scale', 'stacked_xf.5.attn.key_ln.scale', 'stacked_xf.5.attn.out.weight', 'stacked_xf.5.attn.per_dim_scale.per_dim_scale', 'stacked_xf.5.attn.qkv_proj.weight', 'stacked_xf.5.attn.query_ln.scale', 'stacked_xf.5.ff0.weight', 'stacked_xf.5.ff1.weight', 'stacked_xf.5.post_attn_ln.scale', 'stacked_xf.5.post_ff_ln.scale', 'stacked_xf.5.pre_attn_ln.scale', 'stacked_xf.5.pre_ff_ln.scale', 'stacked_xf.6.attn.key_ln.scale', 'stacked_xf.6.attn.out.weight', 'stacked_xf.6.attn.per_dim_scale.per_dim_scale', 'stacked_xf.6.attn.qkv_proj.weight', 'stacked_xf.6.attn.query_ln.scale', 'stacked_xf.6.ff0.weight', 'stacked_xf.6.ff1.weight', 'stacked_xf.6.post_attn_ln.scale', 'stacked_xf.6.post_ff_ln.scale', 'stacked_xf.6.pre_attn_ln.scale', 'stacked_xf.6.pre_ff_ln.scale', 'stacked_xf.7.attn.key_ln.scale', 'stacked_xf.7.attn.out.weight', 'stacked_xf.7.attn.per_dim_scale.per_dim_scale', 'stacked_xf.7.attn.qkv_proj.weight', 'stacked_xf.7.attn.query_ln.scale', 'stacked_xf.7.ff0.weight', 'stacked_xf.7.ff1.weight', 'stacked_xf.7.post_attn_ln.scale', 'stacked_xf.7.post_ff_ln.scale', 'stacked_xf.7.pre_attn_ln.scale', 'stacked_xf.7.pre_ff_ln.scale', 'stacked_xf.8.attn.key_ln.scale', 'stacked_xf.8.attn.out.weight', 'stacked_xf.8.attn.per_dim_scale.per_dim_scale', 'stacked_xf.8.attn.qkv_proj.weight', 'stacked_xf.8.attn.query_ln.scale', 'stacked_xf.8.ff0.weight', 'stacked_xf.8.ff1.weight', 'stacked_xf.8.post_attn_ln.scale', 'stacked_xf.8.post_ff_ln.scale', 'stacked_xf.8.pre_attn_ln.scale', 'stacked_xf.8.pre_ff_ln.scale', 'stacked_xf.9.attn.key_ln.scale', 'stacked_xf.9.attn.out.weight', 'stacked_xf.9.attn.per_dim_scale.per_dim_scale', 'stacked_xf.9.attn.qkv_proj.weight', 'stacked_xf.9.attn.query_ln.scale', 'stacked_xf.9.ff0.weight', 'stacked_xf.9.ff1.weight', 'stacked_xf.9.post_attn_ln.scale', 'stacked_xf.9.post_ff_ln.scale', 'stacked_xf.9.pre_attn_ln.scale', 'stacked_xf.9.pre_ff_ln.scale', 'tokenizer.hidden_layer.bias', 'tokenizer.hidden_layer.weight', 'tokenizer.output_layer.bias', 'tokenizer.output_layer.weight', 'tokenizer.residual_layer.bias', 'tokenizer.residual_layer.weight']\n",
            "- This IS expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of TimesFmModelForPrediction were not initialized from the model checkpoint at google/timesfm-2.5-200m-pytorch and are newly initialized: ['decoder.freq_emb.weight', 'decoder.input_ff_layer.input_layer.bias', 'decoder.input_ff_layer.input_layer.weight', 'decoder.input_ff_layer.output_layer.bias', 'decoder.input_ff_layer.output_layer.weight', 'decoder.input_ff_layer.residual_layer.bias', 'decoder.input_ff_layer.residual_layer.weight', 'decoder.layers.0.input_layernorm.weight', 'decoder.layers.0.mlp.down_proj.bias', 'decoder.layers.0.mlp.down_proj.weight', 'decoder.layers.0.mlp.gate_proj.bias', 'decoder.layers.0.mlp.gate_proj.weight', 'decoder.layers.0.mlp.layer_norm.bias', 'decoder.layers.0.mlp.layer_norm.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.o_proj.bias', 'decoder.layers.0.self_attn.o_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.scaling', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.1.input_layernorm.weight', 'decoder.layers.1.mlp.down_proj.bias', 'decoder.layers.1.mlp.down_proj.weight', 'decoder.layers.1.mlp.gate_proj.bias', 'decoder.layers.1.mlp.gate_proj.weight', 'decoder.layers.1.mlp.layer_norm.bias', 'decoder.layers.1.mlp.layer_norm.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.o_proj.bias', 'decoder.layers.1.self_attn.o_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.scaling', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.10.input_layernorm.weight', 'decoder.layers.10.mlp.down_proj.bias', 'decoder.layers.10.mlp.down_proj.weight', 'decoder.layers.10.mlp.gate_proj.bias', 'decoder.layers.10.mlp.gate_proj.weight', 'decoder.layers.10.mlp.layer_norm.bias', 'decoder.layers.10.mlp.layer_norm.weight', 'decoder.layers.10.self_attn.k_proj.bias', 'decoder.layers.10.self_attn.k_proj.weight', 'decoder.layers.10.self_attn.o_proj.bias', 'decoder.layers.10.self_attn.o_proj.weight', 'decoder.layers.10.self_attn.q_proj.bias', 'decoder.layers.10.self_attn.q_proj.weight', 'decoder.layers.10.self_attn.scaling', 'decoder.layers.10.self_attn.v_proj.bias', 'decoder.layers.10.self_attn.v_proj.weight', 'decoder.layers.11.input_layernorm.weight', 'decoder.layers.11.mlp.down_proj.bias', 'decoder.layers.11.mlp.down_proj.weight', 'decoder.layers.11.mlp.gate_proj.bias', 'decoder.layers.11.mlp.gate_proj.weight', 'decoder.layers.11.mlp.layer_norm.bias', 'decoder.layers.11.mlp.layer_norm.weight', 'decoder.layers.11.self_attn.k_proj.bias', 'decoder.layers.11.self_attn.k_proj.weight', 'decoder.layers.11.self_attn.o_proj.bias', 'decoder.layers.11.self_attn.o_proj.weight', 'decoder.layers.11.self_attn.q_proj.bias', 'decoder.layers.11.self_attn.q_proj.weight', 'decoder.layers.11.self_attn.scaling', 'decoder.layers.11.self_attn.v_proj.bias', 'decoder.layers.11.self_attn.v_proj.weight', 'decoder.layers.12.input_layernorm.weight', 'decoder.layers.12.mlp.down_proj.bias', 'decoder.layers.12.mlp.down_proj.weight', 'decoder.layers.12.mlp.gate_proj.bias', 'decoder.layers.12.mlp.gate_proj.weight', 'decoder.layers.12.mlp.layer_norm.bias', 'decoder.layers.12.mlp.layer_norm.weight', 'decoder.layers.12.self_attn.k_proj.bias', 'decoder.layers.12.self_attn.k_proj.weight', 'decoder.layers.12.self_attn.o_proj.bias', 'decoder.layers.12.self_attn.o_proj.weight', 'decoder.layers.12.self_attn.q_proj.bias', 'decoder.layers.12.self_attn.q_proj.weight', 'decoder.layers.12.self_attn.scaling', 'decoder.layers.12.self_attn.v_proj.bias', 'decoder.layers.12.self_attn.v_proj.weight', 'decoder.layers.13.input_layernorm.weight', 'decoder.layers.13.mlp.down_proj.bias', 'decoder.layers.13.mlp.down_proj.weight', 'decoder.layers.13.mlp.gate_proj.bias', 'decoder.layers.13.mlp.gate_proj.weight', 'decoder.layers.13.mlp.layer_norm.bias', 'decoder.layers.13.mlp.layer_norm.weight', 'decoder.layers.13.self_attn.k_proj.bias', 'decoder.layers.13.self_attn.k_proj.weight', 'decoder.layers.13.self_attn.o_proj.bias', 'decoder.layers.13.self_attn.o_proj.weight', 'decoder.layers.13.self_attn.q_proj.bias', 'decoder.layers.13.self_attn.q_proj.weight', 'decoder.layers.13.self_attn.scaling', 'decoder.layers.13.self_attn.v_proj.bias', 'decoder.layers.13.self_attn.v_proj.weight', 'decoder.layers.14.input_layernorm.weight', 'decoder.layers.14.mlp.down_proj.bias', 'decoder.layers.14.mlp.down_proj.weight', 'decoder.layers.14.mlp.gate_proj.bias', 'decoder.layers.14.mlp.gate_proj.weight', 'decoder.layers.14.mlp.layer_norm.bias', 'decoder.layers.14.mlp.layer_norm.weight', 'decoder.layers.14.self_attn.k_proj.bias', 'decoder.layers.14.self_attn.k_proj.weight', 'decoder.layers.14.self_attn.o_proj.bias', 'decoder.layers.14.self_attn.o_proj.weight', 'decoder.layers.14.self_attn.q_proj.bias', 'decoder.layers.14.self_attn.q_proj.weight', 'decoder.layers.14.self_attn.scaling', 'decoder.layers.14.self_attn.v_proj.bias', 'decoder.layers.14.self_attn.v_proj.weight', 'decoder.layers.15.input_layernorm.weight', 'decoder.layers.15.mlp.down_proj.bias', 'decoder.layers.15.mlp.down_proj.weight', 'decoder.layers.15.mlp.gate_proj.bias', 'decoder.layers.15.mlp.gate_proj.weight', 'decoder.layers.15.mlp.layer_norm.bias', 'decoder.layers.15.mlp.layer_norm.weight', 'decoder.layers.15.self_attn.k_proj.bias', 'decoder.layers.15.self_attn.k_proj.weight', 'decoder.layers.15.self_attn.o_proj.bias', 'decoder.layers.15.self_attn.o_proj.weight', 'decoder.layers.15.self_attn.q_proj.bias', 'decoder.layers.15.self_attn.q_proj.weight', 'decoder.layers.15.self_attn.scaling', 'decoder.layers.15.self_attn.v_proj.bias', 'decoder.layers.15.self_attn.v_proj.weight', 'decoder.layers.16.input_layernorm.weight', 'decoder.layers.16.mlp.down_proj.bias', 'decoder.layers.16.mlp.down_proj.weight', 'decoder.layers.16.mlp.gate_proj.bias', 'decoder.layers.16.mlp.gate_proj.weight', 'decoder.layers.16.mlp.layer_norm.bias', 'decoder.layers.16.mlp.layer_norm.weight', 'decoder.layers.16.self_attn.k_proj.bias', 'decoder.layers.16.self_attn.k_proj.weight', 'decoder.layers.16.self_attn.o_proj.bias', 'decoder.layers.16.self_attn.o_proj.weight', 'decoder.layers.16.self_attn.q_proj.bias', 'decoder.layers.16.self_attn.q_proj.weight', 'decoder.layers.16.self_attn.scaling', 'decoder.layers.16.self_attn.v_proj.bias', 'decoder.layers.16.self_attn.v_proj.weight', 'decoder.layers.17.input_layernorm.weight', 'decoder.layers.17.mlp.down_proj.bias', 'decoder.layers.17.mlp.down_proj.weight', 'decoder.layers.17.mlp.gate_proj.bias', 'decoder.layers.17.mlp.gate_proj.weight', 'decoder.layers.17.mlp.layer_norm.bias', 'decoder.layers.17.mlp.layer_norm.weight', 'decoder.layers.17.self_attn.k_proj.bias', 'decoder.layers.17.self_attn.k_proj.weight', 'decoder.layers.17.self_attn.o_proj.bias', 'decoder.layers.17.self_attn.o_proj.weight', 'decoder.layers.17.self_attn.q_proj.bias', 'decoder.layers.17.self_attn.q_proj.weight', 'decoder.layers.17.self_attn.scaling', 'decoder.layers.17.self_attn.v_proj.bias', 'decoder.layers.17.self_attn.v_proj.weight', 'decoder.layers.18.input_layernorm.weight', 'decoder.layers.18.mlp.down_proj.bias', 'decoder.layers.18.mlp.down_proj.weight', 'decoder.layers.18.mlp.gate_proj.bias', 'decoder.layers.18.mlp.gate_proj.weight', 'decoder.layers.18.mlp.layer_norm.bias', 'decoder.layers.18.mlp.layer_norm.weight', 'decoder.layers.18.self_attn.k_proj.bias', 'decoder.layers.18.self_attn.k_proj.weight', 'decoder.layers.18.self_attn.o_proj.bias', 'decoder.layers.18.self_attn.o_proj.weight', 'decoder.layers.18.self_attn.q_proj.bias', 'decoder.layers.18.self_attn.q_proj.weight', 'decoder.layers.18.self_attn.scaling', 'decoder.layers.18.self_attn.v_proj.bias', 'decoder.layers.18.self_attn.v_proj.weight', 'decoder.layers.19.input_layernorm.weight', 'decoder.layers.19.mlp.down_proj.bias', 'decoder.layers.19.mlp.down_proj.weight', 'decoder.layers.19.mlp.gate_proj.bias', 'decoder.layers.19.mlp.gate_proj.weight', 'decoder.layers.19.mlp.layer_norm.bias', 'decoder.layers.19.mlp.layer_norm.weight', 'decoder.layers.19.self_attn.k_proj.bias', 'decoder.layers.19.self_attn.k_proj.weight', 'decoder.layers.19.self_attn.o_proj.bias', 'decoder.layers.19.self_attn.o_proj.weight', 'decoder.layers.19.self_attn.q_proj.bias', 'decoder.layers.19.self_attn.q_proj.weight', 'decoder.layers.19.self_attn.scaling', 'decoder.layers.19.self_attn.v_proj.bias', 'decoder.layers.19.self_attn.v_proj.weight', 'decoder.layers.2.input_layernorm.weight', 'decoder.layers.2.mlp.down_proj.bias', 'decoder.layers.2.mlp.down_proj.weight', 'decoder.layers.2.mlp.gate_proj.bias', 'decoder.layers.2.mlp.gate_proj.weight', 'decoder.layers.2.mlp.layer_norm.bias', 'decoder.layers.2.mlp.layer_norm.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.o_proj.bias', 'decoder.layers.2.self_attn.o_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.scaling', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.3.input_layernorm.weight', 'decoder.layers.3.mlp.down_proj.bias', 'decoder.layers.3.mlp.down_proj.weight', 'decoder.layers.3.mlp.gate_proj.bias', 'decoder.layers.3.mlp.gate_proj.weight', 'decoder.layers.3.mlp.layer_norm.bias', 'decoder.layers.3.mlp.layer_norm.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.o_proj.bias', 'decoder.layers.3.self_attn.o_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.scaling', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.4.input_layernorm.weight', 'decoder.layers.4.mlp.down_proj.bias', 'decoder.layers.4.mlp.down_proj.weight', 'decoder.layers.4.mlp.gate_proj.bias', 'decoder.layers.4.mlp.gate_proj.weight', 'decoder.layers.4.mlp.layer_norm.bias', 'decoder.layers.4.mlp.layer_norm.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.o_proj.bias', 'decoder.layers.4.self_attn.o_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.scaling', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.5.input_layernorm.weight', 'decoder.layers.5.mlp.down_proj.bias', 'decoder.layers.5.mlp.down_proj.weight', 'decoder.layers.5.mlp.gate_proj.bias', 'decoder.layers.5.mlp.gate_proj.weight', 'decoder.layers.5.mlp.layer_norm.bias', 'decoder.layers.5.mlp.layer_norm.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.o_proj.bias', 'decoder.layers.5.self_attn.o_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.scaling', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.6.input_layernorm.weight', 'decoder.layers.6.mlp.down_proj.bias', 'decoder.layers.6.mlp.down_proj.weight', 'decoder.layers.6.mlp.gate_proj.bias', 'decoder.layers.6.mlp.gate_proj.weight', 'decoder.layers.6.mlp.layer_norm.bias', 'decoder.layers.6.mlp.layer_norm.weight', 'decoder.layers.6.self_attn.k_proj.bias', 'decoder.layers.6.self_attn.k_proj.weight', 'decoder.layers.6.self_attn.o_proj.bias', 'decoder.layers.6.self_attn.o_proj.weight', 'decoder.layers.6.self_attn.q_proj.bias', 'decoder.layers.6.self_attn.q_proj.weight', 'decoder.layers.6.self_attn.scaling', 'decoder.layers.6.self_attn.v_proj.bias', 'decoder.layers.6.self_attn.v_proj.weight', 'decoder.layers.7.input_layernorm.weight', 'decoder.layers.7.mlp.down_proj.bias', 'decoder.layers.7.mlp.down_proj.weight', 'decoder.layers.7.mlp.gate_proj.bias', 'decoder.layers.7.mlp.gate_proj.weight', 'decoder.layers.7.mlp.layer_norm.bias', 'decoder.layers.7.mlp.layer_norm.weight', 'decoder.layers.7.self_attn.k_proj.bias', 'decoder.layers.7.self_attn.k_proj.weight', 'decoder.layers.7.self_attn.o_proj.bias', 'decoder.layers.7.self_attn.o_proj.weight', 'decoder.layers.7.self_attn.q_proj.bias', 'decoder.layers.7.self_attn.q_proj.weight', 'decoder.layers.7.self_attn.scaling', 'decoder.layers.7.self_attn.v_proj.bias', 'decoder.layers.7.self_attn.v_proj.weight', 'decoder.layers.8.input_layernorm.weight', 'decoder.layers.8.mlp.down_proj.bias', 'decoder.layers.8.mlp.down_proj.weight', 'decoder.layers.8.mlp.gate_proj.bias', 'decoder.layers.8.mlp.gate_proj.weight', 'decoder.layers.8.mlp.layer_norm.bias', 'decoder.layers.8.mlp.layer_norm.weight', 'decoder.layers.8.self_attn.k_proj.bias', 'decoder.layers.8.self_attn.k_proj.weight', 'decoder.layers.8.self_attn.o_proj.bias', 'decoder.layers.8.self_attn.o_proj.weight', 'decoder.layers.8.self_attn.q_proj.bias', 'decoder.layers.8.self_attn.q_proj.weight', 'decoder.layers.8.self_attn.scaling', 'decoder.layers.8.self_attn.v_proj.bias', 'decoder.layers.8.self_attn.v_proj.weight', 'decoder.layers.9.input_layernorm.weight', 'decoder.layers.9.mlp.down_proj.bias', 'decoder.layers.9.mlp.down_proj.weight', 'decoder.layers.9.mlp.gate_proj.bias', 'decoder.layers.9.mlp.gate_proj.weight', 'decoder.layers.9.mlp.layer_norm.bias', 'decoder.layers.9.mlp.layer_norm.weight', 'decoder.layers.9.self_attn.k_proj.bias', 'decoder.layers.9.self_attn.k_proj.weight', 'decoder.layers.9.self_attn.o_proj.bias', 'decoder.layers.9.self_attn.o_proj.weight', 'decoder.layers.9.self_attn.q_proj.bias', 'decoder.layers.9.self_attn.q_proj.weight', 'decoder.layers.9.self_attn.scaling', 'decoder.layers.9.self_attn.v_proj.bias', 'decoder.layers.9.self_attn.v_proj.weight', 'horizon_ff_layer.input_layer.bias', 'horizon_ff_layer.input_layer.weight', 'horizon_ff_layer.output_layer.bias', 'horizon_ff_layer.output_layer.weight', 'horizon_ff_layer.residual_layer.bias', 'horizon_ff_layer.residual_layer.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n",
            "  Epoch 1/100 train_loss=1.1551 train_acc=0.2000 eval_loss=1.1850 eval_acc=0.1800 (best)\n",
            "  Epoch 2/100 train_loss=1.1670 train_acc=0.1667 eval_loss=0.0361 eval_acc=0.9867 (best)\n",
            "  Epoch 3/100 train_loss=0.0172 train_acc=1.0000 eval_loss=0.0041 eval_acc=1.0000 (best)\n",
            "  Epoch 4/100 train_loss=0.0024 train_acc=1.0000 eval_loss=0.0016 eval_acc=1.0000 (best)\n",
            "  Epoch 5/100 train_loss=0.0012 train_acc=1.0000 eval_loss=0.0007 eval_acc=1.0000 (best)\n",
            "  Epoch 6/100 train_loss=0.0005 train_acc=1.0000 eval_loss=0.0003 eval_acc=1.0000 (best)\n",
            "  Epoch 7/100 train_loss=0.0002 train_acc=1.0000 eval_loss=0.0001 eval_acc=1.0000 (best)\n",
            "  Epoch 8/100 train_loss=0.0001 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 (best)\n",
            "  Epoch 9/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 (best)\n",
            "  Epoch 10/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 (best)\n",
            "  Epoch 11/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 (best)\n",
            "  Epoch 12/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 (best)\n",
            "  Epoch 13/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 (best)\n",
            "  Epoch 14/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 (best)\n",
            "  Epoch 15/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 (best)\n",
            "  Epoch 16/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 (best)\n",
            "  Epoch 17/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 (best)\n",
            "  Epoch 18/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 (best)\n",
            "  Epoch 19/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 (best)\n",
            "  Epoch 20/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 (best)\n",
            "  Epoch 21/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 (best)\n",
            "  Epoch 22/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 (best)\n",
            "  Epoch 23/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 (best)\n",
            "  Epoch 24/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 (best)\n",
            "  Epoch 25/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 (best)\n",
            "  Epoch 26/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 \n",
            "  Epoch 27/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 \n",
            "  Epoch 28/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 \n",
            "  Epoch 29/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 \n",
            "  Epoch 30/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 \n",
            "  Epoch 31/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 \n",
            "  Epoch 32/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 (best)\n",
            "  Epoch 33/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 \n",
            "  Epoch 34/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 \n",
            "  Epoch 35/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 (best)\n",
            "  Epoch 36/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 (best)\n",
            "  Epoch 37/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 \n",
            "  Epoch 38/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 \n",
            "  Epoch 39/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 \n",
            "  Epoch 40/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 \n",
            "  Epoch 41/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 \n",
            "  Epoch 42/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 \n",
            "  Epoch 43/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 \n",
            "  Epoch 44/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 \n",
            "  Epoch 45/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 \n",
            "  Epoch 46/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 \n",
            "  Early stopping on google/timesfm-2.5-200m-pytorch: no improvement for 10 epochs (best epoch = 36)\n",
            "    tfm[google/timesfm-2.5-200m-pytorch] train_acc=1.0000 eval_acc=1.00000000000000000000000000000000000000000000\n",
            "    mrh_acc=1.0000 mr+h+kg_acc=1.0000 kg_acc=1.0000 ensemble=1.0000 (w=0.60)\n",
            "  Split 1/1 - accuracy=1.0000 time=168.0s\n",
            "Completed BME: Mean Acc=1.0000\n",
            "\n",
            "=== 8/109 Car ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  Decision: Heuristic says no filter (clean signal (no filtering))\n",
            "\n",
            "=== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at google/timesfm-2.5-200m-pytorch were not used when initializing TimesFmModelForPrediction: ['output_projection_point.hidden_layer.weight', 'output_projection_point.output_layer.weight', 'output_projection_point.residual_layer.weight', 'output_projection_quantiles.hidden_layer.weight', 'output_projection_quantiles.output_layer.weight', 'output_projection_quantiles.residual_layer.weight', 'stacked_xf.0.attn.key_ln.scale', 'stacked_xf.0.attn.out.weight', 'stacked_xf.0.attn.per_dim_scale.per_dim_scale', 'stacked_xf.0.attn.qkv_proj.weight', 'stacked_xf.0.attn.query_ln.scale', 'stacked_xf.0.ff0.weight', 'stacked_xf.0.ff1.weight', 'stacked_xf.0.post_attn_ln.scale', 'stacked_xf.0.post_ff_ln.scale', 'stacked_xf.0.pre_attn_ln.scale', 'stacked_xf.0.pre_ff_ln.scale', 'stacked_xf.1.attn.key_ln.scale', 'stacked_xf.1.attn.out.weight', 'stacked_xf.1.attn.per_dim_scale.per_dim_scale', 'stacked_xf.1.attn.qkv_proj.weight', 'stacked_xf.1.attn.query_ln.scale', 'stacked_xf.1.ff0.weight', 'stacked_xf.1.ff1.weight', 'stacked_xf.1.post_attn_ln.scale', 'stacked_xf.1.post_ff_ln.scale', 'stacked_xf.1.pre_attn_ln.scale', 'stacked_xf.1.pre_ff_ln.scale', 'stacked_xf.10.attn.key_ln.scale', 'stacked_xf.10.attn.out.weight', 'stacked_xf.10.attn.per_dim_scale.per_dim_scale', 'stacked_xf.10.attn.qkv_proj.weight', 'stacked_xf.10.attn.query_ln.scale', 'stacked_xf.10.ff0.weight', 'stacked_xf.10.ff1.weight', 'stacked_xf.10.post_attn_ln.scale', 'stacked_xf.10.post_ff_ln.scale', 'stacked_xf.10.pre_attn_ln.scale', 'stacked_xf.10.pre_ff_ln.scale', 'stacked_xf.11.attn.key_ln.scale', 'stacked_xf.11.attn.out.weight', 'stacked_xf.11.attn.per_dim_scale.per_dim_scale', 'stacked_xf.11.attn.qkv_proj.weight', 'stacked_xf.11.attn.query_ln.scale', 'stacked_xf.11.ff0.weight', 'stacked_xf.11.ff1.weight', 'stacked_xf.11.post_attn_ln.scale', 'stacked_xf.11.post_ff_ln.scale', 'stacked_xf.11.pre_attn_ln.scale', 'stacked_xf.11.pre_ff_ln.scale', 'stacked_xf.12.attn.key_ln.scale', 'stacked_xf.12.attn.out.weight', 'stacked_xf.12.attn.per_dim_scale.per_dim_scale', 'stacked_xf.12.attn.qkv_proj.weight', 'stacked_xf.12.attn.query_ln.scale', 'stacked_xf.12.ff0.weight', 'stacked_xf.12.ff1.weight', 'stacked_xf.12.post_attn_ln.scale', 'stacked_xf.12.post_ff_ln.scale', 'stacked_xf.12.pre_attn_ln.scale', 'stacked_xf.12.pre_ff_ln.scale', 'stacked_xf.13.attn.key_ln.scale', 'stacked_xf.13.attn.out.weight', 'stacked_xf.13.attn.per_dim_scale.per_dim_scale', 'stacked_xf.13.attn.qkv_proj.weight', 'stacked_xf.13.attn.query_ln.scale', 'stacked_xf.13.ff0.weight', 'stacked_xf.13.ff1.weight', 'stacked_xf.13.post_attn_ln.scale', 'stacked_xf.13.post_ff_ln.scale', 'stacked_xf.13.pre_attn_ln.scale', 'stacked_xf.13.pre_ff_ln.scale', 'stacked_xf.14.attn.key_ln.scale', 'stacked_xf.14.attn.out.weight', 'stacked_xf.14.attn.per_dim_scale.per_dim_scale', 'stacked_xf.14.attn.qkv_proj.weight', 'stacked_xf.14.attn.query_ln.scale', 'stacked_xf.14.ff0.weight', 'stacked_xf.14.ff1.weight', 'stacked_xf.14.post_attn_ln.scale', 'stacked_xf.14.post_ff_ln.scale', 'stacked_xf.14.pre_attn_ln.scale', 'stacked_xf.14.pre_ff_ln.scale', 'stacked_xf.15.attn.key_ln.scale', 'stacked_xf.15.attn.out.weight', 'stacked_xf.15.attn.per_dim_scale.per_dim_scale', 'stacked_xf.15.attn.qkv_proj.weight', 'stacked_xf.15.attn.query_ln.scale', 'stacked_xf.15.ff0.weight', 'stacked_xf.15.ff1.weight', 'stacked_xf.15.post_attn_ln.scale', 'stacked_xf.15.post_ff_ln.scale', 'stacked_xf.15.pre_attn_ln.scale', 'stacked_xf.15.pre_ff_ln.scale', 'stacked_xf.16.attn.key_ln.scale', 'stacked_xf.16.attn.out.weight', 'stacked_xf.16.attn.per_dim_scale.per_dim_scale', 'stacked_xf.16.attn.qkv_proj.weight', 'stacked_xf.16.attn.query_ln.scale', 'stacked_xf.16.ff0.weight', 'stacked_xf.16.ff1.weight', 'stacked_xf.16.post_attn_ln.scale', 'stacked_xf.16.post_ff_ln.scale', 'stacked_xf.16.pre_attn_ln.scale', 'stacked_xf.16.pre_ff_ln.scale', 'stacked_xf.17.attn.key_ln.scale', 'stacked_xf.17.attn.out.weight', 'stacked_xf.17.attn.per_dim_scale.per_dim_scale', 'stacked_xf.17.attn.qkv_proj.weight', 'stacked_xf.17.attn.query_ln.scale', 'stacked_xf.17.ff0.weight', 'stacked_xf.17.ff1.weight', 'stacked_xf.17.post_attn_ln.scale', 'stacked_xf.17.post_ff_ln.scale', 'stacked_xf.17.pre_attn_ln.scale', 'stacked_xf.17.pre_ff_ln.scale', 'stacked_xf.18.attn.key_ln.scale', 'stacked_xf.18.attn.out.weight', 'stacked_xf.18.attn.per_dim_scale.per_dim_scale', 'stacked_xf.18.attn.qkv_proj.weight', 'stacked_xf.18.attn.query_ln.scale', 'stacked_xf.18.ff0.weight', 'stacked_xf.18.ff1.weight', 'stacked_xf.18.post_attn_ln.scale', 'stacked_xf.18.post_ff_ln.scale', 'stacked_xf.18.pre_attn_ln.scale', 'stacked_xf.18.pre_ff_ln.scale', 'stacked_xf.19.attn.key_ln.scale', 'stacked_xf.19.attn.out.weight', 'stacked_xf.19.attn.per_dim_scale.per_dim_scale', 'stacked_xf.19.attn.qkv_proj.weight', 'stacked_xf.19.attn.query_ln.scale', 'stacked_xf.19.ff0.weight', 'stacked_xf.19.ff1.weight', 'stacked_xf.19.post_attn_ln.scale', 'stacked_xf.19.post_ff_ln.scale', 'stacked_xf.19.pre_attn_ln.scale', 'stacked_xf.19.pre_ff_ln.scale', 'stacked_xf.2.attn.key_ln.scale', 'stacked_xf.2.attn.out.weight', 'stacked_xf.2.attn.per_dim_scale.per_dim_scale', 'stacked_xf.2.attn.qkv_proj.weight', 'stacked_xf.2.attn.query_ln.scale', 'stacked_xf.2.ff0.weight', 'stacked_xf.2.ff1.weight', 'stacked_xf.2.post_attn_ln.scale', 'stacked_xf.2.post_ff_ln.scale', 'stacked_xf.2.pre_attn_ln.scale', 'stacked_xf.2.pre_ff_ln.scale', 'stacked_xf.3.attn.key_ln.scale', 'stacked_xf.3.attn.out.weight', 'stacked_xf.3.attn.per_dim_scale.per_dim_scale', 'stacked_xf.3.attn.qkv_proj.weight', 'stacked_xf.3.attn.query_ln.scale', 'stacked_xf.3.ff0.weight', 'stacked_xf.3.ff1.weight', 'stacked_xf.3.post_attn_ln.scale', 'stacked_xf.3.post_ff_ln.scale', 'stacked_xf.3.pre_attn_ln.scale', 'stacked_xf.3.pre_ff_ln.scale', 'stacked_xf.4.attn.key_ln.scale', 'stacked_xf.4.attn.out.weight', 'stacked_xf.4.attn.per_dim_scale.per_dim_scale', 'stacked_xf.4.attn.qkv_proj.weight', 'stacked_xf.4.attn.query_ln.scale', 'stacked_xf.4.ff0.weight', 'stacked_xf.4.ff1.weight', 'stacked_xf.4.post_attn_ln.scale', 'stacked_xf.4.post_ff_ln.scale', 'stacked_xf.4.pre_attn_ln.scale', 'stacked_xf.4.pre_ff_ln.scale', 'stacked_xf.5.attn.key_ln.scale', 'stacked_xf.5.attn.out.weight', 'stacked_xf.5.attn.per_dim_scale.per_dim_scale', 'stacked_xf.5.attn.qkv_proj.weight', 'stacked_xf.5.attn.query_ln.scale', 'stacked_xf.5.ff0.weight', 'stacked_xf.5.ff1.weight', 'stacked_xf.5.post_attn_ln.scale', 'stacked_xf.5.post_ff_ln.scale', 'stacked_xf.5.pre_attn_ln.scale', 'stacked_xf.5.pre_ff_ln.scale', 'stacked_xf.6.attn.key_ln.scale', 'stacked_xf.6.attn.out.weight', 'stacked_xf.6.attn.per_dim_scale.per_dim_scale', 'stacked_xf.6.attn.qkv_proj.weight', 'stacked_xf.6.attn.query_ln.scale', 'stacked_xf.6.ff0.weight', 'stacked_xf.6.ff1.weight', 'stacked_xf.6.post_attn_ln.scale', 'stacked_xf.6.post_ff_ln.scale', 'stacked_xf.6.pre_attn_ln.scale', 'stacked_xf.6.pre_ff_ln.scale', 'stacked_xf.7.attn.key_ln.scale', 'stacked_xf.7.attn.out.weight', 'stacked_xf.7.attn.per_dim_scale.per_dim_scale', 'stacked_xf.7.attn.qkv_proj.weight', 'stacked_xf.7.attn.query_ln.scale', 'stacked_xf.7.ff0.weight', 'stacked_xf.7.ff1.weight', 'stacked_xf.7.post_attn_ln.scale', 'stacked_xf.7.post_ff_ln.scale', 'stacked_xf.7.pre_attn_ln.scale', 'stacked_xf.7.pre_ff_ln.scale', 'stacked_xf.8.attn.key_ln.scale', 'stacked_xf.8.attn.out.weight', 'stacked_xf.8.attn.per_dim_scale.per_dim_scale', 'stacked_xf.8.attn.qkv_proj.weight', 'stacked_xf.8.attn.query_ln.scale', 'stacked_xf.8.ff0.weight', 'stacked_xf.8.ff1.weight', 'stacked_xf.8.post_attn_ln.scale', 'stacked_xf.8.post_ff_ln.scale', 'stacked_xf.8.pre_attn_ln.scale', 'stacked_xf.8.pre_ff_ln.scale', 'stacked_xf.9.attn.key_ln.scale', 'stacked_xf.9.attn.out.weight', 'stacked_xf.9.attn.per_dim_scale.per_dim_scale', 'stacked_xf.9.attn.qkv_proj.weight', 'stacked_xf.9.attn.query_ln.scale', 'stacked_xf.9.ff0.weight', 'stacked_xf.9.ff1.weight', 'stacked_xf.9.post_attn_ln.scale', 'stacked_xf.9.post_ff_ln.scale', 'stacked_xf.9.pre_attn_ln.scale', 'stacked_xf.9.pre_ff_ln.scale', 'tokenizer.hidden_layer.bias', 'tokenizer.hidden_layer.weight', 'tokenizer.output_layer.bias', 'tokenizer.output_layer.weight', 'tokenizer.residual_layer.bias', 'tokenizer.residual_layer.weight']\n",
            "- This IS expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of TimesFmModelForPrediction were not initialized from the model checkpoint at google/timesfm-2.5-200m-pytorch and are newly initialized: ['decoder.freq_emb.weight', 'decoder.input_ff_layer.input_layer.bias', 'decoder.input_ff_layer.input_layer.weight', 'decoder.input_ff_layer.output_layer.bias', 'decoder.input_ff_layer.output_layer.weight', 'decoder.input_ff_layer.residual_layer.bias', 'decoder.input_ff_layer.residual_layer.weight', 'decoder.layers.0.input_layernorm.weight', 'decoder.layers.0.mlp.down_proj.bias', 'decoder.layers.0.mlp.down_proj.weight', 'decoder.layers.0.mlp.gate_proj.bias', 'decoder.layers.0.mlp.gate_proj.weight', 'decoder.layers.0.mlp.layer_norm.bias', 'decoder.layers.0.mlp.layer_norm.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.o_proj.bias', 'decoder.layers.0.self_attn.o_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.scaling', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.1.input_layernorm.weight', 'decoder.layers.1.mlp.down_proj.bias', 'decoder.layers.1.mlp.down_proj.weight', 'decoder.layers.1.mlp.gate_proj.bias', 'decoder.layers.1.mlp.gate_proj.weight', 'decoder.layers.1.mlp.layer_norm.bias', 'decoder.layers.1.mlp.layer_norm.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.o_proj.bias', 'decoder.layers.1.self_attn.o_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.scaling', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.10.input_layernorm.weight', 'decoder.layers.10.mlp.down_proj.bias', 'decoder.layers.10.mlp.down_proj.weight', 'decoder.layers.10.mlp.gate_proj.bias', 'decoder.layers.10.mlp.gate_proj.weight', 'decoder.layers.10.mlp.layer_norm.bias', 'decoder.layers.10.mlp.layer_norm.weight', 'decoder.layers.10.self_attn.k_proj.bias', 'decoder.layers.10.self_attn.k_proj.weight', 'decoder.layers.10.self_attn.o_proj.bias', 'decoder.layers.10.self_attn.o_proj.weight', 'decoder.layers.10.self_attn.q_proj.bias', 'decoder.layers.10.self_attn.q_proj.weight', 'decoder.layers.10.self_attn.scaling', 'decoder.layers.10.self_attn.v_proj.bias', 'decoder.layers.10.self_attn.v_proj.weight', 'decoder.layers.11.input_layernorm.weight', 'decoder.layers.11.mlp.down_proj.bias', 'decoder.layers.11.mlp.down_proj.weight', 'decoder.layers.11.mlp.gate_proj.bias', 'decoder.layers.11.mlp.gate_proj.weight', 'decoder.layers.11.mlp.layer_norm.bias', 'decoder.layers.11.mlp.layer_norm.weight', 'decoder.layers.11.self_attn.k_proj.bias', 'decoder.layers.11.self_attn.k_proj.weight', 'decoder.layers.11.self_attn.o_proj.bias', 'decoder.layers.11.self_attn.o_proj.weight', 'decoder.layers.11.self_attn.q_proj.bias', 'decoder.layers.11.self_attn.q_proj.weight', 'decoder.layers.11.self_attn.scaling', 'decoder.layers.11.self_attn.v_proj.bias', 'decoder.layers.11.self_attn.v_proj.weight', 'decoder.layers.12.input_layernorm.weight', 'decoder.layers.12.mlp.down_proj.bias', 'decoder.layers.12.mlp.down_proj.weight', 'decoder.layers.12.mlp.gate_proj.bias', 'decoder.layers.12.mlp.gate_proj.weight', 'decoder.layers.12.mlp.layer_norm.bias', 'decoder.layers.12.mlp.layer_norm.weight', 'decoder.layers.12.self_attn.k_proj.bias', 'decoder.layers.12.self_attn.k_proj.weight', 'decoder.layers.12.self_attn.o_proj.bias', 'decoder.layers.12.self_attn.o_proj.weight', 'decoder.layers.12.self_attn.q_proj.bias', 'decoder.layers.12.self_attn.q_proj.weight', 'decoder.layers.12.self_attn.scaling', 'decoder.layers.12.self_attn.v_proj.bias', 'decoder.layers.12.self_attn.v_proj.weight', 'decoder.layers.13.input_layernorm.weight', 'decoder.layers.13.mlp.down_proj.bias', 'decoder.layers.13.mlp.down_proj.weight', 'decoder.layers.13.mlp.gate_proj.bias', 'decoder.layers.13.mlp.gate_proj.weight', 'decoder.layers.13.mlp.layer_norm.bias', 'decoder.layers.13.mlp.layer_norm.weight', 'decoder.layers.13.self_attn.k_proj.bias', 'decoder.layers.13.self_attn.k_proj.weight', 'decoder.layers.13.self_attn.o_proj.bias', 'decoder.layers.13.self_attn.o_proj.weight', 'decoder.layers.13.self_attn.q_proj.bias', 'decoder.layers.13.self_attn.q_proj.weight', 'decoder.layers.13.self_attn.scaling', 'decoder.layers.13.self_attn.v_proj.bias', 'decoder.layers.13.self_attn.v_proj.weight', 'decoder.layers.14.input_layernorm.weight', 'decoder.layers.14.mlp.down_proj.bias', 'decoder.layers.14.mlp.down_proj.weight', 'decoder.layers.14.mlp.gate_proj.bias', 'decoder.layers.14.mlp.gate_proj.weight', 'decoder.layers.14.mlp.layer_norm.bias', 'decoder.layers.14.mlp.layer_norm.weight', 'decoder.layers.14.self_attn.k_proj.bias', 'decoder.layers.14.self_attn.k_proj.weight', 'decoder.layers.14.self_attn.o_proj.bias', 'decoder.layers.14.self_attn.o_proj.weight', 'decoder.layers.14.self_attn.q_proj.bias', 'decoder.layers.14.self_attn.q_proj.weight', 'decoder.layers.14.self_attn.scaling', 'decoder.layers.14.self_attn.v_proj.bias', 'decoder.layers.14.self_attn.v_proj.weight', 'decoder.layers.15.input_layernorm.weight', 'decoder.layers.15.mlp.down_proj.bias', 'decoder.layers.15.mlp.down_proj.weight', 'decoder.layers.15.mlp.gate_proj.bias', 'decoder.layers.15.mlp.gate_proj.weight', 'decoder.layers.15.mlp.layer_norm.bias', 'decoder.layers.15.mlp.layer_norm.weight', 'decoder.layers.15.self_attn.k_proj.bias', 'decoder.layers.15.self_attn.k_proj.weight', 'decoder.layers.15.self_attn.o_proj.bias', 'decoder.layers.15.self_attn.o_proj.weight', 'decoder.layers.15.self_attn.q_proj.bias', 'decoder.layers.15.self_attn.q_proj.weight', 'decoder.layers.15.self_attn.scaling', 'decoder.layers.15.self_attn.v_proj.bias', 'decoder.layers.15.self_attn.v_proj.weight', 'decoder.layers.16.input_layernorm.weight', 'decoder.layers.16.mlp.down_proj.bias', 'decoder.layers.16.mlp.down_proj.weight', 'decoder.layers.16.mlp.gate_proj.bias', 'decoder.layers.16.mlp.gate_proj.weight', 'decoder.layers.16.mlp.layer_norm.bias', 'decoder.layers.16.mlp.layer_norm.weight', 'decoder.layers.16.self_attn.k_proj.bias', 'decoder.layers.16.self_attn.k_proj.weight', 'decoder.layers.16.self_attn.o_proj.bias', 'decoder.layers.16.self_attn.o_proj.weight', 'decoder.layers.16.self_attn.q_proj.bias', 'decoder.layers.16.self_attn.q_proj.weight', 'decoder.layers.16.self_attn.scaling', 'decoder.layers.16.self_attn.v_proj.bias', 'decoder.layers.16.self_attn.v_proj.weight', 'decoder.layers.17.input_layernorm.weight', 'decoder.layers.17.mlp.down_proj.bias', 'decoder.layers.17.mlp.down_proj.weight', 'decoder.layers.17.mlp.gate_proj.bias', 'decoder.layers.17.mlp.gate_proj.weight', 'decoder.layers.17.mlp.layer_norm.bias', 'decoder.layers.17.mlp.layer_norm.weight', 'decoder.layers.17.self_attn.k_proj.bias', 'decoder.layers.17.self_attn.k_proj.weight', 'decoder.layers.17.self_attn.o_proj.bias', 'decoder.layers.17.self_attn.o_proj.weight', 'decoder.layers.17.self_attn.q_proj.bias', 'decoder.layers.17.self_attn.q_proj.weight', 'decoder.layers.17.self_attn.scaling', 'decoder.layers.17.self_attn.v_proj.bias', 'decoder.layers.17.self_attn.v_proj.weight', 'decoder.layers.18.input_layernorm.weight', 'decoder.layers.18.mlp.down_proj.bias', 'decoder.layers.18.mlp.down_proj.weight', 'decoder.layers.18.mlp.gate_proj.bias', 'decoder.layers.18.mlp.gate_proj.weight', 'decoder.layers.18.mlp.layer_norm.bias', 'decoder.layers.18.mlp.layer_norm.weight', 'decoder.layers.18.self_attn.k_proj.bias', 'decoder.layers.18.self_attn.k_proj.weight', 'decoder.layers.18.self_attn.o_proj.bias', 'decoder.layers.18.self_attn.o_proj.weight', 'decoder.layers.18.self_attn.q_proj.bias', 'decoder.layers.18.self_attn.q_proj.weight', 'decoder.layers.18.self_attn.scaling', 'decoder.layers.18.self_attn.v_proj.bias', 'decoder.layers.18.self_attn.v_proj.weight', 'decoder.layers.19.input_layernorm.weight', 'decoder.layers.19.mlp.down_proj.bias', 'decoder.layers.19.mlp.down_proj.weight', 'decoder.layers.19.mlp.gate_proj.bias', 'decoder.layers.19.mlp.gate_proj.weight', 'decoder.layers.19.mlp.layer_norm.bias', 'decoder.layers.19.mlp.layer_norm.weight', 'decoder.layers.19.self_attn.k_proj.bias', 'decoder.layers.19.self_attn.k_proj.weight', 'decoder.layers.19.self_attn.o_proj.bias', 'decoder.layers.19.self_attn.o_proj.weight', 'decoder.layers.19.self_attn.q_proj.bias', 'decoder.layers.19.self_attn.q_proj.weight', 'decoder.layers.19.self_attn.scaling', 'decoder.layers.19.self_attn.v_proj.bias', 'decoder.layers.19.self_attn.v_proj.weight', 'decoder.layers.2.input_layernorm.weight', 'decoder.layers.2.mlp.down_proj.bias', 'decoder.layers.2.mlp.down_proj.weight', 'decoder.layers.2.mlp.gate_proj.bias', 'decoder.layers.2.mlp.gate_proj.weight', 'decoder.layers.2.mlp.layer_norm.bias', 'decoder.layers.2.mlp.layer_norm.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.o_proj.bias', 'decoder.layers.2.self_attn.o_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.scaling', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.3.input_layernorm.weight', 'decoder.layers.3.mlp.down_proj.bias', 'decoder.layers.3.mlp.down_proj.weight', 'decoder.layers.3.mlp.gate_proj.bias', 'decoder.layers.3.mlp.gate_proj.weight', 'decoder.layers.3.mlp.layer_norm.bias', 'decoder.layers.3.mlp.layer_norm.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.o_proj.bias', 'decoder.layers.3.self_attn.o_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.scaling', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.4.input_layernorm.weight', 'decoder.layers.4.mlp.down_proj.bias', 'decoder.layers.4.mlp.down_proj.weight', 'decoder.layers.4.mlp.gate_proj.bias', 'decoder.layers.4.mlp.gate_proj.weight', 'decoder.layers.4.mlp.layer_norm.bias', 'decoder.layers.4.mlp.layer_norm.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.o_proj.bias', 'decoder.layers.4.self_attn.o_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.scaling', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.5.input_layernorm.weight', 'decoder.layers.5.mlp.down_proj.bias', 'decoder.layers.5.mlp.down_proj.weight', 'decoder.layers.5.mlp.gate_proj.bias', 'decoder.layers.5.mlp.gate_proj.weight', 'decoder.layers.5.mlp.layer_norm.bias', 'decoder.layers.5.mlp.layer_norm.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.o_proj.bias', 'decoder.layers.5.self_attn.o_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.scaling', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.6.input_layernorm.weight', 'decoder.layers.6.mlp.down_proj.bias', 'decoder.layers.6.mlp.down_proj.weight', 'decoder.layers.6.mlp.gate_proj.bias', 'decoder.layers.6.mlp.gate_proj.weight', 'decoder.layers.6.mlp.layer_norm.bias', 'decoder.layers.6.mlp.layer_norm.weight', 'decoder.layers.6.self_attn.k_proj.bias', 'decoder.layers.6.self_attn.k_proj.weight', 'decoder.layers.6.self_attn.o_proj.bias', 'decoder.layers.6.self_attn.o_proj.weight', 'decoder.layers.6.self_attn.q_proj.bias', 'decoder.layers.6.self_attn.q_proj.weight', 'decoder.layers.6.self_attn.scaling', 'decoder.layers.6.self_attn.v_proj.bias', 'decoder.layers.6.self_attn.v_proj.weight', 'decoder.layers.7.input_layernorm.weight', 'decoder.layers.7.mlp.down_proj.bias', 'decoder.layers.7.mlp.down_proj.weight', 'decoder.layers.7.mlp.gate_proj.bias', 'decoder.layers.7.mlp.gate_proj.weight', 'decoder.layers.7.mlp.layer_norm.bias', 'decoder.layers.7.mlp.layer_norm.weight', 'decoder.layers.7.self_attn.k_proj.bias', 'decoder.layers.7.self_attn.k_proj.weight', 'decoder.layers.7.self_attn.o_proj.bias', 'decoder.layers.7.self_attn.o_proj.weight', 'decoder.layers.7.self_attn.q_proj.bias', 'decoder.layers.7.self_attn.q_proj.weight', 'decoder.layers.7.self_attn.scaling', 'decoder.layers.7.self_attn.v_proj.bias', 'decoder.layers.7.self_attn.v_proj.weight', 'decoder.layers.8.input_layernorm.weight', 'decoder.layers.8.mlp.down_proj.bias', 'decoder.layers.8.mlp.down_proj.weight', 'decoder.layers.8.mlp.gate_proj.bias', 'decoder.layers.8.mlp.gate_proj.weight', 'decoder.layers.8.mlp.layer_norm.bias', 'decoder.layers.8.mlp.layer_norm.weight', 'decoder.layers.8.self_attn.k_proj.bias', 'decoder.layers.8.self_attn.k_proj.weight', 'decoder.layers.8.self_attn.o_proj.bias', 'decoder.layers.8.self_attn.o_proj.weight', 'decoder.layers.8.self_attn.q_proj.bias', 'decoder.layers.8.self_attn.q_proj.weight', 'decoder.layers.8.self_attn.scaling', 'decoder.layers.8.self_attn.v_proj.bias', 'decoder.layers.8.self_attn.v_proj.weight', 'decoder.layers.9.input_layernorm.weight', 'decoder.layers.9.mlp.down_proj.bias', 'decoder.layers.9.mlp.down_proj.weight', 'decoder.layers.9.mlp.gate_proj.bias', 'decoder.layers.9.mlp.gate_proj.weight', 'decoder.layers.9.mlp.layer_norm.bias', 'decoder.layers.9.mlp.layer_norm.weight', 'decoder.layers.9.self_attn.k_proj.bias', 'decoder.layers.9.self_attn.k_proj.weight', 'decoder.layers.9.self_attn.o_proj.bias', 'decoder.layers.9.self_attn.o_proj.weight', 'decoder.layers.9.self_attn.q_proj.bias', 'decoder.layers.9.self_attn.q_proj.weight', 'decoder.layers.9.self_attn.scaling', 'decoder.layers.9.self_attn.v_proj.bias', 'decoder.layers.9.self_attn.v_proj.weight', 'horizon_ff_layer.input_layer.bias', 'horizon_ff_layer.input_layer.weight', 'horizon_ff_layer.output_layer.bias', 'horizon_ff_layer.output_layer.weight', 'horizon_ff_layer.residual_layer.bias', 'horizon_ff_layer.residual_layer.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n",
            "  Epoch 1/100 train_loss=1.4073 train_acc=0.2333 eval_loss=0.5571 eval_acc=0.7667 (best)\n",
            "  Epoch 2/100 train_loss=0.3956 train_acc=0.8500 eval_loss=0.2659 eval_acc=0.9333 (best)\n",
            "  Epoch 3/100 train_loss=0.0717 train_acc=0.9833 eval_loss=0.2232 eval_acc=0.8833 (best)\n",
            "  Epoch 4/100 train_loss=0.0338 train_acc=1.0000 eval_loss=0.2229 eval_acc=0.9167 (best)\n",
            "  Epoch 5/100 train_loss=0.0138 train_acc=1.0000 eval_loss=0.2177 eval_acc=0.9167 (best)\n",
            "  Epoch 6/100 train_loss=0.0019 train_acc=1.0000 eval_loss=0.1991 eval_acc=0.9167 (best)\n",
            "  Epoch 7/100 train_loss=0.0006 train_acc=1.0000 eval_loss=0.1879 eval_acc=0.9333 (best)\n",
            "  Epoch 8/100 train_loss=0.0003 train_acc=1.0000 eval_loss=0.1851 eval_acc=0.9167 (best)\n",
            "  Epoch 9/100 train_loss=0.0002 train_acc=1.0000 eval_loss=0.1854 eval_acc=0.9167 \n",
            "  Epoch 10/100 train_loss=0.0001 train_acc=1.0000 eval_loss=0.1872 eval_acc=0.9167 \n",
            "  Epoch 11/100 train_loss=0.0001 train_acc=1.0000 eval_loss=0.1904 eval_acc=0.9333 \n",
            "  Epoch 12/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.1928 eval_acc=0.9333 \n",
            "  Epoch 13/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.1949 eval_acc=0.9333 \n",
            "  Epoch 14/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.1967 eval_acc=0.9333 \n",
            "  Epoch 15/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.1981 eval_acc=0.9333 \n",
            "  Epoch 16/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.1990 eval_acc=0.9333 \n",
            "  Epoch 17/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.1996 eval_acc=0.9333 \n",
            "  Epoch 18/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.2001 eval_acc=0.9333 \n",
            "  Early stopping on google/timesfm-2.5-200m-pytorch: no improvement for 10 epochs (best epoch = 8)\n",
            "    tfm[google/timesfm-2.5-200m-pytorch] train_acc=1.0000 eval_acc=0.93333333333333334813630699500208720564842224\n",
            "    mrh_acc=0.9500 mr+h+kg_acc=0.9667 kg_acc=0.9833 ensemble=0.9667 (w=0.60)\n",
            "  Split 1/1 - accuracy=0.9667 time=69.9s\n",
            "Completed Car: Mean Acc=0.9667\n",
            "\n",
            "=== 9/109 CBF ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n",
            "    Gate split 1/5: baseline_loss=0.1866 adaptive_loss=0.0193\n",
            "    Gate split 2/5: baseline_loss=0.0248 adaptive_loss=0.0120\n",
            "    Gate split 3/5: baseline_loss=0.1841 adaptive_loss=0.0238\n",
            "    Gate split 4/5: baseline_loss=0.0710 adaptive_loss=0.1512\n",
            "    Gate split 5/5: baseline_loss=0.1396 adaptive_loss=0.2266\n",
            "  Decision: Adaptive kept (loss 0.0866 vs baseline 0.1212, delta=-0.0346 <= +0.0200); savgol(window=7, poly=2) - high noise (std_diff)\n",
            "\n",
            "=== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at google/timesfm-2.5-200m-pytorch were not used when initializing TimesFmModelForPrediction: ['output_projection_point.hidden_layer.weight', 'output_projection_point.output_layer.weight', 'output_projection_point.residual_layer.weight', 'output_projection_quantiles.hidden_layer.weight', 'output_projection_quantiles.output_layer.weight', 'output_projection_quantiles.residual_layer.weight', 'stacked_xf.0.attn.key_ln.scale', 'stacked_xf.0.attn.out.weight', 'stacked_xf.0.attn.per_dim_scale.per_dim_scale', 'stacked_xf.0.attn.qkv_proj.weight', 'stacked_xf.0.attn.query_ln.scale', 'stacked_xf.0.ff0.weight', 'stacked_xf.0.ff1.weight', 'stacked_xf.0.post_attn_ln.scale', 'stacked_xf.0.post_ff_ln.scale', 'stacked_xf.0.pre_attn_ln.scale', 'stacked_xf.0.pre_ff_ln.scale', 'stacked_xf.1.attn.key_ln.scale', 'stacked_xf.1.attn.out.weight', 'stacked_xf.1.attn.per_dim_scale.per_dim_scale', 'stacked_xf.1.attn.qkv_proj.weight', 'stacked_xf.1.attn.query_ln.scale', 'stacked_xf.1.ff0.weight', 'stacked_xf.1.ff1.weight', 'stacked_xf.1.post_attn_ln.scale', 'stacked_xf.1.post_ff_ln.scale', 'stacked_xf.1.pre_attn_ln.scale', 'stacked_xf.1.pre_ff_ln.scale', 'stacked_xf.10.attn.key_ln.scale', 'stacked_xf.10.attn.out.weight', 'stacked_xf.10.attn.per_dim_scale.per_dim_scale', 'stacked_xf.10.attn.qkv_proj.weight', 'stacked_xf.10.attn.query_ln.scale', 'stacked_xf.10.ff0.weight', 'stacked_xf.10.ff1.weight', 'stacked_xf.10.post_attn_ln.scale', 'stacked_xf.10.post_ff_ln.scale', 'stacked_xf.10.pre_attn_ln.scale', 'stacked_xf.10.pre_ff_ln.scale', 'stacked_xf.11.attn.key_ln.scale', 'stacked_xf.11.attn.out.weight', 'stacked_xf.11.attn.per_dim_scale.per_dim_scale', 'stacked_xf.11.attn.qkv_proj.weight', 'stacked_xf.11.attn.query_ln.scale', 'stacked_xf.11.ff0.weight', 'stacked_xf.11.ff1.weight', 'stacked_xf.11.post_attn_ln.scale', 'stacked_xf.11.post_ff_ln.scale', 'stacked_xf.11.pre_attn_ln.scale', 'stacked_xf.11.pre_ff_ln.scale', 'stacked_xf.12.attn.key_ln.scale', 'stacked_xf.12.attn.out.weight', 'stacked_xf.12.attn.per_dim_scale.per_dim_scale', 'stacked_xf.12.attn.qkv_proj.weight', 'stacked_xf.12.attn.query_ln.scale', 'stacked_xf.12.ff0.weight', 'stacked_xf.12.ff1.weight', 'stacked_xf.12.post_attn_ln.scale', 'stacked_xf.12.post_ff_ln.scale', 'stacked_xf.12.pre_attn_ln.scale', 'stacked_xf.12.pre_ff_ln.scale', 'stacked_xf.13.attn.key_ln.scale', 'stacked_xf.13.attn.out.weight', 'stacked_xf.13.attn.per_dim_scale.per_dim_scale', 'stacked_xf.13.attn.qkv_proj.weight', 'stacked_xf.13.attn.query_ln.scale', 'stacked_xf.13.ff0.weight', 'stacked_xf.13.ff1.weight', 'stacked_xf.13.post_attn_ln.scale', 'stacked_xf.13.post_ff_ln.scale', 'stacked_xf.13.pre_attn_ln.scale', 'stacked_xf.13.pre_ff_ln.scale', 'stacked_xf.14.attn.key_ln.scale', 'stacked_xf.14.attn.out.weight', 'stacked_xf.14.attn.per_dim_scale.per_dim_scale', 'stacked_xf.14.attn.qkv_proj.weight', 'stacked_xf.14.attn.query_ln.scale', 'stacked_xf.14.ff0.weight', 'stacked_xf.14.ff1.weight', 'stacked_xf.14.post_attn_ln.scale', 'stacked_xf.14.post_ff_ln.scale', 'stacked_xf.14.pre_attn_ln.scale', 'stacked_xf.14.pre_ff_ln.scale', 'stacked_xf.15.attn.key_ln.scale', 'stacked_xf.15.attn.out.weight', 'stacked_xf.15.attn.per_dim_scale.per_dim_scale', 'stacked_xf.15.attn.qkv_proj.weight', 'stacked_xf.15.attn.query_ln.scale', 'stacked_xf.15.ff0.weight', 'stacked_xf.15.ff1.weight', 'stacked_xf.15.post_attn_ln.scale', 'stacked_xf.15.post_ff_ln.scale', 'stacked_xf.15.pre_attn_ln.scale', 'stacked_xf.15.pre_ff_ln.scale', 'stacked_xf.16.attn.key_ln.scale', 'stacked_xf.16.attn.out.weight', 'stacked_xf.16.attn.per_dim_scale.per_dim_scale', 'stacked_xf.16.attn.qkv_proj.weight', 'stacked_xf.16.attn.query_ln.scale', 'stacked_xf.16.ff0.weight', 'stacked_xf.16.ff1.weight', 'stacked_xf.16.post_attn_ln.scale', 'stacked_xf.16.post_ff_ln.scale', 'stacked_xf.16.pre_attn_ln.scale', 'stacked_xf.16.pre_ff_ln.scale', 'stacked_xf.17.attn.key_ln.scale', 'stacked_xf.17.attn.out.weight', 'stacked_xf.17.attn.per_dim_scale.per_dim_scale', 'stacked_xf.17.attn.qkv_proj.weight', 'stacked_xf.17.attn.query_ln.scale', 'stacked_xf.17.ff0.weight', 'stacked_xf.17.ff1.weight', 'stacked_xf.17.post_attn_ln.scale', 'stacked_xf.17.post_ff_ln.scale', 'stacked_xf.17.pre_attn_ln.scale', 'stacked_xf.17.pre_ff_ln.scale', 'stacked_xf.18.attn.key_ln.scale', 'stacked_xf.18.attn.out.weight', 'stacked_xf.18.attn.per_dim_scale.per_dim_scale', 'stacked_xf.18.attn.qkv_proj.weight', 'stacked_xf.18.attn.query_ln.scale', 'stacked_xf.18.ff0.weight', 'stacked_xf.18.ff1.weight', 'stacked_xf.18.post_attn_ln.scale', 'stacked_xf.18.post_ff_ln.scale', 'stacked_xf.18.pre_attn_ln.scale', 'stacked_xf.18.pre_ff_ln.scale', 'stacked_xf.19.attn.key_ln.scale', 'stacked_xf.19.attn.out.weight', 'stacked_xf.19.attn.per_dim_scale.per_dim_scale', 'stacked_xf.19.attn.qkv_proj.weight', 'stacked_xf.19.attn.query_ln.scale', 'stacked_xf.19.ff0.weight', 'stacked_xf.19.ff1.weight', 'stacked_xf.19.post_attn_ln.scale', 'stacked_xf.19.post_ff_ln.scale', 'stacked_xf.19.pre_attn_ln.scale', 'stacked_xf.19.pre_ff_ln.scale', 'stacked_xf.2.attn.key_ln.scale', 'stacked_xf.2.attn.out.weight', 'stacked_xf.2.attn.per_dim_scale.per_dim_scale', 'stacked_xf.2.attn.qkv_proj.weight', 'stacked_xf.2.attn.query_ln.scale', 'stacked_xf.2.ff0.weight', 'stacked_xf.2.ff1.weight', 'stacked_xf.2.post_attn_ln.scale', 'stacked_xf.2.post_ff_ln.scale', 'stacked_xf.2.pre_attn_ln.scale', 'stacked_xf.2.pre_ff_ln.scale', 'stacked_xf.3.attn.key_ln.scale', 'stacked_xf.3.attn.out.weight', 'stacked_xf.3.attn.per_dim_scale.per_dim_scale', 'stacked_xf.3.attn.qkv_proj.weight', 'stacked_xf.3.attn.query_ln.scale', 'stacked_xf.3.ff0.weight', 'stacked_xf.3.ff1.weight', 'stacked_xf.3.post_attn_ln.scale', 'stacked_xf.3.post_ff_ln.scale', 'stacked_xf.3.pre_attn_ln.scale', 'stacked_xf.3.pre_ff_ln.scale', 'stacked_xf.4.attn.key_ln.scale', 'stacked_xf.4.attn.out.weight', 'stacked_xf.4.attn.per_dim_scale.per_dim_scale', 'stacked_xf.4.attn.qkv_proj.weight', 'stacked_xf.4.attn.query_ln.scale', 'stacked_xf.4.ff0.weight', 'stacked_xf.4.ff1.weight', 'stacked_xf.4.post_attn_ln.scale', 'stacked_xf.4.post_ff_ln.scale', 'stacked_xf.4.pre_attn_ln.scale', 'stacked_xf.4.pre_ff_ln.scale', 'stacked_xf.5.attn.key_ln.scale', 'stacked_xf.5.attn.out.weight', 'stacked_xf.5.attn.per_dim_scale.per_dim_scale', 'stacked_xf.5.attn.qkv_proj.weight', 'stacked_xf.5.attn.query_ln.scale', 'stacked_xf.5.ff0.weight', 'stacked_xf.5.ff1.weight', 'stacked_xf.5.post_attn_ln.scale', 'stacked_xf.5.post_ff_ln.scale', 'stacked_xf.5.pre_attn_ln.scale', 'stacked_xf.5.pre_ff_ln.scale', 'stacked_xf.6.attn.key_ln.scale', 'stacked_xf.6.attn.out.weight', 'stacked_xf.6.attn.per_dim_scale.per_dim_scale', 'stacked_xf.6.attn.qkv_proj.weight', 'stacked_xf.6.attn.query_ln.scale', 'stacked_xf.6.ff0.weight', 'stacked_xf.6.ff1.weight', 'stacked_xf.6.post_attn_ln.scale', 'stacked_xf.6.post_ff_ln.scale', 'stacked_xf.6.pre_attn_ln.scale', 'stacked_xf.6.pre_ff_ln.scale', 'stacked_xf.7.attn.key_ln.scale', 'stacked_xf.7.attn.out.weight', 'stacked_xf.7.attn.per_dim_scale.per_dim_scale', 'stacked_xf.7.attn.qkv_proj.weight', 'stacked_xf.7.attn.query_ln.scale', 'stacked_xf.7.ff0.weight', 'stacked_xf.7.ff1.weight', 'stacked_xf.7.post_attn_ln.scale', 'stacked_xf.7.post_ff_ln.scale', 'stacked_xf.7.pre_attn_ln.scale', 'stacked_xf.7.pre_ff_ln.scale', 'stacked_xf.8.attn.key_ln.scale', 'stacked_xf.8.attn.out.weight', 'stacked_xf.8.attn.per_dim_scale.per_dim_scale', 'stacked_xf.8.attn.qkv_proj.weight', 'stacked_xf.8.attn.query_ln.scale', 'stacked_xf.8.ff0.weight', 'stacked_xf.8.ff1.weight', 'stacked_xf.8.post_attn_ln.scale', 'stacked_xf.8.post_ff_ln.scale', 'stacked_xf.8.pre_attn_ln.scale', 'stacked_xf.8.pre_ff_ln.scale', 'stacked_xf.9.attn.key_ln.scale', 'stacked_xf.9.attn.out.weight', 'stacked_xf.9.attn.per_dim_scale.per_dim_scale', 'stacked_xf.9.attn.qkv_proj.weight', 'stacked_xf.9.attn.query_ln.scale', 'stacked_xf.9.ff0.weight', 'stacked_xf.9.ff1.weight', 'stacked_xf.9.post_attn_ln.scale', 'stacked_xf.9.post_ff_ln.scale', 'stacked_xf.9.pre_attn_ln.scale', 'stacked_xf.9.pre_ff_ln.scale', 'tokenizer.hidden_layer.bias', 'tokenizer.hidden_layer.weight', 'tokenizer.output_layer.bias', 'tokenizer.output_layer.weight', 'tokenizer.residual_layer.bias', 'tokenizer.residual_layer.weight']\n",
            "- This IS expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of TimesFmModelForPrediction were not initialized from the model checkpoint at google/timesfm-2.5-200m-pytorch and are newly initialized: ['decoder.freq_emb.weight', 'decoder.input_ff_layer.input_layer.bias', 'decoder.input_ff_layer.input_layer.weight', 'decoder.input_ff_layer.output_layer.bias', 'decoder.input_ff_layer.output_layer.weight', 'decoder.input_ff_layer.residual_layer.bias', 'decoder.input_ff_layer.residual_layer.weight', 'decoder.layers.0.input_layernorm.weight', 'decoder.layers.0.mlp.down_proj.bias', 'decoder.layers.0.mlp.down_proj.weight', 'decoder.layers.0.mlp.gate_proj.bias', 'decoder.layers.0.mlp.gate_proj.weight', 'decoder.layers.0.mlp.layer_norm.bias', 'decoder.layers.0.mlp.layer_norm.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.o_proj.bias', 'decoder.layers.0.self_attn.o_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.scaling', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.1.input_layernorm.weight', 'decoder.layers.1.mlp.down_proj.bias', 'decoder.layers.1.mlp.down_proj.weight', 'decoder.layers.1.mlp.gate_proj.bias', 'decoder.layers.1.mlp.gate_proj.weight', 'decoder.layers.1.mlp.layer_norm.bias', 'decoder.layers.1.mlp.layer_norm.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.o_proj.bias', 'decoder.layers.1.self_attn.o_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.scaling', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.10.input_layernorm.weight', 'decoder.layers.10.mlp.down_proj.bias', 'decoder.layers.10.mlp.down_proj.weight', 'decoder.layers.10.mlp.gate_proj.bias', 'decoder.layers.10.mlp.gate_proj.weight', 'decoder.layers.10.mlp.layer_norm.bias', 'decoder.layers.10.mlp.layer_norm.weight', 'decoder.layers.10.self_attn.k_proj.bias', 'decoder.layers.10.self_attn.k_proj.weight', 'decoder.layers.10.self_attn.o_proj.bias', 'decoder.layers.10.self_attn.o_proj.weight', 'decoder.layers.10.self_attn.q_proj.bias', 'decoder.layers.10.self_attn.q_proj.weight', 'decoder.layers.10.self_attn.scaling', 'decoder.layers.10.self_attn.v_proj.bias', 'decoder.layers.10.self_attn.v_proj.weight', 'decoder.layers.11.input_layernorm.weight', 'decoder.layers.11.mlp.down_proj.bias', 'decoder.layers.11.mlp.down_proj.weight', 'decoder.layers.11.mlp.gate_proj.bias', 'decoder.layers.11.mlp.gate_proj.weight', 'decoder.layers.11.mlp.layer_norm.bias', 'decoder.layers.11.mlp.layer_norm.weight', 'decoder.layers.11.self_attn.k_proj.bias', 'decoder.layers.11.self_attn.k_proj.weight', 'decoder.layers.11.self_attn.o_proj.bias', 'decoder.layers.11.self_attn.o_proj.weight', 'decoder.layers.11.self_attn.q_proj.bias', 'decoder.layers.11.self_attn.q_proj.weight', 'decoder.layers.11.self_attn.scaling', 'decoder.layers.11.self_attn.v_proj.bias', 'decoder.layers.11.self_attn.v_proj.weight', 'decoder.layers.12.input_layernorm.weight', 'decoder.layers.12.mlp.down_proj.bias', 'decoder.layers.12.mlp.down_proj.weight', 'decoder.layers.12.mlp.gate_proj.bias', 'decoder.layers.12.mlp.gate_proj.weight', 'decoder.layers.12.mlp.layer_norm.bias', 'decoder.layers.12.mlp.layer_norm.weight', 'decoder.layers.12.self_attn.k_proj.bias', 'decoder.layers.12.self_attn.k_proj.weight', 'decoder.layers.12.self_attn.o_proj.bias', 'decoder.layers.12.self_attn.o_proj.weight', 'decoder.layers.12.self_attn.q_proj.bias', 'decoder.layers.12.self_attn.q_proj.weight', 'decoder.layers.12.self_attn.scaling', 'decoder.layers.12.self_attn.v_proj.bias', 'decoder.layers.12.self_attn.v_proj.weight', 'decoder.layers.13.input_layernorm.weight', 'decoder.layers.13.mlp.down_proj.bias', 'decoder.layers.13.mlp.down_proj.weight', 'decoder.layers.13.mlp.gate_proj.bias', 'decoder.layers.13.mlp.gate_proj.weight', 'decoder.layers.13.mlp.layer_norm.bias', 'decoder.layers.13.mlp.layer_norm.weight', 'decoder.layers.13.self_attn.k_proj.bias', 'decoder.layers.13.self_attn.k_proj.weight', 'decoder.layers.13.self_attn.o_proj.bias', 'decoder.layers.13.self_attn.o_proj.weight', 'decoder.layers.13.self_attn.q_proj.bias', 'decoder.layers.13.self_attn.q_proj.weight', 'decoder.layers.13.self_attn.scaling', 'decoder.layers.13.self_attn.v_proj.bias', 'decoder.layers.13.self_attn.v_proj.weight', 'decoder.layers.14.input_layernorm.weight', 'decoder.layers.14.mlp.down_proj.bias', 'decoder.layers.14.mlp.down_proj.weight', 'decoder.layers.14.mlp.gate_proj.bias', 'decoder.layers.14.mlp.gate_proj.weight', 'decoder.layers.14.mlp.layer_norm.bias', 'decoder.layers.14.mlp.layer_norm.weight', 'decoder.layers.14.self_attn.k_proj.bias', 'decoder.layers.14.self_attn.k_proj.weight', 'decoder.layers.14.self_attn.o_proj.bias', 'decoder.layers.14.self_attn.o_proj.weight', 'decoder.layers.14.self_attn.q_proj.bias', 'decoder.layers.14.self_attn.q_proj.weight', 'decoder.layers.14.self_attn.scaling', 'decoder.layers.14.self_attn.v_proj.bias', 'decoder.layers.14.self_attn.v_proj.weight', 'decoder.layers.15.input_layernorm.weight', 'decoder.layers.15.mlp.down_proj.bias', 'decoder.layers.15.mlp.down_proj.weight', 'decoder.layers.15.mlp.gate_proj.bias', 'decoder.layers.15.mlp.gate_proj.weight', 'decoder.layers.15.mlp.layer_norm.bias', 'decoder.layers.15.mlp.layer_norm.weight', 'decoder.layers.15.self_attn.k_proj.bias', 'decoder.layers.15.self_attn.k_proj.weight', 'decoder.layers.15.self_attn.o_proj.bias', 'decoder.layers.15.self_attn.o_proj.weight', 'decoder.layers.15.self_attn.q_proj.bias', 'decoder.layers.15.self_attn.q_proj.weight', 'decoder.layers.15.self_attn.scaling', 'decoder.layers.15.self_attn.v_proj.bias', 'decoder.layers.15.self_attn.v_proj.weight', 'decoder.layers.16.input_layernorm.weight', 'decoder.layers.16.mlp.down_proj.bias', 'decoder.layers.16.mlp.down_proj.weight', 'decoder.layers.16.mlp.gate_proj.bias', 'decoder.layers.16.mlp.gate_proj.weight', 'decoder.layers.16.mlp.layer_norm.bias', 'decoder.layers.16.mlp.layer_norm.weight', 'decoder.layers.16.self_attn.k_proj.bias', 'decoder.layers.16.self_attn.k_proj.weight', 'decoder.layers.16.self_attn.o_proj.bias', 'decoder.layers.16.self_attn.o_proj.weight', 'decoder.layers.16.self_attn.q_proj.bias', 'decoder.layers.16.self_attn.q_proj.weight', 'decoder.layers.16.self_attn.scaling', 'decoder.layers.16.self_attn.v_proj.bias', 'decoder.layers.16.self_attn.v_proj.weight', 'decoder.layers.17.input_layernorm.weight', 'decoder.layers.17.mlp.down_proj.bias', 'decoder.layers.17.mlp.down_proj.weight', 'decoder.layers.17.mlp.gate_proj.bias', 'decoder.layers.17.mlp.gate_proj.weight', 'decoder.layers.17.mlp.layer_norm.bias', 'decoder.layers.17.mlp.layer_norm.weight', 'decoder.layers.17.self_attn.k_proj.bias', 'decoder.layers.17.self_attn.k_proj.weight', 'decoder.layers.17.self_attn.o_proj.bias', 'decoder.layers.17.self_attn.o_proj.weight', 'decoder.layers.17.self_attn.q_proj.bias', 'decoder.layers.17.self_attn.q_proj.weight', 'decoder.layers.17.self_attn.scaling', 'decoder.layers.17.self_attn.v_proj.bias', 'decoder.layers.17.self_attn.v_proj.weight', 'decoder.layers.18.input_layernorm.weight', 'decoder.layers.18.mlp.down_proj.bias', 'decoder.layers.18.mlp.down_proj.weight', 'decoder.layers.18.mlp.gate_proj.bias', 'decoder.layers.18.mlp.gate_proj.weight', 'decoder.layers.18.mlp.layer_norm.bias', 'decoder.layers.18.mlp.layer_norm.weight', 'decoder.layers.18.self_attn.k_proj.bias', 'decoder.layers.18.self_attn.k_proj.weight', 'decoder.layers.18.self_attn.o_proj.bias', 'decoder.layers.18.self_attn.o_proj.weight', 'decoder.layers.18.self_attn.q_proj.bias', 'decoder.layers.18.self_attn.q_proj.weight', 'decoder.layers.18.self_attn.scaling', 'decoder.layers.18.self_attn.v_proj.bias', 'decoder.layers.18.self_attn.v_proj.weight', 'decoder.layers.19.input_layernorm.weight', 'decoder.layers.19.mlp.down_proj.bias', 'decoder.layers.19.mlp.down_proj.weight', 'decoder.layers.19.mlp.gate_proj.bias', 'decoder.layers.19.mlp.gate_proj.weight', 'decoder.layers.19.mlp.layer_norm.bias', 'decoder.layers.19.mlp.layer_norm.weight', 'decoder.layers.19.self_attn.k_proj.bias', 'decoder.layers.19.self_attn.k_proj.weight', 'decoder.layers.19.self_attn.o_proj.bias', 'decoder.layers.19.self_attn.o_proj.weight', 'decoder.layers.19.self_attn.q_proj.bias', 'decoder.layers.19.self_attn.q_proj.weight', 'decoder.layers.19.self_attn.scaling', 'decoder.layers.19.self_attn.v_proj.bias', 'decoder.layers.19.self_attn.v_proj.weight', 'decoder.layers.2.input_layernorm.weight', 'decoder.layers.2.mlp.down_proj.bias', 'decoder.layers.2.mlp.down_proj.weight', 'decoder.layers.2.mlp.gate_proj.bias', 'decoder.layers.2.mlp.gate_proj.weight', 'decoder.layers.2.mlp.layer_norm.bias', 'decoder.layers.2.mlp.layer_norm.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.o_proj.bias', 'decoder.layers.2.self_attn.o_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.scaling', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.3.input_layernorm.weight', 'decoder.layers.3.mlp.down_proj.bias', 'decoder.layers.3.mlp.down_proj.weight', 'decoder.layers.3.mlp.gate_proj.bias', 'decoder.layers.3.mlp.gate_proj.weight', 'decoder.layers.3.mlp.layer_norm.bias', 'decoder.layers.3.mlp.layer_norm.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.o_proj.bias', 'decoder.layers.3.self_attn.o_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.scaling', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.4.input_layernorm.weight', 'decoder.layers.4.mlp.down_proj.bias', 'decoder.layers.4.mlp.down_proj.weight', 'decoder.layers.4.mlp.gate_proj.bias', 'decoder.layers.4.mlp.gate_proj.weight', 'decoder.layers.4.mlp.layer_norm.bias', 'decoder.layers.4.mlp.layer_norm.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.o_proj.bias', 'decoder.layers.4.self_attn.o_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.scaling', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.5.input_layernorm.weight', 'decoder.layers.5.mlp.down_proj.bias', 'decoder.layers.5.mlp.down_proj.weight', 'decoder.layers.5.mlp.gate_proj.bias', 'decoder.layers.5.mlp.gate_proj.weight', 'decoder.layers.5.mlp.layer_norm.bias', 'decoder.layers.5.mlp.layer_norm.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.o_proj.bias', 'decoder.layers.5.self_attn.o_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.scaling', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.6.input_layernorm.weight', 'decoder.layers.6.mlp.down_proj.bias', 'decoder.layers.6.mlp.down_proj.weight', 'decoder.layers.6.mlp.gate_proj.bias', 'decoder.layers.6.mlp.gate_proj.weight', 'decoder.layers.6.mlp.layer_norm.bias', 'decoder.layers.6.mlp.layer_norm.weight', 'decoder.layers.6.self_attn.k_proj.bias', 'decoder.layers.6.self_attn.k_proj.weight', 'decoder.layers.6.self_attn.o_proj.bias', 'decoder.layers.6.self_attn.o_proj.weight', 'decoder.layers.6.self_attn.q_proj.bias', 'decoder.layers.6.self_attn.q_proj.weight', 'decoder.layers.6.self_attn.scaling', 'decoder.layers.6.self_attn.v_proj.bias', 'decoder.layers.6.self_attn.v_proj.weight', 'decoder.layers.7.input_layernorm.weight', 'decoder.layers.7.mlp.down_proj.bias', 'decoder.layers.7.mlp.down_proj.weight', 'decoder.layers.7.mlp.gate_proj.bias', 'decoder.layers.7.mlp.gate_proj.weight', 'decoder.layers.7.mlp.layer_norm.bias', 'decoder.layers.7.mlp.layer_norm.weight', 'decoder.layers.7.self_attn.k_proj.bias', 'decoder.layers.7.self_attn.k_proj.weight', 'decoder.layers.7.self_attn.o_proj.bias', 'decoder.layers.7.self_attn.o_proj.weight', 'decoder.layers.7.self_attn.q_proj.bias', 'decoder.layers.7.self_attn.q_proj.weight', 'decoder.layers.7.self_attn.scaling', 'decoder.layers.7.self_attn.v_proj.bias', 'decoder.layers.7.self_attn.v_proj.weight', 'decoder.layers.8.input_layernorm.weight', 'decoder.layers.8.mlp.down_proj.bias', 'decoder.layers.8.mlp.down_proj.weight', 'decoder.layers.8.mlp.gate_proj.bias', 'decoder.layers.8.mlp.gate_proj.weight', 'decoder.layers.8.mlp.layer_norm.bias', 'decoder.layers.8.mlp.layer_norm.weight', 'decoder.layers.8.self_attn.k_proj.bias', 'decoder.layers.8.self_attn.k_proj.weight', 'decoder.layers.8.self_attn.o_proj.bias', 'decoder.layers.8.self_attn.o_proj.weight', 'decoder.layers.8.self_attn.q_proj.bias', 'decoder.layers.8.self_attn.q_proj.weight', 'decoder.layers.8.self_attn.scaling', 'decoder.layers.8.self_attn.v_proj.bias', 'decoder.layers.8.self_attn.v_proj.weight', 'decoder.layers.9.input_layernorm.weight', 'decoder.layers.9.mlp.down_proj.bias', 'decoder.layers.9.mlp.down_proj.weight', 'decoder.layers.9.mlp.gate_proj.bias', 'decoder.layers.9.mlp.gate_proj.weight', 'decoder.layers.9.mlp.layer_norm.bias', 'decoder.layers.9.mlp.layer_norm.weight', 'decoder.layers.9.self_attn.k_proj.bias', 'decoder.layers.9.self_attn.k_proj.weight', 'decoder.layers.9.self_attn.o_proj.bias', 'decoder.layers.9.self_attn.o_proj.weight', 'decoder.layers.9.self_attn.q_proj.bias', 'decoder.layers.9.self_attn.q_proj.weight', 'decoder.layers.9.self_attn.scaling', 'decoder.layers.9.self_attn.v_proj.bias', 'decoder.layers.9.self_attn.v_proj.weight', 'horizon_ff_layer.input_layer.bias', 'horizon_ff_layer.input_layer.weight', 'horizon_ff_layer.output_layer.bias', 'horizon_ff_layer.output_layer.weight', 'horizon_ff_layer.residual_layer.bias', 'horizon_ff_layer.residual_layer.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n",
            "  Epoch 1/100 train_loss=1.0629 train_acc=0.4000 eval_loss=1.0825 eval_acc=0.3644 (best)\n",
            "  Epoch 2/100 train_loss=1.0625 train_acc=0.3333 eval_loss=0.0446 eval_acc=0.9900 (best)\n",
            "  Epoch 3/100 train_loss=0.0139 train_acc=1.0000 eval_loss=0.0182 eval_acc=0.9944 (best)\n",
            "  Epoch 4/100 train_loss=0.0024 train_acc=1.0000 eval_loss=0.0130 eval_acc=0.9956 (best)\n",
            "  Epoch 5/100 train_loss=0.0013 train_acc=1.0000 eval_loss=0.0106 eval_acc=0.9956 (best)\n",
            "  Epoch 6/100 train_loss=0.0005 train_acc=1.0000 eval_loss=0.0093 eval_acc=0.9967 (best)\n",
            "  Epoch 7/100 train_loss=0.0002 train_acc=1.0000 eval_loss=0.0087 eval_acc=0.9967 (best)\n",
            "  Epoch 8/100 train_loss=0.0001 train_acc=1.0000 eval_loss=0.0085 eval_acc=0.9967 (best)\n",
            "  Epoch 9/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0085 eval_acc=0.9967 (best)\n",
            "  Epoch 10/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0086 eval_acc=0.9967 \n",
            "  Epoch 11/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0088 eval_acc=0.9967 \n",
            "  Epoch 12/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0090 eval_acc=0.9967 \n",
            "  Epoch 13/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0092 eval_acc=0.9956 \n",
            "  Epoch 14/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0095 eval_acc=0.9956 \n",
            "  Epoch 15/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0097 eval_acc=0.9956 \n",
            "  Epoch 16/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0099 eval_acc=0.9956 \n",
            "  Epoch 17/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0101 eval_acc=0.9956 \n",
            "  Epoch 18/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0102 eval_acc=0.9956 \n",
            "  Epoch 19/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0104 eval_acc=0.9956 \n",
            "  Early stopping on google/timesfm-2.5-200m-pytorch: no improvement for 10 epochs (best epoch = 9)\n",
            "    tfm[google/timesfm-2.5-200m-pytorch] train_acc=1.0000 eval_acc=0.99555555555555552693647314299596473574638367\n",
            "    mrh_acc=0.9989 mr+h+kg_acc=1.0000 kg_acc=1.0000 ensemble=1.0000 (w=0.60)\n",
            "  Split 1/1 - accuracy=1.0000 time=289.2s\n",
            "Completed CBF: Mean Acc=1.0000\n",
            "\n",
            "=== 10/109 Chinatown ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  Decision: Heuristic says no filter (too short to filter)\n",
            "Error processing Chinatown: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n",
            "\n",
            "=== 11/109 ChlorineConcentration ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 556, in main\n",
            "    results = evaluate_dataset_per_split(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 429, in evaluate_dataset_per_split\n",
            "    X_train_extra = np.concatenate([X_train_all, all_dec_train], axis=1)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "ValueError: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n",
            "    Gate split 1/5: baseline_loss=1.0562 adaptive_loss=1.1401\n",
            "    Gate split 2/5: baseline_loss=1.3061 adaptive_loss=1.3891\n",
            "    Gate split 3/5: baseline_loss=1.5024 adaptive_loss=1.5345\n",
            "    Gate split 4/5: baseline_loss=1.1194 adaptive_loss=1.1625\n",
            "    Gate split 5/5: baseline_loss=1.3424 adaptive_loss=1.3590\n",
            "  Decision: Adaptive rejected (loss 1.3170 vs baseline 1.2653, delta=+0.0517 > +0.0200); savgol(window=7, poly=2) - high noise (std_diff)\n",
            "\n",
            "=== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at google/timesfm-2.5-200m-pytorch were not used when initializing TimesFmModelForPrediction: ['output_projection_point.hidden_layer.weight', 'output_projection_point.output_layer.weight', 'output_projection_point.residual_layer.weight', 'output_projection_quantiles.hidden_layer.weight', 'output_projection_quantiles.output_layer.weight', 'output_projection_quantiles.residual_layer.weight', 'stacked_xf.0.attn.key_ln.scale', 'stacked_xf.0.attn.out.weight', 'stacked_xf.0.attn.per_dim_scale.per_dim_scale', 'stacked_xf.0.attn.qkv_proj.weight', 'stacked_xf.0.attn.query_ln.scale', 'stacked_xf.0.ff0.weight', 'stacked_xf.0.ff1.weight', 'stacked_xf.0.post_attn_ln.scale', 'stacked_xf.0.post_ff_ln.scale', 'stacked_xf.0.pre_attn_ln.scale', 'stacked_xf.0.pre_ff_ln.scale', 'stacked_xf.1.attn.key_ln.scale', 'stacked_xf.1.attn.out.weight', 'stacked_xf.1.attn.per_dim_scale.per_dim_scale', 'stacked_xf.1.attn.qkv_proj.weight', 'stacked_xf.1.attn.query_ln.scale', 'stacked_xf.1.ff0.weight', 'stacked_xf.1.ff1.weight', 'stacked_xf.1.post_attn_ln.scale', 'stacked_xf.1.post_ff_ln.scale', 'stacked_xf.1.pre_attn_ln.scale', 'stacked_xf.1.pre_ff_ln.scale', 'stacked_xf.10.attn.key_ln.scale', 'stacked_xf.10.attn.out.weight', 'stacked_xf.10.attn.per_dim_scale.per_dim_scale', 'stacked_xf.10.attn.qkv_proj.weight', 'stacked_xf.10.attn.query_ln.scale', 'stacked_xf.10.ff0.weight', 'stacked_xf.10.ff1.weight', 'stacked_xf.10.post_attn_ln.scale', 'stacked_xf.10.post_ff_ln.scale', 'stacked_xf.10.pre_attn_ln.scale', 'stacked_xf.10.pre_ff_ln.scale', 'stacked_xf.11.attn.key_ln.scale', 'stacked_xf.11.attn.out.weight', 'stacked_xf.11.attn.per_dim_scale.per_dim_scale', 'stacked_xf.11.attn.qkv_proj.weight', 'stacked_xf.11.attn.query_ln.scale', 'stacked_xf.11.ff0.weight', 'stacked_xf.11.ff1.weight', 'stacked_xf.11.post_attn_ln.scale', 'stacked_xf.11.post_ff_ln.scale', 'stacked_xf.11.pre_attn_ln.scale', 'stacked_xf.11.pre_ff_ln.scale', 'stacked_xf.12.attn.key_ln.scale', 'stacked_xf.12.attn.out.weight', 'stacked_xf.12.attn.per_dim_scale.per_dim_scale', 'stacked_xf.12.attn.qkv_proj.weight', 'stacked_xf.12.attn.query_ln.scale', 'stacked_xf.12.ff0.weight', 'stacked_xf.12.ff1.weight', 'stacked_xf.12.post_attn_ln.scale', 'stacked_xf.12.post_ff_ln.scale', 'stacked_xf.12.pre_attn_ln.scale', 'stacked_xf.12.pre_ff_ln.scale', 'stacked_xf.13.attn.key_ln.scale', 'stacked_xf.13.attn.out.weight', 'stacked_xf.13.attn.per_dim_scale.per_dim_scale', 'stacked_xf.13.attn.qkv_proj.weight', 'stacked_xf.13.attn.query_ln.scale', 'stacked_xf.13.ff0.weight', 'stacked_xf.13.ff1.weight', 'stacked_xf.13.post_attn_ln.scale', 'stacked_xf.13.post_ff_ln.scale', 'stacked_xf.13.pre_attn_ln.scale', 'stacked_xf.13.pre_ff_ln.scale', 'stacked_xf.14.attn.key_ln.scale', 'stacked_xf.14.attn.out.weight', 'stacked_xf.14.attn.per_dim_scale.per_dim_scale', 'stacked_xf.14.attn.qkv_proj.weight', 'stacked_xf.14.attn.query_ln.scale', 'stacked_xf.14.ff0.weight', 'stacked_xf.14.ff1.weight', 'stacked_xf.14.post_attn_ln.scale', 'stacked_xf.14.post_ff_ln.scale', 'stacked_xf.14.pre_attn_ln.scale', 'stacked_xf.14.pre_ff_ln.scale', 'stacked_xf.15.attn.key_ln.scale', 'stacked_xf.15.attn.out.weight', 'stacked_xf.15.attn.per_dim_scale.per_dim_scale', 'stacked_xf.15.attn.qkv_proj.weight', 'stacked_xf.15.attn.query_ln.scale', 'stacked_xf.15.ff0.weight', 'stacked_xf.15.ff1.weight', 'stacked_xf.15.post_attn_ln.scale', 'stacked_xf.15.post_ff_ln.scale', 'stacked_xf.15.pre_attn_ln.scale', 'stacked_xf.15.pre_ff_ln.scale', 'stacked_xf.16.attn.key_ln.scale', 'stacked_xf.16.attn.out.weight', 'stacked_xf.16.attn.per_dim_scale.per_dim_scale', 'stacked_xf.16.attn.qkv_proj.weight', 'stacked_xf.16.attn.query_ln.scale', 'stacked_xf.16.ff0.weight', 'stacked_xf.16.ff1.weight', 'stacked_xf.16.post_attn_ln.scale', 'stacked_xf.16.post_ff_ln.scale', 'stacked_xf.16.pre_attn_ln.scale', 'stacked_xf.16.pre_ff_ln.scale', 'stacked_xf.17.attn.key_ln.scale', 'stacked_xf.17.attn.out.weight', 'stacked_xf.17.attn.per_dim_scale.per_dim_scale', 'stacked_xf.17.attn.qkv_proj.weight', 'stacked_xf.17.attn.query_ln.scale', 'stacked_xf.17.ff0.weight', 'stacked_xf.17.ff1.weight', 'stacked_xf.17.post_attn_ln.scale', 'stacked_xf.17.post_ff_ln.scale', 'stacked_xf.17.pre_attn_ln.scale', 'stacked_xf.17.pre_ff_ln.scale', 'stacked_xf.18.attn.key_ln.scale', 'stacked_xf.18.attn.out.weight', 'stacked_xf.18.attn.per_dim_scale.per_dim_scale', 'stacked_xf.18.attn.qkv_proj.weight', 'stacked_xf.18.attn.query_ln.scale', 'stacked_xf.18.ff0.weight', 'stacked_xf.18.ff1.weight', 'stacked_xf.18.post_attn_ln.scale', 'stacked_xf.18.post_ff_ln.scale', 'stacked_xf.18.pre_attn_ln.scale', 'stacked_xf.18.pre_ff_ln.scale', 'stacked_xf.19.attn.key_ln.scale', 'stacked_xf.19.attn.out.weight', 'stacked_xf.19.attn.per_dim_scale.per_dim_scale', 'stacked_xf.19.attn.qkv_proj.weight', 'stacked_xf.19.attn.query_ln.scale', 'stacked_xf.19.ff0.weight', 'stacked_xf.19.ff1.weight', 'stacked_xf.19.post_attn_ln.scale', 'stacked_xf.19.post_ff_ln.scale', 'stacked_xf.19.pre_attn_ln.scale', 'stacked_xf.19.pre_ff_ln.scale', 'stacked_xf.2.attn.key_ln.scale', 'stacked_xf.2.attn.out.weight', 'stacked_xf.2.attn.per_dim_scale.per_dim_scale', 'stacked_xf.2.attn.qkv_proj.weight', 'stacked_xf.2.attn.query_ln.scale', 'stacked_xf.2.ff0.weight', 'stacked_xf.2.ff1.weight', 'stacked_xf.2.post_attn_ln.scale', 'stacked_xf.2.post_ff_ln.scale', 'stacked_xf.2.pre_attn_ln.scale', 'stacked_xf.2.pre_ff_ln.scale', 'stacked_xf.3.attn.key_ln.scale', 'stacked_xf.3.attn.out.weight', 'stacked_xf.3.attn.per_dim_scale.per_dim_scale', 'stacked_xf.3.attn.qkv_proj.weight', 'stacked_xf.3.attn.query_ln.scale', 'stacked_xf.3.ff0.weight', 'stacked_xf.3.ff1.weight', 'stacked_xf.3.post_attn_ln.scale', 'stacked_xf.3.post_ff_ln.scale', 'stacked_xf.3.pre_attn_ln.scale', 'stacked_xf.3.pre_ff_ln.scale', 'stacked_xf.4.attn.key_ln.scale', 'stacked_xf.4.attn.out.weight', 'stacked_xf.4.attn.per_dim_scale.per_dim_scale', 'stacked_xf.4.attn.qkv_proj.weight', 'stacked_xf.4.attn.query_ln.scale', 'stacked_xf.4.ff0.weight', 'stacked_xf.4.ff1.weight', 'stacked_xf.4.post_attn_ln.scale', 'stacked_xf.4.post_ff_ln.scale', 'stacked_xf.4.pre_attn_ln.scale', 'stacked_xf.4.pre_ff_ln.scale', 'stacked_xf.5.attn.key_ln.scale', 'stacked_xf.5.attn.out.weight', 'stacked_xf.5.attn.per_dim_scale.per_dim_scale', 'stacked_xf.5.attn.qkv_proj.weight', 'stacked_xf.5.attn.query_ln.scale', 'stacked_xf.5.ff0.weight', 'stacked_xf.5.ff1.weight', 'stacked_xf.5.post_attn_ln.scale', 'stacked_xf.5.post_ff_ln.scale', 'stacked_xf.5.pre_attn_ln.scale', 'stacked_xf.5.pre_ff_ln.scale', 'stacked_xf.6.attn.key_ln.scale', 'stacked_xf.6.attn.out.weight', 'stacked_xf.6.attn.per_dim_scale.per_dim_scale', 'stacked_xf.6.attn.qkv_proj.weight', 'stacked_xf.6.attn.query_ln.scale', 'stacked_xf.6.ff0.weight', 'stacked_xf.6.ff1.weight', 'stacked_xf.6.post_attn_ln.scale', 'stacked_xf.6.post_ff_ln.scale', 'stacked_xf.6.pre_attn_ln.scale', 'stacked_xf.6.pre_ff_ln.scale', 'stacked_xf.7.attn.key_ln.scale', 'stacked_xf.7.attn.out.weight', 'stacked_xf.7.attn.per_dim_scale.per_dim_scale', 'stacked_xf.7.attn.qkv_proj.weight', 'stacked_xf.7.attn.query_ln.scale', 'stacked_xf.7.ff0.weight', 'stacked_xf.7.ff1.weight', 'stacked_xf.7.post_attn_ln.scale', 'stacked_xf.7.post_ff_ln.scale', 'stacked_xf.7.pre_attn_ln.scale', 'stacked_xf.7.pre_ff_ln.scale', 'stacked_xf.8.attn.key_ln.scale', 'stacked_xf.8.attn.out.weight', 'stacked_xf.8.attn.per_dim_scale.per_dim_scale', 'stacked_xf.8.attn.qkv_proj.weight', 'stacked_xf.8.attn.query_ln.scale', 'stacked_xf.8.ff0.weight', 'stacked_xf.8.ff1.weight', 'stacked_xf.8.post_attn_ln.scale', 'stacked_xf.8.post_ff_ln.scale', 'stacked_xf.8.pre_attn_ln.scale', 'stacked_xf.8.pre_ff_ln.scale', 'stacked_xf.9.attn.key_ln.scale', 'stacked_xf.9.attn.out.weight', 'stacked_xf.9.attn.per_dim_scale.per_dim_scale', 'stacked_xf.9.attn.qkv_proj.weight', 'stacked_xf.9.attn.query_ln.scale', 'stacked_xf.9.ff0.weight', 'stacked_xf.9.ff1.weight', 'stacked_xf.9.post_attn_ln.scale', 'stacked_xf.9.post_ff_ln.scale', 'stacked_xf.9.pre_attn_ln.scale', 'stacked_xf.9.pre_ff_ln.scale', 'tokenizer.hidden_layer.bias', 'tokenizer.hidden_layer.weight', 'tokenizer.output_layer.bias', 'tokenizer.output_layer.weight', 'tokenizer.residual_layer.bias', 'tokenizer.residual_layer.weight']\n",
            "- This IS expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of TimesFmModelForPrediction were not initialized from the model checkpoint at google/timesfm-2.5-200m-pytorch and are newly initialized: ['decoder.freq_emb.weight', 'decoder.input_ff_layer.input_layer.bias', 'decoder.input_ff_layer.input_layer.weight', 'decoder.input_ff_layer.output_layer.bias', 'decoder.input_ff_layer.output_layer.weight', 'decoder.input_ff_layer.residual_layer.bias', 'decoder.input_ff_layer.residual_layer.weight', 'decoder.layers.0.input_layernorm.weight', 'decoder.layers.0.mlp.down_proj.bias', 'decoder.layers.0.mlp.down_proj.weight', 'decoder.layers.0.mlp.gate_proj.bias', 'decoder.layers.0.mlp.gate_proj.weight', 'decoder.layers.0.mlp.layer_norm.bias', 'decoder.layers.0.mlp.layer_norm.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.o_proj.bias', 'decoder.layers.0.self_attn.o_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.scaling', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.1.input_layernorm.weight', 'decoder.layers.1.mlp.down_proj.bias', 'decoder.layers.1.mlp.down_proj.weight', 'decoder.layers.1.mlp.gate_proj.bias', 'decoder.layers.1.mlp.gate_proj.weight', 'decoder.layers.1.mlp.layer_norm.bias', 'decoder.layers.1.mlp.layer_norm.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.o_proj.bias', 'decoder.layers.1.self_attn.o_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.scaling', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.10.input_layernorm.weight', 'decoder.layers.10.mlp.down_proj.bias', 'decoder.layers.10.mlp.down_proj.weight', 'decoder.layers.10.mlp.gate_proj.bias', 'decoder.layers.10.mlp.gate_proj.weight', 'decoder.layers.10.mlp.layer_norm.bias', 'decoder.layers.10.mlp.layer_norm.weight', 'decoder.layers.10.self_attn.k_proj.bias', 'decoder.layers.10.self_attn.k_proj.weight', 'decoder.layers.10.self_attn.o_proj.bias', 'decoder.layers.10.self_attn.o_proj.weight', 'decoder.layers.10.self_attn.q_proj.bias', 'decoder.layers.10.self_attn.q_proj.weight', 'decoder.layers.10.self_attn.scaling', 'decoder.layers.10.self_attn.v_proj.bias', 'decoder.layers.10.self_attn.v_proj.weight', 'decoder.layers.11.input_layernorm.weight', 'decoder.layers.11.mlp.down_proj.bias', 'decoder.layers.11.mlp.down_proj.weight', 'decoder.layers.11.mlp.gate_proj.bias', 'decoder.layers.11.mlp.gate_proj.weight', 'decoder.layers.11.mlp.layer_norm.bias', 'decoder.layers.11.mlp.layer_norm.weight', 'decoder.layers.11.self_attn.k_proj.bias', 'decoder.layers.11.self_attn.k_proj.weight', 'decoder.layers.11.self_attn.o_proj.bias', 'decoder.layers.11.self_attn.o_proj.weight', 'decoder.layers.11.self_attn.q_proj.bias', 'decoder.layers.11.self_attn.q_proj.weight', 'decoder.layers.11.self_attn.scaling', 'decoder.layers.11.self_attn.v_proj.bias', 'decoder.layers.11.self_attn.v_proj.weight', 'decoder.layers.12.input_layernorm.weight', 'decoder.layers.12.mlp.down_proj.bias', 'decoder.layers.12.mlp.down_proj.weight', 'decoder.layers.12.mlp.gate_proj.bias', 'decoder.layers.12.mlp.gate_proj.weight', 'decoder.layers.12.mlp.layer_norm.bias', 'decoder.layers.12.mlp.layer_norm.weight', 'decoder.layers.12.self_attn.k_proj.bias', 'decoder.layers.12.self_attn.k_proj.weight', 'decoder.layers.12.self_attn.o_proj.bias', 'decoder.layers.12.self_attn.o_proj.weight', 'decoder.layers.12.self_attn.q_proj.bias', 'decoder.layers.12.self_attn.q_proj.weight', 'decoder.layers.12.self_attn.scaling', 'decoder.layers.12.self_attn.v_proj.bias', 'decoder.layers.12.self_attn.v_proj.weight', 'decoder.layers.13.input_layernorm.weight', 'decoder.layers.13.mlp.down_proj.bias', 'decoder.layers.13.mlp.down_proj.weight', 'decoder.layers.13.mlp.gate_proj.bias', 'decoder.layers.13.mlp.gate_proj.weight', 'decoder.layers.13.mlp.layer_norm.bias', 'decoder.layers.13.mlp.layer_norm.weight', 'decoder.layers.13.self_attn.k_proj.bias', 'decoder.layers.13.self_attn.k_proj.weight', 'decoder.layers.13.self_attn.o_proj.bias', 'decoder.layers.13.self_attn.o_proj.weight', 'decoder.layers.13.self_attn.q_proj.bias', 'decoder.layers.13.self_attn.q_proj.weight', 'decoder.layers.13.self_attn.scaling', 'decoder.layers.13.self_attn.v_proj.bias', 'decoder.layers.13.self_attn.v_proj.weight', 'decoder.layers.14.input_layernorm.weight', 'decoder.layers.14.mlp.down_proj.bias', 'decoder.layers.14.mlp.down_proj.weight', 'decoder.layers.14.mlp.gate_proj.bias', 'decoder.layers.14.mlp.gate_proj.weight', 'decoder.layers.14.mlp.layer_norm.bias', 'decoder.layers.14.mlp.layer_norm.weight', 'decoder.layers.14.self_attn.k_proj.bias', 'decoder.layers.14.self_attn.k_proj.weight', 'decoder.layers.14.self_attn.o_proj.bias', 'decoder.layers.14.self_attn.o_proj.weight', 'decoder.layers.14.self_attn.q_proj.bias', 'decoder.layers.14.self_attn.q_proj.weight', 'decoder.layers.14.self_attn.scaling', 'decoder.layers.14.self_attn.v_proj.bias', 'decoder.layers.14.self_attn.v_proj.weight', 'decoder.layers.15.input_layernorm.weight', 'decoder.layers.15.mlp.down_proj.bias', 'decoder.layers.15.mlp.down_proj.weight', 'decoder.layers.15.mlp.gate_proj.bias', 'decoder.layers.15.mlp.gate_proj.weight', 'decoder.layers.15.mlp.layer_norm.bias', 'decoder.layers.15.mlp.layer_norm.weight', 'decoder.layers.15.self_attn.k_proj.bias', 'decoder.layers.15.self_attn.k_proj.weight', 'decoder.layers.15.self_attn.o_proj.bias', 'decoder.layers.15.self_attn.o_proj.weight', 'decoder.layers.15.self_attn.q_proj.bias', 'decoder.layers.15.self_attn.q_proj.weight', 'decoder.layers.15.self_attn.scaling', 'decoder.layers.15.self_attn.v_proj.bias', 'decoder.layers.15.self_attn.v_proj.weight', 'decoder.layers.16.input_layernorm.weight', 'decoder.layers.16.mlp.down_proj.bias', 'decoder.layers.16.mlp.down_proj.weight', 'decoder.layers.16.mlp.gate_proj.bias', 'decoder.layers.16.mlp.gate_proj.weight', 'decoder.layers.16.mlp.layer_norm.bias', 'decoder.layers.16.mlp.layer_norm.weight', 'decoder.layers.16.self_attn.k_proj.bias', 'decoder.layers.16.self_attn.k_proj.weight', 'decoder.layers.16.self_attn.o_proj.bias', 'decoder.layers.16.self_attn.o_proj.weight', 'decoder.layers.16.self_attn.q_proj.bias', 'decoder.layers.16.self_attn.q_proj.weight', 'decoder.layers.16.self_attn.scaling', 'decoder.layers.16.self_attn.v_proj.bias', 'decoder.layers.16.self_attn.v_proj.weight', 'decoder.layers.17.input_layernorm.weight', 'decoder.layers.17.mlp.down_proj.bias', 'decoder.layers.17.mlp.down_proj.weight', 'decoder.layers.17.mlp.gate_proj.bias', 'decoder.layers.17.mlp.gate_proj.weight', 'decoder.layers.17.mlp.layer_norm.bias', 'decoder.layers.17.mlp.layer_norm.weight', 'decoder.layers.17.self_attn.k_proj.bias', 'decoder.layers.17.self_attn.k_proj.weight', 'decoder.layers.17.self_attn.o_proj.bias', 'decoder.layers.17.self_attn.o_proj.weight', 'decoder.layers.17.self_attn.q_proj.bias', 'decoder.layers.17.self_attn.q_proj.weight', 'decoder.layers.17.self_attn.scaling', 'decoder.layers.17.self_attn.v_proj.bias', 'decoder.layers.17.self_attn.v_proj.weight', 'decoder.layers.18.input_layernorm.weight', 'decoder.layers.18.mlp.down_proj.bias', 'decoder.layers.18.mlp.down_proj.weight', 'decoder.layers.18.mlp.gate_proj.bias', 'decoder.layers.18.mlp.gate_proj.weight', 'decoder.layers.18.mlp.layer_norm.bias', 'decoder.layers.18.mlp.layer_norm.weight', 'decoder.layers.18.self_attn.k_proj.bias', 'decoder.layers.18.self_attn.k_proj.weight', 'decoder.layers.18.self_attn.o_proj.bias', 'decoder.layers.18.self_attn.o_proj.weight', 'decoder.layers.18.self_attn.q_proj.bias', 'decoder.layers.18.self_attn.q_proj.weight', 'decoder.layers.18.self_attn.scaling', 'decoder.layers.18.self_attn.v_proj.bias', 'decoder.layers.18.self_attn.v_proj.weight', 'decoder.layers.19.input_layernorm.weight', 'decoder.layers.19.mlp.down_proj.bias', 'decoder.layers.19.mlp.down_proj.weight', 'decoder.layers.19.mlp.gate_proj.bias', 'decoder.layers.19.mlp.gate_proj.weight', 'decoder.layers.19.mlp.layer_norm.bias', 'decoder.layers.19.mlp.layer_norm.weight', 'decoder.layers.19.self_attn.k_proj.bias', 'decoder.layers.19.self_attn.k_proj.weight', 'decoder.layers.19.self_attn.o_proj.bias', 'decoder.layers.19.self_attn.o_proj.weight', 'decoder.layers.19.self_attn.q_proj.bias', 'decoder.layers.19.self_attn.q_proj.weight', 'decoder.layers.19.self_attn.scaling', 'decoder.layers.19.self_attn.v_proj.bias', 'decoder.layers.19.self_attn.v_proj.weight', 'decoder.layers.2.input_layernorm.weight', 'decoder.layers.2.mlp.down_proj.bias', 'decoder.layers.2.mlp.down_proj.weight', 'decoder.layers.2.mlp.gate_proj.bias', 'decoder.layers.2.mlp.gate_proj.weight', 'decoder.layers.2.mlp.layer_norm.bias', 'decoder.layers.2.mlp.layer_norm.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.o_proj.bias', 'decoder.layers.2.self_attn.o_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.scaling', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.3.input_layernorm.weight', 'decoder.layers.3.mlp.down_proj.bias', 'decoder.layers.3.mlp.down_proj.weight', 'decoder.layers.3.mlp.gate_proj.bias', 'decoder.layers.3.mlp.gate_proj.weight', 'decoder.layers.3.mlp.layer_norm.bias', 'decoder.layers.3.mlp.layer_norm.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.o_proj.bias', 'decoder.layers.3.self_attn.o_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.scaling', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.4.input_layernorm.weight', 'decoder.layers.4.mlp.down_proj.bias', 'decoder.layers.4.mlp.down_proj.weight', 'decoder.layers.4.mlp.gate_proj.bias', 'decoder.layers.4.mlp.gate_proj.weight', 'decoder.layers.4.mlp.layer_norm.bias', 'decoder.layers.4.mlp.layer_norm.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.o_proj.bias', 'decoder.layers.4.self_attn.o_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.scaling', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.5.input_layernorm.weight', 'decoder.layers.5.mlp.down_proj.bias', 'decoder.layers.5.mlp.down_proj.weight', 'decoder.layers.5.mlp.gate_proj.bias', 'decoder.layers.5.mlp.gate_proj.weight', 'decoder.layers.5.mlp.layer_norm.bias', 'decoder.layers.5.mlp.layer_norm.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.o_proj.bias', 'decoder.layers.5.self_attn.o_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.scaling', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.6.input_layernorm.weight', 'decoder.layers.6.mlp.down_proj.bias', 'decoder.layers.6.mlp.down_proj.weight', 'decoder.layers.6.mlp.gate_proj.bias', 'decoder.layers.6.mlp.gate_proj.weight', 'decoder.layers.6.mlp.layer_norm.bias', 'decoder.layers.6.mlp.layer_norm.weight', 'decoder.layers.6.self_attn.k_proj.bias', 'decoder.layers.6.self_attn.k_proj.weight', 'decoder.layers.6.self_attn.o_proj.bias', 'decoder.layers.6.self_attn.o_proj.weight', 'decoder.layers.6.self_attn.q_proj.bias', 'decoder.layers.6.self_attn.q_proj.weight', 'decoder.layers.6.self_attn.scaling', 'decoder.layers.6.self_attn.v_proj.bias', 'decoder.layers.6.self_attn.v_proj.weight', 'decoder.layers.7.input_layernorm.weight', 'decoder.layers.7.mlp.down_proj.bias', 'decoder.layers.7.mlp.down_proj.weight', 'decoder.layers.7.mlp.gate_proj.bias', 'decoder.layers.7.mlp.gate_proj.weight', 'decoder.layers.7.mlp.layer_norm.bias', 'decoder.layers.7.mlp.layer_norm.weight', 'decoder.layers.7.self_attn.k_proj.bias', 'decoder.layers.7.self_attn.k_proj.weight', 'decoder.layers.7.self_attn.o_proj.bias', 'decoder.layers.7.self_attn.o_proj.weight', 'decoder.layers.7.self_attn.q_proj.bias', 'decoder.layers.7.self_attn.q_proj.weight', 'decoder.layers.7.self_attn.scaling', 'decoder.layers.7.self_attn.v_proj.bias', 'decoder.layers.7.self_attn.v_proj.weight', 'decoder.layers.8.input_layernorm.weight', 'decoder.layers.8.mlp.down_proj.bias', 'decoder.layers.8.mlp.down_proj.weight', 'decoder.layers.8.mlp.gate_proj.bias', 'decoder.layers.8.mlp.gate_proj.weight', 'decoder.layers.8.mlp.layer_norm.bias', 'decoder.layers.8.mlp.layer_norm.weight', 'decoder.layers.8.self_attn.k_proj.bias', 'decoder.layers.8.self_attn.k_proj.weight', 'decoder.layers.8.self_attn.o_proj.bias', 'decoder.layers.8.self_attn.o_proj.weight', 'decoder.layers.8.self_attn.q_proj.bias', 'decoder.layers.8.self_attn.q_proj.weight', 'decoder.layers.8.self_attn.scaling', 'decoder.layers.8.self_attn.v_proj.bias', 'decoder.layers.8.self_attn.v_proj.weight', 'decoder.layers.9.input_layernorm.weight', 'decoder.layers.9.mlp.down_proj.bias', 'decoder.layers.9.mlp.down_proj.weight', 'decoder.layers.9.mlp.gate_proj.bias', 'decoder.layers.9.mlp.gate_proj.weight', 'decoder.layers.9.mlp.layer_norm.bias', 'decoder.layers.9.mlp.layer_norm.weight', 'decoder.layers.9.self_attn.k_proj.bias', 'decoder.layers.9.self_attn.k_proj.weight', 'decoder.layers.9.self_attn.o_proj.bias', 'decoder.layers.9.self_attn.o_proj.weight', 'decoder.layers.9.self_attn.q_proj.bias', 'decoder.layers.9.self_attn.q_proj.weight', 'decoder.layers.9.self_attn.scaling', 'decoder.layers.9.self_attn.v_proj.bias', 'decoder.layers.9.self_attn.v_proj.weight', 'horizon_ff_layer.input_layer.bias', 'horizon_ff_layer.input_layer.weight', 'horizon_ff_layer.output_layer.bias', 'horizon_ff_layer.output_layer.weight', 'horizon_ff_layer.residual_layer.bias', 'horizon_ff_layer.residual_layer.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n",
            "  Epoch 1/100 train_loss=1.1473 train_acc=0.4475 eval_loss=1.0028 eval_acc=0.5620 (best)\n",
            "  Epoch 2/100 train_loss=0.9171 train_acc=0.5567 eval_loss=1.0231 eval_acc=0.5742 \n",
            "  Epoch 3/100 train_loss=0.7878 train_acc=0.6574 eval_loss=0.9305 eval_acc=0.5690 (best)\n",
            "  Epoch 4/100 train_loss=0.6626 train_acc=0.6938 eval_loss=1.0335 eval_acc=0.5896 \n",
            "  Epoch 5/100 train_loss=0.6980 train_acc=0.7388 eval_loss=1.2107 eval_acc=0.5523 \n",
            "  Epoch 6/100 train_loss=0.5744 train_acc=0.7559 eval_loss=0.8657 eval_acc=0.6495 (best)\n",
            "  Epoch 7/100 train_loss=0.4315 train_acc=0.8266 eval_loss=1.0141 eval_acc=0.6276 \n",
            "  Epoch 8/100 train_loss=0.5546 train_acc=0.7966 eval_loss=1.1597 eval_acc=0.6242 \n",
            "  Epoch 9/100 train_loss=0.4478 train_acc=0.8287 eval_loss=0.9718 eval_acc=0.6409 \n",
            "  Epoch 10/100 train_loss=0.2406 train_acc=0.8972 eval_loss=1.5643 eval_acc=0.6125 \n",
            "  Epoch 11/100 train_loss=0.3241 train_acc=0.8951 eval_loss=1.4548 eval_acc=0.6167 \n",
            "  Epoch 12/100 train_loss=0.3578 train_acc=0.8544 eval_loss=1.3739 eval_acc=0.6792 \n",
            "  Epoch 13/100 train_loss=0.2478 train_acc=0.9143 eval_loss=1.3919 eval_acc=0.6828 \n",
            "  Epoch 14/100 train_loss=0.1997 train_acc=0.9251 eval_loss=2.3843 eval_acc=0.5984 \n",
            "  Epoch 15/100 train_loss=0.1756 train_acc=0.9400 eval_loss=1.7964 eval_acc=0.6417 \n",
            "  Epoch 16/100 train_loss=0.4144 train_acc=0.8715 eval_loss=1.9655 eval_acc=0.6307 \n",
            "  Early stopping on google/timesfm-2.5-200m-pytorch: no improvement for 10 epochs (best epoch = 6)\n",
            "    tfm[google/timesfm-2.5-200m-pytorch] train_acc=0.7559 eval_acc=0.63072916666666667406815349750104360282421112\n",
            "    mrh_acc=0.7688 mr+h+kg_acc=0.7688 kg_acc=0.7727 ensemble=0.7758 (w=0.60)\n",
            "  Split 1/1 - accuracy=0.7758 time=1283.9s\n",
            "Completed ChlorineConcentration: Mean Acc=0.7758\n",
            "\n",
            "=== 12/109 CinCECGTorso ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n",
            "    Gate split 1/5: baseline_loss=0.1386 adaptive_loss=0.1463\n",
            "    Gate split 2/5: baseline_loss=0.0854 adaptive_loss=0.0922\n",
            "    Gate split 3/5: baseline_loss=0.1606 adaptive_loss=0.1786\n",
            "    Gate split 4/5: baseline_loss=0.0000 adaptive_loss=0.0001\n",
            "    Gate split 5/5: baseline_loss=0.0221 adaptive_loss=0.0655\n",
            "  Decision: Adaptive kept (loss 0.0966 vs baseline 0.0813, delta=+0.0152 <= +0.0200); savgol(window=21, poly=3) - high noise (std_diff)\n",
            "\n",
            "=== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at google/timesfm-2.5-200m-pytorch were not used when initializing TimesFmModelForPrediction: ['output_projection_point.hidden_layer.weight', 'output_projection_point.output_layer.weight', 'output_projection_point.residual_layer.weight', 'output_projection_quantiles.hidden_layer.weight', 'output_projection_quantiles.output_layer.weight', 'output_projection_quantiles.residual_layer.weight', 'stacked_xf.0.attn.key_ln.scale', 'stacked_xf.0.attn.out.weight', 'stacked_xf.0.attn.per_dim_scale.per_dim_scale', 'stacked_xf.0.attn.qkv_proj.weight', 'stacked_xf.0.attn.query_ln.scale', 'stacked_xf.0.ff0.weight', 'stacked_xf.0.ff1.weight', 'stacked_xf.0.post_attn_ln.scale', 'stacked_xf.0.post_ff_ln.scale', 'stacked_xf.0.pre_attn_ln.scale', 'stacked_xf.0.pre_ff_ln.scale', 'stacked_xf.1.attn.key_ln.scale', 'stacked_xf.1.attn.out.weight', 'stacked_xf.1.attn.per_dim_scale.per_dim_scale', 'stacked_xf.1.attn.qkv_proj.weight', 'stacked_xf.1.attn.query_ln.scale', 'stacked_xf.1.ff0.weight', 'stacked_xf.1.ff1.weight', 'stacked_xf.1.post_attn_ln.scale', 'stacked_xf.1.post_ff_ln.scale', 'stacked_xf.1.pre_attn_ln.scale', 'stacked_xf.1.pre_ff_ln.scale', 'stacked_xf.10.attn.key_ln.scale', 'stacked_xf.10.attn.out.weight', 'stacked_xf.10.attn.per_dim_scale.per_dim_scale', 'stacked_xf.10.attn.qkv_proj.weight', 'stacked_xf.10.attn.query_ln.scale', 'stacked_xf.10.ff0.weight', 'stacked_xf.10.ff1.weight', 'stacked_xf.10.post_attn_ln.scale', 'stacked_xf.10.post_ff_ln.scale', 'stacked_xf.10.pre_attn_ln.scale', 'stacked_xf.10.pre_ff_ln.scale', 'stacked_xf.11.attn.key_ln.scale', 'stacked_xf.11.attn.out.weight', 'stacked_xf.11.attn.per_dim_scale.per_dim_scale', 'stacked_xf.11.attn.qkv_proj.weight', 'stacked_xf.11.attn.query_ln.scale', 'stacked_xf.11.ff0.weight', 'stacked_xf.11.ff1.weight', 'stacked_xf.11.post_attn_ln.scale', 'stacked_xf.11.post_ff_ln.scale', 'stacked_xf.11.pre_attn_ln.scale', 'stacked_xf.11.pre_ff_ln.scale', 'stacked_xf.12.attn.key_ln.scale', 'stacked_xf.12.attn.out.weight', 'stacked_xf.12.attn.per_dim_scale.per_dim_scale', 'stacked_xf.12.attn.qkv_proj.weight', 'stacked_xf.12.attn.query_ln.scale', 'stacked_xf.12.ff0.weight', 'stacked_xf.12.ff1.weight', 'stacked_xf.12.post_attn_ln.scale', 'stacked_xf.12.post_ff_ln.scale', 'stacked_xf.12.pre_attn_ln.scale', 'stacked_xf.12.pre_ff_ln.scale', 'stacked_xf.13.attn.key_ln.scale', 'stacked_xf.13.attn.out.weight', 'stacked_xf.13.attn.per_dim_scale.per_dim_scale', 'stacked_xf.13.attn.qkv_proj.weight', 'stacked_xf.13.attn.query_ln.scale', 'stacked_xf.13.ff0.weight', 'stacked_xf.13.ff1.weight', 'stacked_xf.13.post_attn_ln.scale', 'stacked_xf.13.post_ff_ln.scale', 'stacked_xf.13.pre_attn_ln.scale', 'stacked_xf.13.pre_ff_ln.scale', 'stacked_xf.14.attn.key_ln.scale', 'stacked_xf.14.attn.out.weight', 'stacked_xf.14.attn.per_dim_scale.per_dim_scale', 'stacked_xf.14.attn.qkv_proj.weight', 'stacked_xf.14.attn.query_ln.scale', 'stacked_xf.14.ff0.weight', 'stacked_xf.14.ff1.weight', 'stacked_xf.14.post_attn_ln.scale', 'stacked_xf.14.post_ff_ln.scale', 'stacked_xf.14.pre_attn_ln.scale', 'stacked_xf.14.pre_ff_ln.scale', 'stacked_xf.15.attn.key_ln.scale', 'stacked_xf.15.attn.out.weight', 'stacked_xf.15.attn.per_dim_scale.per_dim_scale', 'stacked_xf.15.attn.qkv_proj.weight', 'stacked_xf.15.attn.query_ln.scale', 'stacked_xf.15.ff0.weight', 'stacked_xf.15.ff1.weight', 'stacked_xf.15.post_attn_ln.scale', 'stacked_xf.15.post_ff_ln.scale', 'stacked_xf.15.pre_attn_ln.scale', 'stacked_xf.15.pre_ff_ln.scale', 'stacked_xf.16.attn.key_ln.scale', 'stacked_xf.16.attn.out.weight', 'stacked_xf.16.attn.per_dim_scale.per_dim_scale', 'stacked_xf.16.attn.qkv_proj.weight', 'stacked_xf.16.attn.query_ln.scale', 'stacked_xf.16.ff0.weight', 'stacked_xf.16.ff1.weight', 'stacked_xf.16.post_attn_ln.scale', 'stacked_xf.16.post_ff_ln.scale', 'stacked_xf.16.pre_attn_ln.scale', 'stacked_xf.16.pre_ff_ln.scale', 'stacked_xf.17.attn.key_ln.scale', 'stacked_xf.17.attn.out.weight', 'stacked_xf.17.attn.per_dim_scale.per_dim_scale', 'stacked_xf.17.attn.qkv_proj.weight', 'stacked_xf.17.attn.query_ln.scale', 'stacked_xf.17.ff0.weight', 'stacked_xf.17.ff1.weight', 'stacked_xf.17.post_attn_ln.scale', 'stacked_xf.17.post_ff_ln.scale', 'stacked_xf.17.pre_attn_ln.scale', 'stacked_xf.17.pre_ff_ln.scale', 'stacked_xf.18.attn.key_ln.scale', 'stacked_xf.18.attn.out.weight', 'stacked_xf.18.attn.per_dim_scale.per_dim_scale', 'stacked_xf.18.attn.qkv_proj.weight', 'stacked_xf.18.attn.query_ln.scale', 'stacked_xf.18.ff0.weight', 'stacked_xf.18.ff1.weight', 'stacked_xf.18.post_attn_ln.scale', 'stacked_xf.18.post_ff_ln.scale', 'stacked_xf.18.pre_attn_ln.scale', 'stacked_xf.18.pre_ff_ln.scale', 'stacked_xf.19.attn.key_ln.scale', 'stacked_xf.19.attn.out.weight', 'stacked_xf.19.attn.per_dim_scale.per_dim_scale', 'stacked_xf.19.attn.qkv_proj.weight', 'stacked_xf.19.attn.query_ln.scale', 'stacked_xf.19.ff0.weight', 'stacked_xf.19.ff1.weight', 'stacked_xf.19.post_attn_ln.scale', 'stacked_xf.19.post_ff_ln.scale', 'stacked_xf.19.pre_attn_ln.scale', 'stacked_xf.19.pre_ff_ln.scale', 'stacked_xf.2.attn.key_ln.scale', 'stacked_xf.2.attn.out.weight', 'stacked_xf.2.attn.per_dim_scale.per_dim_scale', 'stacked_xf.2.attn.qkv_proj.weight', 'stacked_xf.2.attn.query_ln.scale', 'stacked_xf.2.ff0.weight', 'stacked_xf.2.ff1.weight', 'stacked_xf.2.post_attn_ln.scale', 'stacked_xf.2.post_ff_ln.scale', 'stacked_xf.2.pre_attn_ln.scale', 'stacked_xf.2.pre_ff_ln.scale', 'stacked_xf.3.attn.key_ln.scale', 'stacked_xf.3.attn.out.weight', 'stacked_xf.3.attn.per_dim_scale.per_dim_scale', 'stacked_xf.3.attn.qkv_proj.weight', 'stacked_xf.3.attn.query_ln.scale', 'stacked_xf.3.ff0.weight', 'stacked_xf.3.ff1.weight', 'stacked_xf.3.post_attn_ln.scale', 'stacked_xf.3.post_ff_ln.scale', 'stacked_xf.3.pre_attn_ln.scale', 'stacked_xf.3.pre_ff_ln.scale', 'stacked_xf.4.attn.key_ln.scale', 'stacked_xf.4.attn.out.weight', 'stacked_xf.4.attn.per_dim_scale.per_dim_scale', 'stacked_xf.4.attn.qkv_proj.weight', 'stacked_xf.4.attn.query_ln.scale', 'stacked_xf.4.ff0.weight', 'stacked_xf.4.ff1.weight', 'stacked_xf.4.post_attn_ln.scale', 'stacked_xf.4.post_ff_ln.scale', 'stacked_xf.4.pre_attn_ln.scale', 'stacked_xf.4.pre_ff_ln.scale', 'stacked_xf.5.attn.key_ln.scale', 'stacked_xf.5.attn.out.weight', 'stacked_xf.5.attn.per_dim_scale.per_dim_scale', 'stacked_xf.5.attn.qkv_proj.weight', 'stacked_xf.5.attn.query_ln.scale', 'stacked_xf.5.ff0.weight', 'stacked_xf.5.ff1.weight', 'stacked_xf.5.post_attn_ln.scale', 'stacked_xf.5.post_ff_ln.scale', 'stacked_xf.5.pre_attn_ln.scale', 'stacked_xf.5.pre_ff_ln.scale', 'stacked_xf.6.attn.key_ln.scale', 'stacked_xf.6.attn.out.weight', 'stacked_xf.6.attn.per_dim_scale.per_dim_scale', 'stacked_xf.6.attn.qkv_proj.weight', 'stacked_xf.6.attn.query_ln.scale', 'stacked_xf.6.ff0.weight', 'stacked_xf.6.ff1.weight', 'stacked_xf.6.post_attn_ln.scale', 'stacked_xf.6.post_ff_ln.scale', 'stacked_xf.6.pre_attn_ln.scale', 'stacked_xf.6.pre_ff_ln.scale', 'stacked_xf.7.attn.key_ln.scale', 'stacked_xf.7.attn.out.weight', 'stacked_xf.7.attn.per_dim_scale.per_dim_scale', 'stacked_xf.7.attn.qkv_proj.weight', 'stacked_xf.7.attn.query_ln.scale', 'stacked_xf.7.ff0.weight', 'stacked_xf.7.ff1.weight', 'stacked_xf.7.post_attn_ln.scale', 'stacked_xf.7.post_ff_ln.scale', 'stacked_xf.7.pre_attn_ln.scale', 'stacked_xf.7.pre_ff_ln.scale', 'stacked_xf.8.attn.key_ln.scale', 'stacked_xf.8.attn.out.weight', 'stacked_xf.8.attn.per_dim_scale.per_dim_scale', 'stacked_xf.8.attn.qkv_proj.weight', 'stacked_xf.8.attn.query_ln.scale', 'stacked_xf.8.ff0.weight', 'stacked_xf.8.ff1.weight', 'stacked_xf.8.post_attn_ln.scale', 'stacked_xf.8.post_ff_ln.scale', 'stacked_xf.8.pre_attn_ln.scale', 'stacked_xf.8.pre_ff_ln.scale', 'stacked_xf.9.attn.key_ln.scale', 'stacked_xf.9.attn.out.weight', 'stacked_xf.9.attn.per_dim_scale.per_dim_scale', 'stacked_xf.9.attn.qkv_proj.weight', 'stacked_xf.9.attn.query_ln.scale', 'stacked_xf.9.ff0.weight', 'stacked_xf.9.ff1.weight', 'stacked_xf.9.post_attn_ln.scale', 'stacked_xf.9.post_ff_ln.scale', 'stacked_xf.9.pre_attn_ln.scale', 'stacked_xf.9.pre_ff_ln.scale', 'tokenizer.hidden_layer.bias', 'tokenizer.hidden_layer.weight', 'tokenizer.output_layer.bias', 'tokenizer.output_layer.weight', 'tokenizer.residual_layer.bias', 'tokenizer.residual_layer.weight']\n",
            "- This IS expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of TimesFmModelForPrediction were not initialized from the model checkpoint at google/timesfm-2.5-200m-pytorch and are newly initialized: ['decoder.freq_emb.weight', 'decoder.input_ff_layer.input_layer.bias', 'decoder.input_ff_layer.input_layer.weight', 'decoder.input_ff_layer.output_layer.bias', 'decoder.input_ff_layer.output_layer.weight', 'decoder.input_ff_layer.residual_layer.bias', 'decoder.input_ff_layer.residual_layer.weight', 'decoder.layers.0.input_layernorm.weight', 'decoder.layers.0.mlp.down_proj.bias', 'decoder.layers.0.mlp.down_proj.weight', 'decoder.layers.0.mlp.gate_proj.bias', 'decoder.layers.0.mlp.gate_proj.weight', 'decoder.layers.0.mlp.layer_norm.bias', 'decoder.layers.0.mlp.layer_norm.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.o_proj.bias', 'decoder.layers.0.self_attn.o_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.scaling', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.1.input_layernorm.weight', 'decoder.layers.1.mlp.down_proj.bias', 'decoder.layers.1.mlp.down_proj.weight', 'decoder.layers.1.mlp.gate_proj.bias', 'decoder.layers.1.mlp.gate_proj.weight', 'decoder.layers.1.mlp.layer_norm.bias', 'decoder.layers.1.mlp.layer_norm.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.o_proj.bias', 'decoder.layers.1.self_attn.o_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.scaling', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.10.input_layernorm.weight', 'decoder.layers.10.mlp.down_proj.bias', 'decoder.layers.10.mlp.down_proj.weight', 'decoder.layers.10.mlp.gate_proj.bias', 'decoder.layers.10.mlp.gate_proj.weight', 'decoder.layers.10.mlp.layer_norm.bias', 'decoder.layers.10.mlp.layer_norm.weight', 'decoder.layers.10.self_attn.k_proj.bias', 'decoder.layers.10.self_attn.k_proj.weight', 'decoder.layers.10.self_attn.o_proj.bias', 'decoder.layers.10.self_attn.o_proj.weight', 'decoder.layers.10.self_attn.q_proj.bias', 'decoder.layers.10.self_attn.q_proj.weight', 'decoder.layers.10.self_attn.scaling', 'decoder.layers.10.self_attn.v_proj.bias', 'decoder.layers.10.self_attn.v_proj.weight', 'decoder.layers.11.input_layernorm.weight', 'decoder.layers.11.mlp.down_proj.bias', 'decoder.layers.11.mlp.down_proj.weight', 'decoder.layers.11.mlp.gate_proj.bias', 'decoder.layers.11.mlp.gate_proj.weight', 'decoder.layers.11.mlp.layer_norm.bias', 'decoder.layers.11.mlp.layer_norm.weight', 'decoder.layers.11.self_attn.k_proj.bias', 'decoder.layers.11.self_attn.k_proj.weight', 'decoder.layers.11.self_attn.o_proj.bias', 'decoder.layers.11.self_attn.o_proj.weight', 'decoder.layers.11.self_attn.q_proj.bias', 'decoder.layers.11.self_attn.q_proj.weight', 'decoder.layers.11.self_attn.scaling', 'decoder.layers.11.self_attn.v_proj.bias', 'decoder.layers.11.self_attn.v_proj.weight', 'decoder.layers.12.input_layernorm.weight', 'decoder.layers.12.mlp.down_proj.bias', 'decoder.layers.12.mlp.down_proj.weight', 'decoder.layers.12.mlp.gate_proj.bias', 'decoder.layers.12.mlp.gate_proj.weight', 'decoder.layers.12.mlp.layer_norm.bias', 'decoder.layers.12.mlp.layer_norm.weight', 'decoder.layers.12.self_attn.k_proj.bias', 'decoder.layers.12.self_attn.k_proj.weight', 'decoder.layers.12.self_attn.o_proj.bias', 'decoder.layers.12.self_attn.o_proj.weight', 'decoder.layers.12.self_attn.q_proj.bias', 'decoder.layers.12.self_attn.q_proj.weight', 'decoder.layers.12.self_attn.scaling', 'decoder.layers.12.self_attn.v_proj.bias', 'decoder.layers.12.self_attn.v_proj.weight', 'decoder.layers.13.input_layernorm.weight', 'decoder.layers.13.mlp.down_proj.bias', 'decoder.layers.13.mlp.down_proj.weight', 'decoder.layers.13.mlp.gate_proj.bias', 'decoder.layers.13.mlp.gate_proj.weight', 'decoder.layers.13.mlp.layer_norm.bias', 'decoder.layers.13.mlp.layer_norm.weight', 'decoder.layers.13.self_attn.k_proj.bias', 'decoder.layers.13.self_attn.k_proj.weight', 'decoder.layers.13.self_attn.o_proj.bias', 'decoder.layers.13.self_attn.o_proj.weight', 'decoder.layers.13.self_attn.q_proj.bias', 'decoder.layers.13.self_attn.q_proj.weight', 'decoder.layers.13.self_attn.scaling', 'decoder.layers.13.self_attn.v_proj.bias', 'decoder.layers.13.self_attn.v_proj.weight', 'decoder.layers.14.input_layernorm.weight', 'decoder.layers.14.mlp.down_proj.bias', 'decoder.layers.14.mlp.down_proj.weight', 'decoder.layers.14.mlp.gate_proj.bias', 'decoder.layers.14.mlp.gate_proj.weight', 'decoder.layers.14.mlp.layer_norm.bias', 'decoder.layers.14.mlp.layer_norm.weight', 'decoder.layers.14.self_attn.k_proj.bias', 'decoder.layers.14.self_attn.k_proj.weight', 'decoder.layers.14.self_attn.o_proj.bias', 'decoder.layers.14.self_attn.o_proj.weight', 'decoder.layers.14.self_attn.q_proj.bias', 'decoder.layers.14.self_attn.q_proj.weight', 'decoder.layers.14.self_attn.scaling', 'decoder.layers.14.self_attn.v_proj.bias', 'decoder.layers.14.self_attn.v_proj.weight', 'decoder.layers.15.input_layernorm.weight', 'decoder.layers.15.mlp.down_proj.bias', 'decoder.layers.15.mlp.down_proj.weight', 'decoder.layers.15.mlp.gate_proj.bias', 'decoder.layers.15.mlp.gate_proj.weight', 'decoder.layers.15.mlp.layer_norm.bias', 'decoder.layers.15.mlp.layer_norm.weight', 'decoder.layers.15.self_attn.k_proj.bias', 'decoder.layers.15.self_attn.k_proj.weight', 'decoder.layers.15.self_attn.o_proj.bias', 'decoder.layers.15.self_attn.o_proj.weight', 'decoder.layers.15.self_attn.q_proj.bias', 'decoder.layers.15.self_attn.q_proj.weight', 'decoder.layers.15.self_attn.scaling', 'decoder.layers.15.self_attn.v_proj.bias', 'decoder.layers.15.self_attn.v_proj.weight', 'decoder.layers.16.input_layernorm.weight', 'decoder.layers.16.mlp.down_proj.bias', 'decoder.layers.16.mlp.down_proj.weight', 'decoder.layers.16.mlp.gate_proj.bias', 'decoder.layers.16.mlp.gate_proj.weight', 'decoder.layers.16.mlp.layer_norm.bias', 'decoder.layers.16.mlp.layer_norm.weight', 'decoder.layers.16.self_attn.k_proj.bias', 'decoder.layers.16.self_attn.k_proj.weight', 'decoder.layers.16.self_attn.o_proj.bias', 'decoder.layers.16.self_attn.o_proj.weight', 'decoder.layers.16.self_attn.q_proj.bias', 'decoder.layers.16.self_attn.q_proj.weight', 'decoder.layers.16.self_attn.scaling', 'decoder.layers.16.self_attn.v_proj.bias', 'decoder.layers.16.self_attn.v_proj.weight', 'decoder.layers.17.input_layernorm.weight', 'decoder.layers.17.mlp.down_proj.bias', 'decoder.layers.17.mlp.down_proj.weight', 'decoder.layers.17.mlp.gate_proj.bias', 'decoder.layers.17.mlp.gate_proj.weight', 'decoder.layers.17.mlp.layer_norm.bias', 'decoder.layers.17.mlp.layer_norm.weight', 'decoder.layers.17.self_attn.k_proj.bias', 'decoder.layers.17.self_attn.k_proj.weight', 'decoder.layers.17.self_attn.o_proj.bias', 'decoder.layers.17.self_attn.o_proj.weight', 'decoder.layers.17.self_attn.q_proj.bias', 'decoder.layers.17.self_attn.q_proj.weight', 'decoder.layers.17.self_attn.scaling', 'decoder.layers.17.self_attn.v_proj.bias', 'decoder.layers.17.self_attn.v_proj.weight', 'decoder.layers.18.input_layernorm.weight', 'decoder.layers.18.mlp.down_proj.bias', 'decoder.layers.18.mlp.down_proj.weight', 'decoder.layers.18.mlp.gate_proj.bias', 'decoder.layers.18.mlp.gate_proj.weight', 'decoder.layers.18.mlp.layer_norm.bias', 'decoder.layers.18.mlp.layer_norm.weight', 'decoder.layers.18.self_attn.k_proj.bias', 'decoder.layers.18.self_attn.k_proj.weight', 'decoder.layers.18.self_attn.o_proj.bias', 'decoder.layers.18.self_attn.o_proj.weight', 'decoder.layers.18.self_attn.q_proj.bias', 'decoder.layers.18.self_attn.q_proj.weight', 'decoder.layers.18.self_attn.scaling', 'decoder.layers.18.self_attn.v_proj.bias', 'decoder.layers.18.self_attn.v_proj.weight', 'decoder.layers.19.input_layernorm.weight', 'decoder.layers.19.mlp.down_proj.bias', 'decoder.layers.19.mlp.down_proj.weight', 'decoder.layers.19.mlp.gate_proj.bias', 'decoder.layers.19.mlp.gate_proj.weight', 'decoder.layers.19.mlp.layer_norm.bias', 'decoder.layers.19.mlp.layer_norm.weight', 'decoder.layers.19.self_attn.k_proj.bias', 'decoder.layers.19.self_attn.k_proj.weight', 'decoder.layers.19.self_attn.o_proj.bias', 'decoder.layers.19.self_attn.o_proj.weight', 'decoder.layers.19.self_attn.q_proj.bias', 'decoder.layers.19.self_attn.q_proj.weight', 'decoder.layers.19.self_attn.scaling', 'decoder.layers.19.self_attn.v_proj.bias', 'decoder.layers.19.self_attn.v_proj.weight', 'decoder.layers.2.input_layernorm.weight', 'decoder.layers.2.mlp.down_proj.bias', 'decoder.layers.2.mlp.down_proj.weight', 'decoder.layers.2.mlp.gate_proj.bias', 'decoder.layers.2.mlp.gate_proj.weight', 'decoder.layers.2.mlp.layer_norm.bias', 'decoder.layers.2.mlp.layer_norm.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.o_proj.bias', 'decoder.layers.2.self_attn.o_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.scaling', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.3.input_layernorm.weight', 'decoder.layers.3.mlp.down_proj.bias', 'decoder.layers.3.mlp.down_proj.weight', 'decoder.layers.3.mlp.gate_proj.bias', 'decoder.layers.3.mlp.gate_proj.weight', 'decoder.layers.3.mlp.layer_norm.bias', 'decoder.layers.3.mlp.layer_norm.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.o_proj.bias', 'decoder.layers.3.self_attn.o_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.scaling', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.4.input_layernorm.weight', 'decoder.layers.4.mlp.down_proj.bias', 'decoder.layers.4.mlp.down_proj.weight', 'decoder.layers.4.mlp.gate_proj.bias', 'decoder.layers.4.mlp.gate_proj.weight', 'decoder.layers.4.mlp.layer_norm.bias', 'decoder.layers.4.mlp.layer_norm.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.o_proj.bias', 'decoder.layers.4.self_attn.o_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.scaling', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.5.input_layernorm.weight', 'decoder.layers.5.mlp.down_proj.bias', 'decoder.layers.5.mlp.down_proj.weight', 'decoder.layers.5.mlp.gate_proj.bias', 'decoder.layers.5.mlp.gate_proj.weight', 'decoder.layers.5.mlp.layer_norm.bias', 'decoder.layers.5.mlp.layer_norm.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.o_proj.bias', 'decoder.layers.5.self_attn.o_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.scaling', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.6.input_layernorm.weight', 'decoder.layers.6.mlp.down_proj.bias', 'decoder.layers.6.mlp.down_proj.weight', 'decoder.layers.6.mlp.gate_proj.bias', 'decoder.layers.6.mlp.gate_proj.weight', 'decoder.layers.6.mlp.layer_norm.bias', 'decoder.layers.6.mlp.layer_norm.weight', 'decoder.layers.6.self_attn.k_proj.bias', 'decoder.layers.6.self_attn.k_proj.weight', 'decoder.layers.6.self_attn.o_proj.bias', 'decoder.layers.6.self_attn.o_proj.weight', 'decoder.layers.6.self_attn.q_proj.bias', 'decoder.layers.6.self_attn.q_proj.weight', 'decoder.layers.6.self_attn.scaling', 'decoder.layers.6.self_attn.v_proj.bias', 'decoder.layers.6.self_attn.v_proj.weight', 'decoder.layers.7.input_layernorm.weight', 'decoder.layers.7.mlp.down_proj.bias', 'decoder.layers.7.mlp.down_proj.weight', 'decoder.layers.7.mlp.gate_proj.bias', 'decoder.layers.7.mlp.gate_proj.weight', 'decoder.layers.7.mlp.layer_norm.bias', 'decoder.layers.7.mlp.layer_norm.weight', 'decoder.layers.7.self_attn.k_proj.bias', 'decoder.layers.7.self_attn.k_proj.weight', 'decoder.layers.7.self_attn.o_proj.bias', 'decoder.layers.7.self_attn.o_proj.weight', 'decoder.layers.7.self_attn.q_proj.bias', 'decoder.layers.7.self_attn.q_proj.weight', 'decoder.layers.7.self_attn.scaling', 'decoder.layers.7.self_attn.v_proj.bias', 'decoder.layers.7.self_attn.v_proj.weight', 'decoder.layers.8.input_layernorm.weight', 'decoder.layers.8.mlp.down_proj.bias', 'decoder.layers.8.mlp.down_proj.weight', 'decoder.layers.8.mlp.gate_proj.bias', 'decoder.layers.8.mlp.gate_proj.weight', 'decoder.layers.8.mlp.layer_norm.bias', 'decoder.layers.8.mlp.layer_norm.weight', 'decoder.layers.8.self_attn.k_proj.bias', 'decoder.layers.8.self_attn.k_proj.weight', 'decoder.layers.8.self_attn.o_proj.bias', 'decoder.layers.8.self_attn.o_proj.weight', 'decoder.layers.8.self_attn.q_proj.bias', 'decoder.layers.8.self_attn.q_proj.weight', 'decoder.layers.8.self_attn.scaling', 'decoder.layers.8.self_attn.v_proj.bias', 'decoder.layers.8.self_attn.v_proj.weight', 'decoder.layers.9.input_layernorm.weight', 'decoder.layers.9.mlp.down_proj.bias', 'decoder.layers.9.mlp.down_proj.weight', 'decoder.layers.9.mlp.gate_proj.bias', 'decoder.layers.9.mlp.gate_proj.weight', 'decoder.layers.9.mlp.layer_norm.bias', 'decoder.layers.9.mlp.layer_norm.weight', 'decoder.layers.9.self_attn.k_proj.bias', 'decoder.layers.9.self_attn.k_proj.weight', 'decoder.layers.9.self_attn.o_proj.bias', 'decoder.layers.9.self_attn.o_proj.weight', 'decoder.layers.9.self_attn.q_proj.bias', 'decoder.layers.9.self_attn.q_proj.weight', 'decoder.layers.9.self_attn.scaling', 'decoder.layers.9.self_attn.v_proj.bias', 'decoder.layers.9.self_attn.v_proj.weight', 'horizon_ff_layer.input_layer.bias', 'horizon_ff_layer.input_layer.weight', 'horizon_ff_layer.output_layer.bias', 'horizon_ff_layer.output_layer.weight', 'horizon_ff_layer.residual_layer.bias', 'horizon_ff_layer.residual_layer.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n",
            "  Epoch 1/100 train_loss=1.3832 train_acc=0.2000 eval_loss=0.6525 eval_acc=0.7942 (best)\n",
            "  Epoch 2/100 train_loss=0.4421 train_acc=0.8750 eval_loss=0.2292 eval_acc=0.9167 (best)\n",
            "  Epoch 3/100 train_loss=0.0583 train_acc=1.0000 eval_loss=0.1284 eval_acc=0.9507 (best)\n",
            "  Epoch 4/100 train_loss=0.0082 train_acc=1.0000 eval_loss=0.1262 eval_acc=0.9500 (best)\n",
            "  Epoch 5/100 train_loss=0.0031 train_acc=1.0000 eval_loss=0.1238 eval_acc=0.9514 (best)\n",
            "  Epoch 6/100 train_loss=0.0008 train_acc=1.0000 eval_loss=0.1209 eval_acc=0.9529 (best)\n",
            "  Epoch 7/100 train_loss=0.0002 train_acc=1.0000 eval_loss=0.1206 eval_acc=0.9572 (best)\n",
            "  Epoch 8/100 train_loss=0.0001 train_acc=1.0000 eval_loss=0.1218 eval_acc=0.9587 \n",
            "  Epoch 9/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.1243 eval_acc=0.9594 \n",
            "  Epoch 10/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.1273 eval_acc=0.9594 \n",
            "  Epoch 11/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.1306 eval_acc=0.9609 \n",
            "  Epoch 12/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.1335 eval_acc=0.9609 \n",
            "  Epoch 13/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.1361 eval_acc=0.9601 \n",
            "  Epoch 14/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.1384 eval_acc=0.9601 \n",
            "  Epoch 15/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.1403 eval_acc=0.9601 \n",
            "  Epoch 16/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.1418 eval_acc=0.9601 \n",
            "  Epoch 17/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.1432 eval_acc=0.9609 \n",
            "  Early stopping on google/timesfm-2.5-200m-pytorch: no improvement for 10 epochs (best epoch = 7)\n",
            "    tfm[google/timesfm-2.5-200m-pytorch] train_acc=1.0000 eval_acc=0.96086956521739130820947139000054448843002319\n",
            "    mrh_acc=0.9964 mr+h+kg_acc=0.9986 kg_acc=0.9957 ensemble=0.9978 (w=0.60)\n",
            "  Split 1/1 - accuracy=0.9978 time=436.4s\n",
            "Completed CinCECGTorso: Mean Acc=0.9978\n",
            "\n",
            "=== 13/109 Coffee ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n",
            "    Gate split 1/5: baseline_loss=0.2192 adaptive_loss=0.1807\n",
            "    Gate split 2/5: baseline_loss=0.2956 adaptive_loss=0.2637\n",
            "    Gate split 3/5: baseline_loss=0.1915 adaptive_loss=0.1589\n",
            "    Gate split 4/5: baseline_loss=0.2575 adaptive_loss=0.2097\n",
            "    Gate split 5/5: baseline_loss=0.2598 adaptive_loss=0.2022\n",
            "  Decision: Adaptive kept (loss 0.2031 vs baseline 0.2447, delta=-0.0416 <= +0.0200); savgol(window=11, poly=2) - high noise (std_diff)\n",
            "Error processing Coffee: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n",
            "\n",
            "=== 14/109 Computers ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 556, in main\n",
            "    results = evaluate_dataset_per_split(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 429, in evaluate_dataset_per_split\n",
            "    X_train_extra = np.concatenate([X_train_all, all_dec_train], axis=1)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "ValueError: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n",
            "    Gate split 1/5: baseline_loss=0.6426 adaptive_loss=0.5169\n",
            "    Gate split 2/5: baseline_loss=0.6477 adaptive_loss=0.7426\n",
            "    Gate split 3/5: baseline_loss=0.4078 adaptive_loss=0.4603\n",
            "    Gate split 4/5: baseline_loss=0.7643 adaptive_loss=0.7543\n",
            "    Gate split 5/5: baseline_loss=0.3720 adaptive_loss=0.4111\n",
            "  Decision: Adaptive kept (loss 0.5770 vs baseline 0.5669, delta=+0.0101 <= +0.0200); savgol(window=15, poly=3) - high noise (std_diff)\n",
            "Error processing Computers: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n",
            "\n",
            "=== 15/109 CricketX ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 556, in main\n",
            "    results = evaluate_dataset_per_split(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 429, in evaluate_dataset_per_split\n",
            "    X_train_extra = np.concatenate([X_train_all, all_dec_train], axis=1)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "ValueError: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n",
            "    Gate split 1/5: baseline_loss=0.5040 adaptive_loss=0.5576\n",
            "    Gate split 2/5: baseline_loss=0.5574 adaptive_loss=0.5653\n",
            "    Gate split 3/5: baseline_loss=0.5022 adaptive_loss=0.5426\n",
            "    Gate split 4/5: baseline_loss=0.5312 adaptive_loss=0.5943\n",
            "    Gate split 5/5: baseline_loss=0.5791 adaptive_loss=0.6125\n",
            "  Decision: Adaptive rejected (loss 0.5744 vs baseline 0.5348, delta=+0.0397 > +0.0200); savgol(window=11, poly=2) - high noise (std_diff)\n",
            "\n",
            "=== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at google/timesfm-2.5-200m-pytorch were not used when initializing TimesFmModelForPrediction: ['output_projection_point.hidden_layer.weight', 'output_projection_point.output_layer.weight', 'output_projection_point.residual_layer.weight', 'output_projection_quantiles.hidden_layer.weight', 'output_projection_quantiles.output_layer.weight', 'output_projection_quantiles.residual_layer.weight', 'stacked_xf.0.attn.key_ln.scale', 'stacked_xf.0.attn.out.weight', 'stacked_xf.0.attn.per_dim_scale.per_dim_scale', 'stacked_xf.0.attn.qkv_proj.weight', 'stacked_xf.0.attn.query_ln.scale', 'stacked_xf.0.ff0.weight', 'stacked_xf.0.ff1.weight', 'stacked_xf.0.post_attn_ln.scale', 'stacked_xf.0.post_ff_ln.scale', 'stacked_xf.0.pre_attn_ln.scale', 'stacked_xf.0.pre_ff_ln.scale', 'stacked_xf.1.attn.key_ln.scale', 'stacked_xf.1.attn.out.weight', 'stacked_xf.1.attn.per_dim_scale.per_dim_scale', 'stacked_xf.1.attn.qkv_proj.weight', 'stacked_xf.1.attn.query_ln.scale', 'stacked_xf.1.ff0.weight', 'stacked_xf.1.ff1.weight', 'stacked_xf.1.post_attn_ln.scale', 'stacked_xf.1.post_ff_ln.scale', 'stacked_xf.1.pre_attn_ln.scale', 'stacked_xf.1.pre_ff_ln.scale', 'stacked_xf.10.attn.key_ln.scale', 'stacked_xf.10.attn.out.weight', 'stacked_xf.10.attn.per_dim_scale.per_dim_scale', 'stacked_xf.10.attn.qkv_proj.weight', 'stacked_xf.10.attn.query_ln.scale', 'stacked_xf.10.ff0.weight', 'stacked_xf.10.ff1.weight', 'stacked_xf.10.post_attn_ln.scale', 'stacked_xf.10.post_ff_ln.scale', 'stacked_xf.10.pre_attn_ln.scale', 'stacked_xf.10.pre_ff_ln.scale', 'stacked_xf.11.attn.key_ln.scale', 'stacked_xf.11.attn.out.weight', 'stacked_xf.11.attn.per_dim_scale.per_dim_scale', 'stacked_xf.11.attn.qkv_proj.weight', 'stacked_xf.11.attn.query_ln.scale', 'stacked_xf.11.ff0.weight', 'stacked_xf.11.ff1.weight', 'stacked_xf.11.post_attn_ln.scale', 'stacked_xf.11.post_ff_ln.scale', 'stacked_xf.11.pre_attn_ln.scale', 'stacked_xf.11.pre_ff_ln.scale', 'stacked_xf.12.attn.key_ln.scale', 'stacked_xf.12.attn.out.weight', 'stacked_xf.12.attn.per_dim_scale.per_dim_scale', 'stacked_xf.12.attn.qkv_proj.weight', 'stacked_xf.12.attn.query_ln.scale', 'stacked_xf.12.ff0.weight', 'stacked_xf.12.ff1.weight', 'stacked_xf.12.post_attn_ln.scale', 'stacked_xf.12.post_ff_ln.scale', 'stacked_xf.12.pre_attn_ln.scale', 'stacked_xf.12.pre_ff_ln.scale', 'stacked_xf.13.attn.key_ln.scale', 'stacked_xf.13.attn.out.weight', 'stacked_xf.13.attn.per_dim_scale.per_dim_scale', 'stacked_xf.13.attn.qkv_proj.weight', 'stacked_xf.13.attn.query_ln.scale', 'stacked_xf.13.ff0.weight', 'stacked_xf.13.ff1.weight', 'stacked_xf.13.post_attn_ln.scale', 'stacked_xf.13.post_ff_ln.scale', 'stacked_xf.13.pre_attn_ln.scale', 'stacked_xf.13.pre_ff_ln.scale', 'stacked_xf.14.attn.key_ln.scale', 'stacked_xf.14.attn.out.weight', 'stacked_xf.14.attn.per_dim_scale.per_dim_scale', 'stacked_xf.14.attn.qkv_proj.weight', 'stacked_xf.14.attn.query_ln.scale', 'stacked_xf.14.ff0.weight', 'stacked_xf.14.ff1.weight', 'stacked_xf.14.post_attn_ln.scale', 'stacked_xf.14.post_ff_ln.scale', 'stacked_xf.14.pre_attn_ln.scale', 'stacked_xf.14.pre_ff_ln.scale', 'stacked_xf.15.attn.key_ln.scale', 'stacked_xf.15.attn.out.weight', 'stacked_xf.15.attn.per_dim_scale.per_dim_scale', 'stacked_xf.15.attn.qkv_proj.weight', 'stacked_xf.15.attn.query_ln.scale', 'stacked_xf.15.ff0.weight', 'stacked_xf.15.ff1.weight', 'stacked_xf.15.post_attn_ln.scale', 'stacked_xf.15.post_ff_ln.scale', 'stacked_xf.15.pre_attn_ln.scale', 'stacked_xf.15.pre_ff_ln.scale', 'stacked_xf.16.attn.key_ln.scale', 'stacked_xf.16.attn.out.weight', 'stacked_xf.16.attn.per_dim_scale.per_dim_scale', 'stacked_xf.16.attn.qkv_proj.weight', 'stacked_xf.16.attn.query_ln.scale', 'stacked_xf.16.ff0.weight', 'stacked_xf.16.ff1.weight', 'stacked_xf.16.post_attn_ln.scale', 'stacked_xf.16.post_ff_ln.scale', 'stacked_xf.16.pre_attn_ln.scale', 'stacked_xf.16.pre_ff_ln.scale', 'stacked_xf.17.attn.key_ln.scale', 'stacked_xf.17.attn.out.weight', 'stacked_xf.17.attn.per_dim_scale.per_dim_scale', 'stacked_xf.17.attn.qkv_proj.weight', 'stacked_xf.17.attn.query_ln.scale', 'stacked_xf.17.ff0.weight', 'stacked_xf.17.ff1.weight', 'stacked_xf.17.post_attn_ln.scale', 'stacked_xf.17.post_ff_ln.scale', 'stacked_xf.17.pre_attn_ln.scale', 'stacked_xf.17.pre_ff_ln.scale', 'stacked_xf.18.attn.key_ln.scale', 'stacked_xf.18.attn.out.weight', 'stacked_xf.18.attn.per_dim_scale.per_dim_scale', 'stacked_xf.18.attn.qkv_proj.weight', 'stacked_xf.18.attn.query_ln.scale', 'stacked_xf.18.ff0.weight', 'stacked_xf.18.ff1.weight', 'stacked_xf.18.post_attn_ln.scale', 'stacked_xf.18.post_ff_ln.scale', 'stacked_xf.18.pre_attn_ln.scale', 'stacked_xf.18.pre_ff_ln.scale', 'stacked_xf.19.attn.key_ln.scale', 'stacked_xf.19.attn.out.weight', 'stacked_xf.19.attn.per_dim_scale.per_dim_scale', 'stacked_xf.19.attn.qkv_proj.weight', 'stacked_xf.19.attn.query_ln.scale', 'stacked_xf.19.ff0.weight', 'stacked_xf.19.ff1.weight', 'stacked_xf.19.post_attn_ln.scale', 'stacked_xf.19.post_ff_ln.scale', 'stacked_xf.19.pre_attn_ln.scale', 'stacked_xf.19.pre_ff_ln.scale', 'stacked_xf.2.attn.key_ln.scale', 'stacked_xf.2.attn.out.weight', 'stacked_xf.2.attn.per_dim_scale.per_dim_scale', 'stacked_xf.2.attn.qkv_proj.weight', 'stacked_xf.2.attn.query_ln.scale', 'stacked_xf.2.ff0.weight', 'stacked_xf.2.ff1.weight', 'stacked_xf.2.post_attn_ln.scale', 'stacked_xf.2.post_ff_ln.scale', 'stacked_xf.2.pre_attn_ln.scale', 'stacked_xf.2.pre_ff_ln.scale', 'stacked_xf.3.attn.key_ln.scale', 'stacked_xf.3.attn.out.weight', 'stacked_xf.3.attn.per_dim_scale.per_dim_scale', 'stacked_xf.3.attn.qkv_proj.weight', 'stacked_xf.3.attn.query_ln.scale', 'stacked_xf.3.ff0.weight', 'stacked_xf.3.ff1.weight', 'stacked_xf.3.post_attn_ln.scale', 'stacked_xf.3.post_ff_ln.scale', 'stacked_xf.3.pre_attn_ln.scale', 'stacked_xf.3.pre_ff_ln.scale', 'stacked_xf.4.attn.key_ln.scale', 'stacked_xf.4.attn.out.weight', 'stacked_xf.4.attn.per_dim_scale.per_dim_scale', 'stacked_xf.4.attn.qkv_proj.weight', 'stacked_xf.4.attn.query_ln.scale', 'stacked_xf.4.ff0.weight', 'stacked_xf.4.ff1.weight', 'stacked_xf.4.post_attn_ln.scale', 'stacked_xf.4.post_ff_ln.scale', 'stacked_xf.4.pre_attn_ln.scale', 'stacked_xf.4.pre_ff_ln.scale', 'stacked_xf.5.attn.key_ln.scale', 'stacked_xf.5.attn.out.weight', 'stacked_xf.5.attn.per_dim_scale.per_dim_scale', 'stacked_xf.5.attn.qkv_proj.weight', 'stacked_xf.5.attn.query_ln.scale', 'stacked_xf.5.ff0.weight', 'stacked_xf.5.ff1.weight', 'stacked_xf.5.post_attn_ln.scale', 'stacked_xf.5.post_ff_ln.scale', 'stacked_xf.5.pre_attn_ln.scale', 'stacked_xf.5.pre_ff_ln.scale', 'stacked_xf.6.attn.key_ln.scale', 'stacked_xf.6.attn.out.weight', 'stacked_xf.6.attn.per_dim_scale.per_dim_scale', 'stacked_xf.6.attn.qkv_proj.weight', 'stacked_xf.6.attn.query_ln.scale', 'stacked_xf.6.ff0.weight', 'stacked_xf.6.ff1.weight', 'stacked_xf.6.post_attn_ln.scale', 'stacked_xf.6.post_ff_ln.scale', 'stacked_xf.6.pre_attn_ln.scale', 'stacked_xf.6.pre_ff_ln.scale', 'stacked_xf.7.attn.key_ln.scale', 'stacked_xf.7.attn.out.weight', 'stacked_xf.7.attn.per_dim_scale.per_dim_scale', 'stacked_xf.7.attn.qkv_proj.weight', 'stacked_xf.7.attn.query_ln.scale', 'stacked_xf.7.ff0.weight', 'stacked_xf.7.ff1.weight', 'stacked_xf.7.post_attn_ln.scale', 'stacked_xf.7.post_ff_ln.scale', 'stacked_xf.7.pre_attn_ln.scale', 'stacked_xf.7.pre_ff_ln.scale', 'stacked_xf.8.attn.key_ln.scale', 'stacked_xf.8.attn.out.weight', 'stacked_xf.8.attn.per_dim_scale.per_dim_scale', 'stacked_xf.8.attn.qkv_proj.weight', 'stacked_xf.8.attn.query_ln.scale', 'stacked_xf.8.ff0.weight', 'stacked_xf.8.ff1.weight', 'stacked_xf.8.post_attn_ln.scale', 'stacked_xf.8.post_ff_ln.scale', 'stacked_xf.8.pre_attn_ln.scale', 'stacked_xf.8.pre_ff_ln.scale', 'stacked_xf.9.attn.key_ln.scale', 'stacked_xf.9.attn.out.weight', 'stacked_xf.9.attn.per_dim_scale.per_dim_scale', 'stacked_xf.9.attn.qkv_proj.weight', 'stacked_xf.9.attn.query_ln.scale', 'stacked_xf.9.ff0.weight', 'stacked_xf.9.ff1.weight', 'stacked_xf.9.post_attn_ln.scale', 'stacked_xf.9.post_ff_ln.scale', 'stacked_xf.9.pre_attn_ln.scale', 'stacked_xf.9.pre_ff_ln.scale', 'tokenizer.hidden_layer.bias', 'tokenizer.hidden_layer.weight', 'tokenizer.output_layer.bias', 'tokenizer.output_layer.weight', 'tokenizer.residual_layer.bias', 'tokenizer.residual_layer.weight']\n",
            "- This IS expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of TimesFmModelForPrediction were not initialized from the model checkpoint at google/timesfm-2.5-200m-pytorch and are newly initialized: ['decoder.freq_emb.weight', 'decoder.input_ff_layer.input_layer.bias', 'decoder.input_ff_layer.input_layer.weight', 'decoder.input_ff_layer.output_layer.bias', 'decoder.input_ff_layer.output_layer.weight', 'decoder.input_ff_layer.residual_layer.bias', 'decoder.input_ff_layer.residual_layer.weight', 'decoder.layers.0.input_layernorm.weight', 'decoder.layers.0.mlp.down_proj.bias', 'decoder.layers.0.mlp.down_proj.weight', 'decoder.layers.0.mlp.gate_proj.bias', 'decoder.layers.0.mlp.gate_proj.weight', 'decoder.layers.0.mlp.layer_norm.bias', 'decoder.layers.0.mlp.layer_norm.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.o_proj.bias', 'decoder.layers.0.self_attn.o_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.scaling', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.1.input_layernorm.weight', 'decoder.layers.1.mlp.down_proj.bias', 'decoder.layers.1.mlp.down_proj.weight', 'decoder.layers.1.mlp.gate_proj.bias', 'decoder.layers.1.mlp.gate_proj.weight', 'decoder.layers.1.mlp.layer_norm.bias', 'decoder.layers.1.mlp.layer_norm.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.o_proj.bias', 'decoder.layers.1.self_attn.o_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.scaling', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.10.input_layernorm.weight', 'decoder.layers.10.mlp.down_proj.bias', 'decoder.layers.10.mlp.down_proj.weight', 'decoder.layers.10.mlp.gate_proj.bias', 'decoder.layers.10.mlp.gate_proj.weight', 'decoder.layers.10.mlp.layer_norm.bias', 'decoder.layers.10.mlp.layer_norm.weight', 'decoder.layers.10.self_attn.k_proj.bias', 'decoder.layers.10.self_attn.k_proj.weight', 'decoder.layers.10.self_attn.o_proj.bias', 'decoder.layers.10.self_attn.o_proj.weight', 'decoder.layers.10.self_attn.q_proj.bias', 'decoder.layers.10.self_attn.q_proj.weight', 'decoder.layers.10.self_attn.scaling', 'decoder.layers.10.self_attn.v_proj.bias', 'decoder.layers.10.self_attn.v_proj.weight', 'decoder.layers.11.input_layernorm.weight', 'decoder.layers.11.mlp.down_proj.bias', 'decoder.layers.11.mlp.down_proj.weight', 'decoder.layers.11.mlp.gate_proj.bias', 'decoder.layers.11.mlp.gate_proj.weight', 'decoder.layers.11.mlp.layer_norm.bias', 'decoder.layers.11.mlp.layer_norm.weight', 'decoder.layers.11.self_attn.k_proj.bias', 'decoder.layers.11.self_attn.k_proj.weight', 'decoder.layers.11.self_attn.o_proj.bias', 'decoder.layers.11.self_attn.o_proj.weight', 'decoder.layers.11.self_attn.q_proj.bias', 'decoder.layers.11.self_attn.q_proj.weight', 'decoder.layers.11.self_attn.scaling', 'decoder.layers.11.self_attn.v_proj.bias', 'decoder.layers.11.self_attn.v_proj.weight', 'decoder.layers.12.input_layernorm.weight', 'decoder.layers.12.mlp.down_proj.bias', 'decoder.layers.12.mlp.down_proj.weight', 'decoder.layers.12.mlp.gate_proj.bias', 'decoder.layers.12.mlp.gate_proj.weight', 'decoder.layers.12.mlp.layer_norm.bias', 'decoder.layers.12.mlp.layer_norm.weight', 'decoder.layers.12.self_attn.k_proj.bias', 'decoder.layers.12.self_attn.k_proj.weight', 'decoder.layers.12.self_attn.o_proj.bias', 'decoder.layers.12.self_attn.o_proj.weight', 'decoder.layers.12.self_attn.q_proj.bias', 'decoder.layers.12.self_attn.q_proj.weight', 'decoder.layers.12.self_attn.scaling', 'decoder.layers.12.self_attn.v_proj.bias', 'decoder.layers.12.self_attn.v_proj.weight', 'decoder.layers.13.input_layernorm.weight', 'decoder.layers.13.mlp.down_proj.bias', 'decoder.layers.13.mlp.down_proj.weight', 'decoder.layers.13.mlp.gate_proj.bias', 'decoder.layers.13.mlp.gate_proj.weight', 'decoder.layers.13.mlp.layer_norm.bias', 'decoder.layers.13.mlp.layer_norm.weight', 'decoder.layers.13.self_attn.k_proj.bias', 'decoder.layers.13.self_attn.k_proj.weight', 'decoder.layers.13.self_attn.o_proj.bias', 'decoder.layers.13.self_attn.o_proj.weight', 'decoder.layers.13.self_attn.q_proj.bias', 'decoder.layers.13.self_attn.q_proj.weight', 'decoder.layers.13.self_attn.scaling', 'decoder.layers.13.self_attn.v_proj.bias', 'decoder.layers.13.self_attn.v_proj.weight', 'decoder.layers.14.input_layernorm.weight', 'decoder.layers.14.mlp.down_proj.bias', 'decoder.layers.14.mlp.down_proj.weight', 'decoder.layers.14.mlp.gate_proj.bias', 'decoder.layers.14.mlp.gate_proj.weight', 'decoder.layers.14.mlp.layer_norm.bias', 'decoder.layers.14.mlp.layer_norm.weight', 'decoder.layers.14.self_attn.k_proj.bias', 'decoder.layers.14.self_attn.k_proj.weight', 'decoder.layers.14.self_attn.o_proj.bias', 'decoder.layers.14.self_attn.o_proj.weight', 'decoder.layers.14.self_attn.q_proj.bias', 'decoder.layers.14.self_attn.q_proj.weight', 'decoder.layers.14.self_attn.scaling', 'decoder.layers.14.self_attn.v_proj.bias', 'decoder.layers.14.self_attn.v_proj.weight', 'decoder.layers.15.input_layernorm.weight', 'decoder.layers.15.mlp.down_proj.bias', 'decoder.layers.15.mlp.down_proj.weight', 'decoder.layers.15.mlp.gate_proj.bias', 'decoder.layers.15.mlp.gate_proj.weight', 'decoder.layers.15.mlp.layer_norm.bias', 'decoder.layers.15.mlp.layer_norm.weight', 'decoder.layers.15.self_attn.k_proj.bias', 'decoder.layers.15.self_attn.k_proj.weight', 'decoder.layers.15.self_attn.o_proj.bias', 'decoder.layers.15.self_attn.o_proj.weight', 'decoder.layers.15.self_attn.q_proj.bias', 'decoder.layers.15.self_attn.q_proj.weight', 'decoder.layers.15.self_attn.scaling', 'decoder.layers.15.self_attn.v_proj.bias', 'decoder.layers.15.self_attn.v_proj.weight', 'decoder.layers.16.input_layernorm.weight', 'decoder.layers.16.mlp.down_proj.bias', 'decoder.layers.16.mlp.down_proj.weight', 'decoder.layers.16.mlp.gate_proj.bias', 'decoder.layers.16.mlp.gate_proj.weight', 'decoder.layers.16.mlp.layer_norm.bias', 'decoder.layers.16.mlp.layer_norm.weight', 'decoder.layers.16.self_attn.k_proj.bias', 'decoder.layers.16.self_attn.k_proj.weight', 'decoder.layers.16.self_attn.o_proj.bias', 'decoder.layers.16.self_attn.o_proj.weight', 'decoder.layers.16.self_attn.q_proj.bias', 'decoder.layers.16.self_attn.q_proj.weight', 'decoder.layers.16.self_attn.scaling', 'decoder.layers.16.self_attn.v_proj.bias', 'decoder.layers.16.self_attn.v_proj.weight', 'decoder.layers.17.input_layernorm.weight', 'decoder.layers.17.mlp.down_proj.bias', 'decoder.layers.17.mlp.down_proj.weight', 'decoder.layers.17.mlp.gate_proj.bias', 'decoder.layers.17.mlp.gate_proj.weight', 'decoder.layers.17.mlp.layer_norm.bias', 'decoder.layers.17.mlp.layer_norm.weight', 'decoder.layers.17.self_attn.k_proj.bias', 'decoder.layers.17.self_attn.k_proj.weight', 'decoder.layers.17.self_attn.o_proj.bias', 'decoder.layers.17.self_attn.o_proj.weight', 'decoder.layers.17.self_attn.q_proj.bias', 'decoder.layers.17.self_attn.q_proj.weight', 'decoder.layers.17.self_attn.scaling', 'decoder.layers.17.self_attn.v_proj.bias', 'decoder.layers.17.self_attn.v_proj.weight', 'decoder.layers.18.input_layernorm.weight', 'decoder.layers.18.mlp.down_proj.bias', 'decoder.layers.18.mlp.down_proj.weight', 'decoder.layers.18.mlp.gate_proj.bias', 'decoder.layers.18.mlp.gate_proj.weight', 'decoder.layers.18.mlp.layer_norm.bias', 'decoder.layers.18.mlp.layer_norm.weight', 'decoder.layers.18.self_attn.k_proj.bias', 'decoder.layers.18.self_attn.k_proj.weight', 'decoder.layers.18.self_attn.o_proj.bias', 'decoder.layers.18.self_attn.o_proj.weight', 'decoder.layers.18.self_attn.q_proj.bias', 'decoder.layers.18.self_attn.q_proj.weight', 'decoder.layers.18.self_attn.scaling', 'decoder.layers.18.self_attn.v_proj.bias', 'decoder.layers.18.self_attn.v_proj.weight', 'decoder.layers.19.input_layernorm.weight', 'decoder.layers.19.mlp.down_proj.bias', 'decoder.layers.19.mlp.down_proj.weight', 'decoder.layers.19.mlp.gate_proj.bias', 'decoder.layers.19.mlp.gate_proj.weight', 'decoder.layers.19.mlp.layer_norm.bias', 'decoder.layers.19.mlp.layer_norm.weight', 'decoder.layers.19.self_attn.k_proj.bias', 'decoder.layers.19.self_attn.k_proj.weight', 'decoder.layers.19.self_attn.o_proj.bias', 'decoder.layers.19.self_attn.o_proj.weight', 'decoder.layers.19.self_attn.q_proj.bias', 'decoder.layers.19.self_attn.q_proj.weight', 'decoder.layers.19.self_attn.scaling', 'decoder.layers.19.self_attn.v_proj.bias', 'decoder.layers.19.self_attn.v_proj.weight', 'decoder.layers.2.input_layernorm.weight', 'decoder.layers.2.mlp.down_proj.bias', 'decoder.layers.2.mlp.down_proj.weight', 'decoder.layers.2.mlp.gate_proj.bias', 'decoder.layers.2.mlp.gate_proj.weight', 'decoder.layers.2.mlp.layer_norm.bias', 'decoder.layers.2.mlp.layer_norm.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.o_proj.bias', 'decoder.layers.2.self_attn.o_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.scaling', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.3.input_layernorm.weight', 'decoder.layers.3.mlp.down_proj.bias', 'decoder.layers.3.mlp.down_proj.weight', 'decoder.layers.3.mlp.gate_proj.bias', 'decoder.layers.3.mlp.gate_proj.weight', 'decoder.layers.3.mlp.layer_norm.bias', 'decoder.layers.3.mlp.layer_norm.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.o_proj.bias', 'decoder.layers.3.self_attn.o_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.scaling', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.4.input_layernorm.weight', 'decoder.layers.4.mlp.down_proj.bias', 'decoder.layers.4.mlp.down_proj.weight', 'decoder.layers.4.mlp.gate_proj.bias', 'decoder.layers.4.mlp.gate_proj.weight', 'decoder.layers.4.mlp.layer_norm.bias', 'decoder.layers.4.mlp.layer_norm.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.o_proj.bias', 'decoder.layers.4.self_attn.o_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.scaling', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.5.input_layernorm.weight', 'decoder.layers.5.mlp.down_proj.bias', 'decoder.layers.5.mlp.down_proj.weight', 'decoder.layers.5.mlp.gate_proj.bias', 'decoder.layers.5.mlp.gate_proj.weight', 'decoder.layers.5.mlp.layer_norm.bias', 'decoder.layers.5.mlp.layer_norm.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.o_proj.bias', 'decoder.layers.5.self_attn.o_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.scaling', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.6.input_layernorm.weight', 'decoder.layers.6.mlp.down_proj.bias', 'decoder.layers.6.mlp.down_proj.weight', 'decoder.layers.6.mlp.gate_proj.bias', 'decoder.layers.6.mlp.gate_proj.weight', 'decoder.layers.6.mlp.layer_norm.bias', 'decoder.layers.6.mlp.layer_norm.weight', 'decoder.layers.6.self_attn.k_proj.bias', 'decoder.layers.6.self_attn.k_proj.weight', 'decoder.layers.6.self_attn.o_proj.bias', 'decoder.layers.6.self_attn.o_proj.weight', 'decoder.layers.6.self_attn.q_proj.bias', 'decoder.layers.6.self_attn.q_proj.weight', 'decoder.layers.6.self_attn.scaling', 'decoder.layers.6.self_attn.v_proj.bias', 'decoder.layers.6.self_attn.v_proj.weight', 'decoder.layers.7.input_layernorm.weight', 'decoder.layers.7.mlp.down_proj.bias', 'decoder.layers.7.mlp.down_proj.weight', 'decoder.layers.7.mlp.gate_proj.bias', 'decoder.layers.7.mlp.gate_proj.weight', 'decoder.layers.7.mlp.layer_norm.bias', 'decoder.layers.7.mlp.layer_norm.weight', 'decoder.layers.7.self_attn.k_proj.bias', 'decoder.layers.7.self_attn.k_proj.weight', 'decoder.layers.7.self_attn.o_proj.bias', 'decoder.layers.7.self_attn.o_proj.weight', 'decoder.layers.7.self_attn.q_proj.bias', 'decoder.layers.7.self_attn.q_proj.weight', 'decoder.layers.7.self_attn.scaling', 'decoder.layers.7.self_attn.v_proj.bias', 'decoder.layers.7.self_attn.v_proj.weight', 'decoder.layers.8.input_layernorm.weight', 'decoder.layers.8.mlp.down_proj.bias', 'decoder.layers.8.mlp.down_proj.weight', 'decoder.layers.8.mlp.gate_proj.bias', 'decoder.layers.8.mlp.gate_proj.weight', 'decoder.layers.8.mlp.layer_norm.bias', 'decoder.layers.8.mlp.layer_norm.weight', 'decoder.layers.8.self_attn.k_proj.bias', 'decoder.layers.8.self_attn.k_proj.weight', 'decoder.layers.8.self_attn.o_proj.bias', 'decoder.layers.8.self_attn.o_proj.weight', 'decoder.layers.8.self_attn.q_proj.bias', 'decoder.layers.8.self_attn.q_proj.weight', 'decoder.layers.8.self_attn.scaling', 'decoder.layers.8.self_attn.v_proj.bias', 'decoder.layers.8.self_attn.v_proj.weight', 'decoder.layers.9.input_layernorm.weight', 'decoder.layers.9.mlp.down_proj.bias', 'decoder.layers.9.mlp.down_proj.weight', 'decoder.layers.9.mlp.gate_proj.bias', 'decoder.layers.9.mlp.gate_proj.weight', 'decoder.layers.9.mlp.layer_norm.bias', 'decoder.layers.9.mlp.layer_norm.weight', 'decoder.layers.9.self_attn.k_proj.bias', 'decoder.layers.9.self_attn.k_proj.weight', 'decoder.layers.9.self_attn.o_proj.bias', 'decoder.layers.9.self_attn.o_proj.weight', 'decoder.layers.9.self_attn.q_proj.bias', 'decoder.layers.9.self_attn.q_proj.weight', 'decoder.layers.9.self_attn.scaling', 'decoder.layers.9.self_attn.v_proj.bias', 'decoder.layers.9.self_attn.v_proj.weight', 'horizon_ff_layer.input_layer.bias', 'horizon_ff_layer.input_layer.weight', 'horizon_ff_layer.output_layer.bias', 'horizon_ff_layer.output_layer.weight', 'horizon_ff_layer.residual_layer.bias', 'horizon_ff_layer.residual_layer.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n",
            "  Epoch 1/100 train_loss=1.6841 train_acc=0.4949 eval_loss=1.0456 eval_acc=0.6436 (best)\n",
            "  Epoch 2/100 train_loss=0.5459 train_acc=0.8564 eval_loss=0.6594 eval_acc=0.7949 (best)\n",
            "  Epoch 3/100 train_loss=0.1736 train_acc=0.9641 eval_loss=0.6608 eval_acc=0.7795 \n",
            "  Epoch 4/100 train_loss=0.0849 train_acc=0.9821 eval_loss=0.9357 eval_acc=0.7590 \n",
            "  Epoch 5/100 train_loss=0.0850 train_acc=0.9718 eval_loss=0.9478 eval_acc=0.7744 \n",
            "  Epoch 6/100 train_loss=0.0956 train_acc=0.9667 eval_loss=0.7679 eval_acc=0.7923 \n",
            "  Epoch 7/100 train_loss=0.0996 train_acc=0.9615 eval_loss=1.2559 eval_acc=0.7179 \n",
            "  Epoch 8/100 train_loss=0.0854 train_acc=0.9692 eval_loss=1.0322 eval_acc=0.7795 \n",
            "  Epoch 9/100 train_loss=0.0694 train_acc=0.9718 eval_loss=1.2685 eval_acc=0.7513 \n",
            "  Epoch 10/100 train_loss=0.1167 train_acc=0.9564 eval_loss=1.2495 eval_acc=0.7410 \n",
            "  Epoch 11/100 train_loss=0.0683 train_acc=0.9692 eval_loss=1.4427 eval_acc=0.7051 \n",
            "  Epoch 12/100 train_loss=0.1864 train_acc=0.9359 eval_loss=1.6319 eval_acc=0.7231 \n",
            "  Early stopping on google/timesfm-2.5-200m-pytorch: no improvement for 10 epochs (best epoch = 2)\n",
            "    tfm[google/timesfm-2.5-200m-pytorch] train_acc=0.8564 eval_acc=0.72307692307692306155075812057475559413433075\n",
            "    mrh_acc=0.8436 mr+h+kg_acc=0.8410 kg_acc=0.8410 ensemble=0.8436 (w=0.60)\n",
            "  Split 1/1 - accuracy=0.8436 time=310.6s\n",
            "Completed CricketX: Mean Acc=0.8436\n",
            "\n",
            "=== 16/109 CricketY ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n",
            "    Gate split 1/5: baseline_loss=0.5451 adaptive_loss=0.5965\n",
            "    Gate split 2/5: baseline_loss=0.4849 adaptive_loss=0.5151\n",
            "    Gate split 3/5: baseline_loss=0.5602 adaptive_loss=0.5965\n",
            "    Gate split 4/5: baseline_loss=0.5678 adaptive_loss=0.5588\n",
            "    Gate split 5/5: baseline_loss=0.5116 adaptive_loss=0.5295\n",
            "  Decision: Adaptive rejected (loss 0.5593 vs baseline 0.5339, delta=+0.0254 > +0.0200); savgol(window=11, poly=2) - high noise (std_diff)\n",
            "\n",
            "=== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at google/timesfm-2.5-200m-pytorch were not used when initializing TimesFmModelForPrediction: ['output_projection_point.hidden_layer.weight', 'output_projection_point.output_layer.weight', 'output_projection_point.residual_layer.weight', 'output_projection_quantiles.hidden_layer.weight', 'output_projection_quantiles.output_layer.weight', 'output_projection_quantiles.residual_layer.weight', 'stacked_xf.0.attn.key_ln.scale', 'stacked_xf.0.attn.out.weight', 'stacked_xf.0.attn.per_dim_scale.per_dim_scale', 'stacked_xf.0.attn.qkv_proj.weight', 'stacked_xf.0.attn.query_ln.scale', 'stacked_xf.0.ff0.weight', 'stacked_xf.0.ff1.weight', 'stacked_xf.0.post_attn_ln.scale', 'stacked_xf.0.post_ff_ln.scale', 'stacked_xf.0.pre_attn_ln.scale', 'stacked_xf.0.pre_ff_ln.scale', 'stacked_xf.1.attn.key_ln.scale', 'stacked_xf.1.attn.out.weight', 'stacked_xf.1.attn.per_dim_scale.per_dim_scale', 'stacked_xf.1.attn.qkv_proj.weight', 'stacked_xf.1.attn.query_ln.scale', 'stacked_xf.1.ff0.weight', 'stacked_xf.1.ff1.weight', 'stacked_xf.1.post_attn_ln.scale', 'stacked_xf.1.post_ff_ln.scale', 'stacked_xf.1.pre_attn_ln.scale', 'stacked_xf.1.pre_ff_ln.scale', 'stacked_xf.10.attn.key_ln.scale', 'stacked_xf.10.attn.out.weight', 'stacked_xf.10.attn.per_dim_scale.per_dim_scale', 'stacked_xf.10.attn.qkv_proj.weight', 'stacked_xf.10.attn.query_ln.scale', 'stacked_xf.10.ff0.weight', 'stacked_xf.10.ff1.weight', 'stacked_xf.10.post_attn_ln.scale', 'stacked_xf.10.post_ff_ln.scale', 'stacked_xf.10.pre_attn_ln.scale', 'stacked_xf.10.pre_ff_ln.scale', 'stacked_xf.11.attn.key_ln.scale', 'stacked_xf.11.attn.out.weight', 'stacked_xf.11.attn.per_dim_scale.per_dim_scale', 'stacked_xf.11.attn.qkv_proj.weight', 'stacked_xf.11.attn.query_ln.scale', 'stacked_xf.11.ff0.weight', 'stacked_xf.11.ff1.weight', 'stacked_xf.11.post_attn_ln.scale', 'stacked_xf.11.post_ff_ln.scale', 'stacked_xf.11.pre_attn_ln.scale', 'stacked_xf.11.pre_ff_ln.scale', 'stacked_xf.12.attn.key_ln.scale', 'stacked_xf.12.attn.out.weight', 'stacked_xf.12.attn.per_dim_scale.per_dim_scale', 'stacked_xf.12.attn.qkv_proj.weight', 'stacked_xf.12.attn.query_ln.scale', 'stacked_xf.12.ff0.weight', 'stacked_xf.12.ff1.weight', 'stacked_xf.12.post_attn_ln.scale', 'stacked_xf.12.post_ff_ln.scale', 'stacked_xf.12.pre_attn_ln.scale', 'stacked_xf.12.pre_ff_ln.scale', 'stacked_xf.13.attn.key_ln.scale', 'stacked_xf.13.attn.out.weight', 'stacked_xf.13.attn.per_dim_scale.per_dim_scale', 'stacked_xf.13.attn.qkv_proj.weight', 'stacked_xf.13.attn.query_ln.scale', 'stacked_xf.13.ff0.weight', 'stacked_xf.13.ff1.weight', 'stacked_xf.13.post_attn_ln.scale', 'stacked_xf.13.post_ff_ln.scale', 'stacked_xf.13.pre_attn_ln.scale', 'stacked_xf.13.pre_ff_ln.scale', 'stacked_xf.14.attn.key_ln.scale', 'stacked_xf.14.attn.out.weight', 'stacked_xf.14.attn.per_dim_scale.per_dim_scale', 'stacked_xf.14.attn.qkv_proj.weight', 'stacked_xf.14.attn.query_ln.scale', 'stacked_xf.14.ff0.weight', 'stacked_xf.14.ff1.weight', 'stacked_xf.14.post_attn_ln.scale', 'stacked_xf.14.post_ff_ln.scale', 'stacked_xf.14.pre_attn_ln.scale', 'stacked_xf.14.pre_ff_ln.scale', 'stacked_xf.15.attn.key_ln.scale', 'stacked_xf.15.attn.out.weight', 'stacked_xf.15.attn.per_dim_scale.per_dim_scale', 'stacked_xf.15.attn.qkv_proj.weight', 'stacked_xf.15.attn.query_ln.scale', 'stacked_xf.15.ff0.weight', 'stacked_xf.15.ff1.weight', 'stacked_xf.15.post_attn_ln.scale', 'stacked_xf.15.post_ff_ln.scale', 'stacked_xf.15.pre_attn_ln.scale', 'stacked_xf.15.pre_ff_ln.scale', 'stacked_xf.16.attn.key_ln.scale', 'stacked_xf.16.attn.out.weight', 'stacked_xf.16.attn.per_dim_scale.per_dim_scale', 'stacked_xf.16.attn.qkv_proj.weight', 'stacked_xf.16.attn.query_ln.scale', 'stacked_xf.16.ff0.weight', 'stacked_xf.16.ff1.weight', 'stacked_xf.16.post_attn_ln.scale', 'stacked_xf.16.post_ff_ln.scale', 'stacked_xf.16.pre_attn_ln.scale', 'stacked_xf.16.pre_ff_ln.scale', 'stacked_xf.17.attn.key_ln.scale', 'stacked_xf.17.attn.out.weight', 'stacked_xf.17.attn.per_dim_scale.per_dim_scale', 'stacked_xf.17.attn.qkv_proj.weight', 'stacked_xf.17.attn.query_ln.scale', 'stacked_xf.17.ff0.weight', 'stacked_xf.17.ff1.weight', 'stacked_xf.17.post_attn_ln.scale', 'stacked_xf.17.post_ff_ln.scale', 'stacked_xf.17.pre_attn_ln.scale', 'stacked_xf.17.pre_ff_ln.scale', 'stacked_xf.18.attn.key_ln.scale', 'stacked_xf.18.attn.out.weight', 'stacked_xf.18.attn.per_dim_scale.per_dim_scale', 'stacked_xf.18.attn.qkv_proj.weight', 'stacked_xf.18.attn.query_ln.scale', 'stacked_xf.18.ff0.weight', 'stacked_xf.18.ff1.weight', 'stacked_xf.18.post_attn_ln.scale', 'stacked_xf.18.post_ff_ln.scale', 'stacked_xf.18.pre_attn_ln.scale', 'stacked_xf.18.pre_ff_ln.scale', 'stacked_xf.19.attn.key_ln.scale', 'stacked_xf.19.attn.out.weight', 'stacked_xf.19.attn.per_dim_scale.per_dim_scale', 'stacked_xf.19.attn.qkv_proj.weight', 'stacked_xf.19.attn.query_ln.scale', 'stacked_xf.19.ff0.weight', 'stacked_xf.19.ff1.weight', 'stacked_xf.19.post_attn_ln.scale', 'stacked_xf.19.post_ff_ln.scale', 'stacked_xf.19.pre_attn_ln.scale', 'stacked_xf.19.pre_ff_ln.scale', 'stacked_xf.2.attn.key_ln.scale', 'stacked_xf.2.attn.out.weight', 'stacked_xf.2.attn.per_dim_scale.per_dim_scale', 'stacked_xf.2.attn.qkv_proj.weight', 'stacked_xf.2.attn.query_ln.scale', 'stacked_xf.2.ff0.weight', 'stacked_xf.2.ff1.weight', 'stacked_xf.2.post_attn_ln.scale', 'stacked_xf.2.post_ff_ln.scale', 'stacked_xf.2.pre_attn_ln.scale', 'stacked_xf.2.pre_ff_ln.scale', 'stacked_xf.3.attn.key_ln.scale', 'stacked_xf.3.attn.out.weight', 'stacked_xf.3.attn.per_dim_scale.per_dim_scale', 'stacked_xf.3.attn.qkv_proj.weight', 'stacked_xf.3.attn.query_ln.scale', 'stacked_xf.3.ff0.weight', 'stacked_xf.3.ff1.weight', 'stacked_xf.3.post_attn_ln.scale', 'stacked_xf.3.post_ff_ln.scale', 'stacked_xf.3.pre_attn_ln.scale', 'stacked_xf.3.pre_ff_ln.scale', 'stacked_xf.4.attn.key_ln.scale', 'stacked_xf.4.attn.out.weight', 'stacked_xf.4.attn.per_dim_scale.per_dim_scale', 'stacked_xf.4.attn.qkv_proj.weight', 'stacked_xf.4.attn.query_ln.scale', 'stacked_xf.4.ff0.weight', 'stacked_xf.4.ff1.weight', 'stacked_xf.4.post_attn_ln.scale', 'stacked_xf.4.post_ff_ln.scale', 'stacked_xf.4.pre_attn_ln.scale', 'stacked_xf.4.pre_ff_ln.scale', 'stacked_xf.5.attn.key_ln.scale', 'stacked_xf.5.attn.out.weight', 'stacked_xf.5.attn.per_dim_scale.per_dim_scale', 'stacked_xf.5.attn.qkv_proj.weight', 'stacked_xf.5.attn.query_ln.scale', 'stacked_xf.5.ff0.weight', 'stacked_xf.5.ff1.weight', 'stacked_xf.5.post_attn_ln.scale', 'stacked_xf.5.post_ff_ln.scale', 'stacked_xf.5.pre_attn_ln.scale', 'stacked_xf.5.pre_ff_ln.scale', 'stacked_xf.6.attn.key_ln.scale', 'stacked_xf.6.attn.out.weight', 'stacked_xf.6.attn.per_dim_scale.per_dim_scale', 'stacked_xf.6.attn.qkv_proj.weight', 'stacked_xf.6.attn.query_ln.scale', 'stacked_xf.6.ff0.weight', 'stacked_xf.6.ff1.weight', 'stacked_xf.6.post_attn_ln.scale', 'stacked_xf.6.post_ff_ln.scale', 'stacked_xf.6.pre_attn_ln.scale', 'stacked_xf.6.pre_ff_ln.scale', 'stacked_xf.7.attn.key_ln.scale', 'stacked_xf.7.attn.out.weight', 'stacked_xf.7.attn.per_dim_scale.per_dim_scale', 'stacked_xf.7.attn.qkv_proj.weight', 'stacked_xf.7.attn.query_ln.scale', 'stacked_xf.7.ff0.weight', 'stacked_xf.7.ff1.weight', 'stacked_xf.7.post_attn_ln.scale', 'stacked_xf.7.post_ff_ln.scale', 'stacked_xf.7.pre_attn_ln.scale', 'stacked_xf.7.pre_ff_ln.scale', 'stacked_xf.8.attn.key_ln.scale', 'stacked_xf.8.attn.out.weight', 'stacked_xf.8.attn.per_dim_scale.per_dim_scale', 'stacked_xf.8.attn.qkv_proj.weight', 'stacked_xf.8.attn.query_ln.scale', 'stacked_xf.8.ff0.weight', 'stacked_xf.8.ff1.weight', 'stacked_xf.8.post_attn_ln.scale', 'stacked_xf.8.post_ff_ln.scale', 'stacked_xf.8.pre_attn_ln.scale', 'stacked_xf.8.pre_ff_ln.scale', 'stacked_xf.9.attn.key_ln.scale', 'stacked_xf.9.attn.out.weight', 'stacked_xf.9.attn.per_dim_scale.per_dim_scale', 'stacked_xf.9.attn.qkv_proj.weight', 'stacked_xf.9.attn.query_ln.scale', 'stacked_xf.9.ff0.weight', 'stacked_xf.9.ff1.weight', 'stacked_xf.9.post_attn_ln.scale', 'stacked_xf.9.post_ff_ln.scale', 'stacked_xf.9.pre_attn_ln.scale', 'stacked_xf.9.pre_ff_ln.scale', 'tokenizer.hidden_layer.bias', 'tokenizer.hidden_layer.weight', 'tokenizer.output_layer.bias', 'tokenizer.output_layer.weight', 'tokenizer.residual_layer.bias', 'tokenizer.residual_layer.weight']\n",
            "- This IS expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of TimesFmModelForPrediction were not initialized from the model checkpoint at google/timesfm-2.5-200m-pytorch and are newly initialized: ['decoder.freq_emb.weight', 'decoder.input_ff_layer.input_layer.bias', 'decoder.input_ff_layer.input_layer.weight', 'decoder.input_ff_layer.output_layer.bias', 'decoder.input_ff_layer.output_layer.weight', 'decoder.input_ff_layer.residual_layer.bias', 'decoder.input_ff_layer.residual_layer.weight', 'decoder.layers.0.input_layernorm.weight', 'decoder.layers.0.mlp.down_proj.bias', 'decoder.layers.0.mlp.down_proj.weight', 'decoder.layers.0.mlp.gate_proj.bias', 'decoder.layers.0.mlp.gate_proj.weight', 'decoder.layers.0.mlp.layer_norm.bias', 'decoder.layers.0.mlp.layer_norm.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.o_proj.bias', 'decoder.layers.0.self_attn.o_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.scaling', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.1.input_layernorm.weight', 'decoder.layers.1.mlp.down_proj.bias', 'decoder.layers.1.mlp.down_proj.weight', 'decoder.layers.1.mlp.gate_proj.bias', 'decoder.layers.1.mlp.gate_proj.weight', 'decoder.layers.1.mlp.layer_norm.bias', 'decoder.layers.1.mlp.layer_norm.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.o_proj.bias', 'decoder.layers.1.self_attn.o_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.scaling', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.10.input_layernorm.weight', 'decoder.layers.10.mlp.down_proj.bias', 'decoder.layers.10.mlp.down_proj.weight', 'decoder.layers.10.mlp.gate_proj.bias', 'decoder.layers.10.mlp.gate_proj.weight', 'decoder.layers.10.mlp.layer_norm.bias', 'decoder.layers.10.mlp.layer_norm.weight', 'decoder.layers.10.self_attn.k_proj.bias', 'decoder.layers.10.self_attn.k_proj.weight', 'decoder.layers.10.self_attn.o_proj.bias', 'decoder.layers.10.self_attn.o_proj.weight', 'decoder.layers.10.self_attn.q_proj.bias', 'decoder.layers.10.self_attn.q_proj.weight', 'decoder.layers.10.self_attn.scaling', 'decoder.layers.10.self_attn.v_proj.bias', 'decoder.layers.10.self_attn.v_proj.weight', 'decoder.layers.11.input_layernorm.weight', 'decoder.layers.11.mlp.down_proj.bias', 'decoder.layers.11.mlp.down_proj.weight', 'decoder.layers.11.mlp.gate_proj.bias', 'decoder.layers.11.mlp.gate_proj.weight', 'decoder.layers.11.mlp.layer_norm.bias', 'decoder.layers.11.mlp.layer_norm.weight', 'decoder.layers.11.self_attn.k_proj.bias', 'decoder.layers.11.self_attn.k_proj.weight', 'decoder.layers.11.self_attn.o_proj.bias', 'decoder.layers.11.self_attn.o_proj.weight', 'decoder.layers.11.self_attn.q_proj.bias', 'decoder.layers.11.self_attn.q_proj.weight', 'decoder.layers.11.self_attn.scaling', 'decoder.layers.11.self_attn.v_proj.bias', 'decoder.layers.11.self_attn.v_proj.weight', 'decoder.layers.12.input_layernorm.weight', 'decoder.layers.12.mlp.down_proj.bias', 'decoder.layers.12.mlp.down_proj.weight', 'decoder.layers.12.mlp.gate_proj.bias', 'decoder.layers.12.mlp.gate_proj.weight', 'decoder.layers.12.mlp.layer_norm.bias', 'decoder.layers.12.mlp.layer_norm.weight', 'decoder.layers.12.self_attn.k_proj.bias', 'decoder.layers.12.self_attn.k_proj.weight', 'decoder.layers.12.self_attn.o_proj.bias', 'decoder.layers.12.self_attn.o_proj.weight', 'decoder.layers.12.self_attn.q_proj.bias', 'decoder.layers.12.self_attn.q_proj.weight', 'decoder.layers.12.self_attn.scaling', 'decoder.layers.12.self_attn.v_proj.bias', 'decoder.layers.12.self_attn.v_proj.weight', 'decoder.layers.13.input_layernorm.weight', 'decoder.layers.13.mlp.down_proj.bias', 'decoder.layers.13.mlp.down_proj.weight', 'decoder.layers.13.mlp.gate_proj.bias', 'decoder.layers.13.mlp.gate_proj.weight', 'decoder.layers.13.mlp.layer_norm.bias', 'decoder.layers.13.mlp.layer_norm.weight', 'decoder.layers.13.self_attn.k_proj.bias', 'decoder.layers.13.self_attn.k_proj.weight', 'decoder.layers.13.self_attn.o_proj.bias', 'decoder.layers.13.self_attn.o_proj.weight', 'decoder.layers.13.self_attn.q_proj.bias', 'decoder.layers.13.self_attn.q_proj.weight', 'decoder.layers.13.self_attn.scaling', 'decoder.layers.13.self_attn.v_proj.bias', 'decoder.layers.13.self_attn.v_proj.weight', 'decoder.layers.14.input_layernorm.weight', 'decoder.layers.14.mlp.down_proj.bias', 'decoder.layers.14.mlp.down_proj.weight', 'decoder.layers.14.mlp.gate_proj.bias', 'decoder.layers.14.mlp.gate_proj.weight', 'decoder.layers.14.mlp.layer_norm.bias', 'decoder.layers.14.mlp.layer_norm.weight', 'decoder.layers.14.self_attn.k_proj.bias', 'decoder.layers.14.self_attn.k_proj.weight', 'decoder.layers.14.self_attn.o_proj.bias', 'decoder.layers.14.self_attn.o_proj.weight', 'decoder.layers.14.self_attn.q_proj.bias', 'decoder.layers.14.self_attn.q_proj.weight', 'decoder.layers.14.self_attn.scaling', 'decoder.layers.14.self_attn.v_proj.bias', 'decoder.layers.14.self_attn.v_proj.weight', 'decoder.layers.15.input_layernorm.weight', 'decoder.layers.15.mlp.down_proj.bias', 'decoder.layers.15.mlp.down_proj.weight', 'decoder.layers.15.mlp.gate_proj.bias', 'decoder.layers.15.mlp.gate_proj.weight', 'decoder.layers.15.mlp.layer_norm.bias', 'decoder.layers.15.mlp.layer_norm.weight', 'decoder.layers.15.self_attn.k_proj.bias', 'decoder.layers.15.self_attn.k_proj.weight', 'decoder.layers.15.self_attn.o_proj.bias', 'decoder.layers.15.self_attn.o_proj.weight', 'decoder.layers.15.self_attn.q_proj.bias', 'decoder.layers.15.self_attn.q_proj.weight', 'decoder.layers.15.self_attn.scaling', 'decoder.layers.15.self_attn.v_proj.bias', 'decoder.layers.15.self_attn.v_proj.weight', 'decoder.layers.16.input_layernorm.weight', 'decoder.layers.16.mlp.down_proj.bias', 'decoder.layers.16.mlp.down_proj.weight', 'decoder.layers.16.mlp.gate_proj.bias', 'decoder.layers.16.mlp.gate_proj.weight', 'decoder.layers.16.mlp.layer_norm.bias', 'decoder.layers.16.mlp.layer_norm.weight', 'decoder.layers.16.self_attn.k_proj.bias', 'decoder.layers.16.self_attn.k_proj.weight', 'decoder.layers.16.self_attn.o_proj.bias', 'decoder.layers.16.self_attn.o_proj.weight', 'decoder.layers.16.self_attn.q_proj.bias', 'decoder.layers.16.self_attn.q_proj.weight', 'decoder.layers.16.self_attn.scaling', 'decoder.layers.16.self_attn.v_proj.bias', 'decoder.layers.16.self_attn.v_proj.weight', 'decoder.layers.17.input_layernorm.weight', 'decoder.layers.17.mlp.down_proj.bias', 'decoder.layers.17.mlp.down_proj.weight', 'decoder.layers.17.mlp.gate_proj.bias', 'decoder.layers.17.mlp.gate_proj.weight', 'decoder.layers.17.mlp.layer_norm.bias', 'decoder.layers.17.mlp.layer_norm.weight', 'decoder.layers.17.self_attn.k_proj.bias', 'decoder.layers.17.self_attn.k_proj.weight', 'decoder.layers.17.self_attn.o_proj.bias', 'decoder.layers.17.self_attn.o_proj.weight', 'decoder.layers.17.self_attn.q_proj.bias', 'decoder.layers.17.self_attn.q_proj.weight', 'decoder.layers.17.self_attn.scaling', 'decoder.layers.17.self_attn.v_proj.bias', 'decoder.layers.17.self_attn.v_proj.weight', 'decoder.layers.18.input_layernorm.weight', 'decoder.layers.18.mlp.down_proj.bias', 'decoder.layers.18.mlp.down_proj.weight', 'decoder.layers.18.mlp.gate_proj.bias', 'decoder.layers.18.mlp.gate_proj.weight', 'decoder.layers.18.mlp.layer_norm.bias', 'decoder.layers.18.mlp.layer_norm.weight', 'decoder.layers.18.self_attn.k_proj.bias', 'decoder.layers.18.self_attn.k_proj.weight', 'decoder.layers.18.self_attn.o_proj.bias', 'decoder.layers.18.self_attn.o_proj.weight', 'decoder.layers.18.self_attn.q_proj.bias', 'decoder.layers.18.self_attn.q_proj.weight', 'decoder.layers.18.self_attn.scaling', 'decoder.layers.18.self_attn.v_proj.bias', 'decoder.layers.18.self_attn.v_proj.weight', 'decoder.layers.19.input_layernorm.weight', 'decoder.layers.19.mlp.down_proj.bias', 'decoder.layers.19.mlp.down_proj.weight', 'decoder.layers.19.mlp.gate_proj.bias', 'decoder.layers.19.mlp.gate_proj.weight', 'decoder.layers.19.mlp.layer_norm.bias', 'decoder.layers.19.mlp.layer_norm.weight', 'decoder.layers.19.self_attn.k_proj.bias', 'decoder.layers.19.self_attn.k_proj.weight', 'decoder.layers.19.self_attn.o_proj.bias', 'decoder.layers.19.self_attn.o_proj.weight', 'decoder.layers.19.self_attn.q_proj.bias', 'decoder.layers.19.self_attn.q_proj.weight', 'decoder.layers.19.self_attn.scaling', 'decoder.layers.19.self_attn.v_proj.bias', 'decoder.layers.19.self_attn.v_proj.weight', 'decoder.layers.2.input_layernorm.weight', 'decoder.layers.2.mlp.down_proj.bias', 'decoder.layers.2.mlp.down_proj.weight', 'decoder.layers.2.mlp.gate_proj.bias', 'decoder.layers.2.mlp.gate_proj.weight', 'decoder.layers.2.mlp.layer_norm.bias', 'decoder.layers.2.mlp.layer_norm.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.o_proj.bias', 'decoder.layers.2.self_attn.o_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.scaling', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.3.input_layernorm.weight', 'decoder.layers.3.mlp.down_proj.bias', 'decoder.layers.3.mlp.down_proj.weight', 'decoder.layers.3.mlp.gate_proj.bias', 'decoder.layers.3.mlp.gate_proj.weight', 'decoder.layers.3.mlp.layer_norm.bias', 'decoder.layers.3.mlp.layer_norm.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.o_proj.bias', 'decoder.layers.3.self_attn.o_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.scaling', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.4.input_layernorm.weight', 'decoder.layers.4.mlp.down_proj.bias', 'decoder.layers.4.mlp.down_proj.weight', 'decoder.layers.4.mlp.gate_proj.bias', 'decoder.layers.4.mlp.gate_proj.weight', 'decoder.layers.4.mlp.layer_norm.bias', 'decoder.layers.4.mlp.layer_norm.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.o_proj.bias', 'decoder.layers.4.self_attn.o_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.scaling', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.5.input_layernorm.weight', 'decoder.layers.5.mlp.down_proj.bias', 'decoder.layers.5.mlp.down_proj.weight', 'decoder.layers.5.mlp.gate_proj.bias', 'decoder.layers.5.mlp.gate_proj.weight', 'decoder.layers.5.mlp.layer_norm.bias', 'decoder.layers.5.mlp.layer_norm.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.o_proj.bias', 'decoder.layers.5.self_attn.o_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.scaling', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.6.input_layernorm.weight', 'decoder.layers.6.mlp.down_proj.bias', 'decoder.layers.6.mlp.down_proj.weight', 'decoder.layers.6.mlp.gate_proj.bias', 'decoder.layers.6.mlp.gate_proj.weight', 'decoder.layers.6.mlp.layer_norm.bias', 'decoder.layers.6.mlp.layer_norm.weight', 'decoder.layers.6.self_attn.k_proj.bias', 'decoder.layers.6.self_attn.k_proj.weight', 'decoder.layers.6.self_attn.o_proj.bias', 'decoder.layers.6.self_attn.o_proj.weight', 'decoder.layers.6.self_attn.q_proj.bias', 'decoder.layers.6.self_attn.q_proj.weight', 'decoder.layers.6.self_attn.scaling', 'decoder.layers.6.self_attn.v_proj.bias', 'decoder.layers.6.self_attn.v_proj.weight', 'decoder.layers.7.input_layernorm.weight', 'decoder.layers.7.mlp.down_proj.bias', 'decoder.layers.7.mlp.down_proj.weight', 'decoder.layers.7.mlp.gate_proj.bias', 'decoder.layers.7.mlp.gate_proj.weight', 'decoder.layers.7.mlp.layer_norm.bias', 'decoder.layers.7.mlp.layer_norm.weight', 'decoder.layers.7.self_attn.k_proj.bias', 'decoder.layers.7.self_attn.k_proj.weight', 'decoder.layers.7.self_attn.o_proj.bias', 'decoder.layers.7.self_attn.o_proj.weight', 'decoder.layers.7.self_attn.q_proj.bias', 'decoder.layers.7.self_attn.q_proj.weight', 'decoder.layers.7.self_attn.scaling', 'decoder.layers.7.self_attn.v_proj.bias', 'decoder.layers.7.self_attn.v_proj.weight', 'decoder.layers.8.input_layernorm.weight', 'decoder.layers.8.mlp.down_proj.bias', 'decoder.layers.8.mlp.down_proj.weight', 'decoder.layers.8.mlp.gate_proj.bias', 'decoder.layers.8.mlp.gate_proj.weight', 'decoder.layers.8.mlp.layer_norm.bias', 'decoder.layers.8.mlp.layer_norm.weight', 'decoder.layers.8.self_attn.k_proj.bias', 'decoder.layers.8.self_attn.k_proj.weight', 'decoder.layers.8.self_attn.o_proj.bias', 'decoder.layers.8.self_attn.o_proj.weight', 'decoder.layers.8.self_attn.q_proj.bias', 'decoder.layers.8.self_attn.q_proj.weight', 'decoder.layers.8.self_attn.scaling', 'decoder.layers.8.self_attn.v_proj.bias', 'decoder.layers.8.self_attn.v_proj.weight', 'decoder.layers.9.input_layernorm.weight', 'decoder.layers.9.mlp.down_proj.bias', 'decoder.layers.9.mlp.down_proj.weight', 'decoder.layers.9.mlp.gate_proj.bias', 'decoder.layers.9.mlp.gate_proj.weight', 'decoder.layers.9.mlp.layer_norm.bias', 'decoder.layers.9.mlp.layer_norm.weight', 'decoder.layers.9.self_attn.k_proj.bias', 'decoder.layers.9.self_attn.k_proj.weight', 'decoder.layers.9.self_attn.o_proj.bias', 'decoder.layers.9.self_attn.o_proj.weight', 'decoder.layers.9.self_attn.q_proj.bias', 'decoder.layers.9.self_attn.q_proj.weight', 'decoder.layers.9.self_attn.scaling', 'decoder.layers.9.self_attn.v_proj.bias', 'decoder.layers.9.self_attn.v_proj.weight', 'horizon_ff_layer.input_layer.bias', 'horizon_ff_layer.input_layer.weight', 'horizon_ff_layer.output_layer.bias', 'horizon_ff_layer.output_layer.weight', 'horizon_ff_layer.residual_layer.bias', 'horizon_ff_layer.residual_layer.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n",
            "  Epoch 1/100 train_loss=1.7310 train_acc=0.4154 eval_loss=1.1530 eval_acc=0.6205 (best)\n",
            "  Epoch 2/100 train_loss=0.6082 train_acc=0.8308 eval_loss=0.7081 eval_acc=0.7667 (best)\n",
            "  Epoch 3/100 train_loss=0.2308 train_acc=0.9487 eval_loss=0.5930 eval_acc=0.7974 (best)\n",
            "  Epoch 4/100 train_loss=0.1180 train_acc=0.9641 eval_loss=0.8897 eval_acc=0.7513 \n",
            "  Epoch 5/100 train_loss=0.0569 train_acc=0.9872 eval_loss=0.9968 eval_acc=0.7154 \n",
            "  Epoch 6/100 train_loss=0.1360 train_acc=0.9564 eval_loss=1.0046 eval_acc=0.7103 \n",
            "  Epoch 7/100 train_loss=0.0885 train_acc=0.9718 eval_loss=0.9248 eval_acc=0.7436 \n",
            "  Epoch 8/100 train_loss=0.0817 train_acc=0.9744 eval_loss=1.4956 eval_acc=0.7103 \n",
            "  Epoch 9/100 train_loss=0.2596 train_acc=0.9256 eval_loss=0.9441 eval_acc=0.7667 \n",
            "  Epoch 10/100 train_loss=0.1348 train_acc=0.9590 eval_loss=1.5273 eval_acc=0.6923 \n",
            "  Epoch 11/100 train_loss=0.0857 train_acc=0.9667 eval_loss=1.2115 eval_acc=0.7897 \n",
            "  Epoch 12/100 train_loss=0.0805 train_acc=0.9744 eval_loss=1.6557 eval_acc=0.7103 \n",
            "  Epoch 13/100 train_loss=0.0723 train_acc=0.9769 eval_loss=1.3390 eval_acc=0.7564 \n",
            "  Early stopping on google/timesfm-2.5-200m-pytorch: no improvement for 10 epochs (best epoch = 3)\n",
            "    tfm[google/timesfm-2.5-200m-pytorch] train_acc=0.9487 eval_acc=0.75641025641025638748260462307371199131011963\n",
            "    mrh_acc=0.8205 mr+h+kg_acc=0.8410 kg_acc=0.8436 ensemble=0.8385 (w=0.60)\n",
            "  Split 1/1 - accuracy=0.8385 time=333.2s\n",
            "Completed CricketY: Mean Acc=0.8385\n",
            "\n",
            "=== 17/109 CricketZ ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n",
            "    Gate split 1/5: baseline_loss=0.4566 adaptive_loss=0.4789\n",
            "    Gate split 2/5: baseline_loss=0.4725 adaptive_loss=0.4936\n",
            "    Gate split 3/5: baseline_loss=0.5746 adaptive_loss=0.5778\n",
            "    Gate split 4/5: baseline_loss=0.4915 adaptive_loss=0.5147\n",
            "    Gate split 5/5: baseline_loss=0.5379 adaptive_loss=0.5616\n",
            "  Decision: Adaptive kept (loss 0.5253 vs baseline 0.5067, delta=+0.0187 <= +0.0200); savgol(window=11, poly=2) - high noise (std_diff)\n",
            "\n",
            "=== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at google/timesfm-2.5-200m-pytorch were not used when initializing TimesFmModelForPrediction: ['output_projection_point.hidden_layer.weight', 'output_projection_point.output_layer.weight', 'output_projection_point.residual_layer.weight', 'output_projection_quantiles.hidden_layer.weight', 'output_projection_quantiles.output_layer.weight', 'output_projection_quantiles.residual_layer.weight', 'stacked_xf.0.attn.key_ln.scale', 'stacked_xf.0.attn.out.weight', 'stacked_xf.0.attn.per_dim_scale.per_dim_scale', 'stacked_xf.0.attn.qkv_proj.weight', 'stacked_xf.0.attn.query_ln.scale', 'stacked_xf.0.ff0.weight', 'stacked_xf.0.ff1.weight', 'stacked_xf.0.post_attn_ln.scale', 'stacked_xf.0.post_ff_ln.scale', 'stacked_xf.0.pre_attn_ln.scale', 'stacked_xf.0.pre_ff_ln.scale', 'stacked_xf.1.attn.key_ln.scale', 'stacked_xf.1.attn.out.weight', 'stacked_xf.1.attn.per_dim_scale.per_dim_scale', 'stacked_xf.1.attn.qkv_proj.weight', 'stacked_xf.1.attn.query_ln.scale', 'stacked_xf.1.ff0.weight', 'stacked_xf.1.ff1.weight', 'stacked_xf.1.post_attn_ln.scale', 'stacked_xf.1.post_ff_ln.scale', 'stacked_xf.1.pre_attn_ln.scale', 'stacked_xf.1.pre_ff_ln.scale', 'stacked_xf.10.attn.key_ln.scale', 'stacked_xf.10.attn.out.weight', 'stacked_xf.10.attn.per_dim_scale.per_dim_scale', 'stacked_xf.10.attn.qkv_proj.weight', 'stacked_xf.10.attn.query_ln.scale', 'stacked_xf.10.ff0.weight', 'stacked_xf.10.ff1.weight', 'stacked_xf.10.post_attn_ln.scale', 'stacked_xf.10.post_ff_ln.scale', 'stacked_xf.10.pre_attn_ln.scale', 'stacked_xf.10.pre_ff_ln.scale', 'stacked_xf.11.attn.key_ln.scale', 'stacked_xf.11.attn.out.weight', 'stacked_xf.11.attn.per_dim_scale.per_dim_scale', 'stacked_xf.11.attn.qkv_proj.weight', 'stacked_xf.11.attn.query_ln.scale', 'stacked_xf.11.ff0.weight', 'stacked_xf.11.ff1.weight', 'stacked_xf.11.post_attn_ln.scale', 'stacked_xf.11.post_ff_ln.scale', 'stacked_xf.11.pre_attn_ln.scale', 'stacked_xf.11.pre_ff_ln.scale', 'stacked_xf.12.attn.key_ln.scale', 'stacked_xf.12.attn.out.weight', 'stacked_xf.12.attn.per_dim_scale.per_dim_scale', 'stacked_xf.12.attn.qkv_proj.weight', 'stacked_xf.12.attn.query_ln.scale', 'stacked_xf.12.ff0.weight', 'stacked_xf.12.ff1.weight', 'stacked_xf.12.post_attn_ln.scale', 'stacked_xf.12.post_ff_ln.scale', 'stacked_xf.12.pre_attn_ln.scale', 'stacked_xf.12.pre_ff_ln.scale', 'stacked_xf.13.attn.key_ln.scale', 'stacked_xf.13.attn.out.weight', 'stacked_xf.13.attn.per_dim_scale.per_dim_scale', 'stacked_xf.13.attn.qkv_proj.weight', 'stacked_xf.13.attn.query_ln.scale', 'stacked_xf.13.ff0.weight', 'stacked_xf.13.ff1.weight', 'stacked_xf.13.post_attn_ln.scale', 'stacked_xf.13.post_ff_ln.scale', 'stacked_xf.13.pre_attn_ln.scale', 'stacked_xf.13.pre_ff_ln.scale', 'stacked_xf.14.attn.key_ln.scale', 'stacked_xf.14.attn.out.weight', 'stacked_xf.14.attn.per_dim_scale.per_dim_scale', 'stacked_xf.14.attn.qkv_proj.weight', 'stacked_xf.14.attn.query_ln.scale', 'stacked_xf.14.ff0.weight', 'stacked_xf.14.ff1.weight', 'stacked_xf.14.post_attn_ln.scale', 'stacked_xf.14.post_ff_ln.scale', 'stacked_xf.14.pre_attn_ln.scale', 'stacked_xf.14.pre_ff_ln.scale', 'stacked_xf.15.attn.key_ln.scale', 'stacked_xf.15.attn.out.weight', 'stacked_xf.15.attn.per_dim_scale.per_dim_scale', 'stacked_xf.15.attn.qkv_proj.weight', 'stacked_xf.15.attn.query_ln.scale', 'stacked_xf.15.ff0.weight', 'stacked_xf.15.ff1.weight', 'stacked_xf.15.post_attn_ln.scale', 'stacked_xf.15.post_ff_ln.scale', 'stacked_xf.15.pre_attn_ln.scale', 'stacked_xf.15.pre_ff_ln.scale', 'stacked_xf.16.attn.key_ln.scale', 'stacked_xf.16.attn.out.weight', 'stacked_xf.16.attn.per_dim_scale.per_dim_scale', 'stacked_xf.16.attn.qkv_proj.weight', 'stacked_xf.16.attn.query_ln.scale', 'stacked_xf.16.ff0.weight', 'stacked_xf.16.ff1.weight', 'stacked_xf.16.post_attn_ln.scale', 'stacked_xf.16.post_ff_ln.scale', 'stacked_xf.16.pre_attn_ln.scale', 'stacked_xf.16.pre_ff_ln.scale', 'stacked_xf.17.attn.key_ln.scale', 'stacked_xf.17.attn.out.weight', 'stacked_xf.17.attn.per_dim_scale.per_dim_scale', 'stacked_xf.17.attn.qkv_proj.weight', 'stacked_xf.17.attn.query_ln.scale', 'stacked_xf.17.ff0.weight', 'stacked_xf.17.ff1.weight', 'stacked_xf.17.post_attn_ln.scale', 'stacked_xf.17.post_ff_ln.scale', 'stacked_xf.17.pre_attn_ln.scale', 'stacked_xf.17.pre_ff_ln.scale', 'stacked_xf.18.attn.key_ln.scale', 'stacked_xf.18.attn.out.weight', 'stacked_xf.18.attn.per_dim_scale.per_dim_scale', 'stacked_xf.18.attn.qkv_proj.weight', 'stacked_xf.18.attn.query_ln.scale', 'stacked_xf.18.ff0.weight', 'stacked_xf.18.ff1.weight', 'stacked_xf.18.post_attn_ln.scale', 'stacked_xf.18.post_ff_ln.scale', 'stacked_xf.18.pre_attn_ln.scale', 'stacked_xf.18.pre_ff_ln.scale', 'stacked_xf.19.attn.key_ln.scale', 'stacked_xf.19.attn.out.weight', 'stacked_xf.19.attn.per_dim_scale.per_dim_scale', 'stacked_xf.19.attn.qkv_proj.weight', 'stacked_xf.19.attn.query_ln.scale', 'stacked_xf.19.ff0.weight', 'stacked_xf.19.ff1.weight', 'stacked_xf.19.post_attn_ln.scale', 'stacked_xf.19.post_ff_ln.scale', 'stacked_xf.19.pre_attn_ln.scale', 'stacked_xf.19.pre_ff_ln.scale', 'stacked_xf.2.attn.key_ln.scale', 'stacked_xf.2.attn.out.weight', 'stacked_xf.2.attn.per_dim_scale.per_dim_scale', 'stacked_xf.2.attn.qkv_proj.weight', 'stacked_xf.2.attn.query_ln.scale', 'stacked_xf.2.ff0.weight', 'stacked_xf.2.ff1.weight', 'stacked_xf.2.post_attn_ln.scale', 'stacked_xf.2.post_ff_ln.scale', 'stacked_xf.2.pre_attn_ln.scale', 'stacked_xf.2.pre_ff_ln.scale', 'stacked_xf.3.attn.key_ln.scale', 'stacked_xf.3.attn.out.weight', 'stacked_xf.3.attn.per_dim_scale.per_dim_scale', 'stacked_xf.3.attn.qkv_proj.weight', 'stacked_xf.3.attn.query_ln.scale', 'stacked_xf.3.ff0.weight', 'stacked_xf.3.ff1.weight', 'stacked_xf.3.post_attn_ln.scale', 'stacked_xf.3.post_ff_ln.scale', 'stacked_xf.3.pre_attn_ln.scale', 'stacked_xf.3.pre_ff_ln.scale', 'stacked_xf.4.attn.key_ln.scale', 'stacked_xf.4.attn.out.weight', 'stacked_xf.4.attn.per_dim_scale.per_dim_scale', 'stacked_xf.4.attn.qkv_proj.weight', 'stacked_xf.4.attn.query_ln.scale', 'stacked_xf.4.ff0.weight', 'stacked_xf.4.ff1.weight', 'stacked_xf.4.post_attn_ln.scale', 'stacked_xf.4.post_ff_ln.scale', 'stacked_xf.4.pre_attn_ln.scale', 'stacked_xf.4.pre_ff_ln.scale', 'stacked_xf.5.attn.key_ln.scale', 'stacked_xf.5.attn.out.weight', 'stacked_xf.5.attn.per_dim_scale.per_dim_scale', 'stacked_xf.5.attn.qkv_proj.weight', 'stacked_xf.5.attn.query_ln.scale', 'stacked_xf.5.ff0.weight', 'stacked_xf.5.ff1.weight', 'stacked_xf.5.post_attn_ln.scale', 'stacked_xf.5.post_ff_ln.scale', 'stacked_xf.5.pre_attn_ln.scale', 'stacked_xf.5.pre_ff_ln.scale', 'stacked_xf.6.attn.key_ln.scale', 'stacked_xf.6.attn.out.weight', 'stacked_xf.6.attn.per_dim_scale.per_dim_scale', 'stacked_xf.6.attn.qkv_proj.weight', 'stacked_xf.6.attn.query_ln.scale', 'stacked_xf.6.ff0.weight', 'stacked_xf.6.ff1.weight', 'stacked_xf.6.post_attn_ln.scale', 'stacked_xf.6.post_ff_ln.scale', 'stacked_xf.6.pre_attn_ln.scale', 'stacked_xf.6.pre_ff_ln.scale', 'stacked_xf.7.attn.key_ln.scale', 'stacked_xf.7.attn.out.weight', 'stacked_xf.7.attn.per_dim_scale.per_dim_scale', 'stacked_xf.7.attn.qkv_proj.weight', 'stacked_xf.7.attn.query_ln.scale', 'stacked_xf.7.ff0.weight', 'stacked_xf.7.ff1.weight', 'stacked_xf.7.post_attn_ln.scale', 'stacked_xf.7.post_ff_ln.scale', 'stacked_xf.7.pre_attn_ln.scale', 'stacked_xf.7.pre_ff_ln.scale', 'stacked_xf.8.attn.key_ln.scale', 'stacked_xf.8.attn.out.weight', 'stacked_xf.8.attn.per_dim_scale.per_dim_scale', 'stacked_xf.8.attn.qkv_proj.weight', 'stacked_xf.8.attn.query_ln.scale', 'stacked_xf.8.ff0.weight', 'stacked_xf.8.ff1.weight', 'stacked_xf.8.post_attn_ln.scale', 'stacked_xf.8.post_ff_ln.scale', 'stacked_xf.8.pre_attn_ln.scale', 'stacked_xf.8.pre_ff_ln.scale', 'stacked_xf.9.attn.key_ln.scale', 'stacked_xf.9.attn.out.weight', 'stacked_xf.9.attn.per_dim_scale.per_dim_scale', 'stacked_xf.9.attn.qkv_proj.weight', 'stacked_xf.9.attn.query_ln.scale', 'stacked_xf.9.ff0.weight', 'stacked_xf.9.ff1.weight', 'stacked_xf.9.post_attn_ln.scale', 'stacked_xf.9.post_ff_ln.scale', 'stacked_xf.9.pre_attn_ln.scale', 'stacked_xf.9.pre_ff_ln.scale', 'tokenizer.hidden_layer.bias', 'tokenizer.hidden_layer.weight', 'tokenizer.output_layer.bias', 'tokenizer.output_layer.weight', 'tokenizer.residual_layer.bias', 'tokenizer.residual_layer.weight']\n",
            "- This IS expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of TimesFmModelForPrediction were not initialized from the model checkpoint at google/timesfm-2.5-200m-pytorch and are newly initialized: ['decoder.freq_emb.weight', 'decoder.input_ff_layer.input_layer.bias', 'decoder.input_ff_layer.input_layer.weight', 'decoder.input_ff_layer.output_layer.bias', 'decoder.input_ff_layer.output_layer.weight', 'decoder.input_ff_layer.residual_layer.bias', 'decoder.input_ff_layer.residual_layer.weight', 'decoder.layers.0.input_layernorm.weight', 'decoder.layers.0.mlp.down_proj.bias', 'decoder.layers.0.mlp.down_proj.weight', 'decoder.layers.0.mlp.gate_proj.bias', 'decoder.layers.0.mlp.gate_proj.weight', 'decoder.layers.0.mlp.layer_norm.bias', 'decoder.layers.0.mlp.layer_norm.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.o_proj.bias', 'decoder.layers.0.self_attn.o_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.scaling', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.1.input_layernorm.weight', 'decoder.layers.1.mlp.down_proj.bias', 'decoder.layers.1.mlp.down_proj.weight', 'decoder.layers.1.mlp.gate_proj.bias', 'decoder.layers.1.mlp.gate_proj.weight', 'decoder.layers.1.mlp.layer_norm.bias', 'decoder.layers.1.mlp.layer_norm.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.o_proj.bias', 'decoder.layers.1.self_attn.o_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.scaling', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.10.input_layernorm.weight', 'decoder.layers.10.mlp.down_proj.bias', 'decoder.layers.10.mlp.down_proj.weight', 'decoder.layers.10.mlp.gate_proj.bias', 'decoder.layers.10.mlp.gate_proj.weight', 'decoder.layers.10.mlp.layer_norm.bias', 'decoder.layers.10.mlp.layer_norm.weight', 'decoder.layers.10.self_attn.k_proj.bias', 'decoder.layers.10.self_attn.k_proj.weight', 'decoder.layers.10.self_attn.o_proj.bias', 'decoder.layers.10.self_attn.o_proj.weight', 'decoder.layers.10.self_attn.q_proj.bias', 'decoder.layers.10.self_attn.q_proj.weight', 'decoder.layers.10.self_attn.scaling', 'decoder.layers.10.self_attn.v_proj.bias', 'decoder.layers.10.self_attn.v_proj.weight', 'decoder.layers.11.input_layernorm.weight', 'decoder.layers.11.mlp.down_proj.bias', 'decoder.layers.11.mlp.down_proj.weight', 'decoder.layers.11.mlp.gate_proj.bias', 'decoder.layers.11.mlp.gate_proj.weight', 'decoder.layers.11.mlp.layer_norm.bias', 'decoder.layers.11.mlp.layer_norm.weight', 'decoder.layers.11.self_attn.k_proj.bias', 'decoder.layers.11.self_attn.k_proj.weight', 'decoder.layers.11.self_attn.o_proj.bias', 'decoder.layers.11.self_attn.o_proj.weight', 'decoder.layers.11.self_attn.q_proj.bias', 'decoder.layers.11.self_attn.q_proj.weight', 'decoder.layers.11.self_attn.scaling', 'decoder.layers.11.self_attn.v_proj.bias', 'decoder.layers.11.self_attn.v_proj.weight', 'decoder.layers.12.input_layernorm.weight', 'decoder.layers.12.mlp.down_proj.bias', 'decoder.layers.12.mlp.down_proj.weight', 'decoder.layers.12.mlp.gate_proj.bias', 'decoder.layers.12.mlp.gate_proj.weight', 'decoder.layers.12.mlp.layer_norm.bias', 'decoder.layers.12.mlp.layer_norm.weight', 'decoder.layers.12.self_attn.k_proj.bias', 'decoder.layers.12.self_attn.k_proj.weight', 'decoder.layers.12.self_attn.o_proj.bias', 'decoder.layers.12.self_attn.o_proj.weight', 'decoder.layers.12.self_attn.q_proj.bias', 'decoder.layers.12.self_attn.q_proj.weight', 'decoder.layers.12.self_attn.scaling', 'decoder.layers.12.self_attn.v_proj.bias', 'decoder.layers.12.self_attn.v_proj.weight', 'decoder.layers.13.input_layernorm.weight', 'decoder.layers.13.mlp.down_proj.bias', 'decoder.layers.13.mlp.down_proj.weight', 'decoder.layers.13.mlp.gate_proj.bias', 'decoder.layers.13.mlp.gate_proj.weight', 'decoder.layers.13.mlp.layer_norm.bias', 'decoder.layers.13.mlp.layer_norm.weight', 'decoder.layers.13.self_attn.k_proj.bias', 'decoder.layers.13.self_attn.k_proj.weight', 'decoder.layers.13.self_attn.o_proj.bias', 'decoder.layers.13.self_attn.o_proj.weight', 'decoder.layers.13.self_attn.q_proj.bias', 'decoder.layers.13.self_attn.q_proj.weight', 'decoder.layers.13.self_attn.scaling', 'decoder.layers.13.self_attn.v_proj.bias', 'decoder.layers.13.self_attn.v_proj.weight', 'decoder.layers.14.input_layernorm.weight', 'decoder.layers.14.mlp.down_proj.bias', 'decoder.layers.14.mlp.down_proj.weight', 'decoder.layers.14.mlp.gate_proj.bias', 'decoder.layers.14.mlp.gate_proj.weight', 'decoder.layers.14.mlp.layer_norm.bias', 'decoder.layers.14.mlp.layer_norm.weight', 'decoder.layers.14.self_attn.k_proj.bias', 'decoder.layers.14.self_attn.k_proj.weight', 'decoder.layers.14.self_attn.o_proj.bias', 'decoder.layers.14.self_attn.o_proj.weight', 'decoder.layers.14.self_attn.q_proj.bias', 'decoder.layers.14.self_attn.q_proj.weight', 'decoder.layers.14.self_attn.scaling', 'decoder.layers.14.self_attn.v_proj.bias', 'decoder.layers.14.self_attn.v_proj.weight', 'decoder.layers.15.input_layernorm.weight', 'decoder.layers.15.mlp.down_proj.bias', 'decoder.layers.15.mlp.down_proj.weight', 'decoder.layers.15.mlp.gate_proj.bias', 'decoder.layers.15.mlp.gate_proj.weight', 'decoder.layers.15.mlp.layer_norm.bias', 'decoder.layers.15.mlp.layer_norm.weight', 'decoder.layers.15.self_attn.k_proj.bias', 'decoder.layers.15.self_attn.k_proj.weight', 'decoder.layers.15.self_attn.o_proj.bias', 'decoder.layers.15.self_attn.o_proj.weight', 'decoder.layers.15.self_attn.q_proj.bias', 'decoder.layers.15.self_attn.q_proj.weight', 'decoder.layers.15.self_attn.scaling', 'decoder.layers.15.self_attn.v_proj.bias', 'decoder.layers.15.self_attn.v_proj.weight', 'decoder.layers.16.input_layernorm.weight', 'decoder.layers.16.mlp.down_proj.bias', 'decoder.layers.16.mlp.down_proj.weight', 'decoder.layers.16.mlp.gate_proj.bias', 'decoder.layers.16.mlp.gate_proj.weight', 'decoder.layers.16.mlp.layer_norm.bias', 'decoder.layers.16.mlp.layer_norm.weight', 'decoder.layers.16.self_attn.k_proj.bias', 'decoder.layers.16.self_attn.k_proj.weight', 'decoder.layers.16.self_attn.o_proj.bias', 'decoder.layers.16.self_attn.o_proj.weight', 'decoder.layers.16.self_attn.q_proj.bias', 'decoder.layers.16.self_attn.q_proj.weight', 'decoder.layers.16.self_attn.scaling', 'decoder.layers.16.self_attn.v_proj.bias', 'decoder.layers.16.self_attn.v_proj.weight', 'decoder.layers.17.input_layernorm.weight', 'decoder.layers.17.mlp.down_proj.bias', 'decoder.layers.17.mlp.down_proj.weight', 'decoder.layers.17.mlp.gate_proj.bias', 'decoder.layers.17.mlp.gate_proj.weight', 'decoder.layers.17.mlp.layer_norm.bias', 'decoder.layers.17.mlp.layer_norm.weight', 'decoder.layers.17.self_attn.k_proj.bias', 'decoder.layers.17.self_attn.k_proj.weight', 'decoder.layers.17.self_attn.o_proj.bias', 'decoder.layers.17.self_attn.o_proj.weight', 'decoder.layers.17.self_attn.q_proj.bias', 'decoder.layers.17.self_attn.q_proj.weight', 'decoder.layers.17.self_attn.scaling', 'decoder.layers.17.self_attn.v_proj.bias', 'decoder.layers.17.self_attn.v_proj.weight', 'decoder.layers.18.input_layernorm.weight', 'decoder.layers.18.mlp.down_proj.bias', 'decoder.layers.18.mlp.down_proj.weight', 'decoder.layers.18.mlp.gate_proj.bias', 'decoder.layers.18.mlp.gate_proj.weight', 'decoder.layers.18.mlp.layer_norm.bias', 'decoder.layers.18.mlp.layer_norm.weight', 'decoder.layers.18.self_attn.k_proj.bias', 'decoder.layers.18.self_attn.k_proj.weight', 'decoder.layers.18.self_attn.o_proj.bias', 'decoder.layers.18.self_attn.o_proj.weight', 'decoder.layers.18.self_attn.q_proj.bias', 'decoder.layers.18.self_attn.q_proj.weight', 'decoder.layers.18.self_attn.scaling', 'decoder.layers.18.self_attn.v_proj.bias', 'decoder.layers.18.self_attn.v_proj.weight', 'decoder.layers.19.input_layernorm.weight', 'decoder.layers.19.mlp.down_proj.bias', 'decoder.layers.19.mlp.down_proj.weight', 'decoder.layers.19.mlp.gate_proj.bias', 'decoder.layers.19.mlp.gate_proj.weight', 'decoder.layers.19.mlp.layer_norm.bias', 'decoder.layers.19.mlp.layer_norm.weight', 'decoder.layers.19.self_attn.k_proj.bias', 'decoder.layers.19.self_attn.k_proj.weight', 'decoder.layers.19.self_attn.o_proj.bias', 'decoder.layers.19.self_attn.o_proj.weight', 'decoder.layers.19.self_attn.q_proj.bias', 'decoder.layers.19.self_attn.q_proj.weight', 'decoder.layers.19.self_attn.scaling', 'decoder.layers.19.self_attn.v_proj.bias', 'decoder.layers.19.self_attn.v_proj.weight', 'decoder.layers.2.input_layernorm.weight', 'decoder.layers.2.mlp.down_proj.bias', 'decoder.layers.2.mlp.down_proj.weight', 'decoder.layers.2.mlp.gate_proj.bias', 'decoder.layers.2.mlp.gate_proj.weight', 'decoder.layers.2.mlp.layer_norm.bias', 'decoder.layers.2.mlp.layer_norm.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.o_proj.bias', 'decoder.layers.2.self_attn.o_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.scaling', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.3.input_layernorm.weight', 'decoder.layers.3.mlp.down_proj.bias', 'decoder.layers.3.mlp.down_proj.weight', 'decoder.layers.3.mlp.gate_proj.bias', 'decoder.layers.3.mlp.gate_proj.weight', 'decoder.layers.3.mlp.layer_norm.bias', 'decoder.layers.3.mlp.layer_norm.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.o_proj.bias', 'decoder.layers.3.self_attn.o_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.scaling', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.4.input_layernorm.weight', 'decoder.layers.4.mlp.down_proj.bias', 'decoder.layers.4.mlp.down_proj.weight', 'decoder.layers.4.mlp.gate_proj.bias', 'decoder.layers.4.mlp.gate_proj.weight', 'decoder.layers.4.mlp.layer_norm.bias', 'decoder.layers.4.mlp.layer_norm.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.o_proj.bias', 'decoder.layers.4.self_attn.o_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.scaling', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.5.input_layernorm.weight', 'decoder.layers.5.mlp.down_proj.bias', 'decoder.layers.5.mlp.down_proj.weight', 'decoder.layers.5.mlp.gate_proj.bias', 'decoder.layers.5.mlp.gate_proj.weight', 'decoder.layers.5.mlp.layer_norm.bias', 'decoder.layers.5.mlp.layer_norm.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.o_proj.bias', 'decoder.layers.5.self_attn.o_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.scaling', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.6.input_layernorm.weight', 'decoder.layers.6.mlp.down_proj.bias', 'decoder.layers.6.mlp.down_proj.weight', 'decoder.layers.6.mlp.gate_proj.bias', 'decoder.layers.6.mlp.gate_proj.weight', 'decoder.layers.6.mlp.layer_norm.bias', 'decoder.layers.6.mlp.layer_norm.weight', 'decoder.layers.6.self_attn.k_proj.bias', 'decoder.layers.6.self_attn.k_proj.weight', 'decoder.layers.6.self_attn.o_proj.bias', 'decoder.layers.6.self_attn.o_proj.weight', 'decoder.layers.6.self_attn.q_proj.bias', 'decoder.layers.6.self_attn.q_proj.weight', 'decoder.layers.6.self_attn.scaling', 'decoder.layers.6.self_attn.v_proj.bias', 'decoder.layers.6.self_attn.v_proj.weight', 'decoder.layers.7.input_layernorm.weight', 'decoder.layers.7.mlp.down_proj.bias', 'decoder.layers.7.mlp.down_proj.weight', 'decoder.layers.7.mlp.gate_proj.bias', 'decoder.layers.7.mlp.gate_proj.weight', 'decoder.layers.7.mlp.layer_norm.bias', 'decoder.layers.7.mlp.layer_norm.weight', 'decoder.layers.7.self_attn.k_proj.bias', 'decoder.layers.7.self_attn.k_proj.weight', 'decoder.layers.7.self_attn.o_proj.bias', 'decoder.layers.7.self_attn.o_proj.weight', 'decoder.layers.7.self_attn.q_proj.bias', 'decoder.layers.7.self_attn.q_proj.weight', 'decoder.layers.7.self_attn.scaling', 'decoder.layers.7.self_attn.v_proj.bias', 'decoder.layers.7.self_attn.v_proj.weight', 'decoder.layers.8.input_layernorm.weight', 'decoder.layers.8.mlp.down_proj.bias', 'decoder.layers.8.mlp.down_proj.weight', 'decoder.layers.8.mlp.gate_proj.bias', 'decoder.layers.8.mlp.gate_proj.weight', 'decoder.layers.8.mlp.layer_norm.bias', 'decoder.layers.8.mlp.layer_norm.weight', 'decoder.layers.8.self_attn.k_proj.bias', 'decoder.layers.8.self_attn.k_proj.weight', 'decoder.layers.8.self_attn.o_proj.bias', 'decoder.layers.8.self_attn.o_proj.weight', 'decoder.layers.8.self_attn.q_proj.bias', 'decoder.layers.8.self_attn.q_proj.weight', 'decoder.layers.8.self_attn.scaling', 'decoder.layers.8.self_attn.v_proj.bias', 'decoder.layers.8.self_attn.v_proj.weight', 'decoder.layers.9.input_layernorm.weight', 'decoder.layers.9.mlp.down_proj.bias', 'decoder.layers.9.mlp.down_proj.weight', 'decoder.layers.9.mlp.gate_proj.bias', 'decoder.layers.9.mlp.gate_proj.weight', 'decoder.layers.9.mlp.layer_norm.bias', 'decoder.layers.9.mlp.layer_norm.weight', 'decoder.layers.9.self_attn.k_proj.bias', 'decoder.layers.9.self_attn.k_proj.weight', 'decoder.layers.9.self_attn.o_proj.bias', 'decoder.layers.9.self_attn.o_proj.weight', 'decoder.layers.9.self_attn.q_proj.bias', 'decoder.layers.9.self_attn.q_proj.weight', 'decoder.layers.9.self_attn.scaling', 'decoder.layers.9.self_attn.v_proj.bias', 'decoder.layers.9.self_attn.v_proj.weight', 'horizon_ff_layer.input_layer.bias', 'horizon_ff_layer.input_layer.weight', 'horizon_ff_layer.output_layer.bias', 'horizon_ff_layer.output_layer.weight', 'horizon_ff_layer.residual_layer.bias', 'horizon_ff_layer.residual_layer.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n",
            "  Epoch 1/100 train_loss=1.7309 train_acc=0.4538 eval_loss=1.0247 eval_acc=0.6769 (best)\n",
            "  Epoch 2/100 train_loss=0.6127 train_acc=0.8205 eval_loss=0.7290 eval_acc=0.7692 (best)\n",
            "  Epoch 3/100 train_loss=0.1959 train_acc=0.9590 eval_loss=0.5349 eval_acc=0.8000 (best)\n",
            "  Epoch 4/100 train_loss=0.1186 train_acc=0.9744 eval_loss=0.7650 eval_acc=0.7590 \n",
            "  Epoch 5/100 train_loss=0.0995 train_acc=0.9692 eval_loss=0.9365 eval_acc=0.7231 \n",
            "  Epoch 6/100 train_loss=0.1877 train_acc=0.9385 eval_loss=1.0285 eval_acc=0.7410 \n",
            "  Epoch 7/100 train_loss=0.0710 train_acc=0.9769 eval_loss=1.0886 eval_acc=0.7538 \n",
            "  Epoch 8/100 train_loss=0.1032 train_acc=0.9692 eval_loss=1.1610 eval_acc=0.7564 \n",
            "  Epoch 9/100 train_loss=0.1779 train_acc=0.9487 eval_loss=1.1933 eval_acc=0.7538 \n",
            "  Epoch 10/100 train_loss=0.2139 train_acc=0.9590 eval_loss=1.2289 eval_acc=0.7667 \n",
            "  Epoch 11/100 train_loss=0.2123 train_acc=0.9410 eval_loss=1.4534 eval_acc=0.7256 \n",
            "  Epoch 12/100 train_loss=0.1207 train_acc=0.9615 eval_loss=1.3427 eval_acc=0.7590 \n",
            "  Epoch 13/100 train_loss=0.0897 train_acc=0.9718 eval_loss=1.1695 eval_acc=0.7795 \n",
            "  Early stopping on google/timesfm-2.5-200m-pytorch: no improvement for 10 epochs (best epoch = 3)\n",
            "    tfm[google/timesfm-2.5-200m-pytorch] train_acc=0.9590 eval_acc=0.77948717948717949344228372865472920238971710\n",
            "    mrh_acc=0.8615 mr+h+kg_acc=0.8564 kg_acc=0.8513 ensemble=0.8615 (w=0.60)\n",
            "  Split 1/1 - accuracy=0.8615 time=333.1s\n",
            "Completed CricketZ: Mean Acc=0.8615\n",
            "\n",
            "=== 18/109 Crop ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  Decision: Heuristic says no filter (too short to filter)\n",
            "\n",
            "=== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at google/timesfm-2.5-200m-pytorch were not used when initializing TimesFmModelForPrediction: ['output_projection_point.hidden_layer.weight', 'output_projection_point.output_layer.weight', 'output_projection_point.residual_layer.weight', 'output_projection_quantiles.hidden_layer.weight', 'output_projection_quantiles.output_layer.weight', 'output_projection_quantiles.residual_layer.weight', 'stacked_xf.0.attn.key_ln.scale', 'stacked_xf.0.attn.out.weight', 'stacked_xf.0.attn.per_dim_scale.per_dim_scale', 'stacked_xf.0.attn.qkv_proj.weight', 'stacked_xf.0.attn.query_ln.scale', 'stacked_xf.0.ff0.weight', 'stacked_xf.0.ff1.weight', 'stacked_xf.0.post_attn_ln.scale', 'stacked_xf.0.post_ff_ln.scale', 'stacked_xf.0.pre_attn_ln.scale', 'stacked_xf.0.pre_ff_ln.scale', 'stacked_xf.1.attn.key_ln.scale', 'stacked_xf.1.attn.out.weight', 'stacked_xf.1.attn.per_dim_scale.per_dim_scale', 'stacked_xf.1.attn.qkv_proj.weight', 'stacked_xf.1.attn.query_ln.scale', 'stacked_xf.1.ff0.weight', 'stacked_xf.1.ff1.weight', 'stacked_xf.1.post_attn_ln.scale', 'stacked_xf.1.post_ff_ln.scale', 'stacked_xf.1.pre_attn_ln.scale', 'stacked_xf.1.pre_ff_ln.scale', 'stacked_xf.10.attn.key_ln.scale', 'stacked_xf.10.attn.out.weight', 'stacked_xf.10.attn.per_dim_scale.per_dim_scale', 'stacked_xf.10.attn.qkv_proj.weight', 'stacked_xf.10.attn.query_ln.scale', 'stacked_xf.10.ff0.weight', 'stacked_xf.10.ff1.weight', 'stacked_xf.10.post_attn_ln.scale', 'stacked_xf.10.post_ff_ln.scale', 'stacked_xf.10.pre_attn_ln.scale', 'stacked_xf.10.pre_ff_ln.scale', 'stacked_xf.11.attn.key_ln.scale', 'stacked_xf.11.attn.out.weight', 'stacked_xf.11.attn.per_dim_scale.per_dim_scale', 'stacked_xf.11.attn.qkv_proj.weight', 'stacked_xf.11.attn.query_ln.scale', 'stacked_xf.11.ff0.weight', 'stacked_xf.11.ff1.weight', 'stacked_xf.11.post_attn_ln.scale', 'stacked_xf.11.post_ff_ln.scale', 'stacked_xf.11.pre_attn_ln.scale', 'stacked_xf.11.pre_ff_ln.scale', 'stacked_xf.12.attn.key_ln.scale', 'stacked_xf.12.attn.out.weight', 'stacked_xf.12.attn.per_dim_scale.per_dim_scale', 'stacked_xf.12.attn.qkv_proj.weight', 'stacked_xf.12.attn.query_ln.scale', 'stacked_xf.12.ff0.weight', 'stacked_xf.12.ff1.weight', 'stacked_xf.12.post_attn_ln.scale', 'stacked_xf.12.post_ff_ln.scale', 'stacked_xf.12.pre_attn_ln.scale', 'stacked_xf.12.pre_ff_ln.scale', 'stacked_xf.13.attn.key_ln.scale', 'stacked_xf.13.attn.out.weight', 'stacked_xf.13.attn.per_dim_scale.per_dim_scale', 'stacked_xf.13.attn.qkv_proj.weight', 'stacked_xf.13.attn.query_ln.scale', 'stacked_xf.13.ff0.weight', 'stacked_xf.13.ff1.weight', 'stacked_xf.13.post_attn_ln.scale', 'stacked_xf.13.post_ff_ln.scale', 'stacked_xf.13.pre_attn_ln.scale', 'stacked_xf.13.pre_ff_ln.scale', 'stacked_xf.14.attn.key_ln.scale', 'stacked_xf.14.attn.out.weight', 'stacked_xf.14.attn.per_dim_scale.per_dim_scale', 'stacked_xf.14.attn.qkv_proj.weight', 'stacked_xf.14.attn.query_ln.scale', 'stacked_xf.14.ff0.weight', 'stacked_xf.14.ff1.weight', 'stacked_xf.14.post_attn_ln.scale', 'stacked_xf.14.post_ff_ln.scale', 'stacked_xf.14.pre_attn_ln.scale', 'stacked_xf.14.pre_ff_ln.scale', 'stacked_xf.15.attn.key_ln.scale', 'stacked_xf.15.attn.out.weight', 'stacked_xf.15.attn.per_dim_scale.per_dim_scale', 'stacked_xf.15.attn.qkv_proj.weight', 'stacked_xf.15.attn.query_ln.scale', 'stacked_xf.15.ff0.weight', 'stacked_xf.15.ff1.weight', 'stacked_xf.15.post_attn_ln.scale', 'stacked_xf.15.post_ff_ln.scale', 'stacked_xf.15.pre_attn_ln.scale', 'stacked_xf.15.pre_ff_ln.scale', 'stacked_xf.16.attn.key_ln.scale', 'stacked_xf.16.attn.out.weight', 'stacked_xf.16.attn.per_dim_scale.per_dim_scale', 'stacked_xf.16.attn.qkv_proj.weight', 'stacked_xf.16.attn.query_ln.scale', 'stacked_xf.16.ff0.weight', 'stacked_xf.16.ff1.weight', 'stacked_xf.16.post_attn_ln.scale', 'stacked_xf.16.post_ff_ln.scale', 'stacked_xf.16.pre_attn_ln.scale', 'stacked_xf.16.pre_ff_ln.scale', 'stacked_xf.17.attn.key_ln.scale', 'stacked_xf.17.attn.out.weight', 'stacked_xf.17.attn.per_dim_scale.per_dim_scale', 'stacked_xf.17.attn.qkv_proj.weight', 'stacked_xf.17.attn.query_ln.scale', 'stacked_xf.17.ff0.weight', 'stacked_xf.17.ff1.weight', 'stacked_xf.17.post_attn_ln.scale', 'stacked_xf.17.post_ff_ln.scale', 'stacked_xf.17.pre_attn_ln.scale', 'stacked_xf.17.pre_ff_ln.scale', 'stacked_xf.18.attn.key_ln.scale', 'stacked_xf.18.attn.out.weight', 'stacked_xf.18.attn.per_dim_scale.per_dim_scale', 'stacked_xf.18.attn.qkv_proj.weight', 'stacked_xf.18.attn.query_ln.scale', 'stacked_xf.18.ff0.weight', 'stacked_xf.18.ff1.weight', 'stacked_xf.18.post_attn_ln.scale', 'stacked_xf.18.post_ff_ln.scale', 'stacked_xf.18.pre_attn_ln.scale', 'stacked_xf.18.pre_ff_ln.scale', 'stacked_xf.19.attn.key_ln.scale', 'stacked_xf.19.attn.out.weight', 'stacked_xf.19.attn.per_dim_scale.per_dim_scale', 'stacked_xf.19.attn.qkv_proj.weight', 'stacked_xf.19.attn.query_ln.scale', 'stacked_xf.19.ff0.weight', 'stacked_xf.19.ff1.weight', 'stacked_xf.19.post_attn_ln.scale', 'stacked_xf.19.post_ff_ln.scale', 'stacked_xf.19.pre_attn_ln.scale', 'stacked_xf.19.pre_ff_ln.scale', 'stacked_xf.2.attn.key_ln.scale', 'stacked_xf.2.attn.out.weight', 'stacked_xf.2.attn.per_dim_scale.per_dim_scale', 'stacked_xf.2.attn.qkv_proj.weight', 'stacked_xf.2.attn.query_ln.scale', 'stacked_xf.2.ff0.weight', 'stacked_xf.2.ff1.weight', 'stacked_xf.2.post_attn_ln.scale', 'stacked_xf.2.post_ff_ln.scale', 'stacked_xf.2.pre_attn_ln.scale', 'stacked_xf.2.pre_ff_ln.scale', 'stacked_xf.3.attn.key_ln.scale', 'stacked_xf.3.attn.out.weight', 'stacked_xf.3.attn.per_dim_scale.per_dim_scale', 'stacked_xf.3.attn.qkv_proj.weight', 'stacked_xf.3.attn.query_ln.scale', 'stacked_xf.3.ff0.weight', 'stacked_xf.3.ff1.weight', 'stacked_xf.3.post_attn_ln.scale', 'stacked_xf.3.post_ff_ln.scale', 'stacked_xf.3.pre_attn_ln.scale', 'stacked_xf.3.pre_ff_ln.scale', 'stacked_xf.4.attn.key_ln.scale', 'stacked_xf.4.attn.out.weight', 'stacked_xf.4.attn.per_dim_scale.per_dim_scale', 'stacked_xf.4.attn.qkv_proj.weight', 'stacked_xf.4.attn.query_ln.scale', 'stacked_xf.4.ff0.weight', 'stacked_xf.4.ff1.weight', 'stacked_xf.4.post_attn_ln.scale', 'stacked_xf.4.post_ff_ln.scale', 'stacked_xf.4.pre_attn_ln.scale', 'stacked_xf.4.pre_ff_ln.scale', 'stacked_xf.5.attn.key_ln.scale', 'stacked_xf.5.attn.out.weight', 'stacked_xf.5.attn.per_dim_scale.per_dim_scale', 'stacked_xf.5.attn.qkv_proj.weight', 'stacked_xf.5.attn.query_ln.scale', 'stacked_xf.5.ff0.weight', 'stacked_xf.5.ff1.weight', 'stacked_xf.5.post_attn_ln.scale', 'stacked_xf.5.post_ff_ln.scale', 'stacked_xf.5.pre_attn_ln.scale', 'stacked_xf.5.pre_ff_ln.scale', 'stacked_xf.6.attn.key_ln.scale', 'stacked_xf.6.attn.out.weight', 'stacked_xf.6.attn.per_dim_scale.per_dim_scale', 'stacked_xf.6.attn.qkv_proj.weight', 'stacked_xf.6.attn.query_ln.scale', 'stacked_xf.6.ff0.weight', 'stacked_xf.6.ff1.weight', 'stacked_xf.6.post_attn_ln.scale', 'stacked_xf.6.post_ff_ln.scale', 'stacked_xf.6.pre_attn_ln.scale', 'stacked_xf.6.pre_ff_ln.scale', 'stacked_xf.7.attn.key_ln.scale', 'stacked_xf.7.attn.out.weight', 'stacked_xf.7.attn.per_dim_scale.per_dim_scale', 'stacked_xf.7.attn.qkv_proj.weight', 'stacked_xf.7.attn.query_ln.scale', 'stacked_xf.7.ff0.weight', 'stacked_xf.7.ff1.weight', 'stacked_xf.7.post_attn_ln.scale', 'stacked_xf.7.post_ff_ln.scale', 'stacked_xf.7.pre_attn_ln.scale', 'stacked_xf.7.pre_ff_ln.scale', 'stacked_xf.8.attn.key_ln.scale', 'stacked_xf.8.attn.out.weight', 'stacked_xf.8.attn.per_dim_scale.per_dim_scale', 'stacked_xf.8.attn.qkv_proj.weight', 'stacked_xf.8.attn.query_ln.scale', 'stacked_xf.8.ff0.weight', 'stacked_xf.8.ff1.weight', 'stacked_xf.8.post_attn_ln.scale', 'stacked_xf.8.post_ff_ln.scale', 'stacked_xf.8.pre_attn_ln.scale', 'stacked_xf.8.pre_ff_ln.scale', 'stacked_xf.9.attn.key_ln.scale', 'stacked_xf.9.attn.out.weight', 'stacked_xf.9.attn.per_dim_scale.per_dim_scale', 'stacked_xf.9.attn.qkv_proj.weight', 'stacked_xf.9.attn.query_ln.scale', 'stacked_xf.9.ff0.weight', 'stacked_xf.9.ff1.weight', 'stacked_xf.9.post_attn_ln.scale', 'stacked_xf.9.post_ff_ln.scale', 'stacked_xf.9.pre_attn_ln.scale', 'stacked_xf.9.pre_ff_ln.scale', 'tokenizer.hidden_layer.bias', 'tokenizer.hidden_layer.weight', 'tokenizer.output_layer.bias', 'tokenizer.output_layer.weight', 'tokenizer.residual_layer.bias', 'tokenizer.residual_layer.weight']\n",
            "- This IS expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of TimesFmModelForPrediction were not initialized from the model checkpoint at google/timesfm-2.5-200m-pytorch and are newly initialized: ['decoder.freq_emb.weight', 'decoder.input_ff_layer.input_layer.bias', 'decoder.input_ff_layer.input_layer.weight', 'decoder.input_ff_layer.output_layer.bias', 'decoder.input_ff_layer.output_layer.weight', 'decoder.input_ff_layer.residual_layer.bias', 'decoder.input_ff_layer.residual_layer.weight', 'decoder.layers.0.input_layernorm.weight', 'decoder.layers.0.mlp.down_proj.bias', 'decoder.layers.0.mlp.down_proj.weight', 'decoder.layers.0.mlp.gate_proj.bias', 'decoder.layers.0.mlp.gate_proj.weight', 'decoder.layers.0.mlp.layer_norm.bias', 'decoder.layers.0.mlp.layer_norm.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.o_proj.bias', 'decoder.layers.0.self_attn.o_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.scaling', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.1.input_layernorm.weight', 'decoder.layers.1.mlp.down_proj.bias', 'decoder.layers.1.mlp.down_proj.weight', 'decoder.layers.1.mlp.gate_proj.bias', 'decoder.layers.1.mlp.gate_proj.weight', 'decoder.layers.1.mlp.layer_norm.bias', 'decoder.layers.1.mlp.layer_norm.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.o_proj.bias', 'decoder.layers.1.self_attn.o_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.scaling', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.10.input_layernorm.weight', 'decoder.layers.10.mlp.down_proj.bias', 'decoder.layers.10.mlp.down_proj.weight', 'decoder.layers.10.mlp.gate_proj.bias', 'decoder.layers.10.mlp.gate_proj.weight', 'decoder.layers.10.mlp.layer_norm.bias', 'decoder.layers.10.mlp.layer_norm.weight', 'decoder.layers.10.self_attn.k_proj.bias', 'decoder.layers.10.self_attn.k_proj.weight', 'decoder.layers.10.self_attn.o_proj.bias', 'decoder.layers.10.self_attn.o_proj.weight', 'decoder.layers.10.self_attn.q_proj.bias', 'decoder.layers.10.self_attn.q_proj.weight', 'decoder.layers.10.self_attn.scaling', 'decoder.layers.10.self_attn.v_proj.bias', 'decoder.layers.10.self_attn.v_proj.weight', 'decoder.layers.11.input_layernorm.weight', 'decoder.layers.11.mlp.down_proj.bias', 'decoder.layers.11.mlp.down_proj.weight', 'decoder.layers.11.mlp.gate_proj.bias', 'decoder.layers.11.mlp.gate_proj.weight', 'decoder.layers.11.mlp.layer_norm.bias', 'decoder.layers.11.mlp.layer_norm.weight', 'decoder.layers.11.self_attn.k_proj.bias', 'decoder.layers.11.self_attn.k_proj.weight', 'decoder.layers.11.self_attn.o_proj.bias', 'decoder.layers.11.self_attn.o_proj.weight', 'decoder.layers.11.self_attn.q_proj.bias', 'decoder.layers.11.self_attn.q_proj.weight', 'decoder.layers.11.self_attn.scaling', 'decoder.layers.11.self_attn.v_proj.bias', 'decoder.layers.11.self_attn.v_proj.weight', 'decoder.layers.12.input_layernorm.weight', 'decoder.layers.12.mlp.down_proj.bias', 'decoder.layers.12.mlp.down_proj.weight', 'decoder.layers.12.mlp.gate_proj.bias', 'decoder.layers.12.mlp.gate_proj.weight', 'decoder.layers.12.mlp.layer_norm.bias', 'decoder.layers.12.mlp.layer_norm.weight', 'decoder.layers.12.self_attn.k_proj.bias', 'decoder.layers.12.self_attn.k_proj.weight', 'decoder.layers.12.self_attn.o_proj.bias', 'decoder.layers.12.self_attn.o_proj.weight', 'decoder.layers.12.self_attn.q_proj.bias', 'decoder.layers.12.self_attn.q_proj.weight', 'decoder.layers.12.self_attn.scaling', 'decoder.layers.12.self_attn.v_proj.bias', 'decoder.layers.12.self_attn.v_proj.weight', 'decoder.layers.13.input_layernorm.weight', 'decoder.layers.13.mlp.down_proj.bias', 'decoder.layers.13.mlp.down_proj.weight', 'decoder.layers.13.mlp.gate_proj.bias', 'decoder.layers.13.mlp.gate_proj.weight', 'decoder.layers.13.mlp.layer_norm.bias', 'decoder.layers.13.mlp.layer_norm.weight', 'decoder.layers.13.self_attn.k_proj.bias', 'decoder.layers.13.self_attn.k_proj.weight', 'decoder.layers.13.self_attn.o_proj.bias', 'decoder.layers.13.self_attn.o_proj.weight', 'decoder.layers.13.self_attn.q_proj.bias', 'decoder.layers.13.self_attn.q_proj.weight', 'decoder.layers.13.self_attn.scaling', 'decoder.layers.13.self_attn.v_proj.bias', 'decoder.layers.13.self_attn.v_proj.weight', 'decoder.layers.14.input_layernorm.weight', 'decoder.layers.14.mlp.down_proj.bias', 'decoder.layers.14.mlp.down_proj.weight', 'decoder.layers.14.mlp.gate_proj.bias', 'decoder.layers.14.mlp.gate_proj.weight', 'decoder.layers.14.mlp.layer_norm.bias', 'decoder.layers.14.mlp.layer_norm.weight', 'decoder.layers.14.self_attn.k_proj.bias', 'decoder.layers.14.self_attn.k_proj.weight', 'decoder.layers.14.self_attn.o_proj.bias', 'decoder.layers.14.self_attn.o_proj.weight', 'decoder.layers.14.self_attn.q_proj.bias', 'decoder.layers.14.self_attn.q_proj.weight', 'decoder.layers.14.self_attn.scaling', 'decoder.layers.14.self_attn.v_proj.bias', 'decoder.layers.14.self_attn.v_proj.weight', 'decoder.layers.15.input_layernorm.weight', 'decoder.layers.15.mlp.down_proj.bias', 'decoder.layers.15.mlp.down_proj.weight', 'decoder.layers.15.mlp.gate_proj.bias', 'decoder.layers.15.mlp.gate_proj.weight', 'decoder.layers.15.mlp.layer_norm.bias', 'decoder.layers.15.mlp.layer_norm.weight', 'decoder.layers.15.self_attn.k_proj.bias', 'decoder.layers.15.self_attn.k_proj.weight', 'decoder.layers.15.self_attn.o_proj.bias', 'decoder.layers.15.self_attn.o_proj.weight', 'decoder.layers.15.self_attn.q_proj.bias', 'decoder.layers.15.self_attn.q_proj.weight', 'decoder.layers.15.self_attn.scaling', 'decoder.layers.15.self_attn.v_proj.bias', 'decoder.layers.15.self_attn.v_proj.weight', 'decoder.layers.16.input_layernorm.weight', 'decoder.layers.16.mlp.down_proj.bias', 'decoder.layers.16.mlp.down_proj.weight', 'decoder.layers.16.mlp.gate_proj.bias', 'decoder.layers.16.mlp.gate_proj.weight', 'decoder.layers.16.mlp.layer_norm.bias', 'decoder.layers.16.mlp.layer_norm.weight', 'decoder.layers.16.self_attn.k_proj.bias', 'decoder.layers.16.self_attn.k_proj.weight', 'decoder.layers.16.self_attn.o_proj.bias', 'decoder.layers.16.self_attn.o_proj.weight', 'decoder.layers.16.self_attn.q_proj.bias', 'decoder.layers.16.self_attn.q_proj.weight', 'decoder.layers.16.self_attn.scaling', 'decoder.layers.16.self_attn.v_proj.bias', 'decoder.layers.16.self_attn.v_proj.weight', 'decoder.layers.17.input_layernorm.weight', 'decoder.layers.17.mlp.down_proj.bias', 'decoder.layers.17.mlp.down_proj.weight', 'decoder.layers.17.mlp.gate_proj.bias', 'decoder.layers.17.mlp.gate_proj.weight', 'decoder.layers.17.mlp.layer_norm.bias', 'decoder.layers.17.mlp.layer_norm.weight', 'decoder.layers.17.self_attn.k_proj.bias', 'decoder.layers.17.self_attn.k_proj.weight', 'decoder.layers.17.self_attn.o_proj.bias', 'decoder.layers.17.self_attn.o_proj.weight', 'decoder.layers.17.self_attn.q_proj.bias', 'decoder.layers.17.self_attn.q_proj.weight', 'decoder.layers.17.self_attn.scaling', 'decoder.layers.17.self_attn.v_proj.bias', 'decoder.layers.17.self_attn.v_proj.weight', 'decoder.layers.18.input_layernorm.weight', 'decoder.layers.18.mlp.down_proj.bias', 'decoder.layers.18.mlp.down_proj.weight', 'decoder.layers.18.mlp.gate_proj.bias', 'decoder.layers.18.mlp.gate_proj.weight', 'decoder.layers.18.mlp.layer_norm.bias', 'decoder.layers.18.mlp.layer_norm.weight', 'decoder.layers.18.self_attn.k_proj.bias', 'decoder.layers.18.self_attn.k_proj.weight', 'decoder.layers.18.self_attn.o_proj.bias', 'decoder.layers.18.self_attn.o_proj.weight', 'decoder.layers.18.self_attn.q_proj.bias', 'decoder.layers.18.self_attn.q_proj.weight', 'decoder.layers.18.self_attn.scaling', 'decoder.layers.18.self_attn.v_proj.bias', 'decoder.layers.18.self_attn.v_proj.weight', 'decoder.layers.19.input_layernorm.weight', 'decoder.layers.19.mlp.down_proj.bias', 'decoder.layers.19.mlp.down_proj.weight', 'decoder.layers.19.mlp.gate_proj.bias', 'decoder.layers.19.mlp.gate_proj.weight', 'decoder.layers.19.mlp.layer_norm.bias', 'decoder.layers.19.mlp.layer_norm.weight', 'decoder.layers.19.self_attn.k_proj.bias', 'decoder.layers.19.self_attn.k_proj.weight', 'decoder.layers.19.self_attn.o_proj.bias', 'decoder.layers.19.self_attn.o_proj.weight', 'decoder.layers.19.self_attn.q_proj.bias', 'decoder.layers.19.self_attn.q_proj.weight', 'decoder.layers.19.self_attn.scaling', 'decoder.layers.19.self_attn.v_proj.bias', 'decoder.layers.19.self_attn.v_proj.weight', 'decoder.layers.2.input_layernorm.weight', 'decoder.layers.2.mlp.down_proj.bias', 'decoder.layers.2.mlp.down_proj.weight', 'decoder.layers.2.mlp.gate_proj.bias', 'decoder.layers.2.mlp.gate_proj.weight', 'decoder.layers.2.mlp.layer_norm.bias', 'decoder.layers.2.mlp.layer_norm.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.o_proj.bias', 'decoder.layers.2.self_attn.o_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.scaling', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.3.input_layernorm.weight', 'decoder.layers.3.mlp.down_proj.bias', 'decoder.layers.3.mlp.down_proj.weight', 'decoder.layers.3.mlp.gate_proj.bias', 'decoder.layers.3.mlp.gate_proj.weight', 'decoder.layers.3.mlp.layer_norm.bias', 'decoder.layers.3.mlp.layer_norm.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.o_proj.bias', 'decoder.layers.3.self_attn.o_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.scaling', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.4.input_layernorm.weight', 'decoder.layers.4.mlp.down_proj.bias', 'decoder.layers.4.mlp.down_proj.weight', 'decoder.layers.4.mlp.gate_proj.bias', 'decoder.layers.4.mlp.gate_proj.weight', 'decoder.layers.4.mlp.layer_norm.bias', 'decoder.layers.4.mlp.layer_norm.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.o_proj.bias', 'decoder.layers.4.self_attn.o_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.scaling', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.5.input_layernorm.weight', 'decoder.layers.5.mlp.down_proj.bias', 'decoder.layers.5.mlp.down_proj.weight', 'decoder.layers.5.mlp.gate_proj.bias', 'decoder.layers.5.mlp.gate_proj.weight', 'decoder.layers.5.mlp.layer_norm.bias', 'decoder.layers.5.mlp.layer_norm.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.o_proj.bias', 'decoder.layers.5.self_attn.o_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.scaling', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.6.input_layernorm.weight', 'decoder.layers.6.mlp.down_proj.bias', 'decoder.layers.6.mlp.down_proj.weight', 'decoder.layers.6.mlp.gate_proj.bias', 'decoder.layers.6.mlp.gate_proj.weight', 'decoder.layers.6.mlp.layer_norm.bias', 'decoder.layers.6.mlp.layer_norm.weight', 'decoder.layers.6.self_attn.k_proj.bias', 'decoder.layers.6.self_attn.k_proj.weight', 'decoder.layers.6.self_attn.o_proj.bias', 'decoder.layers.6.self_attn.o_proj.weight', 'decoder.layers.6.self_attn.q_proj.bias', 'decoder.layers.6.self_attn.q_proj.weight', 'decoder.layers.6.self_attn.scaling', 'decoder.layers.6.self_attn.v_proj.bias', 'decoder.layers.6.self_attn.v_proj.weight', 'decoder.layers.7.input_layernorm.weight', 'decoder.layers.7.mlp.down_proj.bias', 'decoder.layers.7.mlp.down_proj.weight', 'decoder.layers.7.mlp.gate_proj.bias', 'decoder.layers.7.mlp.gate_proj.weight', 'decoder.layers.7.mlp.layer_norm.bias', 'decoder.layers.7.mlp.layer_norm.weight', 'decoder.layers.7.self_attn.k_proj.bias', 'decoder.layers.7.self_attn.k_proj.weight', 'decoder.layers.7.self_attn.o_proj.bias', 'decoder.layers.7.self_attn.o_proj.weight', 'decoder.layers.7.self_attn.q_proj.bias', 'decoder.layers.7.self_attn.q_proj.weight', 'decoder.layers.7.self_attn.scaling', 'decoder.layers.7.self_attn.v_proj.bias', 'decoder.layers.7.self_attn.v_proj.weight', 'decoder.layers.8.input_layernorm.weight', 'decoder.layers.8.mlp.down_proj.bias', 'decoder.layers.8.mlp.down_proj.weight', 'decoder.layers.8.mlp.gate_proj.bias', 'decoder.layers.8.mlp.gate_proj.weight', 'decoder.layers.8.mlp.layer_norm.bias', 'decoder.layers.8.mlp.layer_norm.weight', 'decoder.layers.8.self_attn.k_proj.bias', 'decoder.layers.8.self_attn.k_proj.weight', 'decoder.layers.8.self_attn.o_proj.bias', 'decoder.layers.8.self_attn.o_proj.weight', 'decoder.layers.8.self_attn.q_proj.bias', 'decoder.layers.8.self_attn.q_proj.weight', 'decoder.layers.8.self_attn.scaling', 'decoder.layers.8.self_attn.v_proj.bias', 'decoder.layers.8.self_attn.v_proj.weight', 'decoder.layers.9.input_layernorm.weight', 'decoder.layers.9.mlp.down_proj.bias', 'decoder.layers.9.mlp.down_proj.weight', 'decoder.layers.9.mlp.gate_proj.bias', 'decoder.layers.9.mlp.gate_proj.weight', 'decoder.layers.9.mlp.layer_norm.bias', 'decoder.layers.9.mlp.layer_norm.weight', 'decoder.layers.9.self_attn.k_proj.bias', 'decoder.layers.9.self_attn.k_proj.weight', 'decoder.layers.9.self_attn.o_proj.bias', 'decoder.layers.9.self_attn.o_proj.weight', 'decoder.layers.9.self_attn.q_proj.bias', 'decoder.layers.9.self_attn.q_proj.weight', 'decoder.layers.9.self_attn.scaling', 'decoder.layers.9.self_attn.v_proj.bias', 'decoder.layers.9.self_attn.v_proj.weight', 'horizon_ff_layer.input_layer.bias', 'horizon_ff_layer.input_layer.weight', 'horizon_ff_layer.output_layer.bias', 'horizon_ff_layer.output_layer.weight', 'horizon_ff_layer.residual_layer.bias', 'horizon_ff_layer.residual_layer.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n",
            "  Epoch 1/100 train_loss=1.3104 train_acc=0.5974 eval_loss=0.9482 eval_acc=0.6595 (best)\n",
            "  Epoch 2/100 train_loss=0.7901 train_acc=0.7311 eval_loss=0.8446 eval_acc=0.7215 (best)\n",
            "  Epoch 3/100 train_loss=0.6212 train_acc=0.7878 eval_loss=0.8618 eval_acc=0.7234 \n",
            "  Epoch 4/100 train_loss=0.5180 train_acc=0.8214 eval_loss=0.9398 eval_acc=0.6913 \n",
            "  Epoch 5/100 train_loss=0.4392 train_acc=0.8482 eval_loss=0.9919 eval_acc=0.7099 \n",
            "  Epoch 6/100 train_loss=0.3840 train_acc=0.8697 eval_loss=1.0289 eval_acc=0.7243 \n",
            "  Epoch 7/100 train_loss=0.3391 train_acc=0.8906 eval_loss=1.1725 eval_acc=0.7070 \n",
            "  Epoch 8/100 train_loss=0.3295 train_acc=0.8889 eval_loss=1.2523 eval_acc=0.7206 \n",
            "  Epoch 9/100 train_loss=0.2943 train_acc=0.9032 eval_loss=1.1826 eval_acc=0.7311 \n",
            "  Epoch 10/100 train_loss=0.3126 train_acc=0.9038 eval_loss=1.3337 eval_acc=0.7266 \n",
            "  Epoch 11/100 train_loss=0.2691 train_acc=0.9140 eval_loss=1.3906 eval_acc=0.7165 \n",
            "  Epoch 12/100 train_loss=0.2431 train_acc=0.9281 eval_loss=1.2424 eval_acc=0.7421 \n",
            "  Early stopping on google/timesfm-2.5-200m-pytorch: no improvement for 10 epochs (best epoch = 2)\n",
            "    tfm[google/timesfm-2.5-200m-pytorch] train_acc=0.7311 eval_acc=0.74214285714285710415794028449454344809055328\n",
            "    mrh_acc=0.7790 mr+h+kg_acc=0.7862 kg_acc=0.7787 ensemble=0.7863 (w=0.60)\n",
            "  Split 1/1 - accuracy=0.7863 time=7131.5s\n",
            "Completed Crop: Mean Acc=0.7863\n",
            "\n",
            "=== 19/109 DiatomSizeReduction ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  Decision: Heuristic says no filter (clean signal (no filtering))\n",
            "\n",
            "=== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at google/timesfm-2.5-200m-pytorch were not used when initializing TimesFmModelForPrediction: ['output_projection_point.hidden_layer.weight', 'output_projection_point.output_layer.weight', 'output_projection_point.residual_layer.weight', 'output_projection_quantiles.hidden_layer.weight', 'output_projection_quantiles.output_layer.weight', 'output_projection_quantiles.residual_layer.weight', 'stacked_xf.0.attn.key_ln.scale', 'stacked_xf.0.attn.out.weight', 'stacked_xf.0.attn.per_dim_scale.per_dim_scale', 'stacked_xf.0.attn.qkv_proj.weight', 'stacked_xf.0.attn.query_ln.scale', 'stacked_xf.0.ff0.weight', 'stacked_xf.0.ff1.weight', 'stacked_xf.0.post_attn_ln.scale', 'stacked_xf.0.post_ff_ln.scale', 'stacked_xf.0.pre_attn_ln.scale', 'stacked_xf.0.pre_ff_ln.scale', 'stacked_xf.1.attn.key_ln.scale', 'stacked_xf.1.attn.out.weight', 'stacked_xf.1.attn.per_dim_scale.per_dim_scale', 'stacked_xf.1.attn.qkv_proj.weight', 'stacked_xf.1.attn.query_ln.scale', 'stacked_xf.1.ff0.weight', 'stacked_xf.1.ff1.weight', 'stacked_xf.1.post_attn_ln.scale', 'stacked_xf.1.post_ff_ln.scale', 'stacked_xf.1.pre_attn_ln.scale', 'stacked_xf.1.pre_ff_ln.scale', 'stacked_xf.10.attn.key_ln.scale', 'stacked_xf.10.attn.out.weight', 'stacked_xf.10.attn.per_dim_scale.per_dim_scale', 'stacked_xf.10.attn.qkv_proj.weight', 'stacked_xf.10.attn.query_ln.scale', 'stacked_xf.10.ff0.weight', 'stacked_xf.10.ff1.weight', 'stacked_xf.10.post_attn_ln.scale', 'stacked_xf.10.post_ff_ln.scale', 'stacked_xf.10.pre_attn_ln.scale', 'stacked_xf.10.pre_ff_ln.scale', 'stacked_xf.11.attn.key_ln.scale', 'stacked_xf.11.attn.out.weight', 'stacked_xf.11.attn.per_dim_scale.per_dim_scale', 'stacked_xf.11.attn.qkv_proj.weight', 'stacked_xf.11.attn.query_ln.scale', 'stacked_xf.11.ff0.weight', 'stacked_xf.11.ff1.weight', 'stacked_xf.11.post_attn_ln.scale', 'stacked_xf.11.post_ff_ln.scale', 'stacked_xf.11.pre_attn_ln.scale', 'stacked_xf.11.pre_ff_ln.scale', 'stacked_xf.12.attn.key_ln.scale', 'stacked_xf.12.attn.out.weight', 'stacked_xf.12.attn.per_dim_scale.per_dim_scale', 'stacked_xf.12.attn.qkv_proj.weight', 'stacked_xf.12.attn.query_ln.scale', 'stacked_xf.12.ff0.weight', 'stacked_xf.12.ff1.weight', 'stacked_xf.12.post_attn_ln.scale', 'stacked_xf.12.post_ff_ln.scale', 'stacked_xf.12.pre_attn_ln.scale', 'stacked_xf.12.pre_ff_ln.scale', 'stacked_xf.13.attn.key_ln.scale', 'stacked_xf.13.attn.out.weight', 'stacked_xf.13.attn.per_dim_scale.per_dim_scale', 'stacked_xf.13.attn.qkv_proj.weight', 'stacked_xf.13.attn.query_ln.scale', 'stacked_xf.13.ff0.weight', 'stacked_xf.13.ff1.weight', 'stacked_xf.13.post_attn_ln.scale', 'stacked_xf.13.post_ff_ln.scale', 'stacked_xf.13.pre_attn_ln.scale', 'stacked_xf.13.pre_ff_ln.scale', 'stacked_xf.14.attn.key_ln.scale', 'stacked_xf.14.attn.out.weight', 'stacked_xf.14.attn.per_dim_scale.per_dim_scale', 'stacked_xf.14.attn.qkv_proj.weight', 'stacked_xf.14.attn.query_ln.scale', 'stacked_xf.14.ff0.weight', 'stacked_xf.14.ff1.weight', 'stacked_xf.14.post_attn_ln.scale', 'stacked_xf.14.post_ff_ln.scale', 'stacked_xf.14.pre_attn_ln.scale', 'stacked_xf.14.pre_ff_ln.scale', 'stacked_xf.15.attn.key_ln.scale', 'stacked_xf.15.attn.out.weight', 'stacked_xf.15.attn.per_dim_scale.per_dim_scale', 'stacked_xf.15.attn.qkv_proj.weight', 'stacked_xf.15.attn.query_ln.scale', 'stacked_xf.15.ff0.weight', 'stacked_xf.15.ff1.weight', 'stacked_xf.15.post_attn_ln.scale', 'stacked_xf.15.post_ff_ln.scale', 'stacked_xf.15.pre_attn_ln.scale', 'stacked_xf.15.pre_ff_ln.scale', 'stacked_xf.16.attn.key_ln.scale', 'stacked_xf.16.attn.out.weight', 'stacked_xf.16.attn.per_dim_scale.per_dim_scale', 'stacked_xf.16.attn.qkv_proj.weight', 'stacked_xf.16.attn.query_ln.scale', 'stacked_xf.16.ff0.weight', 'stacked_xf.16.ff1.weight', 'stacked_xf.16.post_attn_ln.scale', 'stacked_xf.16.post_ff_ln.scale', 'stacked_xf.16.pre_attn_ln.scale', 'stacked_xf.16.pre_ff_ln.scale', 'stacked_xf.17.attn.key_ln.scale', 'stacked_xf.17.attn.out.weight', 'stacked_xf.17.attn.per_dim_scale.per_dim_scale', 'stacked_xf.17.attn.qkv_proj.weight', 'stacked_xf.17.attn.query_ln.scale', 'stacked_xf.17.ff0.weight', 'stacked_xf.17.ff1.weight', 'stacked_xf.17.post_attn_ln.scale', 'stacked_xf.17.post_ff_ln.scale', 'stacked_xf.17.pre_attn_ln.scale', 'stacked_xf.17.pre_ff_ln.scale', 'stacked_xf.18.attn.key_ln.scale', 'stacked_xf.18.attn.out.weight', 'stacked_xf.18.attn.per_dim_scale.per_dim_scale', 'stacked_xf.18.attn.qkv_proj.weight', 'stacked_xf.18.attn.query_ln.scale', 'stacked_xf.18.ff0.weight', 'stacked_xf.18.ff1.weight', 'stacked_xf.18.post_attn_ln.scale', 'stacked_xf.18.post_ff_ln.scale', 'stacked_xf.18.pre_attn_ln.scale', 'stacked_xf.18.pre_ff_ln.scale', 'stacked_xf.19.attn.key_ln.scale', 'stacked_xf.19.attn.out.weight', 'stacked_xf.19.attn.per_dim_scale.per_dim_scale', 'stacked_xf.19.attn.qkv_proj.weight', 'stacked_xf.19.attn.query_ln.scale', 'stacked_xf.19.ff0.weight', 'stacked_xf.19.ff1.weight', 'stacked_xf.19.post_attn_ln.scale', 'stacked_xf.19.post_ff_ln.scale', 'stacked_xf.19.pre_attn_ln.scale', 'stacked_xf.19.pre_ff_ln.scale', 'stacked_xf.2.attn.key_ln.scale', 'stacked_xf.2.attn.out.weight', 'stacked_xf.2.attn.per_dim_scale.per_dim_scale', 'stacked_xf.2.attn.qkv_proj.weight', 'stacked_xf.2.attn.query_ln.scale', 'stacked_xf.2.ff0.weight', 'stacked_xf.2.ff1.weight', 'stacked_xf.2.post_attn_ln.scale', 'stacked_xf.2.post_ff_ln.scale', 'stacked_xf.2.pre_attn_ln.scale', 'stacked_xf.2.pre_ff_ln.scale', 'stacked_xf.3.attn.key_ln.scale', 'stacked_xf.3.attn.out.weight', 'stacked_xf.3.attn.per_dim_scale.per_dim_scale', 'stacked_xf.3.attn.qkv_proj.weight', 'stacked_xf.3.attn.query_ln.scale', 'stacked_xf.3.ff0.weight', 'stacked_xf.3.ff1.weight', 'stacked_xf.3.post_attn_ln.scale', 'stacked_xf.3.post_ff_ln.scale', 'stacked_xf.3.pre_attn_ln.scale', 'stacked_xf.3.pre_ff_ln.scale', 'stacked_xf.4.attn.key_ln.scale', 'stacked_xf.4.attn.out.weight', 'stacked_xf.4.attn.per_dim_scale.per_dim_scale', 'stacked_xf.4.attn.qkv_proj.weight', 'stacked_xf.4.attn.query_ln.scale', 'stacked_xf.4.ff0.weight', 'stacked_xf.4.ff1.weight', 'stacked_xf.4.post_attn_ln.scale', 'stacked_xf.4.post_ff_ln.scale', 'stacked_xf.4.pre_attn_ln.scale', 'stacked_xf.4.pre_ff_ln.scale', 'stacked_xf.5.attn.key_ln.scale', 'stacked_xf.5.attn.out.weight', 'stacked_xf.5.attn.per_dim_scale.per_dim_scale', 'stacked_xf.5.attn.qkv_proj.weight', 'stacked_xf.5.attn.query_ln.scale', 'stacked_xf.5.ff0.weight', 'stacked_xf.5.ff1.weight', 'stacked_xf.5.post_attn_ln.scale', 'stacked_xf.5.post_ff_ln.scale', 'stacked_xf.5.pre_attn_ln.scale', 'stacked_xf.5.pre_ff_ln.scale', 'stacked_xf.6.attn.key_ln.scale', 'stacked_xf.6.attn.out.weight', 'stacked_xf.6.attn.per_dim_scale.per_dim_scale', 'stacked_xf.6.attn.qkv_proj.weight', 'stacked_xf.6.attn.query_ln.scale', 'stacked_xf.6.ff0.weight', 'stacked_xf.6.ff1.weight', 'stacked_xf.6.post_attn_ln.scale', 'stacked_xf.6.post_ff_ln.scale', 'stacked_xf.6.pre_attn_ln.scale', 'stacked_xf.6.pre_ff_ln.scale', 'stacked_xf.7.attn.key_ln.scale', 'stacked_xf.7.attn.out.weight', 'stacked_xf.7.attn.per_dim_scale.per_dim_scale', 'stacked_xf.7.attn.qkv_proj.weight', 'stacked_xf.7.attn.query_ln.scale', 'stacked_xf.7.ff0.weight', 'stacked_xf.7.ff1.weight', 'stacked_xf.7.post_attn_ln.scale', 'stacked_xf.7.post_ff_ln.scale', 'stacked_xf.7.pre_attn_ln.scale', 'stacked_xf.7.pre_ff_ln.scale', 'stacked_xf.8.attn.key_ln.scale', 'stacked_xf.8.attn.out.weight', 'stacked_xf.8.attn.per_dim_scale.per_dim_scale', 'stacked_xf.8.attn.qkv_proj.weight', 'stacked_xf.8.attn.query_ln.scale', 'stacked_xf.8.ff0.weight', 'stacked_xf.8.ff1.weight', 'stacked_xf.8.post_attn_ln.scale', 'stacked_xf.8.post_ff_ln.scale', 'stacked_xf.8.pre_attn_ln.scale', 'stacked_xf.8.pre_ff_ln.scale', 'stacked_xf.9.attn.key_ln.scale', 'stacked_xf.9.attn.out.weight', 'stacked_xf.9.attn.per_dim_scale.per_dim_scale', 'stacked_xf.9.attn.qkv_proj.weight', 'stacked_xf.9.attn.query_ln.scale', 'stacked_xf.9.ff0.weight', 'stacked_xf.9.ff1.weight', 'stacked_xf.9.post_attn_ln.scale', 'stacked_xf.9.post_ff_ln.scale', 'stacked_xf.9.pre_attn_ln.scale', 'stacked_xf.9.pre_ff_ln.scale', 'tokenizer.hidden_layer.bias', 'tokenizer.hidden_layer.weight', 'tokenizer.output_layer.bias', 'tokenizer.output_layer.weight', 'tokenizer.residual_layer.bias', 'tokenizer.residual_layer.weight']\n",
            "- This IS expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of TimesFmModelForPrediction were not initialized from the model checkpoint at google/timesfm-2.5-200m-pytorch and are newly initialized: ['decoder.freq_emb.weight', 'decoder.input_ff_layer.input_layer.bias', 'decoder.input_ff_layer.input_layer.weight', 'decoder.input_ff_layer.output_layer.bias', 'decoder.input_ff_layer.output_layer.weight', 'decoder.input_ff_layer.residual_layer.bias', 'decoder.input_ff_layer.residual_layer.weight', 'decoder.layers.0.input_layernorm.weight', 'decoder.layers.0.mlp.down_proj.bias', 'decoder.layers.0.mlp.down_proj.weight', 'decoder.layers.0.mlp.gate_proj.bias', 'decoder.layers.0.mlp.gate_proj.weight', 'decoder.layers.0.mlp.layer_norm.bias', 'decoder.layers.0.mlp.layer_norm.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.o_proj.bias', 'decoder.layers.0.self_attn.o_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.scaling', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.1.input_layernorm.weight', 'decoder.layers.1.mlp.down_proj.bias', 'decoder.layers.1.mlp.down_proj.weight', 'decoder.layers.1.mlp.gate_proj.bias', 'decoder.layers.1.mlp.gate_proj.weight', 'decoder.layers.1.mlp.layer_norm.bias', 'decoder.layers.1.mlp.layer_norm.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.o_proj.bias', 'decoder.layers.1.self_attn.o_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.scaling', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.10.input_layernorm.weight', 'decoder.layers.10.mlp.down_proj.bias', 'decoder.layers.10.mlp.down_proj.weight', 'decoder.layers.10.mlp.gate_proj.bias', 'decoder.layers.10.mlp.gate_proj.weight', 'decoder.layers.10.mlp.layer_norm.bias', 'decoder.layers.10.mlp.layer_norm.weight', 'decoder.layers.10.self_attn.k_proj.bias', 'decoder.layers.10.self_attn.k_proj.weight', 'decoder.layers.10.self_attn.o_proj.bias', 'decoder.layers.10.self_attn.o_proj.weight', 'decoder.layers.10.self_attn.q_proj.bias', 'decoder.layers.10.self_attn.q_proj.weight', 'decoder.layers.10.self_attn.scaling', 'decoder.layers.10.self_attn.v_proj.bias', 'decoder.layers.10.self_attn.v_proj.weight', 'decoder.layers.11.input_layernorm.weight', 'decoder.layers.11.mlp.down_proj.bias', 'decoder.layers.11.mlp.down_proj.weight', 'decoder.layers.11.mlp.gate_proj.bias', 'decoder.layers.11.mlp.gate_proj.weight', 'decoder.layers.11.mlp.layer_norm.bias', 'decoder.layers.11.mlp.layer_norm.weight', 'decoder.layers.11.self_attn.k_proj.bias', 'decoder.layers.11.self_attn.k_proj.weight', 'decoder.layers.11.self_attn.o_proj.bias', 'decoder.layers.11.self_attn.o_proj.weight', 'decoder.layers.11.self_attn.q_proj.bias', 'decoder.layers.11.self_attn.q_proj.weight', 'decoder.layers.11.self_attn.scaling', 'decoder.layers.11.self_attn.v_proj.bias', 'decoder.layers.11.self_attn.v_proj.weight', 'decoder.layers.12.input_layernorm.weight', 'decoder.layers.12.mlp.down_proj.bias', 'decoder.layers.12.mlp.down_proj.weight', 'decoder.layers.12.mlp.gate_proj.bias', 'decoder.layers.12.mlp.gate_proj.weight', 'decoder.layers.12.mlp.layer_norm.bias', 'decoder.layers.12.mlp.layer_norm.weight', 'decoder.layers.12.self_attn.k_proj.bias', 'decoder.layers.12.self_attn.k_proj.weight', 'decoder.layers.12.self_attn.o_proj.bias', 'decoder.layers.12.self_attn.o_proj.weight', 'decoder.layers.12.self_attn.q_proj.bias', 'decoder.layers.12.self_attn.q_proj.weight', 'decoder.layers.12.self_attn.scaling', 'decoder.layers.12.self_attn.v_proj.bias', 'decoder.layers.12.self_attn.v_proj.weight', 'decoder.layers.13.input_layernorm.weight', 'decoder.layers.13.mlp.down_proj.bias', 'decoder.layers.13.mlp.down_proj.weight', 'decoder.layers.13.mlp.gate_proj.bias', 'decoder.layers.13.mlp.gate_proj.weight', 'decoder.layers.13.mlp.layer_norm.bias', 'decoder.layers.13.mlp.layer_norm.weight', 'decoder.layers.13.self_attn.k_proj.bias', 'decoder.layers.13.self_attn.k_proj.weight', 'decoder.layers.13.self_attn.o_proj.bias', 'decoder.layers.13.self_attn.o_proj.weight', 'decoder.layers.13.self_attn.q_proj.bias', 'decoder.layers.13.self_attn.q_proj.weight', 'decoder.layers.13.self_attn.scaling', 'decoder.layers.13.self_attn.v_proj.bias', 'decoder.layers.13.self_attn.v_proj.weight', 'decoder.layers.14.input_layernorm.weight', 'decoder.layers.14.mlp.down_proj.bias', 'decoder.layers.14.mlp.down_proj.weight', 'decoder.layers.14.mlp.gate_proj.bias', 'decoder.layers.14.mlp.gate_proj.weight', 'decoder.layers.14.mlp.layer_norm.bias', 'decoder.layers.14.mlp.layer_norm.weight', 'decoder.layers.14.self_attn.k_proj.bias', 'decoder.layers.14.self_attn.k_proj.weight', 'decoder.layers.14.self_attn.o_proj.bias', 'decoder.layers.14.self_attn.o_proj.weight', 'decoder.layers.14.self_attn.q_proj.bias', 'decoder.layers.14.self_attn.q_proj.weight', 'decoder.layers.14.self_attn.scaling', 'decoder.layers.14.self_attn.v_proj.bias', 'decoder.layers.14.self_attn.v_proj.weight', 'decoder.layers.15.input_layernorm.weight', 'decoder.layers.15.mlp.down_proj.bias', 'decoder.layers.15.mlp.down_proj.weight', 'decoder.layers.15.mlp.gate_proj.bias', 'decoder.layers.15.mlp.gate_proj.weight', 'decoder.layers.15.mlp.layer_norm.bias', 'decoder.layers.15.mlp.layer_norm.weight', 'decoder.layers.15.self_attn.k_proj.bias', 'decoder.layers.15.self_attn.k_proj.weight', 'decoder.layers.15.self_attn.o_proj.bias', 'decoder.layers.15.self_attn.o_proj.weight', 'decoder.layers.15.self_attn.q_proj.bias', 'decoder.layers.15.self_attn.q_proj.weight', 'decoder.layers.15.self_attn.scaling', 'decoder.layers.15.self_attn.v_proj.bias', 'decoder.layers.15.self_attn.v_proj.weight', 'decoder.layers.16.input_layernorm.weight', 'decoder.layers.16.mlp.down_proj.bias', 'decoder.layers.16.mlp.down_proj.weight', 'decoder.layers.16.mlp.gate_proj.bias', 'decoder.layers.16.mlp.gate_proj.weight', 'decoder.layers.16.mlp.layer_norm.bias', 'decoder.layers.16.mlp.layer_norm.weight', 'decoder.layers.16.self_attn.k_proj.bias', 'decoder.layers.16.self_attn.k_proj.weight', 'decoder.layers.16.self_attn.o_proj.bias', 'decoder.layers.16.self_attn.o_proj.weight', 'decoder.layers.16.self_attn.q_proj.bias', 'decoder.layers.16.self_attn.q_proj.weight', 'decoder.layers.16.self_attn.scaling', 'decoder.layers.16.self_attn.v_proj.bias', 'decoder.layers.16.self_attn.v_proj.weight', 'decoder.layers.17.input_layernorm.weight', 'decoder.layers.17.mlp.down_proj.bias', 'decoder.layers.17.mlp.down_proj.weight', 'decoder.layers.17.mlp.gate_proj.bias', 'decoder.layers.17.mlp.gate_proj.weight', 'decoder.layers.17.mlp.layer_norm.bias', 'decoder.layers.17.mlp.layer_norm.weight', 'decoder.layers.17.self_attn.k_proj.bias', 'decoder.layers.17.self_attn.k_proj.weight', 'decoder.layers.17.self_attn.o_proj.bias', 'decoder.layers.17.self_attn.o_proj.weight', 'decoder.layers.17.self_attn.q_proj.bias', 'decoder.layers.17.self_attn.q_proj.weight', 'decoder.layers.17.self_attn.scaling', 'decoder.layers.17.self_attn.v_proj.bias', 'decoder.layers.17.self_attn.v_proj.weight', 'decoder.layers.18.input_layernorm.weight', 'decoder.layers.18.mlp.down_proj.bias', 'decoder.layers.18.mlp.down_proj.weight', 'decoder.layers.18.mlp.gate_proj.bias', 'decoder.layers.18.mlp.gate_proj.weight', 'decoder.layers.18.mlp.layer_norm.bias', 'decoder.layers.18.mlp.layer_norm.weight', 'decoder.layers.18.self_attn.k_proj.bias', 'decoder.layers.18.self_attn.k_proj.weight', 'decoder.layers.18.self_attn.o_proj.bias', 'decoder.layers.18.self_attn.o_proj.weight', 'decoder.layers.18.self_attn.q_proj.bias', 'decoder.layers.18.self_attn.q_proj.weight', 'decoder.layers.18.self_attn.scaling', 'decoder.layers.18.self_attn.v_proj.bias', 'decoder.layers.18.self_attn.v_proj.weight', 'decoder.layers.19.input_layernorm.weight', 'decoder.layers.19.mlp.down_proj.bias', 'decoder.layers.19.mlp.down_proj.weight', 'decoder.layers.19.mlp.gate_proj.bias', 'decoder.layers.19.mlp.gate_proj.weight', 'decoder.layers.19.mlp.layer_norm.bias', 'decoder.layers.19.mlp.layer_norm.weight', 'decoder.layers.19.self_attn.k_proj.bias', 'decoder.layers.19.self_attn.k_proj.weight', 'decoder.layers.19.self_attn.o_proj.bias', 'decoder.layers.19.self_attn.o_proj.weight', 'decoder.layers.19.self_attn.q_proj.bias', 'decoder.layers.19.self_attn.q_proj.weight', 'decoder.layers.19.self_attn.scaling', 'decoder.layers.19.self_attn.v_proj.bias', 'decoder.layers.19.self_attn.v_proj.weight', 'decoder.layers.2.input_layernorm.weight', 'decoder.layers.2.mlp.down_proj.bias', 'decoder.layers.2.mlp.down_proj.weight', 'decoder.layers.2.mlp.gate_proj.bias', 'decoder.layers.2.mlp.gate_proj.weight', 'decoder.layers.2.mlp.layer_norm.bias', 'decoder.layers.2.mlp.layer_norm.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.o_proj.bias', 'decoder.layers.2.self_attn.o_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.scaling', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.3.input_layernorm.weight', 'decoder.layers.3.mlp.down_proj.bias', 'decoder.layers.3.mlp.down_proj.weight', 'decoder.layers.3.mlp.gate_proj.bias', 'decoder.layers.3.mlp.gate_proj.weight', 'decoder.layers.3.mlp.layer_norm.bias', 'decoder.layers.3.mlp.layer_norm.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.o_proj.bias', 'decoder.layers.3.self_attn.o_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.scaling', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.4.input_layernorm.weight', 'decoder.layers.4.mlp.down_proj.bias', 'decoder.layers.4.mlp.down_proj.weight', 'decoder.layers.4.mlp.gate_proj.bias', 'decoder.layers.4.mlp.gate_proj.weight', 'decoder.layers.4.mlp.layer_norm.bias', 'decoder.layers.4.mlp.layer_norm.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.o_proj.bias', 'decoder.layers.4.self_attn.o_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.scaling', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.5.input_layernorm.weight', 'decoder.layers.5.mlp.down_proj.bias', 'decoder.layers.5.mlp.down_proj.weight', 'decoder.layers.5.mlp.gate_proj.bias', 'decoder.layers.5.mlp.gate_proj.weight', 'decoder.layers.5.mlp.layer_norm.bias', 'decoder.layers.5.mlp.layer_norm.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.o_proj.bias', 'decoder.layers.5.self_attn.o_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.scaling', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.6.input_layernorm.weight', 'decoder.layers.6.mlp.down_proj.bias', 'decoder.layers.6.mlp.down_proj.weight', 'decoder.layers.6.mlp.gate_proj.bias', 'decoder.layers.6.mlp.gate_proj.weight', 'decoder.layers.6.mlp.layer_norm.bias', 'decoder.layers.6.mlp.layer_norm.weight', 'decoder.layers.6.self_attn.k_proj.bias', 'decoder.layers.6.self_attn.k_proj.weight', 'decoder.layers.6.self_attn.o_proj.bias', 'decoder.layers.6.self_attn.o_proj.weight', 'decoder.layers.6.self_attn.q_proj.bias', 'decoder.layers.6.self_attn.q_proj.weight', 'decoder.layers.6.self_attn.scaling', 'decoder.layers.6.self_attn.v_proj.bias', 'decoder.layers.6.self_attn.v_proj.weight', 'decoder.layers.7.input_layernorm.weight', 'decoder.layers.7.mlp.down_proj.bias', 'decoder.layers.7.mlp.down_proj.weight', 'decoder.layers.7.mlp.gate_proj.bias', 'decoder.layers.7.mlp.gate_proj.weight', 'decoder.layers.7.mlp.layer_norm.bias', 'decoder.layers.7.mlp.layer_norm.weight', 'decoder.layers.7.self_attn.k_proj.bias', 'decoder.layers.7.self_attn.k_proj.weight', 'decoder.layers.7.self_attn.o_proj.bias', 'decoder.layers.7.self_attn.o_proj.weight', 'decoder.layers.7.self_attn.q_proj.bias', 'decoder.layers.7.self_attn.q_proj.weight', 'decoder.layers.7.self_attn.scaling', 'decoder.layers.7.self_attn.v_proj.bias', 'decoder.layers.7.self_attn.v_proj.weight', 'decoder.layers.8.input_layernorm.weight', 'decoder.layers.8.mlp.down_proj.bias', 'decoder.layers.8.mlp.down_proj.weight', 'decoder.layers.8.mlp.gate_proj.bias', 'decoder.layers.8.mlp.gate_proj.weight', 'decoder.layers.8.mlp.layer_norm.bias', 'decoder.layers.8.mlp.layer_norm.weight', 'decoder.layers.8.self_attn.k_proj.bias', 'decoder.layers.8.self_attn.k_proj.weight', 'decoder.layers.8.self_attn.o_proj.bias', 'decoder.layers.8.self_attn.o_proj.weight', 'decoder.layers.8.self_attn.q_proj.bias', 'decoder.layers.8.self_attn.q_proj.weight', 'decoder.layers.8.self_attn.scaling', 'decoder.layers.8.self_attn.v_proj.bias', 'decoder.layers.8.self_attn.v_proj.weight', 'decoder.layers.9.input_layernorm.weight', 'decoder.layers.9.mlp.down_proj.bias', 'decoder.layers.9.mlp.down_proj.weight', 'decoder.layers.9.mlp.gate_proj.bias', 'decoder.layers.9.mlp.gate_proj.weight', 'decoder.layers.9.mlp.layer_norm.bias', 'decoder.layers.9.mlp.layer_norm.weight', 'decoder.layers.9.self_attn.k_proj.bias', 'decoder.layers.9.self_attn.k_proj.weight', 'decoder.layers.9.self_attn.o_proj.bias', 'decoder.layers.9.self_attn.o_proj.weight', 'decoder.layers.9.self_attn.q_proj.bias', 'decoder.layers.9.self_attn.q_proj.weight', 'decoder.layers.9.self_attn.scaling', 'decoder.layers.9.self_attn.v_proj.bias', 'decoder.layers.9.self_attn.v_proj.weight', 'horizon_ff_layer.input_layer.bias', 'horizon_ff_layer.input_layer.weight', 'horizon_ff_layer.output_layer.bias', 'horizon_ff_layer.output_layer.weight', 'horizon_ff_layer.residual_layer.bias', 'horizon_ff_layer.residual_layer.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n",
            "  Epoch 1/100 train_loss=1.3683 train_acc=0.3125 eval_loss=1.4209 eval_acc=0.3464 (best)\n",
            "  Epoch 2/100 train_loss=1.3603 train_acc=0.3125 eval_loss=0.6627 eval_acc=0.6471 (best)\n",
            "  Epoch 3/100 train_loss=0.0625 train_acc=1.0000 eval_loss=0.6207 eval_acc=0.6536 (best)\n",
            "  Epoch 4/100 train_loss=0.0293 train_acc=1.0000 eval_loss=0.6182 eval_acc=0.6405 (best)\n",
            "  Epoch 5/100 train_loss=0.0059 train_acc=1.0000 eval_loss=0.6235 eval_acc=0.6340 \n",
            "  Epoch 6/100 train_loss=0.0048 train_acc=1.0000 eval_loss=0.6198 eval_acc=0.6373 \n",
            "  Epoch 7/100 train_loss=0.0018 train_acc=1.0000 eval_loss=0.6192 eval_acc=0.6405 \n",
            "  Epoch 8/100 train_loss=0.0007 train_acc=1.0000 eval_loss=0.6226 eval_acc=0.6405 \n",
            "  Epoch 9/100 train_loss=0.0002 train_acc=1.0000 eval_loss=0.6292 eval_acc=0.6438 \n",
            "  Epoch 10/100 train_loss=0.0001 train_acc=1.0000 eval_loss=0.6380 eval_acc=0.6438 \n",
            "  Epoch 11/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.6482 eval_acc=0.6536 \n",
            "  Epoch 12/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.6584 eval_acc=0.6536 \n",
            "  Epoch 13/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.6681 eval_acc=0.6536 \n",
            "  Epoch 14/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.6773 eval_acc=0.6536 \n",
            "  Early stopping on google/timesfm-2.5-200m-pytorch: no improvement for 10 epochs (best epoch = 4)\n",
            "    tfm[google/timesfm-2.5-200m-pytorch] train_acc=1.0000 eval_acc=0.65359477124183007479274465367780067026615143\n",
            "    mrh_acc=0.9837 mr+h+kg_acc=0.9837 kg_acc=0.9837 ensemble=0.9837 (w=0.60)\n",
            "  Split 1/1 - accuracy=0.9837 time=80.8s\n",
            "Completed DiatomSizeReduction: Mean Acc=0.9837\n",
            "\n",
            "=== 20/109 DistalPhalanxOutlineAgeGroup ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n",
            "    Gate split 1/5: baseline_loss=0.6350 adaptive_loss=0.6448\n",
            "    Gate split 2/5: baseline_loss=0.2980 adaptive_loss=0.2675\n",
            "    Gate split 3/5: baseline_loss=0.4133 adaptive_loss=0.4349\n",
            "    Gate split 4/5: baseline_loss=0.4500 adaptive_loss=0.4529\n",
            "    Gate split 5/5: baseline_loss=0.3353 adaptive_loss=0.3121\n",
            "  Decision: Adaptive kept (loss 0.4225 vs baseline 0.4263, delta=-0.0039 <= +0.0200); savgol(window=5, poly=2) - high noise (std_diff)\n",
            "\n",
            "=== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at google/timesfm-2.5-200m-pytorch were not used when initializing TimesFmModelForPrediction: ['output_projection_point.hidden_layer.weight', 'output_projection_point.output_layer.weight', 'output_projection_point.residual_layer.weight', 'output_projection_quantiles.hidden_layer.weight', 'output_projection_quantiles.output_layer.weight', 'output_projection_quantiles.residual_layer.weight', 'stacked_xf.0.attn.key_ln.scale', 'stacked_xf.0.attn.out.weight', 'stacked_xf.0.attn.per_dim_scale.per_dim_scale', 'stacked_xf.0.attn.qkv_proj.weight', 'stacked_xf.0.attn.query_ln.scale', 'stacked_xf.0.ff0.weight', 'stacked_xf.0.ff1.weight', 'stacked_xf.0.post_attn_ln.scale', 'stacked_xf.0.post_ff_ln.scale', 'stacked_xf.0.pre_attn_ln.scale', 'stacked_xf.0.pre_ff_ln.scale', 'stacked_xf.1.attn.key_ln.scale', 'stacked_xf.1.attn.out.weight', 'stacked_xf.1.attn.per_dim_scale.per_dim_scale', 'stacked_xf.1.attn.qkv_proj.weight', 'stacked_xf.1.attn.query_ln.scale', 'stacked_xf.1.ff0.weight', 'stacked_xf.1.ff1.weight', 'stacked_xf.1.post_attn_ln.scale', 'stacked_xf.1.post_ff_ln.scale', 'stacked_xf.1.pre_attn_ln.scale', 'stacked_xf.1.pre_ff_ln.scale', 'stacked_xf.10.attn.key_ln.scale', 'stacked_xf.10.attn.out.weight', 'stacked_xf.10.attn.per_dim_scale.per_dim_scale', 'stacked_xf.10.attn.qkv_proj.weight', 'stacked_xf.10.attn.query_ln.scale', 'stacked_xf.10.ff0.weight', 'stacked_xf.10.ff1.weight', 'stacked_xf.10.post_attn_ln.scale', 'stacked_xf.10.post_ff_ln.scale', 'stacked_xf.10.pre_attn_ln.scale', 'stacked_xf.10.pre_ff_ln.scale', 'stacked_xf.11.attn.key_ln.scale', 'stacked_xf.11.attn.out.weight', 'stacked_xf.11.attn.per_dim_scale.per_dim_scale', 'stacked_xf.11.attn.qkv_proj.weight', 'stacked_xf.11.attn.query_ln.scale', 'stacked_xf.11.ff0.weight', 'stacked_xf.11.ff1.weight', 'stacked_xf.11.post_attn_ln.scale', 'stacked_xf.11.post_ff_ln.scale', 'stacked_xf.11.pre_attn_ln.scale', 'stacked_xf.11.pre_ff_ln.scale', 'stacked_xf.12.attn.key_ln.scale', 'stacked_xf.12.attn.out.weight', 'stacked_xf.12.attn.per_dim_scale.per_dim_scale', 'stacked_xf.12.attn.qkv_proj.weight', 'stacked_xf.12.attn.query_ln.scale', 'stacked_xf.12.ff0.weight', 'stacked_xf.12.ff1.weight', 'stacked_xf.12.post_attn_ln.scale', 'stacked_xf.12.post_ff_ln.scale', 'stacked_xf.12.pre_attn_ln.scale', 'stacked_xf.12.pre_ff_ln.scale', 'stacked_xf.13.attn.key_ln.scale', 'stacked_xf.13.attn.out.weight', 'stacked_xf.13.attn.per_dim_scale.per_dim_scale', 'stacked_xf.13.attn.qkv_proj.weight', 'stacked_xf.13.attn.query_ln.scale', 'stacked_xf.13.ff0.weight', 'stacked_xf.13.ff1.weight', 'stacked_xf.13.post_attn_ln.scale', 'stacked_xf.13.post_ff_ln.scale', 'stacked_xf.13.pre_attn_ln.scale', 'stacked_xf.13.pre_ff_ln.scale', 'stacked_xf.14.attn.key_ln.scale', 'stacked_xf.14.attn.out.weight', 'stacked_xf.14.attn.per_dim_scale.per_dim_scale', 'stacked_xf.14.attn.qkv_proj.weight', 'stacked_xf.14.attn.query_ln.scale', 'stacked_xf.14.ff0.weight', 'stacked_xf.14.ff1.weight', 'stacked_xf.14.post_attn_ln.scale', 'stacked_xf.14.post_ff_ln.scale', 'stacked_xf.14.pre_attn_ln.scale', 'stacked_xf.14.pre_ff_ln.scale', 'stacked_xf.15.attn.key_ln.scale', 'stacked_xf.15.attn.out.weight', 'stacked_xf.15.attn.per_dim_scale.per_dim_scale', 'stacked_xf.15.attn.qkv_proj.weight', 'stacked_xf.15.attn.query_ln.scale', 'stacked_xf.15.ff0.weight', 'stacked_xf.15.ff1.weight', 'stacked_xf.15.post_attn_ln.scale', 'stacked_xf.15.post_ff_ln.scale', 'stacked_xf.15.pre_attn_ln.scale', 'stacked_xf.15.pre_ff_ln.scale', 'stacked_xf.16.attn.key_ln.scale', 'stacked_xf.16.attn.out.weight', 'stacked_xf.16.attn.per_dim_scale.per_dim_scale', 'stacked_xf.16.attn.qkv_proj.weight', 'stacked_xf.16.attn.query_ln.scale', 'stacked_xf.16.ff0.weight', 'stacked_xf.16.ff1.weight', 'stacked_xf.16.post_attn_ln.scale', 'stacked_xf.16.post_ff_ln.scale', 'stacked_xf.16.pre_attn_ln.scale', 'stacked_xf.16.pre_ff_ln.scale', 'stacked_xf.17.attn.key_ln.scale', 'stacked_xf.17.attn.out.weight', 'stacked_xf.17.attn.per_dim_scale.per_dim_scale', 'stacked_xf.17.attn.qkv_proj.weight', 'stacked_xf.17.attn.query_ln.scale', 'stacked_xf.17.ff0.weight', 'stacked_xf.17.ff1.weight', 'stacked_xf.17.post_attn_ln.scale', 'stacked_xf.17.post_ff_ln.scale', 'stacked_xf.17.pre_attn_ln.scale', 'stacked_xf.17.pre_ff_ln.scale', 'stacked_xf.18.attn.key_ln.scale', 'stacked_xf.18.attn.out.weight', 'stacked_xf.18.attn.per_dim_scale.per_dim_scale', 'stacked_xf.18.attn.qkv_proj.weight', 'stacked_xf.18.attn.query_ln.scale', 'stacked_xf.18.ff0.weight', 'stacked_xf.18.ff1.weight', 'stacked_xf.18.post_attn_ln.scale', 'stacked_xf.18.post_ff_ln.scale', 'stacked_xf.18.pre_attn_ln.scale', 'stacked_xf.18.pre_ff_ln.scale', 'stacked_xf.19.attn.key_ln.scale', 'stacked_xf.19.attn.out.weight', 'stacked_xf.19.attn.per_dim_scale.per_dim_scale', 'stacked_xf.19.attn.qkv_proj.weight', 'stacked_xf.19.attn.query_ln.scale', 'stacked_xf.19.ff0.weight', 'stacked_xf.19.ff1.weight', 'stacked_xf.19.post_attn_ln.scale', 'stacked_xf.19.post_ff_ln.scale', 'stacked_xf.19.pre_attn_ln.scale', 'stacked_xf.19.pre_ff_ln.scale', 'stacked_xf.2.attn.key_ln.scale', 'stacked_xf.2.attn.out.weight', 'stacked_xf.2.attn.per_dim_scale.per_dim_scale', 'stacked_xf.2.attn.qkv_proj.weight', 'stacked_xf.2.attn.query_ln.scale', 'stacked_xf.2.ff0.weight', 'stacked_xf.2.ff1.weight', 'stacked_xf.2.post_attn_ln.scale', 'stacked_xf.2.post_ff_ln.scale', 'stacked_xf.2.pre_attn_ln.scale', 'stacked_xf.2.pre_ff_ln.scale', 'stacked_xf.3.attn.key_ln.scale', 'stacked_xf.3.attn.out.weight', 'stacked_xf.3.attn.per_dim_scale.per_dim_scale', 'stacked_xf.3.attn.qkv_proj.weight', 'stacked_xf.3.attn.query_ln.scale', 'stacked_xf.3.ff0.weight', 'stacked_xf.3.ff1.weight', 'stacked_xf.3.post_attn_ln.scale', 'stacked_xf.3.post_ff_ln.scale', 'stacked_xf.3.pre_attn_ln.scale', 'stacked_xf.3.pre_ff_ln.scale', 'stacked_xf.4.attn.key_ln.scale', 'stacked_xf.4.attn.out.weight', 'stacked_xf.4.attn.per_dim_scale.per_dim_scale', 'stacked_xf.4.attn.qkv_proj.weight', 'stacked_xf.4.attn.query_ln.scale', 'stacked_xf.4.ff0.weight', 'stacked_xf.4.ff1.weight', 'stacked_xf.4.post_attn_ln.scale', 'stacked_xf.4.post_ff_ln.scale', 'stacked_xf.4.pre_attn_ln.scale', 'stacked_xf.4.pre_ff_ln.scale', 'stacked_xf.5.attn.key_ln.scale', 'stacked_xf.5.attn.out.weight', 'stacked_xf.5.attn.per_dim_scale.per_dim_scale', 'stacked_xf.5.attn.qkv_proj.weight', 'stacked_xf.5.attn.query_ln.scale', 'stacked_xf.5.ff0.weight', 'stacked_xf.5.ff1.weight', 'stacked_xf.5.post_attn_ln.scale', 'stacked_xf.5.post_ff_ln.scale', 'stacked_xf.5.pre_attn_ln.scale', 'stacked_xf.5.pre_ff_ln.scale', 'stacked_xf.6.attn.key_ln.scale', 'stacked_xf.6.attn.out.weight', 'stacked_xf.6.attn.per_dim_scale.per_dim_scale', 'stacked_xf.6.attn.qkv_proj.weight', 'stacked_xf.6.attn.query_ln.scale', 'stacked_xf.6.ff0.weight', 'stacked_xf.6.ff1.weight', 'stacked_xf.6.post_attn_ln.scale', 'stacked_xf.6.post_ff_ln.scale', 'stacked_xf.6.pre_attn_ln.scale', 'stacked_xf.6.pre_ff_ln.scale', 'stacked_xf.7.attn.key_ln.scale', 'stacked_xf.7.attn.out.weight', 'stacked_xf.7.attn.per_dim_scale.per_dim_scale', 'stacked_xf.7.attn.qkv_proj.weight', 'stacked_xf.7.attn.query_ln.scale', 'stacked_xf.7.ff0.weight', 'stacked_xf.7.ff1.weight', 'stacked_xf.7.post_attn_ln.scale', 'stacked_xf.7.post_ff_ln.scale', 'stacked_xf.7.pre_attn_ln.scale', 'stacked_xf.7.pre_ff_ln.scale', 'stacked_xf.8.attn.key_ln.scale', 'stacked_xf.8.attn.out.weight', 'stacked_xf.8.attn.per_dim_scale.per_dim_scale', 'stacked_xf.8.attn.qkv_proj.weight', 'stacked_xf.8.attn.query_ln.scale', 'stacked_xf.8.ff0.weight', 'stacked_xf.8.ff1.weight', 'stacked_xf.8.post_attn_ln.scale', 'stacked_xf.8.post_ff_ln.scale', 'stacked_xf.8.pre_attn_ln.scale', 'stacked_xf.8.pre_ff_ln.scale', 'stacked_xf.9.attn.key_ln.scale', 'stacked_xf.9.attn.out.weight', 'stacked_xf.9.attn.per_dim_scale.per_dim_scale', 'stacked_xf.9.attn.qkv_proj.weight', 'stacked_xf.9.attn.query_ln.scale', 'stacked_xf.9.ff0.weight', 'stacked_xf.9.ff1.weight', 'stacked_xf.9.post_attn_ln.scale', 'stacked_xf.9.post_ff_ln.scale', 'stacked_xf.9.pre_attn_ln.scale', 'stacked_xf.9.pre_ff_ln.scale', 'tokenizer.hidden_layer.bias', 'tokenizer.hidden_layer.weight', 'tokenizer.output_layer.bias', 'tokenizer.output_layer.weight', 'tokenizer.residual_layer.bias', 'tokenizer.residual_layer.weight']\n",
            "- This IS expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of TimesFmModelForPrediction were not initialized from the model checkpoint at google/timesfm-2.5-200m-pytorch and are newly initialized: ['decoder.freq_emb.weight', 'decoder.input_ff_layer.input_layer.bias', 'decoder.input_ff_layer.input_layer.weight', 'decoder.input_ff_layer.output_layer.bias', 'decoder.input_ff_layer.output_layer.weight', 'decoder.input_ff_layer.residual_layer.bias', 'decoder.input_ff_layer.residual_layer.weight', 'decoder.layers.0.input_layernorm.weight', 'decoder.layers.0.mlp.down_proj.bias', 'decoder.layers.0.mlp.down_proj.weight', 'decoder.layers.0.mlp.gate_proj.bias', 'decoder.layers.0.mlp.gate_proj.weight', 'decoder.layers.0.mlp.layer_norm.bias', 'decoder.layers.0.mlp.layer_norm.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.o_proj.bias', 'decoder.layers.0.self_attn.o_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.scaling', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.1.input_layernorm.weight', 'decoder.layers.1.mlp.down_proj.bias', 'decoder.layers.1.mlp.down_proj.weight', 'decoder.layers.1.mlp.gate_proj.bias', 'decoder.layers.1.mlp.gate_proj.weight', 'decoder.layers.1.mlp.layer_norm.bias', 'decoder.layers.1.mlp.layer_norm.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.o_proj.bias', 'decoder.layers.1.self_attn.o_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.scaling', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.10.input_layernorm.weight', 'decoder.layers.10.mlp.down_proj.bias', 'decoder.layers.10.mlp.down_proj.weight', 'decoder.layers.10.mlp.gate_proj.bias', 'decoder.layers.10.mlp.gate_proj.weight', 'decoder.layers.10.mlp.layer_norm.bias', 'decoder.layers.10.mlp.layer_norm.weight', 'decoder.layers.10.self_attn.k_proj.bias', 'decoder.layers.10.self_attn.k_proj.weight', 'decoder.layers.10.self_attn.o_proj.bias', 'decoder.layers.10.self_attn.o_proj.weight', 'decoder.layers.10.self_attn.q_proj.bias', 'decoder.layers.10.self_attn.q_proj.weight', 'decoder.layers.10.self_attn.scaling', 'decoder.layers.10.self_attn.v_proj.bias', 'decoder.layers.10.self_attn.v_proj.weight', 'decoder.layers.11.input_layernorm.weight', 'decoder.layers.11.mlp.down_proj.bias', 'decoder.layers.11.mlp.down_proj.weight', 'decoder.layers.11.mlp.gate_proj.bias', 'decoder.layers.11.mlp.gate_proj.weight', 'decoder.layers.11.mlp.layer_norm.bias', 'decoder.layers.11.mlp.layer_norm.weight', 'decoder.layers.11.self_attn.k_proj.bias', 'decoder.layers.11.self_attn.k_proj.weight', 'decoder.layers.11.self_attn.o_proj.bias', 'decoder.layers.11.self_attn.o_proj.weight', 'decoder.layers.11.self_attn.q_proj.bias', 'decoder.layers.11.self_attn.q_proj.weight', 'decoder.layers.11.self_attn.scaling', 'decoder.layers.11.self_attn.v_proj.bias', 'decoder.layers.11.self_attn.v_proj.weight', 'decoder.layers.12.input_layernorm.weight', 'decoder.layers.12.mlp.down_proj.bias', 'decoder.layers.12.mlp.down_proj.weight', 'decoder.layers.12.mlp.gate_proj.bias', 'decoder.layers.12.mlp.gate_proj.weight', 'decoder.layers.12.mlp.layer_norm.bias', 'decoder.layers.12.mlp.layer_norm.weight', 'decoder.layers.12.self_attn.k_proj.bias', 'decoder.layers.12.self_attn.k_proj.weight', 'decoder.layers.12.self_attn.o_proj.bias', 'decoder.layers.12.self_attn.o_proj.weight', 'decoder.layers.12.self_attn.q_proj.bias', 'decoder.layers.12.self_attn.q_proj.weight', 'decoder.layers.12.self_attn.scaling', 'decoder.layers.12.self_attn.v_proj.bias', 'decoder.layers.12.self_attn.v_proj.weight', 'decoder.layers.13.input_layernorm.weight', 'decoder.layers.13.mlp.down_proj.bias', 'decoder.layers.13.mlp.down_proj.weight', 'decoder.layers.13.mlp.gate_proj.bias', 'decoder.layers.13.mlp.gate_proj.weight', 'decoder.layers.13.mlp.layer_norm.bias', 'decoder.layers.13.mlp.layer_norm.weight', 'decoder.layers.13.self_attn.k_proj.bias', 'decoder.layers.13.self_attn.k_proj.weight', 'decoder.layers.13.self_attn.o_proj.bias', 'decoder.layers.13.self_attn.o_proj.weight', 'decoder.layers.13.self_attn.q_proj.bias', 'decoder.layers.13.self_attn.q_proj.weight', 'decoder.layers.13.self_attn.scaling', 'decoder.layers.13.self_attn.v_proj.bias', 'decoder.layers.13.self_attn.v_proj.weight', 'decoder.layers.14.input_layernorm.weight', 'decoder.layers.14.mlp.down_proj.bias', 'decoder.layers.14.mlp.down_proj.weight', 'decoder.layers.14.mlp.gate_proj.bias', 'decoder.layers.14.mlp.gate_proj.weight', 'decoder.layers.14.mlp.layer_norm.bias', 'decoder.layers.14.mlp.layer_norm.weight', 'decoder.layers.14.self_attn.k_proj.bias', 'decoder.layers.14.self_attn.k_proj.weight', 'decoder.layers.14.self_attn.o_proj.bias', 'decoder.layers.14.self_attn.o_proj.weight', 'decoder.layers.14.self_attn.q_proj.bias', 'decoder.layers.14.self_attn.q_proj.weight', 'decoder.layers.14.self_attn.scaling', 'decoder.layers.14.self_attn.v_proj.bias', 'decoder.layers.14.self_attn.v_proj.weight', 'decoder.layers.15.input_layernorm.weight', 'decoder.layers.15.mlp.down_proj.bias', 'decoder.layers.15.mlp.down_proj.weight', 'decoder.layers.15.mlp.gate_proj.bias', 'decoder.layers.15.mlp.gate_proj.weight', 'decoder.layers.15.mlp.layer_norm.bias', 'decoder.layers.15.mlp.layer_norm.weight', 'decoder.layers.15.self_attn.k_proj.bias', 'decoder.layers.15.self_attn.k_proj.weight', 'decoder.layers.15.self_attn.o_proj.bias', 'decoder.layers.15.self_attn.o_proj.weight', 'decoder.layers.15.self_attn.q_proj.bias', 'decoder.layers.15.self_attn.q_proj.weight', 'decoder.layers.15.self_attn.scaling', 'decoder.layers.15.self_attn.v_proj.bias', 'decoder.layers.15.self_attn.v_proj.weight', 'decoder.layers.16.input_layernorm.weight', 'decoder.layers.16.mlp.down_proj.bias', 'decoder.layers.16.mlp.down_proj.weight', 'decoder.layers.16.mlp.gate_proj.bias', 'decoder.layers.16.mlp.gate_proj.weight', 'decoder.layers.16.mlp.layer_norm.bias', 'decoder.layers.16.mlp.layer_norm.weight', 'decoder.layers.16.self_attn.k_proj.bias', 'decoder.layers.16.self_attn.k_proj.weight', 'decoder.layers.16.self_attn.o_proj.bias', 'decoder.layers.16.self_attn.o_proj.weight', 'decoder.layers.16.self_attn.q_proj.bias', 'decoder.layers.16.self_attn.q_proj.weight', 'decoder.layers.16.self_attn.scaling', 'decoder.layers.16.self_attn.v_proj.bias', 'decoder.layers.16.self_attn.v_proj.weight', 'decoder.layers.17.input_layernorm.weight', 'decoder.layers.17.mlp.down_proj.bias', 'decoder.layers.17.mlp.down_proj.weight', 'decoder.layers.17.mlp.gate_proj.bias', 'decoder.layers.17.mlp.gate_proj.weight', 'decoder.layers.17.mlp.layer_norm.bias', 'decoder.layers.17.mlp.layer_norm.weight', 'decoder.layers.17.self_attn.k_proj.bias', 'decoder.layers.17.self_attn.k_proj.weight', 'decoder.layers.17.self_attn.o_proj.bias', 'decoder.layers.17.self_attn.o_proj.weight', 'decoder.layers.17.self_attn.q_proj.bias', 'decoder.layers.17.self_attn.q_proj.weight', 'decoder.layers.17.self_attn.scaling', 'decoder.layers.17.self_attn.v_proj.bias', 'decoder.layers.17.self_attn.v_proj.weight', 'decoder.layers.18.input_layernorm.weight', 'decoder.layers.18.mlp.down_proj.bias', 'decoder.layers.18.mlp.down_proj.weight', 'decoder.layers.18.mlp.gate_proj.bias', 'decoder.layers.18.mlp.gate_proj.weight', 'decoder.layers.18.mlp.layer_norm.bias', 'decoder.layers.18.mlp.layer_norm.weight', 'decoder.layers.18.self_attn.k_proj.bias', 'decoder.layers.18.self_attn.k_proj.weight', 'decoder.layers.18.self_attn.o_proj.bias', 'decoder.layers.18.self_attn.o_proj.weight', 'decoder.layers.18.self_attn.q_proj.bias', 'decoder.layers.18.self_attn.q_proj.weight', 'decoder.layers.18.self_attn.scaling', 'decoder.layers.18.self_attn.v_proj.bias', 'decoder.layers.18.self_attn.v_proj.weight', 'decoder.layers.19.input_layernorm.weight', 'decoder.layers.19.mlp.down_proj.bias', 'decoder.layers.19.mlp.down_proj.weight', 'decoder.layers.19.mlp.gate_proj.bias', 'decoder.layers.19.mlp.gate_proj.weight', 'decoder.layers.19.mlp.layer_norm.bias', 'decoder.layers.19.mlp.layer_norm.weight', 'decoder.layers.19.self_attn.k_proj.bias', 'decoder.layers.19.self_attn.k_proj.weight', 'decoder.layers.19.self_attn.o_proj.bias', 'decoder.layers.19.self_attn.o_proj.weight', 'decoder.layers.19.self_attn.q_proj.bias', 'decoder.layers.19.self_attn.q_proj.weight', 'decoder.layers.19.self_attn.scaling', 'decoder.layers.19.self_attn.v_proj.bias', 'decoder.layers.19.self_attn.v_proj.weight', 'decoder.layers.2.input_layernorm.weight', 'decoder.layers.2.mlp.down_proj.bias', 'decoder.layers.2.mlp.down_proj.weight', 'decoder.layers.2.mlp.gate_proj.bias', 'decoder.layers.2.mlp.gate_proj.weight', 'decoder.layers.2.mlp.layer_norm.bias', 'decoder.layers.2.mlp.layer_norm.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.o_proj.bias', 'decoder.layers.2.self_attn.o_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.scaling', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.3.input_layernorm.weight', 'decoder.layers.3.mlp.down_proj.bias', 'decoder.layers.3.mlp.down_proj.weight', 'decoder.layers.3.mlp.gate_proj.bias', 'decoder.layers.3.mlp.gate_proj.weight', 'decoder.layers.3.mlp.layer_norm.bias', 'decoder.layers.3.mlp.layer_norm.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.o_proj.bias', 'decoder.layers.3.self_attn.o_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.scaling', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.4.input_layernorm.weight', 'decoder.layers.4.mlp.down_proj.bias', 'decoder.layers.4.mlp.down_proj.weight', 'decoder.layers.4.mlp.gate_proj.bias', 'decoder.layers.4.mlp.gate_proj.weight', 'decoder.layers.4.mlp.layer_norm.bias', 'decoder.layers.4.mlp.layer_norm.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.o_proj.bias', 'decoder.layers.4.self_attn.o_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.scaling', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.5.input_layernorm.weight', 'decoder.layers.5.mlp.down_proj.bias', 'decoder.layers.5.mlp.down_proj.weight', 'decoder.layers.5.mlp.gate_proj.bias', 'decoder.layers.5.mlp.gate_proj.weight', 'decoder.layers.5.mlp.layer_norm.bias', 'decoder.layers.5.mlp.layer_norm.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.o_proj.bias', 'decoder.layers.5.self_attn.o_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.scaling', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.6.input_layernorm.weight', 'decoder.layers.6.mlp.down_proj.bias', 'decoder.layers.6.mlp.down_proj.weight', 'decoder.layers.6.mlp.gate_proj.bias', 'decoder.layers.6.mlp.gate_proj.weight', 'decoder.layers.6.mlp.layer_norm.bias', 'decoder.layers.6.mlp.layer_norm.weight', 'decoder.layers.6.self_attn.k_proj.bias', 'decoder.layers.6.self_attn.k_proj.weight', 'decoder.layers.6.self_attn.o_proj.bias', 'decoder.layers.6.self_attn.o_proj.weight', 'decoder.layers.6.self_attn.q_proj.bias', 'decoder.layers.6.self_attn.q_proj.weight', 'decoder.layers.6.self_attn.scaling', 'decoder.layers.6.self_attn.v_proj.bias', 'decoder.layers.6.self_attn.v_proj.weight', 'decoder.layers.7.input_layernorm.weight', 'decoder.layers.7.mlp.down_proj.bias', 'decoder.layers.7.mlp.down_proj.weight', 'decoder.layers.7.mlp.gate_proj.bias', 'decoder.layers.7.mlp.gate_proj.weight', 'decoder.layers.7.mlp.layer_norm.bias', 'decoder.layers.7.mlp.layer_norm.weight', 'decoder.layers.7.self_attn.k_proj.bias', 'decoder.layers.7.self_attn.k_proj.weight', 'decoder.layers.7.self_attn.o_proj.bias', 'decoder.layers.7.self_attn.o_proj.weight', 'decoder.layers.7.self_attn.q_proj.bias', 'decoder.layers.7.self_attn.q_proj.weight', 'decoder.layers.7.self_attn.scaling', 'decoder.layers.7.self_attn.v_proj.bias', 'decoder.layers.7.self_attn.v_proj.weight', 'decoder.layers.8.input_layernorm.weight', 'decoder.layers.8.mlp.down_proj.bias', 'decoder.layers.8.mlp.down_proj.weight', 'decoder.layers.8.mlp.gate_proj.bias', 'decoder.layers.8.mlp.gate_proj.weight', 'decoder.layers.8.mlp.layer_norm.bias', 'decoder.layers.8.mlp.layer_norm.weight', 'decoder.layers.8.self_attn.k_proj.bias', 'decoder.layers.8.self_attn.k_proj.weight', 'decoder.layers.8.self_attn.o_proj.bias', 'decoder.layers.8.self_attn.o_proj.weight', 'decoder.layers.8.self_attn.q_proj.bias', 'decoder.layers.8.self_attn.q_proj.weight', 'decoder.layers.8.self_attn.scaling', 'decoder.layers.8.self_attn.v_proj.bias', 'decoder.layers.8.self_attn.v_proj.weight', 'decoder.layers.9.input_layernorm.weight', 'decoder.layers.9.mlp.down_proj.bias', 'decoder.layers.9.mlp.down_proj.weight', 'decoder.layers.9.mlp.gate_proj.bias', 'decoder.layers.9.mlp.gate_proj.weight', 'decoder.layers.9.mlp.layer_norm.bias', 'decoder.layers.9.mlp.layer_norm.weight', 'decoder.layers.9.self_attn.k_proj.bias', 'decoder.layers.9.self_attn.k_proj.weight', 'decoder.layers.9.self_attn.o_proj.bias', 'decoder.layers.9.self_attn.o_proj.weight', 'decoder.layers.9.self_attn.q_proj.bias', 'decoder.layers.9.self_attn.q_proj.weight', 'decoder.layers.9.self_attn.scaling', 'decoder.layers.9.self_attn.v_proj.bias', 'decoder.layers.9.self_attn.v_proj.weight', 'horizon_ff_layer.input_layer.bias', 'horizon_ff_layer.input_layer.weight', 'horizon_ff_layer.output_layer.bias', 'horizon_ff_layer.output_layer.weight', 'horizon_ff_layer.residual_layer.bias', 'horizon_ff_layer.residual_layer.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n",
            "  Epoch 1/100 train_loss=0.5835 train_acc=0.7775 eval_loss=0.3496 eval_acc=0.8489 (best)\n",
            "  Epoch 2/100 train_loss=0.3793 train_acc=0.8300 eval_loss=0.3500 eval_acc=0.8417 \n",
            "  Epoch 3/100 train_loss=0.3035 train_acc=0.9025 eval_loss=0.4081 eval_acc=0.8489 \n",
            "  Epoch 4/100 train_loss=0.2509 train_acc=0.9000 eval_loss=0.5170 eval_acc=0.8129 \n",
            "  Epoch 5/100 train_loss=0.1535 train_acc=0.9450 eval_loss=0.6039 eval_acc=0.8129 \n",
            "  Epoch 6/100 train_loss=0.3815 train_acc=0.8650 eval_loss=0.4268 eval_acc=0.8561 \n",
            "  Epoch 7/100 train_loss=0.2250 train_acc=0.9200 eval_loss=0.5616 eval_acc=0.8489 \n",
            "  Epoch 8/100 train_loss=0.2006 train_acc=0.9300 eval_loss=1.2765 eval_acc=0.8417 \n",
            "  Epoch 9/100 train_loss=0.2076 train_acc=0.9225 eval_loss=0.7378 eval_acc=0.7986 \n",
            "  Epoch 10/100 train_loss=0.0969 train_acc=0.9600 eval_loss=0.8921 eval_acc=0.8489 \n",
            "  Epoch 11/100 train_loss=0.0631 train_acc=0.9800 eval_loss=1.9472 eval_acc=0.7482 \n",
            "  Early stopping on google/timesfm-2.5-200m-pytorch: no improvement for 10 epochs (best epoch = 1)\n",
            "    tfm[google/timesfm-2.5-200m-pytorch] train_acc=0.7775 eval_acc=0.74820143884892087449145492428215220570564270\n",
            "    mrh_acc=0.8345 mr+h+kg_acc=0.8345 kg_acc=0.8273 ensemble=0.8417 (w=0.60)\n",
            "  Split 1/1 - accuracy=0.8417 time=228.6s\n",
            "Completed DistalPhalanxOutlineAgeGroup: Mean Acc=0.8417\n",
            "\n",
            "=== 21/109 DistalPhalanxOutlineCorrect ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n",
            "    Gate split 1/5: baseline_loss=0.6904 adaptive_loss=0.6606\n",
            "    Gate split 2/5: baseline_loss=0.6937 adaptive_loss=0.6758\n",
            "    Gate split 3/5: baseline_loss=0.7528 adaptive_loss=0.7115\n",
            "    Gate split 4/5: baseline_loss=0.4493 adaptive_loss=0.4487\n",
            "    Gate split 5/5: baseline_loss=0.6114 adaptive_loss=0.6067\n",
            "  Decision: Adaptive kept (loss 0.6207 vs baseline 0.6395, delta=-0.0188 <= +0.0200); savgol(window=5, poly=2) - high noise (std_diff)\n",
            "Error processing DistalPhalanxOutlineCorrect: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n",
            "\n",
            "=== 22/109 DistalPhalanxTW ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 556, in main\n",
            "    results = evaluate_dataset_per_split(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 429, in evaluate_dataset_per_split\n",
            "    X_train_extra = np.concatenate([X_train_all, all_dec_train], axis=1)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "ValueError: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Gate split 1/5: baseline_loss=0.8113 adaptive_loss=0.8491\n",
            "    Gate split 2/5: baseline_loss=0.9690 adaptive_loss=1.0238\n",
            "    Gate split 3/5: baseline_loss=1.0356 adaptive_loss=1.1077\n",
            "    Gate split 4/5: baseline_loss=0.8761 adaptive_loss=0.8806\n",
            "    Gate split 5/5: baseline_loss=0.9090 adaptive_loss=0.9167\n",
            "  Decision: Adaptive rejected (loss 0.9556 vs baseline 0.9202, delta=+0.0354 > +0.0200); savgol(window=5, poly=2) - high noise (std_diff)\n",
            "\n",
            "=== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at google/timesfm-2.5-200m-pytorch were not used when initializing TimesFmModelForPrediction: ['output_projection_point.hidden_layer.weight', 'output_projection_point.output_layer.weight', 'output_projection_point.residual_layer.weight', 'output_projection_quantiles.hidden_layer.weight', 'output_projection_quantiles.output_layer.weight', 'output_projection_quantiles.residual_layer.weight', 'stacked_xf.0.attn.key_ln.scale', 'stacked_xf.0.attn.out.weight', 'stacked_xf.0.attn.per_dim_scale.per_dim_scale', 'stacked_xf.0.attn.qkv_proj.weight', 'stacked_xf.0.attn.query_ln.scale', 'stacked_xf.0.ff0.weight', 'stacked_xf.0.ff1.weight', 'stacked_xf.0.post_attn_ln.scale', 'stacked_xf.0.post_ff_ln.scale', 'stacked_xf.0.pre_attn_ln.scale', 'stacked_xf.0.pre_ff_ln.scale', 'stacked_xf.1.attn.key_ln.scale', 'stacked_xf.1.attn.out.weight', 'stacked_xf.1.attn.per_dim_scale.per_dim_scale', 'stacked_xf.1.attn.qkv_proj.weight', 'stacked_xf.1.attn.query_ln.scale', 'stacked_xf.1.ff0.weight', 'stacked_xf.1.ff1.weight', 'stacked_xf.1.post_attn_ln.scale', 'stacked_xf.1.post_ff_ln.scale', 'stacked_xf.1.pre_attn_ln.scale', 'stacked_xf.1.pre_ff_ln.scale', 'stacked_xf.10.attn.key_ln.scale', 'stacked_xf.10.attn.out.weight', 'stacked_xf.10.attn.per_dim_scale.per_dim_scale', 'stacked_xf.10.attn.qkv_proj.weight', 'stacked_xf.10.attn.query_ln.scale', 'stacked_xf.10.ff0.weight', 'stacked_xf.10.ff1.weight', 'stacked_xf.10.post_attn_ln.scale', 'stacked_xf.10.post_ff_ln.scale', 'stacked_xf.10.pre_attn_ln.scale', 'stacked_xf.10.pre_ff_ln.scale', 'stacked_xf.11.attn.key_ln.scale', 'stacked_xf.11.attn.out.weight', 'stacked_xf.11.attn.per_dim_scale.per_dim_scale', 'stacked_xf.11.attn.qkv_proj.weight', 'stacked_xf.11.attn.query_ln.scale', 'stacked_xf.11.ff0.weight', 'stacked_xf.11.ff1.weight', 'stacked_xf.11.post_attn_ln.scale', 'stacked_xf.11.post_ff_ln.scale', 'stacked_xf.11.pre_attn_ln.scale', 'stacked_xf.11.pre_ff_ln.scale', 'stacked_xf.12.attn.key_ln.scale', 'stacked_xf.12.attn.out.weight', 'stacked_xf.12.attn.per_dim_scale.per_dim_scale', 'stacked_xf.12.attn.qkv_proj.weight', 'stacked_xf.12.attn.query_ln.scale', 'stacked_xf.12.ff0.weight', 'stacked_xf.12.ff1.weight', 'stacked_xf.12.post_attn_ln.scale', 'stacked_xf.12.post_ff_ln.scale', 'stacked_xf.12.pre_attn_ln.scale', 'stacked_xf.12.pre_ff_ln.scale', 'stacked_xf.13.attn.key_ln.scale', 'stacked_xf.13.attn.out.weight', 'stacked_xf.13.attn.per_dim_scale.per_dim_scale', 'stacked_xf.13.attn.qkv_proj.weight', 'stacked_xf.13.attn.query_ln.scale', 'stacked_xf.13.ff0.weight', 'stacked_xf.13.ff1.weight', 'stacked_xf.13.post_attn_ln.scale', 'stacked_xf.13.post_ff_ln.scale', 'stacked_xf.13.pre_attn_ln.scale', 'stacked_xf.13.pre_ff_ln.scale', 'stacked_xf.14.attn.key_ln.scale', 'stacked_xf.14.attn.out.weight', 'stacked_xf.14.attn.per_dim_scale.per_dim_scale', 'stacked_xf.14.attn.qkv_proj.weight', 'stacked_xf.14.attn.query_ln.scale', 'stacked_xf.14.ff0.weight', 'stacked_xf.14.ff1.weight', 'stacked_xf.14.post_attn_ln.scale', 'stacked_xf.14.post_ff_ln.scale', 'stacked_xf.14.pre_attn_ln.scale', 'stacked_xf.14.pre_ff_ln.scale', 'stacked_xf.15.attn.key_ln.scale', 'stacked_xf.15.attn.out.weight', 'stacked_xf.15.attn.per_dim_scale.per_dim_scale', 'stacked_xf.15.attn.qkv_proj.weight', 'stacked_xf.15.attn.query_ln.scale', 'stacked_xf.15.ff0.weight', 'stacked_xf.15.ff1.weight', 'stacked_xf.15.post_attn_ln.scale', 'stacked_xf.15.post_ff_ln.scale', 'stacked_xf.15.pre_attn_ln.scale', 'stacked_xf.15.pre_ff_ln.scale', 'stacked_xf.16.attn.key_ln.scale', 'stacked_xf.16.attn.out.weight', 'stacked_xf.16.attn.per_dim_scale.per_dim_scale', 'stacked_xf.16.attn.qkv_proj.weight', 'stacked_xf.16.attn.query_ln.scale', 'stacked_xf.16.ff0.weight', 'stacked_xf.16.ff1.weight', 'stacked_xf.16.post_attn_ln.scale', 'stacked_xf.16.post_ff_ln.scale', 'stacked_xf.16.pre_attn_ln.scale', 'stacked_xf.16.pre_ff_ln.scale', 'stacked_xf.17.attn.key_ln.scale', 'stacked_xf.17.attn.out.weight', 'stacked_xf.17.attn.per_dim_scale.per_dim_scale', 'stacked_xf.17.attn.qkv_proj.weight', 'stacked_xf.17.attn.query_ln.scale', 'stacked_xf.17.ff0.weight', 'stacked_xf.17.ff1.weight', 'stacked_xf.17.post_attn_ln.scale', 'stacked_xf.17.post_ff_ln.scale', 'stacked_xf.17.pre_attn_ln.scale', 'stacked_xf.17.pre_ff_ln.scale', 'stacked_xf.18.attn.key_ln.scale', 'stacked_xf.18.attn.out.weight', 'stacked_xf.18.attn.per_dim_scale.per_dim_scale', 'stacked_xf.18.attn.qkv_proj.weight', 'stacked_xf.18.attn.query_ln.scale', 'stacked_xf.18.ff0.weight', 'stacked_xf.18.ff1.weight', 'stacked_xf.18.post_attn_ln.scale', 'stacked_xf.18.post_ff_ln.scale', 'stacked_xf.18.pre_attn_ln.scale', 'stacked_xf.18.pre_ff_ln.scale', 'stacked_xf.19.attn.key_ln.scale', 'stacked_xf.19.attn.out.weight', 'stacked_xf.19.attn.per_dim_scale.per_dim_scale', 'stacked_xf.19.attn.qkv_proj.weight', 'stacked_xf.19.attn.query_ln.scale', 'stacked_xf.19.ff0.weight', 'stacked_xf.19.ff1.weight', 'stacked_xf.19.post_attn_ln.scale', 'stacked_xf.19.post_ff_ln.scale', 'stacked_xf.19.pre_attn_ln.scale', 'stacked_xf.19.pre_ff_ln.scale', 'stacked_xf.2.attn.key_ln.scale', 'stacked_xf.2.attn.out.weight', 'stacked_xf.2.attn.per_dim_scale.per_dim_scale', 'stacked_xf.2.attn.qkv_proj.weight', 'stacked_xf.2.attn.query_ln.scale', 'stacked_xf.2.ff0.weight', 'stacked_xf.2.ff1.weight', 'stacked_xf.2.post_attn_ln.scale', 'stacked_xf.2.post_ff_ln.scale', 'stacked_xf.2.pre_attn_ln.scale', 'stacked_xf.2.pre_ff_ln.scale', 'stacked_xf.3.attn.key_ln.scale', 'stacked_xf.3.attn.out.weight', 'stacked_xf.3.attn.per_dim_scale.per_dim_scale', 'stacked_xf.3.attn.qkv_proj.weight', 'stacked_xf.3.attn.query_ln.scale', 'stacked_xf.3.ff0.weight', 'stacked_xf.3.ff1.weight', 'stacked_xf.3.post_attn_ln.scale', 'stacked_xf.3.post_ff_ln.scale', 'stacked_xf.3.pre_attn_ln.scale', 'stacked_xf.3.pre_ff_ln.scale', 'stacked_xf.4.attn.key_ln.scale', 'stacked_xf.4.attn.out.weight', 'stacked_xf.4.attn.per_dim_scale.per_dim_scale', 'stacked_xf.4.attn.qkv_proj.weight', 'stacked_xf.4.attn.query_ln.scale', 'stacked_xf.4.ff0.weight', 'stacked_xf.4.ff1.weight', 'stacked_xf.4.post_attn_ln.scale', 'stacked_xf.4.post_ff_ln.scale', 'stacked_xf.4.pre_attn_ln.scale', 'stacked_xf.4.pre_ff_ln.scale', 'stacked_xf.5.attn.key_ln.scale', 'stacked_xf.5.attn.out.weight', 'stacked_xf.5.attn.per_dim_scale.per_dim_scale', 'stacked_xf.5.attn.qkv_proj.weight', 'stacked_xf.5.attn.query_ln.scale', 'stacked_xf.5.ff0.weight', 'stacked_xf.5.ff1.weight', 'stacked_xf.5.post_attn_ln.scale', 'stacked_xf.5.post_ff_ln.scale', 'stacked_xf.5.pre_attn_ln.scale', 'stacked_xf.5.pre_ff_ln.scale', 'stacked_xf.6.attn.key_ln.scale', 'stacked_xf.6.attn.out.weight', 'stacked_xf.6.attn.per_dim_scale.per_dim_scale', 'stacked_xf.6.attn.qkv_proj.weight', 'stacked_xf.6.attn.query_ln.scale', 'stacked_xf.6.ff0.weight', 'stacked_xf.6.ff1.weight', 'stacked_xf.6.post_attn_ln.scale', 'stacked_xf.6.post_ff_ln.scale', 'stacked_xf.6.pre_attn_ln.scale', 'stacked_xf.6.pre_ff_ln.scale', 'stacked_xf.7.attn.key_ln.scale', 'stacked_xf.7.attn.out.weight', 'stacked_xf.7.attn.per_dim_scale.per_dim_scale', 'stacked_xf.7.attn.qkv_proj.weight', 'stacked_xf.7.attn.query_ln.scale', 'stacked_xf.7.ff0.weight', 'stacked_xf.7.ff1.weight', 'stacked_xf.7.post_attn_ln.scale', 'stacked_xf.7.post_ff_ln.scale', 'stacked_xf.7.pre_attn_ln.scale', 'stacked_xf.7.pre_ff_ln.scale', 'stacked_xf.8.attn.key_ln.scale', 'stacked_xf.8.attn.out.weight', 'stacked_xf.8.attn.per_dim_scale.per_dim_scale', 'stacked_xf.8.attn.qkv_proj.weight', 'stacked_xf.8.attn.query_ln.scale', 'stacked_xf.8.ff0.weight', 'stacked_xf.8.ff1.weight', 'stacked_xf.8.post_attn_ln.scale', 'stacked_xf.8.post_ff_ln.scale', 'stacked_xf.8.pre_attn_ln.scale', 'stacked_xf.8.pre_ff_ln.scale', 'stacked_xf.9.attn.key_ln.scale', 'stacked_xf.9.attn.out.weight', 'stacked_xf.9.attn.per_dim_scale.per_dim_scale', 'stacked_xf.9.attn.qkv_proj.weight', 'stacked_xf.9.attn.query_ln.scale', 'stacked_xf.9.ff0.weight', 'stacked_xf.9.ff1.weight', 'stacked_xf.9.post_attn_ln.scale', 'stacked_xf.9.post_ff_ln.scale', 'stacked_xf.9.pre_attn_ln.scale', 'stacked_xf.9.pre_ff_ln.scale', 'tokenizer.hidden_layer.bias', 'tokenizer.hidden_layer.weight', 'tokenizer.output_layer.bias', 'tokenizer.output_layer.weight', 'tokenizer.residual_layer.bias', 'tokenizer.residual_layer.weight']\n",
            "- This IS expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of TimesFmModelForPrediction were not initialized from the model checkpoint at google/timesfm-2.5-200m-pytorch and are newly initialized: ['decoder.freq_emb.weight', 'decoder.input_ff_layer.input_layer.bias', 'decoder.input_ff_layer.input_layer.weight', 'decoder.input_ff_layer.output_layer.bias', 'decoder.input_ff_layer.output_layer.weight', 'decoder.input_ff_layer.residual_layer.bias', 'decoder.input_ff_layer.residual_layer.weight', 'decoder.layers.0.input_layernorm.weight', 'decoder.layers.0.mlp.down_proj.bias', 'decoder.layers.0.mlp.down_proj.weight', 'decoder.layers.0.mlp.gate_proj.bias', 'decoder.layers.0.mlp.gate_proj.weight', 'decoder.layers.0.mlp.layer_norm.bias', 'decoder.layers.0.mlp.layer_norm.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.o_proj.bias', 'decoder.layers.0.self_attn.o_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.scaling', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.1.input_layernorm.weight', 'decoder.layers.1.mlp.down_proj.bias', 'decoder.layers.1.mlp.down_proj.weight', 'decoder.layers.1.mlp.gate_proj.bias', 'decoder.layers.1.mlp.gate_proj.weight', 'decoder.layers.1.mlp.layer_norm.bias', 'decoder.layers.1.mlp.layer_norm.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.o_proj.bias', 'decoder.layers.1.self_attn.o_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.scaling', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.10.input_layernorm.weight', 'decoder.layers.10.mlp.down_proj.bias', 'decoder.layers.10.mlp.down_proj.weight', 'decoder.layers.10.mlp.gate_proj.bias', 'decoder.layers.10.mlp.gate_proj.weight', 'decoder.layers.10.mlp.layer_norm.bias', 'decoder.layers.10.mlp.layer_norm.weight', 'decoder.layers.10.self_attn.k_proj.bias', 'decoder.layers.10.self_attn.k_proj.weight', 'decoder.layers.10.self_attn.o_proj.bias', 'decoder.layers.10.self_attn.o_proj.weight', 'decoder.layers.10.self_attn.q_proj.bias', 'decoder.layers.10.self_attn.q_proj.weight', 'decoder.layers.10.self_attn.scaling', 'decoder.layers.10.self_attn.v_proj.bias', 'decoder.layers.10.self_attn.v_proj.weight', 'decoder.layers.11.input_layernorm.weight', 'decoder.layers.11.mlp.down_proj.bias', 'decoder.layers.11.mlp.down_proj.weight', 'decoder.layers.11.mlp.gate_proj.bias', 'decoder.layers.11.mlp.gate_proj.weight', 'decoder.layers.11.mlp.layer_norm.bias', 'decoder.layers.11.mlp.layer_norm.weight', 'decoder.layers.11.self_attn.k_proj.bias', 'decoder.layers.11.self_attn.k_proj.weight', 'decoder.layers.11.self_attn.o_proj.bias', 'decoder.layers.11.self_attn.o_proj.weight', 'decoder.layers.11.self_attn.q_proj.bias', 'decoder.layers.11.self_attn.q_proj.weight', 'decoder.layers.11.self_attn.scaling', 'decoder.layers.11.self_attn.v_proj.bias', 'decoder.layers.11.self_attn.v_proj.weight', 'decoder.layers.12.input_layernorm.weight', 'decoder.layers.12.mlp.down_proj.bias', 'decoder.layers.12.mlp.down_proj.weight', 'decoder.layers.12.mlp.gate_proj.bias', 'decoder.layers.12.mlp.gate_proj.weight', 'decoder.layers.12.mlp.layer_norm.bias', 'decoder.layers.12.mlp.layer_norm.weight', 'decoder.layers.12.self_attn.k_proj.bias', 'decoder.layers.12.self_attn.k_proj.weight', 'decoder.layers.12.self_attn.o_proj.bias', 'decoder.layers.12.self_attn.o_proj.weight', 'decoder.layers.12.self_attn.q_proj.bias', 'decoder.layers.12.self_attn.q_proj.weight', 'decoder.layers.12.self_attn.scaling', 'decoder.layers.12.self_attn.v_proj.bias', 'decoder.layers.12.self_attn.v_proj.weight', 'decoder.layers.13.input_layernorm.weight', 'decoder.layers.13.mlp.down_proj.bias', 'decoder.layers.13.mlp.down_proj.weight', 'decoder.layers.13.mlp.gate_proj.bias', 'decoder.layers.13.mlp.gate_proj.weight', 'decoder.layers.13.mlp.layer_norm.bias', 'decoder.layers.13.mlp.layer_norm.weight', 'decoder.layers.13.self_attn.k_proj.bias', 'decoder.layers.13.self_attn.k_proj.weight', 'decoder.layers.13.self_attn.o_proj.bias', 'decoder.layers.13.self_attn.o_proj.weight', 'decoder.layers.13.self_attn.q_proj.bias', 'decoder.layers.13.self_attn.q_proj.weight', 'decoder.layers.13.self_attn.scaling', 'decoder.layers.13.self_attn.v_proj.bias', 'decoder.layers.13.self_attn.v_proj.weight', 'decoder.layers.14.input_layernorm.weight', 'decoder.layers.14.mlp.down_proj.bias', 'decoder.layers.14.mlp.down_proj.weight', 'decoder.layers.14.mlp.gate_proj.bias', 'decoder.layers.14.mlp.gate_proj.weight', 'decoder.layers.14.mlp.layer_norm.bias', 'decoder.layers.14.mlp.layer_norm.weight', 'decoder.layers.14.self_attn.k_proj.bias', 'decoder.layers.14.self_attn.k_proj.weight', 'decoder.layers.14.self_attn.o_proj.bias', 'decoder.layers.14.self_attn.o_proj.weight', 'decoder.layers.14.self_attn.q_proj.bias', 'decoder.layers.14.self_attn.q_proj.weight', 'decoder.layers.14.self_attn.scaling', 'decoder.layers.14.self_attn.v_proj.bias', 'decoder.layers.14.self_attn.v_proj.weight', 'decoder.layers.15.input_layernorm.weight', 'decoder.layers.15.mlp.down_proj.bias', 'decoder.layers.15.mlp.down_proj.weight', 'decoder.layers.15.mlp.gate_proj.bias', 'decoder.layers.15.mlp.gate_proj.weight', 'decoder.layers.15.mlp.layer_norm.bias', 'decoder.layers.15.mlp.layer_norm.weight', 'decoder.layers.15.self_attn.k_proj.bias', 'decoder.layers.15.self_attn.k_proj.weight', 'decoder.layers.15.self_attn.o_proj.bias', 'decoder.layers.15.self_attn.o_proj.weight', 'decoder.layers.15.self_attn.q_proj.bias', 'decoder.layers.15.self_attn.q_proj.weight', 'decoder.layers.15.self_attn.scaling', 'decoder.layers.15.self_attn.v_proj.bias', 'decoder.layers.15.self_attn.v_proj.weight', 'decoder.layers.16.input_layernorm.weight', 'decoder.layers.16.mlp.down_proj.bias', 'decoder.layers.16.mlp.down_proj.weight', 'decoder.layers.16.mlp.gate_proj.bias', 'decoder.layers.16.mlp.gate_proj.weight', 'decoder.layers.16.mlp.layer_norm.bias', 'decoder.layers.16.mlp.layer_norm.weight', 'decoder.layers.16.self_attn.k_proj.bias', 'decoder.layers.16.self_attn.k_proj.weight', 'decoder.layers.16.self_attn.o_proj.bias', 'decoder.layers.16.self_attn.o_proj.weight', 'decoder.layers.16.self_attn.q_proj.bias', 'decoder.layers.16.self_attn.q_proj.weight', 'decoder.layers.16.self_attn.scaling', 'decoder.layers.16.self_attn.v_proj.bias', 'decoder.layers.16.self_attn.v_proj.weight', 'decoder.layers.17.input_layernorm.weight', 'decoder.layers.17.mlp.down_proj.bias', 'decoder.layers.17.mlp.down_proj.weight', 'decoder.layers.17.mlp.gate_proj.bias', 'decoder.layers.17.mlp.gate_proj.weight', 'decoder.layers.17.mlp.layer_norm.bias', 'decoder.layers.17.mlp.layer_norm.weight', 'decoder.layers.17.self_attn.k_proj.bias', 'decoder.layers.17.self_attn.k_proj.weight', 'decoder.layers.17.self_attn.o_proj.bias', 'decoder.layers.17.self_attn.o_proj.weight', 'decoder.layers.17.self_attn.q_proj.bias', 'decoder.layers.17.self_attn.q_proj.weight', 'decoder.layers.17.self_attn.scaling', 'decoder.layers.17.self_attn.v_proj.bias', 'decoder.layers.17.self_attn.v_proj.weight', 'decoder.layers.18.input_layernorm.weight', 'decoder.layers.18.mlp.down_proj.bias', 'decoder.layers.18.mlp.down_proj.weight', 'decoder.layers.18.mlp.gate_proj.bias', 'decoder.layers.18.mlp.gate_proj.weight', 'decoder.layers.18.mlp.layer_norm.bias', 'decoder.layers.18.mlp.layer_norm.weight', 'decoder.layers.18.self_attn.k_proj.bias', 'decoder.layers.18.self_attn.k_proj.weight', 'decoder.layers.18.self_attn.o_proj.bias', 'decoder.layers.18.self_attn.o_proj.weight', 'decoder.layers.18.self_attn.q_proj.bias', 'decoder.layers.18.self_attn.q_proj.weight', 'decoder.layers.18.self_attn.scaling', 'decoder.layers.18.self_attn.v_proj.bias', 'decoder.layers.18.self_attn.v_proj.weight', 'decoder.layers.19.input_layernorm.weight', 'decoder.layers.19.mlp.down_proj.bias', 'decoder.layers.19.mlp.down_proj.weight', 'decoder.layers.19.mlp.gate_proj.bias', 'decoder.layers.19.mlp.gate_proj.weight', 'decoder.layers.19.mlp.layer_norm.bias', 'decoder.layers.19.mlp.layer_norm.weight', 'decoder.layers.19.self_attn.k_proj.bias', 'decoder.layers.19.self_attn.k_proj.weight', 'decoder.layers.19.self_attn.o_proj.bias', 'decoder.layers.19.self_attn.o_proj.weight', 'decoder.layers.19.self_attn.q_proj.bias', 'decoder.layers.19.self_attn.q_proj.weight', 'decoder.layers.19.self_attn.scaling', 'decoder.layers.19.self_attn.v_proj.bias', 'decoder.layers.19.self_attn.v_proj.weight', 'decoder.layers.2.input_layernorm.weight', 'decoder.layers.2.mlp.down_proj.bias', 'decoder.layers.2.mlp.down_proj.weight', 'decoder.layers.2.mlp.gate_proj.bias', 'decoder.layers.2.mlp.gate_proj.weight', 'decoder.layers.2.mlp.layer_norm.bias', 'decoder.layers.2.mlp.layer_norm.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.o_proj.bias', 'decoder.layers.2.self_attn.o_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.scaling', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.3.input_layernorm.weight', 'decoder.layers.3.mlp.down_proj.bias', 'decoder.layers.3.mlp.down_proj.weight', 'decoder.layers.3.mlp.gate_proj.bias', 'decoder.layers.3.mlp.gate_proj.weight', 'decoder.layers.3.mlp.layer_norm.bias', 'decoder.layers.3.mlp.layer_norm.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.o_proj.bias', 'decoder.layers.3.self_attn.o_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.scaling', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.4.input_layernorm.weight', 'decoder.layers.4.mlp.down_proj.bias', 'decoder.layers.4.mlp.down_proj.weight', 'decoder.layers.4.mlp.gate_proj.bias', 'decoder.layers.4.mlp.gate_proj.weight', 'decoder.layers.4.mlp.layer_norm.bias', 'decoder.layers.4.mlp.layer_norm.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.o_proj.bias', 'decoder.layers.4.self_attn.o_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.scaling', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.5.input_layernorm.weight', 'decoder.layers.5.mlp.down_proj.bias', 'decoder.layers.5.mlp.down_proj.weight', 'decoder.layers.5.mlp.gate_proj.bias', 'decoder.layers.5.mlp.gate_proj.weight', 'decoder.layers.5.mlp.layer_norm.bias', 'decoder.layers.5.mlp.layer_norm.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.o_proj.bias', 'decoder.layers.5.self_attn.o_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.scaling', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.6.input_layernorm.weight', 'decoder.layers.6.mlp.down_proj.bias', 'decoder.layers.6.mlp.down_proj.weight', 'decoder.layers.6.mlp.gate_proj.bias', 'decoder.layers.6.mlp.gate_proj.weight', 'decoder.layers.6.mlp.layer_norm.bias', 'decoder.layers.6.mlp.layer_norm.weight', 'decoder.layers.6.self_attn.k_proj.bias', 'decoder.layers.6.self_attn.k_proj.weight', 'decoder.layers.6.self_attn.o_proj.bias', 'decoder.layers.6.self_attn.o_proj.weight', 'decoder.layers.6.self_attn.q_proj.bias', 'decoder.layers.6.self_attn.q_proj.weight', 'decoder.layers.6.self_attn.scaling', 'decoder.layers.6.self_attn.v_proj.bias', 'decoder.layers.6.self_attn.v_proj.weight', 'decoder.layers.7.input_layernorm.weight', 'decoder.layers.7.mlp.down_proj.bias', 'decoder.layers.7.mlp.down_proj.weight', 'decoder.layers.7.mlp.gate_proj.bias', 'decoder.layers.7.mlp.gate_proj.weight', 'decoder.layers.7.mlp.layer_norm.bias', 'decoder.layers.7.mlp.layer_norm.weight', 'decoder.layers.7.self_attn.k_proj.bias', 'decoder.layers.7.self_attn.k_proj.weight', 'decoder.layers.7.self_attn.o_proj.bias', 'decoder.layers.7.self_attn.o_proj.weight', 'decoder.layers.7.self_attn.q_proj.bias', 'decoder.layers.7.self_attn.q_proj.weight', 'decoder.layers.7.self_attn.scaling', 'decoder.layers.7.self_attn.v_proj.bias', 'decoder.layers.7.self_attn.v_proj.weight', 'decoder.layers.8.input_layernorm.weight', 'decoder.layers.8.mlp.down_proj.bias', 'decoder.layers.8.mlp.down_proj.weight', 'decoder.layers.8.mlp.gate_proj.bias', 'decoder.layers.8.mlp.gate_proj.weight', 'decoder.layers.8.mlp.layer_norm.bias', 'decoder.layers.8.mlp.layer_norm.weight', 'decoder.layers.8.self_attn.k_proj.bias', 'decoder.layers.8.self_attn.k_proj.weight', 'decoder.layers.8.self_attn.o_proj.bias', 'decoder.layers.8.self_attn.o_proj.weight', 'decoder.layers.8.self_attn.q_proj.bias', 'decoder.layers.8.self_attn.q_proj.weight', 'decoder.layers.8.self_attn.scaling', 'decoder.layers.8.self_attn.v_proj.bias', 'decoder.layers.8.self_attn.v_proj.weight', 'decoder.layers.9.input_layernorm.weight', 'decoder.layers.9.mlp.down_proj.bias', 'decoder.layers.9.mlp.down_proj.weight', 'decoder.layers.9.mlp.gate_proj.bias', 'decoder.layers.9.mlp.gate_proj.weight', 'decoder.layers.9.mlp.layer_norm.bias', 'decoder.layers.9.mlp.layer_norm.weight', 'decoder.layers.9.self_attn.k_proj.bias', 'decoder.layers.9.self_attn.k_proj.weight', 'decoder.layers.9.self_attn.o_proj.bias', 'decoder.layers.9.self_attn.o_proj.weight', 'decoder.layers.9.self_attn.q_proj.bias', 'decoder.layers.9.self_attn.q_proj.weight', 'decoder.layers.9.self_attn.scaling', 'decoder.layers.9.self_attn.v_proj.bias', 'decoder.layers.9.self_attn.v_proj.weight', 'horizon_ff_layer.input_layer.bias', 'horizon_ff_layer.input_layer.weight', 'horizon_ff_layer.output_layer.bias', 'horizon_ff_layer.output_layer.weight', 'horizon_ff_layer.residual_layer.bias', 'horizon_ff_layer.residual_layer.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n",
            "  Epoch 1/100 train_loss=0.9224 train_acc=0.6400 eval_loss=0.6682 eval_acc=0.7122 (best)\n",
            "  Epoch 2/100 train_loss=0.5040 train_acc=0.8175 eval_loss=0.6683 eval_acc=0.7770 \n",
            "  Epoch 3/100 train_loss=0.3958 train_acc=0.8525 eval_loss=0.8060 eval_acc=0.6835 \n",
            "  Epoch 4/100 train_loss=0.2643 train_acc=0.8825 eval_loss=0.9513 eval_acc=0.7626 \n",
            "  Epoch 5/100 train_loss=0.3629 train_acc=0.8750 eval_loss=0.8307 eval_acc=0.7626 \n",
            "  Epoch 6/100 train_loss=0.1916 train_acc=0.9500 eval_loss=0.9439 eval_acc=0.7050 \n",
            "  Epoch 7/100 train_loss=0.1396 train_acc=0.9400 eval_loss=1.1099 eval_acc=0.7338 \n",
            "  Epoch 8/100 train_loss=0.0452 train_acc=0.9875 eval_loss=1.3107 eval_acc=0.7626 \n",
            "  Epoch 9/100 train_loss=0.1389 train_acc=0.9650 eval_loss=1.3586 eval_acc=0.7482 \n",
            "  Epoch 10/100 train_loss=0.0964 train_acc=0.9700 eval_loss=1.3449 eval_acc=0.7410 \n",
            "  Epoch 11/100 train_loss=0.1284 train_acc=0.9550 eval_loss=1.2434 eval_acc=0.7554 \n",
            "  Early stopping on google/timesfm-2.5-200m-pytorch: no improvement for 10 epochs (best epoch = 1)\n",
            "    tfm[google/timesfm-2.5-200m-pytorch] train_acc=0.6400 eval_acc=0.75539568345323737652563522715354338288307190\n",
            "    mrh_acc=0.7770 mr+h+kg_acc=0.7770 kg_acc=0.7770 ensemble=0.7770 (w=0.60)\n",
            "  Split 1/1 - accuracy=0.7770 time=231.1s\n",
            "Completed DistalPhalanxTW: Mean Acc=0.7770\n",
            "\n",
            "=== 23/109 Earthquakes ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n",
            "    Gate split 1/5: baseline_loss=0.9414 adaptive_loss=0.9835\n",
            "    Gate split 2/5: baseline_loss=0.9796 adaptive_loss=0.8812\n",
            "    Gate split 3/5: baseline_loss=1.0147 adaptive_loss=1.1336\n",
            "    Gate split 4/5: baseline_loss=1.0060 adaptive_loss=1.1143\n",
            "    Gate split 5/5: baseline_loss=0.9095 adaptive_loss=0.9219\n",
            "  Decision: Adaptive rejected (loss 1.0069 vs baseline 0.9702, delta=+0.0367 > +0.0200); savgol(window=15, poly=3) - high noise (std_diff)\n",
            "Error processing Earthquakes: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n",
            "\n",
            "=== 24/109 ECG200 ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 556, in main\n",
            "    results = evaluate_dataset_per_split(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 429, in evaluate_dataset_per_split\n",
            "    X_train_extra = np.concatenate([X_train_all, all_dec_train], axis=1)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "ValueError: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Gate split 1/5: baseline_loss=0.4561 adaptive_loss=0.4349\n",
            "    Gate split 2/5: baseline_loss=0.6455 adaptive_loss=0.6712\n",
            "    Gate split 3/5: baseline_loss=0.4568 adaptive_loss=0.4445\n",
            "    Gate split 4/5: baseline_loss=0.5332 adaptive_loss=0.5135\n",
            "    Gate split 5/5: baseline_loss=0.5386 adaptive_loss=0.5164\n",
            "  Decision: Adaptive kept (loss 0.5161 vs baseline 0.5261, delta=-0.0100 <= +0.0200); savgol(window=5, poly=2) - high noise (std_diff)\n",
            "Error processing ECG200: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n",
            "\n",
            "=== 25/109 ECG5000 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 556, in main\n",
            "    results = evaluate_dataset_per_split(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 429, in evaluate_dataset_per_split\n",
            "    X_train_extra = np.concatenate([X_train_all, all_dec_train], axis=1)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "ValueError: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n",
            "    Gate split 1/5: baseline_loss=0.7544 adaptive_loss=0.7679\n",
            "    Gate split 2/5: baseline_loss=0.8294 adaptive_loss=0.9100\n",
            "    Gate split 3/5: baseline_loss=0.7479 adaptive_loss=0.7909\n",
            "    Gate split 4/5: baseline_loss=0.6731 adaptive_loss=0.6562\n",
            "    Gate split 5/5: baseline_loss=0.6250 adaptive_loss=0.5885\n",
            "  Decision: Adaptive kept (loss 0.7427 vs baseline 0.7260, delta=+0.0168 <= +0.0200); savgol(window=7, poly=2) - high noise (std_diff)\n",
            "\n",
            "=== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at google/timesfm-2.5-200m-pytorch were not used when initializing TimesFmModelForPrediction: ['output_projection_point.hidden_layer.weight', 'output_projection_point.output_layer.weight', 'output_projection_point.residual_layer.weight', 'output_projection_quantiles.hidden_layer.weight', 'output_projection_quantiles.output_layer.weight', 'output_projection_quantiles.residual_layer.weight', 'stacked_xf.0.attn.key_ln.scale', 'stacked_xf.0.attn.out.weight', 'stacked_xf.0.attn.per_dim_scale.per_dim_scale', 'stacked_xf.0.attn.qkv_proj.weight', 'stacked_xf.0.attn.query_ln.scale', 'stacked_xf.0.ff0.weight', 'stacked_xf.0.ff1.weight', 'stacked_xf.0.post_attn_ln.scale', 'stacked_xf.0.post_ff_ln.scale', 'stacked_xf.0.pre_attn_ln.scale', 'stacked_xf.0.pre_ff_ln.scale', 'stacked_xf.1.attn.key_ln.scale', 'stacked_xf.1.attn.out.weight', 'stacked_xf.1.attn.per_dim_scale.per_dim_scale', 'stacked_xf.1.attn.qkv_proj.weight', 'stacked_xf.1.attn.query_ln.scale', 'stacked_xf.1.ff0.weight', 'stacked_xf.1.ff1.weight', 'stacked_xf.1.post_attn_ln.scale', 'stacked_xf.1.post_ff_ln.scale', 'stacked_xf.1.pre_attn_ln.scale', 'stacked_xf.1.pre_ff_ln.scale', 'stacked_xf.10.attn.key_ln.scale', 'stacked_xf.10.attn.out.weight', 'stacked_xf.10.attn.per_dim_scale.per_dim_scale', 'stacked_xf.10.attn.qkv_proj.weight', 'stacked_xf.10.attn.query_ln.scale', 'stacked_xf.10.ff0.weight', 'stacked_xf.10.ff1.weight', 'stacked_xf.10.post_attn_ln.scale', 'stacked_xf.10.post_ff_ln.scale', 'stacked_xf.10.pre_attn_ln.scale', 'stacked_xf.10.pre_ff_ln.scale', 'stacked_xf.11.attn.key_ln.scale', 'stacked_xf.11.attn.out.weight', 'stacked_xf.11.attn.per_dim_scale.per_dim_scale', 'stacked_xf.11.attn.qkv_proj.weight', 'stacked_xf.11.attn.query_ln.scale', 'stacked_xf.11.ff0.weight', 'stacked_xf.11.ff1.weight', 'stacked_xf.11.post_attn_ln.scale', 'stacked_xf.11.post_ff_ln.scale', 'stacked_xf.11.pre_attn_ln.scale', 'stacked_xf.11.pre_ff_ln.scale', 'stacked_xf.12.attn.key_ln.scale', 'stacked_xf.12.attn.out.weight', 'stacked_xf.12.attn.per_dim_scale.per_dim_scale', 'stacked_xf.12.attn.qkv_proj.weight', 'stacked_xf.12.attn.query_ln.scale', 'stacked_xf.12.ff0.weight', 'stacked_xf.12.ff1.weight', 'stacked_xf.12.post_attn_ln.scale', 'stacked_xf.12.post_ff_ln.scale', 'stacked_xf.12.pre_attn_ln.scale', 'stacked_xf.12.pre_ff_ln.scale', 'stacked_xf.13.attn.key_ln.scale', 'stacked_xf.13.attn.out.weight', 'stacked_xf.13.attn.per_dim_scale.per_dim_scale', 'stacked_xf.13.attn.qkv_proj.weight', 'stacked_xf.13.attn.query_ln.scale', 'stacked_xf.13.ff0.weight', 'stacked_xf.13.ff1.weight', 'stacked_xf.13.post_attn_ln.scale', 'stacked_xf.13.post_ff_ln.scale', 'stacked_xf.13.pre_attn_ln.scale', 'stacked_xf.13.pre_ff_ln.scale', 'stacked_xf.14.attn.key_ln.scale', 'stacked_xf.14.attn.out.weight', 'stacked_xf.14.attn.per_dim_scale.per_dim_scale', 'stacked_xf.14.attn.qkv_proj.weight', 'stacked_xf.14.attn.query_ln.scale', 'stacked_xf.14.ff0.weight', 'stacked_xf.14.ff1.weight', 'stacked_xf.14.post_attn_ln.scale', 'stacked_xf.14.post_ff_ln.scale', 'stacked_xf.14.pre_attn_ln.scale', 'stacked_xf.14.pre_ff_ln.scale', 'stacked_xf.15.attn.key_ln.scale', 'stacked_xf.15.attn.out.weight', 'stacked_xf.15.attn.per_dim_scale.per_dim_scale', 'stacked_xf.15.attn.qkv_proj.weight', 'stacked_xf.15.attn.query_ln.scale', 'stacked_xf.15.ff0.weight', 'stacked_xf.15.ff1.weight', 'stacked_xf.15.post_attn_ln.scale', 'stacked_xf.15.post_ff_ln.scale', 'stacked_xf.15.pre_attn_ln.scale', 'stacked_xf.15.pre_ff_ln.scale', 'stacked_xf.16.attn.key_ln.scale', 'stacked_xf.16.attn.out.weight', 'stacked_xf.16.attn.per_dim_scale.per_dim_scale', 'stacked_xf.16.attn.qkv_proj.weight', 'stacked_xf.16.attn.query_ln.scale', 'stacked_xf.16.ff0.weight', 'stacked_xf.16.ff1.weight', 'stacked_xf.16.post_attn_ln.scale', 'stacked_xf.16.post_ff_ln.scale', 'stacked_xf.16.pre_attn_ln.scale', 'stacked_xf.16.pre_ff_ln.scale', 'stacked_xf.17.attn.key_ln.scale', 'stacked_xf.17.attn.out.weight', 'stacked_xf.17.attn.per_dim_scale.per_dim_scale', 'stacked_xf.17.attn.qkv_proj.weight', 'stacked_xf.17.attn.query_ln.scale', 'stacked_xf.17.ff0.weight', 'stacked_xf.17.ff1.weight', 'stacked_xf.17.post_attn_ln.scale', 'stacked_xf.17.post_ff_ln.scale', 'stacked_xf.17.pre_attn_ln.scale', 'stacked_xf.17.pre_ff_ln.scale', 'stacked_xf.18.attn.key_ln.scale', 'stacked_xf.18.attn.out.weight', 'stacked_xf.18.attn.per_dim_scale.per_dim_scale', 'stacked_xf.18.attn.qkv_proj.weight', 'stacked_xf.18.attn.query_ln.scale', 'stacked_xf.18.ff0.weight', 'stacked_xf.18.ff1.weight', 'stacked_xf.18.post_attn_ln.scale', 'stacked_xf.18.post_ff_ln.scale', 'stacked_xf.18.pre_attn_ln.scale', 'stacked_xf.18.pre_ff_ln.scale', 'stacked_xf.19.attn.key_ln.scale', 'stacked_xf.19.attn.out.weight', 'stacked_xf.19.attn.per_dim_scale.per_dim_scale', 'stacked_xf.19.attn.qkv_proj.weight', 'stacked_xf.19.attn.query_ln.scale', 'stacked_xf.19.ff0.weight', 'stacked_xf.19.ff1.weight', 'stacked_xf.19.post_attn_ln.scale', 'stacked_xf.19.post_ff_ln.scale', 'stacked_xf.19.pre_attn_ln.scale', 'stacked_xf.19.pre_ff_ln.scale', 'stacked_xf.2.attn.key_ln.scale', 'stacked_xf.2.attn.out.weight', 'stacked_xf.2.attn.per_dim_scale.per_dim_scale', 'stacked_xf.2.attn.qkv_proj.weight', 'stacked_xf.2.attn.query_ln.scale', 'stacked_xf.2.ff0.weight', 'stacked_xf.2.ff1.weight', 'stacked_xf.2.post_attn_ln.scale', 'stacked_xf.2.post_ff_ln.scale', 'stacked_xf.2.pre_attn_ln.scale', 'stacked_xf.2.pre_ff_ln.scale', 'stacked_xf.3.attn.key_ln.scale', 'stacked_xf.3.attn.out.weight', 'stacked_xf.3.attn.per_dim_scale.per_dim_scale', 'stacked_xf.3.attn.qkv_proj.weight', 'stacked_xf.3.attn.query_ln.scale', 'stacked_xf.3.ff0.weight', 'stacked_xf.3.ff1.weight', 'stacked_xf.3.post_attn_ln.scale', 'stacked_xf.3.post_ff_ln.scale', 'stacked_xf.3.pre_attn_ln.scale', 'stacked_xf.3.pre_ff_ln.scale', 'stacked_xf.4.attn.key_ln.scale', 'stacked_xf.4.attn.out.weight', 'stacked_xf.4.attn.per_dim_scale.per_dim_scale', 'stacked_xf.4.attn.qkv_proj.weight', 'stacked_xf.4.attn.query_ln.scale', 'stacked_xf.4.ff0.weight', 'stacked_xf.4.ff1.weight', 'stacked_xf.4.post_attn_ln.scale', 'stacked_xf.4.post_ff_ln.scale', 'stacked_xf.4.pre_attn_ln.scale', 'stacked_xf.4.pre_ff_ln.scale', 'stacked_xf.5.attn.key_ln.scale', 'stacked_xf.5.attn.out.weight', 'stacked_xf.5.attn.per_dim_scale.per_dim_scale', 'stacked_xf.5.attn.qkv_proj.weight', 'stacked_xf.5.attn.query_ln.scale', 'stacked_xf.5.ff0.weight', 'stacked_xf.5.ff1.weight', 'stacked_xf.5.post_attn_ln.scale', 'stacked_xf.5.post_ff_ln.scale', 'stacked_xf.5.pre_attn_ln.scale', 'stacked_xf.5.pre_ff_ln.scale', 'stacked_xf.6.attn.key_ln.scale', 'stacked_xf.6.attn.out.weight', 'stacked_xf.6.attn.per_dim_scale.per_dim_scale', 'stacked_xf.6.attn.qkv_proj.weight', 'stacked_xf.6.attn.query_ln.scale', 'stacked_xf.6.ff0.weight', 'stacked_xf.6.ff1.weight', 'stacked_xf.6.post_attn_ln.scale', 'stacked_xf.6.post_ff_ln.scale', 'stacked_xf.6.pre_attn_ln.scale', 'stacked_xf.6.pre_ff_ln.scale', 'stacked_xf.7.attn.key_ln.scale', 'stacked_xf.7.attn.out.weight', 'stacked_xf.7.attn.per_dim_scale.per_dim_scale', 'stacked_xf.7.attn.qkv_proj.weight', 'stacked_xf.7.attn.query_ln.scale', 'stacked_xf.7.ff0.weight', 'stacked_xf.7.ff1.weight', 'stacked_xf.7.post_attn_ln.scale', 'stacked_xf.7.post_ff_ln.scale', 'stacked_xf.7.pre_attn_ln.scale', 'stacked_xf.7.pre_ff_ln.scale', 'stacked_xf.8.attn.key_ln.scale', 'stacked_xf.8.attn.out.weight', 'stacked_xf.8.attn.per_dim_scale.per_dim_scale', 'stacked_xf.8.attn.qkv_proj.weight', 'stacked_xf.8.attn.query_ln.scale', 'stacked_xf.8.ff0.weight', 'stacked_xf.8.ff1.weight', 'stacked_xf.8.post_attn_ln.scale', 'stacked_xf.8.post_ff_ln.scale', 'stacked_xf.8.pre_attn_ln.scale', 'stacked_xf.8.pre_ff_ln.scale', 'stacked_xf.9.attn.key_ln.scale', 'stacked_xf.9.attn.out.weight', 'stacked_xf.9.attn.per_dim_scale.per_dim_scale', 'stacked_xf.9.attn.qkv_proj.weight', 'stacked_xf.9.attn.query_ln.scale', 'stacked_xf.9.ff0.weight', 'stacked_xf.9.ff1.weight', 'stacked_xf.9.post_attn_ln.scale', 'stacked_xf.9.post_ff_ln.scale', 'stacked_xf.9.pre_attn_ln.scale', 'stacked_xf.9.pre_ff_ln.scale', 'tokenizer.hidden_layer.bias', 'tokenizer.hidden_layer.weight', 'tokenizer.output_layer.bias', 'tokenizer.output_layer.weight', 'tokenizer.residual_layer.bias', 'tokenizer.residual_layer.weight']\n",
            "- This IS expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of TimesFmModelForPrediction were not initialized from the model checkpoint at google/timesfm-2.5-200m-pytorch and are newly initialized: ['decoder.freq_emb.weight', 'decoder.input_ff_layer.input_layer.bias', 'decoder.input_ff_layer.input_layer.weight', 'decoder.input_ff_layer.output_layer.bias', 'decoder.input_ff_layer.output_layer.weight', 'decoder.input_ff_layer.residual_layer.bias', 'decoder.input_ff_layer.residual_layer.weight', 'decoder.layers.0.input_layernorm.weight', 'decoder.layers.0.mlp.down_proj.bias', 'decoder.layers.0.mlp.down_proj.weight', 'decoder.layers.0.mlp.gate_proj.bias', 'decoder.layers.0.mlp.gate_proj.weight', 'decoder.layers.0.mlp.layer_norm.bias', 'decoder.layers.0.mlp.layer_norm.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.o_proj.bias', 'decoder.layers.0.self_attn.o_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.scaling', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.1.input_layernorm.weight', 'decoder.layers.1.mlp.down_proj.bias', 'decoder.layers.1.mlp.down_proj.weight', 'decoder.layers.1.mlp.gate_proj.bias', 'decoder.layers.1.mlp.gate_proj.weight', 'decoder.layers.1.mlp.layer_norm.bias', 'decoder.layers.1.mlp.layer_norm.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.o_proj.bias', 'decoder.layers.1.self_attn.o_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.scaling', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.10.input_layernorm.weight', 'decoder.layers.10.mlp.down_proj.bias', 'decoder.layers.10.mlp.down_proj.weight', 'decoder.layers.10.mlp.gate_proj.bias', 'decoder.layers.10.mlp.gate_proj.weight', 'decoder.layers.10.mlp.layer_norm.bias', 'decoder.layers.10.mlp.layer_norm.weight', 'decoder.layers.10.self_attn.k_proj.bias', 'decoder.layers.10.self_attn.k_proj.weight', 'decoder.layers.10.self_attn.o_proj.bias', 'decoder.layers.10.self_attn.o_proj.weight', 'decoder.layers.10.self_attn.q_proj.bias', 'decoder.layers.10.self_attn.q_proj.weight', 'decoder.layers.10.self_attn.scaling', 'decoder.layers.10.self_attn.v_proj.bias', 'decoder.layers.10.self_attn.v_proj.weight', 'decoder.layers.11.input_layernorm.weight', 'decoder.layers.11.mlp.down_proj.bias', 'decoder.layers.11.mlp.down_proj.weight', 'decoder.layers.11.mlp.gate_proj.bias', 'decoder.layers.11.mlp.gate_proj.weight', 'decoder.layers.11.mlp.layer_norm.bias', 'decoder.layers.11.mlp.layer_norm.weight', 'decoder.layers.11.self_attn.k_proj.bias', 'decoder.layers.11.self_attn.k_proj.weight', 'decoder.layers.11.self_attn.o_proj.bias', 'decoder.layers.11.self_attn.o_proj.weight', 'decoder.layers.11.self_attn.q_proj.bias', 'decoder.layers.11.self_attn.q_proj.weight', 'decoder.layers.11.self_attn.scaling', 'decoder.layers.11.self_attn.v_proj.bias', 'decoder.layers.11.self_attn.v_proj.weight', 'decoder.layers.12.input_layernorm.weight', 'decoder.layers.12.mlp.down_proj.bias', 'decoder.layers.12.mlp.down_proj.weight', 'decoder.layers.12.mlp.gate_proj.bias', 'decoder.layers.12.mlp.gate_proj.weight', 'decoder.layers.12.mlp.layer_norm.bias', 'decoder.layers.12.mlp.layer_norm.weight', 'decoder.layers.12.self_attn.k_proj.bias', 'decoder.layers.12.self_attn.k_proj.weight', 'decoder.layers.12.self_attn.o_proj.bias', 'decoder.layers.12.self_attn.o_proj.weight', 'decoder.layers.12.self_attn.q_proj.bias', 'decoder.layers.12.self_attn.q_proj.weight', 'decoder.layers.12.self_attn.scaling', 'decoder.layers.12.self_attn.v_proj.bias', 'decoder.layers.12.self_attn.v_proj.weight', 'decoder.layers.13.input_layernorm.weight', 'decoder.layers.13.mlp.down_proj.bias', 'decoder.layers.13.mlp.down_proj.weight', 'decoder.layers.13.mlp.gate_proj.bias', 'decoder.layers.13.mlp.gate_proj.weight', 'decoder.layers.13.mlp.layer_norm.bias', 'decoder.layers.13.mlp.layer_norm.weight', 'decoder.layers.13.self_attn.k_proj.bias', 'decoder.layers.13.self_attn.k_proj.weight', 'decoder.layers.13.self_attn.o_proj.bias', 'decoder.layers.13.self_attn.o_proj.weight', 'decoder.layers.13.self_attn.q_proj.bias', 'decoder.layers.13.self_attn.q_proj.weight', 'decoder.layers.13.self_attn.scaling', 'decoder.layers.13.self_attn.v_proj.bias', 'decoder.layers.13.self_attn.v_proj.weight', 'decoder.layers.14.input_layernorm.weight', 'decoder.layers.14.mlp.down_proj.bias', 'decoder.layers.14.mlp.down_proj.weight', 'decoder.layers.14.mlp.gate_proj.bias', 'decoder.layers.14.mlp.gate_proj.weight', 'decoder.layers.14.mlp.layer_norm.bias', 'decoder.layers.14.mlp.layer_norm.weight', 'decoder.layers.14.self_attn.k_proj.bias', 'decoder.layers.14.self_attn.k_proj.weight', 'decoder.layers.14.self_attn.o_proj.bias', 'decoder.layers.14.self_attn.o_proj.weight', 'decoder.layers.14.self_attn.q_proj.bias', 'decoder.layers.14.self_attn.q_proj.weight', 'decoder.layers.14.self_attn.scaling', 'decoder.layers.14.self_attn.v_proj.bias', 'decoder.layers.14.self_attn.v_proj.weight', 'decoder.layers.15.input_layernorm.weight', 'decoder.layers.15.mlp.down_proj.bias', 'decoder.layers.15.mlp.down_proj.weight', 'decoder.layers.15.mlp.gate_proj.bias', 'decoder.layers.15.mlp.gate_proj.weight', 'decoder.layers.15.mlp.layer_norm.bias', 'decoder.layers.15.mlp.layer_norm.weight', 'decoder.layers.15.self_attn.k_proj.bias', 'decoder.layers.15.self_attn.k_proj.weight', 'decoder.layers.15.self_attn.o_proj.bias', 'decoder.layers.15.self_attn.o_proj.weight', 'decoder.layers.15.self_attn.q_proj.bias', 'decoder.layers.15.self_attn.q_proj.weight', 'decoder.layers.15.self_attn.scaling', 'decoder.layers.15.self_attn.v_proj.bias', 'decoder.layers.15.self_attn.v_proj.weight', 'decoder.layers.16.input_layernorm.weight', 'decoder.layers.16.mlp.down_proj.bias', 'decoder.layers.16.mlp.down_proj.weight', 'decoder.layers.16.mlp.gate_proj.bias', 'decoder.layers.16.mlp.gate_proj.weight', 'decoder.layers.16.mlp.layer_norm.bias', 'decoder.layers.16.mlp.layer_norm.weight', 'decoder.layers.16.self_attn.k_proj.bias', 'decoder.layers.16.self_attn.k_proj.weight', 'decoder.layers.16.self_attn.o_proj.bias', 'decoder.layers.16.self_attn.o_proj.weight', 'decoder.layers.16.self_attn.q_proj.bias', 'decoder.layers.16.self_attn.q_proj.weight', 'decoder.layers.16.self_attn.scaling', 'decoder.layers.16.self_attn.v_proj.bias', 'decoder.layers.16.self_attn.v_proj.weight', 'decoder.layers.17.input_layernorm.weight', 'decoder.layers.17.mlp.down_proj.bias', 'decoder.layers.17.mlp.down_proj.weight', 'decoder.layers.17.mlp.gate_proj.bias', 'decoder.layers.17.mlp.gate_proj.weight', 'decoder.layers.17.mlp.layer_norm.bias', 'decoder.layers.17.mlp.layer_norm.weight', 'decoder.layers.17.self_attn.k_proj.bias', 'decoder.layers.17.self_attn.k_proj.weight', 'decoder.layers.17.self_attn.o_proj.bias', 'decoder.layers.17.self_attn.o_proj.weight', 'decoder.layers.17.self_attn.q_proj.bias', 'decoder.layers.17.self_attn.q_proj.weight', 'decoder.layers.17.self_attn.scaling', 'decoder.layers.17.self_attn.v_proj.bias', 'decoder.layers.17.self_attn.v_proj.weight', 'decoder.layers.18.input_layernorm.weight', 'decoder.layers.18.mlp.down_proj.bias', 'decoder.layers.18.mlp.down_proj.weight', 'decoder.layers.18.mlp.gate_proj.bias', 'decoder.layers.18.mlp.gate_proj.weight', 'decoder.layers.18.mlp.layer_norm.bias', 'decoder.layers.18.mlp.layer_norm.weight', 'decoder.layers.18.self_attn.k_proj.bias', 'decoder.layers.18.self_attn.k_proj.weight', 'decoder.layers.18.self_attn.o_proj.bias', 'decoder.layers.18.self_attn.o_proj.weight', 'decoder.layers.18.self_attn.q_proj.bias', 'decoder.layers.18.self_attn.q_proj.weight', 'decoder.layers.18.self_attn.scaling', 'decoder.layers.18.self_attn.v_proj.bias', 'decoder.layers.18.self_attn.v_proj.weight', 'decoder.layers.19.input_layernorm.weight', 'decoder.layers.19.mlp.down_proj.bias', 'decoder.layers.19.mlp.down_proj.weight', 'decoder.layers.19.mlp.gate_proj.bias', 'decoder.layers.19.mlp.gate_proj.weight', 'decoder.layers.19.mlp.layer_norm.bias', 'decoder.layers.19.mlp.layer_norm.weight', 'decoder.layers.19.self_attn.k_proj.bias', 'decoder.layers.19.self_attn.k_proj.weight', 'decoder.layers.19.self_attn.o_proj.bias', 'decoder.layers.19.self_attn.o_proj.weight', 'decoder.layers.19.self_attn.q_proj.bias', 'decoder.layers.19.self_attn.q_proj.weight', 'decoder.layers.19.self_attn.scaling', 'decoder.layers.19.self_attn.v_proj.bias', 'decoder.layers.19.self_attn.v_proj.weight', 'decoder.layers.2.input_layernorm.weight', 'decoder.layers.2.mlp.down_proj.bias', 'decoder.layers.2.mlp.down_proj.weight', 'decoder.layers.2.mlp.gate_proj.bias', 'decoder.layers.2.mlp.gate_proj.weight', 'decoder.layers.2.mlp.layer_norm.bias', 'decoder.layers.2.mlp.layer_norm.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.o_proj.bias', 'decoder.layers.2.self_attn.o_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.scaling', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.3.input_layernorm.weight', 'decoder.layers.3.mlp.down_proj.bias', 'decoder.layers.3.mlp.down_proj.weight', 'decoder.layers.3.mlp.gate_proj.bias', 'decoder.layers.3.mlp.gate_proj.weight', 'decoder.layers.3.mlp.layer_norm.bias', 'decoder.layers.3.mlp.layer_norm.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.o_proj.bias', 'decoder.layers.3.self_attn.o_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.scaling', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.4.input_layernorm.weight', 'decoder.layers.4.mlp.down_proj.bias', 'decoder.layers.4.mlp.down_proj.weight', 'decoder.layers.4.mlp.gate_proj.bias', 'decoder.layers.4.mlp.gate_proj.weight', 'decoder.layers.4.mlp.layer_norm.bias', 'decoder.layers.4.mlp.layer_norm.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.o_proj.bias', 'decoder.layers.4.self_attn.o_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.scaling', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.5.input_layernorm.weight', 'decoder.layers.5.mlp.down_proj.bias', 'decoder.layers.5.mlp.down_proj.weight', 'decoder.layers.5.mlp.gate_proj.bias', 'decoder.layers.5.mlp.gate_proj.weight', 'decoder.layers.5.mlp.layer_norm.bias', 'decoder.layers.5.mlp.layer_norm.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.o_proj.bias', 'decoder.layers.5.self_attn.o_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.scaling', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.6.input_layernorm.weight', 'decoder.layers.6.mlp.down_proj.bias', 'decoder.layers.6.mlp.down_proj.weight', 'decoder.layers.6.mlp.gate_proj.bias', 'decoder.layers.6.mlp.gate_proj.weight', 'decoder.layers.6.mlp.layer_norm.bias', 'decoder.layers.6.mlp.layer_norm.weight', 'decoder.layers.6.self_attn.k_proj.bias', 'decoder.layers.6.self_attn.k_proj.weight', 'decoder.layers.6.self_attn.o_proj.bias', 'decoder.layers.6.self_attn.o_proj.weight', 'decoder.layers.6.self_attn.q_proj.bias', 'decoder.layers.6.self_attn.q_proj.weight', 'decoder.layers.6.self_attn.scaling', 'decoder.layers.6.self_attn.v_proj.bias', 'decoder.layers.6.self_attn.v_proj.weight', 'decoder.layers.7.input_layernorm.weight', 'decoder.layers.7.mlp.down_proj.bias', 'decoder.layers.7.mlp.down_proj.weight', 'decoder.layers.7.mlp.gate_proj.bias', 'decoder.layers.7.mlp.gate_proj.weight', 'decoder.layers.7.mlp.layer_norm.bias', 'decoder.layers.7.mlp.layer_norm.weight', 'decoder.layers.7.self_attn.k_proj.bias', 'decoder.layers.7.self_attn.k_proj.weight', 'decoder.layers.7.self_attn.o_proj.bias', 'decoder.layers.7.self_attn.o_proj.weight', 'decoder.layers.7.self_attn.q_proj.bias', 'decoder.layers.7.self_attn.q_proj.weight', 'decoder.layers.7.self_attn.scaling', 'decoder.layers.7.self_attn.v_proj.bias', 'decoder.layers.7.self_attn.v_proj.weight', 'decoder.layers.8.input_layernorm.weight', 'decoder.layers.8.mlp.down_proj.bias', 'decoder.layers.8.mlp.down_proj.weight', 'decoder.layers.8.mlp.gate_proj.bias', 'decoder.layers.8.mlp.gate_proj.weight', 'decoder.layers.8.mlp.layer_norm.bias', 'decoder.layers.8.mlp.layer_norm.weight', 'decoder.layers.8.self_attn.k_proj.bias', 'decoder.layers.8.self_attn.k_proj.weight', 'decoder.layers.8.self_attn.o_proj.bias', 'decoder.layers.8.self_attn.o_proj.weight', 'decoder.layers.8.self_attn.q_proj.bias', 'decoder.layers.8.self_attn.q_proj.weight', 'decoder.layers.8.self_attn.scaling', 'decoder.layers.8.self_attn.v_proj.bias', 'decoder.layers.8.self_attn.v_proj.weight', 'decoder.layers.9.input_layernorm.weight', 'decoder.layers.9.mlp.down_proj.bias', 'decoder.layers.9.mlp.down_proj.weight', 'decoder.layers.9.mlp.gate_proj.bias', 'decoder.layers.9.mlp.gate_proj.weight', 'decoder.layers.9.mlp.layer_norm.bias', 'decoder.layers.9.mlp.layer_norm.weight', 'decoder.layers.9.self_attn.k_proj.bias', 'decoder.layers.9.self_attn.k_proj.weight', 'decoder.layers.9.self_attn.o_proj.bias', 'decoder.layers.9.self_attn.o_proj.weight', 'decoder.layers.9.self_attn.q_proj.bias', 'decoder.layers.9.self_attn.q_proj.weight', 'decoder.layers.9.self_attn.scaling', 'decoder.layers.9.self_attn.v_proj.bias', 'decoder.layers.9.self_attn.v_proj.weight', 'horizon_ff_layer.input_layer.bias', 'horizon_ff_layer.input_layer.weight', 'horizon_ff_layer.output_layer.bias', 'horizon_ff_layer.output_layer.weight', 'horizon_ff_layer.residual_layer.bias', 'horizon_ff_layer.residual_layer.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n",
            "  Epoch 1/100 train_loss=0.5530 train_acc=0.8340 eval_loss=0.2239 eval_acc=0.9384 (best)\n",
            "  Epoch 2/100 train_loss=0.1976 train_acc=0.9340 eval_loss=0.2425 eval_acc=0.9360 \n",
            "  Epoch 3/100 train_loss=0.1207 train_acc=0.9520 eval_loss=0.2304 eval_acc=0.9411 \n",
            "  Epoch 4/100 train_loss=0.1062 train_acc=0.9580 eval_loss=0.2864 eval_acc=0.9387 \n",
            "  Epoch 5/100 train_loss=0.0720 train_acc=0.9820 eval_loss=0.2802 eval_acc=0.9189 \n",
            "  Epoch 6/100 train_loss=0.0409 train_acc=0.9800 eval_loss=0.3523 eval_acc=0.9416 \n",
            "  Epoch 7/100 train_loss=0.0484 train_acc=0.9880 eval_loss=0.3035 eval_acc=0.9331 \n",
            "  Epoch 8/100 train_loss=0.0044 train_acc=1.0000 eval_loss=0.3096 eval_acc=0.9264 \n",
            "  Epoch 9/100 train_loss=0.0019 train_acc=1.0000 eval_loss=0.4297 eval_acc=0.9387 \n",
            "  Epoch 10/100 train_loss=0.0003 train_acc=1.0000 eval_loss=0.4511 eval_acc=0.9427 \n",
            "  Epoch 11/100 train_loss=0.0001 train_acc=1.0000 eval_loss=0.4610 eval_acc=0.9444 \n",
            "  Early stopping on google/timesfm-2.5-200m-pytorch: no improvement for 10 epochs (best epoch = 1)\n",
            "    tfm[google/timesfm-2.5-200m-pytorch] train_acc=0.8340 eval_acc=0.94444444444444441977282167499652132391929626\n",
            "    mrh_acc=0.9456 mr+h+kg_acc=0.9471 kg_acc=0.9484 ensemble=0.9476 (w=0.60)\n",
            "  Split 1/1 - accuracy=0.9476 time=1039.7s\n",
            "Completed ECG5000: Mean Acc=0.9476\n",
            "\n",
            "=== 26/109 ECGFiveDays ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n",
            "    Gate split 1/5: baseline_loss=0.1371 adaptive_loss=0.0845\n",
            "    Gate split 2/5: baseline_loss=0.2443 adaptive_loss=0.2210\n",
            "    Gate split 3/5: baseline_loss=0.2437 adaptive_loss=0.3516\n",
            "    Gate split 4/5: baseline_loss=0.2655 adaptive_loss=0.2923\n",
            "    Gate split 5/5: baseline_loss=0.2730 adaptive_loss=0.2521\n",
            "  Decision: Adaptive kept (loss 0.2403 vs baseline 0.2327, delta=+0.0076 <= +0.0200); savgol(window=7, poly=2) - high noise (std_diff)\n",
            "Error processing ECGFiveDays: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n",
            "\n",
            "=== 27/109 ElectricDevices ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 556, in main\n",
            "    results = evaluate_dataset_per_split(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 429, in evaluate_dataset_per_split\n",
            "    X_train_extra = np.concatenate([X_train_all, all_dec_train], axis=1)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "ValueError: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n",
            "    Gate split 1/5: baseline_loss=0.5373 adaptive_loss=0.6411\n",
            "    Gate split 2/5: baseline_loss=0.7806 adaptive_loss=0.7910\n",
            "    Gate split 3/5: baseline_loss=0.4469 adaptive_loss=0.5188\n",
            "    Gate split 4/5: baseline_loss=0.6641 adaptive_loss=0.7420\n",
            "    Gate split 5/5: baseline_loss=0.6926 adaptive_loss=0.7731\n",
            "  Decision: Adaptive rejected (loss 0.6932 vs baseline 0.6243, delta=+0.0689 > +0.0200); savgol(window=5, poly=2) - high noise (std_diff)\n",
            "\n",
            "=== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at google/timesfm-2.5-200m-pytorch were not used when initializing TimesFmModelForPrediction: ['output_projection_point.hidden_layer.weight', 'output_projection_point.output_layer.weight', 'output_projection_point.residual_layer.weight', 'output_projection_quantiles.hidden_layer.weight', 'output_projection_quantiles.output_layer.weight', 'output_projection_quantiles.residual_layer.weight', 'stacked_xf.0.attn.key_ln.scale', 'stacked_xf.0.attn.out.weight', 'stacked_xf.0.attn.per_dim_scale.per_dim_scale', 'stacked_xf.0.attn.qkv_proj.weight', 'stacked_xf.0.attn.query_ln.scale', 'stacked_xf.0.ff0.weight', 'stacked_xf.0.ff1.weight', 'stacked_xf.0.post_attn_ln.scale', 'stacked_xf.0.post_ff_ln.scale', 'stacked_xf.0.pre_attn_ln.scale', 'stacked_xf.0.pre_ff_ln.scale', 'stacked_xf.1.attn.key_ln.scale', 'stacked_xf.1.attn.out.weight', 'stacked_xf.1.attn.per_dim_scale.per_dim_scale', 'stacked_xf.1.attn.qkv_proj.weight', 'stacked_xf.1.attn.query_ln.scale', 'stacked_xf.1.ff0.weight', 'stacked_xf.1.ff1.weight', 'stacked_xf.1.post_attn_ln.scale', 'stacked_xf.1.post_ff_ln.scale', 'stacked_xf.1.pre_attn_ln.scale', 'stacked_xf.1.pre_ff_ln.scale', 'stacked_xf.10.attn.key_ln.scale', 'stacked_xf.10.attn.out.weight', 'stacked_xf.10.attn.per_dim_scale.per_dim_scale', 'stacked_xf.10.attn.qkv_proj.weight', 'stacked_xf.10.attn.query_ln.scale', 'stacked_xf.10.ff0.weight', 'stacked_xf.10.ff1.weight', 'stacked_xf.10.post_attn_ln.scale', 'stacked_xf.10.post_ff_ln.scale', 'stacked_xf.10.pre_attn_ln.scale', 'stacked_xf.10.pre_ff_ln.scale', 'stacked_xf.11.attn.key_ln.scale', 'stacked_xf.11.attn.out.weight', 'stacked_xf.11.attn.per_dim_scale.per_dim_scale', 'stacked_xf.11.attn.qkv_proj.weight', 'stacked_xf.11.attn.query_ln.scale', 'stacked_xf.11.ff0.weight', 'stacked_xf.11.ff1.weight', 'stacked_xf.11.post_attn_ln.scale', 'stacked_xf.11.post_ff_ln.scale', 'stacked_xf.11.pre_attn_ln.scale', 'stacked_xf.11.pre_ff_ln.scale', 'stacked_xf.12.attn.key_ln.scale', 'stacked_xf.12.attn.out.weight', 'stacked_xf.12.attn.per_dim_scale.per_dim_scale', 'stacked_xf.12.attn.qkv_proj.weight', 'stacked_xf.12.attn.query_ln.scale', 'stacked_xf.12.ff0.weight', 'stacked_xf.12.ff1.weight', 'stacked_xf.12.post_attn_ln.scale', 'stacked_xf.12.post_ff_ln.scale', 'stacked_xf.12.pre_attn_ln.scale', 'stacked_xf.12.pre_ff_ln.scale', 'stacked_xf.13.attn.key_ln.scale', 'stacked_xf.13.attn.out.weight', 'stacked_xf.13.attn.per_dim_scale.per_dim_scale', 'stacked_xf.13.attn.qkv_proj.weight', 'stacked_xf.13.attn.query_ln.scale', 'stacked_xf.13.ff0.weight', 'stacked_xf.13.ff1.weight', 'stacked_xf.13.post_attn_ln.scale', 'stacked_xf.13.post_ff_ln.scale', 'stacked_xf.13.pre_attn_ln.scale', 'stacked_xf.13.pre_ff_ln.scale', 'stacked_xf.14.attn.key_ln.scale', 'stacked_xf.14.attn.out.weight', 'stacked_xf.14.attn.per_dim_scale.per_dim_scale', 'stacked_xf.14.attn.qkv_proj.weight', 'stacked_xf.14.attn.query_ln.scale', 'stacked_xf.14.ff0.weight', 'stacked_xf.14.ff1.weight', 'stacked_xf.14.post_attn_ln.scale', 'stacked_xf.14.post_ff_ln.scale', 'stacked_xf.14.pre_attn_ln.scale', 'stacked_xf.14.pre_ff_ln.scale', 'stacked_xf.15.attn.key_ln.scale', 'stacked_xf.15.attn.out.weight', 'stacked_xf.15.attn.per_dim_scale.per_dim_scale', 'stacked_xf.15.attn.qkv_proj.weight', 'stacked_xf.15.attn.query_ln.scale', 'stacked_xf.15.ff0.weight', 'stacked_xf.15.ff1.weight', 'stacked_xf.15.post_attn_ln.scale', 'stacked_xf.15.post_ff_ln.scale', 'stacked_xf.15.pre_attn_ln.scale', 'stacked_xf.15.pre_ff_ln.scale', 'stacked_xf.16.attn.key_ln.scale', 'stacked_xf.16.attn.out.weight', 'stacked_xf.16.attn.per_dim_scale.per_dim_scale', 'stacked_xf.16.attn.qkv_proj.weight', 'stacked_xf.16.attn.query_ln.scale', 'stacked_xf.16.ff0.weight', 'stacked_xf.16.ff1.weight', 'stacked_xf.16.post_attn_ln.scale', 'stacked_xf.16.post_ff_ln.scale', 'stacked_xf.16.pre_attn_ln.scale', 'stacked_xf.16.pre_ff_ln.scale', 'stacked_xf.17.attn.key_ln.scale', 'stacked_xf.17.attn.out.weight', 'stacked_xf.17.attn.per_dim_scale.per_dim_scale', 'stacked_xf.17.attn.qkv_proj.weight', 'stacked_xf.17.attn.query_ln.scale', 'stacked_xf.17.ff0.weight', 'stacked_xf.17.ff1.weight', 'stacked_xf.17.post_attn_ln.scale', 'stacked_xf.17.post_ff_ln.scale', 'stacked_xf.17.pre_attn_ln.scale', 'stacked_xf.17.pre_ff_ln.scale', 'stacked_xf.18.attn.key_ln.scale', 'stacked_xf.18.attn.out.weight', 'stacked_xf.18.attn.per_dim_scale.per_dim_scale', 'stacked_xf.18.attn.qkv_proj.weight', 'stacked_xf.18.attn.query_ln.scale', 'stacked_xf.18.ff0.weight', 'stacked_xf.18.ff1.weight', 'stacked_xf.18.post_attn_ln.scale', 'stacked_xf.18.post_ff_ln.scale', 'stacked_xf.18.pre_attn_ln.scale', 'stacked_xf.18.pre_ff_ln.scale', 'stacked_xf.19.attn.key_ln.scale', 'stacked_xf.19.attn.out.weight', 'stacked_xf.19.attn.per_dim_scale.per_dim_scale', 'stacked_xf.19.attn.qkv_proj.weight', 'stacked_xf.19.attn.query_ln.scale', 'stacked_xf.19.ff0.weight', 'stacked_xf.19.ff1.weight', 'stacked_xf.19.post_attn_ln.scale', 'stacked_xf.19.post_ff_ln.scale', 'stacked_xf.19.pre_attn_ln.scale', 'stacked_xf.19.pre_ff_ln.scale', 'stacked_xf.2.attn.key_ln.scale', 'stacked_xf.2.attn.out.weight', 'stacked_xf.2.attn.per_dim_scale.per_dim_scale', 'stacked_xf.2.attn.qkv_proj.weight', 'stacked_xf.2.attn.query_ln.scale', 'stacked_xf.2.ff0.weight', 'stacked_xf.2.ff1.weight', 'stacked_xf.2.post_attn_ln.scale', 'stacked_xf.2.post_ff_ln.scale', 'stacked_xf.2.pre_attn_ln.scale', 'stacked_xf.2.pre_ff_ln.scale', 'stacked_xf.3.attn.key_ln.scale', 'stacked_xf.3.attn.out.weight', 'stacked_xf.3.attn.per_dim_scale.per_dim_scale', 'stacked_xf.3.attn.qkv_proj.weight', 'stacked_xf.3.attn.query_ln.scale', 'stacked_xf.3.ff0.weight', 'stacked_xf.3.ff1.weight', 'stacked_xf.3.post_attn_ln.scale', 'stacked_xf.3.post_ff_ln.scale', 'stacked_xf.3.pre_attn_ln.scale', 'stacked_xf.3.pre_ff_ln.scale', 'stacked_xf.4.attn.key_ln.scale', 'stacked_xf.4.attn.out.weight', 'stacked_xf.4.attn.per_dim_scale.per_dim_scale', 'stacked_xf.4.attn.qkv_proj.weight', 'stacked_xf.4.attn.query_ln.scale', 'stacked_xf.4.ff0.weight', 'stacked_xf.4.ff1.weight', 'stacked_xf.4.post_attn_ln.scale', 'stacked_xf.4.post_ff_ln.scale', 'stacked_xf.4.pre_attn_ln.scale', 'stacked_xf.4.pre_ff_ln.scale', 'stacked_xf.5.attn.key_ln.scale', 'stacked_xf.5.attn.out.weight', 'stacked_xf.5.attn.per_dim_scale.per_dim_scale', 'stacked_xf.5.attn.qkv_proj.weight', 'stacked_xf.5.attn.query_ln.scale', 'stacked_xf.5.ff0.weight', 'stacked_xf.5.ff1.weight', 'stacked_xf.5.post_attn_ln.scale', 'stacked_xf.5.post_ff_ln.scale', 'stacked_xf.5.pre_attn_ln.scale', 'stacked_xf.5.pre_ff_ln.scale', 'stacked_xf.6.attn.key_ln.scale', 'stacked_xf.6.attn.out.weight', 'stacked_xf.6.attn.per_dim_scale.per_dim_scale', 'stacked_xf.6.attn.qkv_proj.weight', 'stacked_xf.6.attn.query_ln.scale', 'stacked_xf.6.ff0.weight', 'stacked_xf.6.ff1.weight', 'stacked_xf.6.post_attn_ln.scale', 'stacked_xf.6.post_ff_ln.scale', 'stacked_xf.6.pre_attn_ln.scale', 'stacked_xf.6.pre_ff_ln.scale', 'stacked_xf.7.attn.key_ln.scale', 'stacked_xf.7.attn.out.weight', 'stacked_xf.7.attn.per_dim_scale.per_dim_scale', 'stacked_xf.7.attn.qkv_proj.weight', 'stacked_xf.7.attn.query_ln.scale', 'stacked_xf.7.ff0.weight', 'stacked_xf.7.ff1.weight', 'stacked_xf.7.post_attn_ln.scale', 'stacked_xf.7.post_ff_ln.scale', 'stacked_xf.7.pre_attn_ln.scale', 'stacked_xf.7.pre_ff_ln.scale', 'stacked_xf.8.attn.key_ln.scale', 'stacked_xf.8.attn.out.weight', 'stacked_xf.8.attn.per_dim_scale.per_dim_scale', 'stacked_xf.8.attn.qkv_proj.weight', 'stacked_xf.8.attn.query_ln.scale', 'stacked_xf.8.ff0.weight', 'stacked_xf.8.ff1.weight', 'stacked_xf.8.post_attn_ln.scale', 'stacked_xf.8.post_ff_ln.scale', 'stacked_xf.8.pre_attn_ln.scale', 'stacked_xf.8.pre_ff_ln.scale', 'stacked_xf.9.attn.key_ln.scale', 'stacked_xf.9.attn.out.weight', 'stacked_xf.9.attn.per_dim_scale.per_dim_scale', 'stacked_xf.9.attn.qkv_proj.weight', 'stacked_xf.9.attn.query_ln.scale', 'stacked_xf.9.ff0.weight', 'stacked_xf.9.ff1.weight', 'stacked_xf.9.post_attn_ln.scale', 'stacked_xf.9.post_ff_ln.scale', 'stacked_xf.9.pre_attn_ln.scale', 'stacked_xf.9.pre_ff_ln.scale', 'tokenizer.hidden_layer.bias', 'tokenizer.hidden_layer.weight', 'tokenizer.output_layer.bias', 'tokenizer.output_layer.weight', 'tokenizer.residual_layer.bias', 'tokenizer.residual_layer.weight']\n",
            "- This IS expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of TimesFmModelForPrediction were not initialized from the model checkpoint at google/timesfm-2.5-200m-pytorch and are newly initialized: ['decoder.freq_emb.weight', 'decoder.input_ff_layer.input_layer.bias', 'decoder.input_ff_layer.input_layer.weight', 'decoder.input_ff_layer.output_layer.bias', 'decoder.input_ff_layer.output_layer.weight', 'decoder.input_ff_layer.residual_layer.bias', 'decoder.input_ff_layer.residual_layer.weight', 'decoder.layers.0.input_layernorm.weight', 'decoder.layers.0.mlp.down_proj.bias', 'decoder.layers.0.mlp.down_proj.weight', 'decoder.layers.0.mlp.gate_proj.bias', 'decoder.layers.0.mlp.gate_proj.weight', 'decoder.layers.0.mlp.layer_norm.bias', 'decoder.layers.0.mlp.layer_norm.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.o_proj.bias', 'decoder.layers.0.self_attn.o_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.scaling', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.1.input_layernorm.weight', 'decoder.layers.1.mlp.down_proj.bias', 'decoder.layers.1.mlp.down_proj.weight', 'decoder.layers.1.mlp.gate_proj.bias', 'decoder.layers.1.mlp.gate_proj.weight', 'decoder.layers.1.mlp.layer_norm.bias', 'decoder.layers.1.mlp.layer_norm.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.o_proj.bias', 'decoder.layers.1.self_attn.o_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.scaling', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.10.input_layernorm.weight', 'decoder.layers.10.mlp.down_proj.bias', 'decoder.layers.10.mlp.down_proj.weight', 'decoder.layers.10.mlp.gate_proj.bias', 'decoder.layers.10.mlp.gate_proj.weight', 'decoder.layers.10.mlp.layer_norm.bias', 'decoder.layers.10.mlp.layer_norm.weight', 'decoder.layers.10.self_attn.k_proj.bias', 'decoder.layers.10.self_attn.k_proj.weight', 'decoder.layers.10.self_attn.o_proj.bias', 'decoder.layers.10.self_attn.o_proj.weight', 'decoder.layers.10.self_attn.q_proj.bias', 'decoder.layers.10.self_attn.q_proj.weight', 'decoder.layers.10.self_attn.scaling', 'decoder.layers.10.self_attn.v_proj.bias', 'decoder.layers.10.self_attn.v_proj.weight', 'decoder.layers.11.input_layernorm.weight', 'decoder.layers.11.mlp.down_proj.bias', 'decoder.layers.11.mlp.down_proj.weight', 'decoder.layers.11.mlp.gate_proj.bias', 'decoder.layers.11.mlp.gate_proj.weight', 'decoder.layers.11.mlp.layer_norm.bias', 'decoder.layers.11.mlp.layer_norm.weight', 'decoder.layers.11.self_attn.k_proj.bias', 'decoder.layers.11.self_attn.k_proj.weight', 'decoder.layers.11.self_attn.o_proj.bias', 'decoder.layers.11.self_attn.o_proj.weight', 'decoder.layers.11.self_attn.q_proj.bias', 'decoder.layers.11.self_attn.q_proj.weight', 'decoder.layers.11.self_attn.scaling', 'decoder.layers.11.self_attn.v_proj.bias', 'decoder.layers.11.self_attn.v_proj.weight', 'decoder.layers.12.input_layernorm.weight', 'decoder.layers.12.mlp.down_proj.bias', 'decoder.layers.12.mlp.down_proj.weight', 'decoder.layers.12.mlp.gate_proj.bias', 'decoder.layers.12.mlp.gate_proj.weight', 'decoder.layers.12.mlp.layer_norm.bias', 'decoder.layers.12.mlp.layer_norm.weight', 'decoder.layers.12.self_attn.k_proj.bias', 'decoder.layers.12.self_attn.k_proj.weight', 'decoder.layers.12.self_attn.o_proj.bias', 'decoder.layers.12.self_attn.o_proj.weight', 'decoder.layers.12.self_attn.q_proj.bias', 'decoder.layers.12.self_attn.q_proj.weight', 'decoder.layers.12.self_attn.scaling', 'decoder.layers.12.self_attn.v_proj.bias', 'decoder.layers.12.self_attn.v_proj.weight', 'decoder.layers.13.input_layernorm.weight', 'decoder.layers.13.mlp.down_proj.bias', 'decoder.layers.13.mlp.down_proj.weight', 'decoder.layers.13.mlp.gate_proj.bias', 'decoder.layers.13.mlp.gate_proj.weight', 'decoder.layers.13.mlp.layer_norm.bias', 'decoder.layers.13.mlp.layer_norm.weight', 'decoder.layers.13.self_attn.k_proj.bias', 'decoder.layers.13.self_attn.k_proj.weight', 'decoder.layers.13.self_attn.o_proj.bias', 'decoder.layers.13.self_attn.o_proj.weight', 'decoder.layers.13.self_attn.q_proj.bias', 'decoder.layers.13.self_attn.q_proj.weight', 'decoder.layers.13.self_attn.scaling', 'decoder.layers.13.self_attn.v_proj.bias', 'decoder.layers.13.self_attn.v_proj.weight', 'decoder.layers.14.input_layernorm.weight', 'decoder.layers.14.mlp.down_proj.bias', 'decoder.layers.14.mlp.down_proj.weight', 'decoder.layers.14.mlp.gate_proj.bias', 'decoder.layers.14.mlp.gate_proj.weight', 'decoder.layers.14.mlp.layer_norm.bias', 'decoder.layers.14.mlp.layer_norm.weight', 'decoder.layers.14.self_attn.k_proj.bias', 'decoder.layers.14.self_attn.k_proj.weight', 'decoder.layers.14.self_attn.o_proj.bias', 'decoder.layers.14.self_attn.o_proj.weight', 'decoder.layers.14.self_attn.q_proj.bias', 'decoder.layers.14.self_attn.q_proj.weight', 'decoder.layers.14.self_attn.scaling', 'decoder.layers.14.self_attn.v_proj.bias', 'decoder.layers.14.self_attn.v_proj.weight', 'decoder.layers.15.input_layernorm.weight', 'decoder.layers.15.mlp.down_proj.bias', 'decoder.layers.15.mlp.down_proj.weight', 'decoder.layers.15.mlp.gate_proj.bias', 'decoder.layers.15.mlp.gate_proj.weight', 'decoder.layers.15.mlp.layer_norm.bias', 'decoder.layers.15.mlp.layer_norm.weight', 'decoder.layers.15.self_attn.k_proj.bias', 'decoder.layers.15.self_attn.k_proj.weight', 'decoder.layers.15.self_attn.o_proj.bias', 'decoder.layers.15.self_attn.o_proj.weight', 'decoder.layers.15.self_attn.q_proj.bias', 'decoder.layers.15.self_attn.q_proj.weight', 'decoder.layers.15.self_attn.scaling', 'decoder.layers.15.self_attn.v_proj.bias', 'decoder.layers.15.self_attn.v_proj.weight', 'decoder.layers.16.input_layernorm.weight', 'decoder.layers.16.mlp.down_proj.bias', 'decoder.layers.16.mlp.down_proj.weight', 'decoder.layers.16.mlp.gate_proj.bias', 'decoder.layers.16.mlp.gate_proj.weight', 'decoder.layers.16.mlp.layer_norm.bias', 'decoder.layers.16.mlp.layer_norm.weight', 'decoder.layers.16.self_attn.k_proj.bias', 'decoder.layers.16.self_attn.k_proj.weight', 'decoder.layers.16.self_attn.o_proj.bias', 'decoder.layers.16.self_attn.o_proj.weight', 'decoder.layers.16.self_attn.q_proj.bias', 'decoder.layers.16.self_attn.q_proj.weight', 'decoder.layers.16.self_attn.scaling', 'decoder.layers.16.self_attn.v_proj.bias', 'decoder.layers.16.self_attn.v_proj.weight', 'decoder.layers.17.input_layernorm.weight', 'decoder.layers.17.mlp.down_proj.bias', 'decoder.layers.17.mlp.down_proj.weight', 'decoder.layers.17.mlp.gate_proj.bias', 'decoder.layers.17.mlp.gate_proj.weight', 'decoder.layers.17.mlp.layer_norm.bias', 'decoder.layers.17.mlp.layer_norm.weight', 'decoder.layers.17.self_attn.k_proj.bias', 'decoder.layers.17.self_attn.k_proj.weight', 'decoder.layers.17.self_attn.o_proj.bias', 'decoder.layers.17.self_attn.o_proj.weight', 'decoder.layers.17.self_attn.q_proj.bias', 'decoder.layers.17.self_attn.q_proj.weight', 'decoder.layers.17.self_attn.scaling', 'decoder.layers.17.self_attn.v_proj.bias', 'decoder.layers.17.self_attn.v_proj.weight', 'decoder.layers.18.input_layernorm.weight', 'decoder.layers.18.mlp.down_proj.bias', 'decoder.layers.18.mlp.down_proj.weight', 'decoder.layers.18.mlp.gate_proj.bias', 'decoder.layers.18.mlp.gate_proj.weight', 'decoder.layers.18.mlp.layer_norm.bias', 'decoder.layers.18.mlp.layer_norm.weight', 'decoder.layers.18.self_attn.k_proj.bias', 'decoder.layers.18.self_attn.k_proj.weight', 'decoder.layers.18.self_attn.o_proj.bias', 'decoder.layers.18.self_attn.o_proj.weight', 'decoder.layers.18.self_attn.q_proj.bias', 'decoder.layers.18.self_attn.q_proj.weight', 'decoder.layers.18.self_attn.scaling', 'decoder.layers.18.self_attn.v_proj.bias', 'decoder.layers.18.self_attn.v_proj.weight', 'decoder.layers.19.input_layernorm.weight', 'decoder.layers.19.mlp.down_proj.bias', 'decoder.layers.19.mlp.down_proj.weight', 'decoder.layers.19.mlp.gate_proj.bias', 'decoder.layers.19.mlp.gate_proj.weight', 'decoder.layers.19.mlp.layer_norm.bias', 'decoder.layers.19.mlp.layer_norm.weight', 'decoder.layers.19.self_attn.k_proj.bias', 'decoder.layers.19.self_attn.k_proj.weight', 'decoder.layers.19.self_attn.o_proj.bias', 'decoder.layers.19.self_attn.o_proj.weight', 'decoder.layers.19.self_attn.q_proj.bias', 'decoder.layers.19.self_attn.q_proj.weight', 'decoder.layers.19.self_attn.scaling', 'decoder.layers.19.self_attn.v_proj.bias', 'decoder.layers.19.self_attn.v_proj.weight', 'decoder.layers.2.input_layernorm.weight', 'decoder.layers.2.mlp.down_proj.bias', 'decoder.layers.2.mlp.down_proj.weight', 'decoder.layers.2.mlp.gate_proj.bias', 'decoder.layers.2.mlp.gate_proj.weight', 'decoder.layers.2.mlp.layer_norm.bias', 'decoder.layers.2.mlp.layer_norm.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.o_proj.bias', 'decoder.layers.2.self_attn.o_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.scaling', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.3.input_layernorm.weight', 'decoder.layers.3.mlp.down_proj.bias', 'decoder.layers.3.mlp.down_proj.weight', 'decoder.layers.3.mlp.gate_proj.bias', 'decoder.layers.3.mlp.gate_proj.weight', 'decoder.layers.3.mlp.layer_norm.bias', 'decoder.layers.3.mlp.layer_norm.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.o_proj.bias', 'decoder.layers.3.self_attn.o_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.scaling', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.4.input_layernorm.weight', 'decoder.layers.4.mlp.down_proj.bias', 'decoder.layers.4.mlp.down_proj.weight', 'decoder.layers.4.mlp.gate_proj.bias', 'decoder.layers.4.mlp.gate_proj.weight', 'decoder.layers.4.mlp.layer_norm.bias', 'decoder.layers.4.mlp.layer_norm.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.o_proj.bias', 'decoder.layers.4.self_attn.o_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.scaling', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.5.input_layernorm.weight', 'decoder.layers.5.mlp.down_proj.bias', 'decoder.layers.5.mlp.down_proj.weight', 'decoder.layers.5.mlp.gate_proj.bias', 'decoder.layers.5.mlp.gate_proj.weight', 'decoder.layers.5.mlp.layer_norm.bias', 'decoder.layers.5.mlp.layer_norm.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.o_proj.bias', 'decoder.layers.5.self_attn.o_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.scaling', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.6.input_layernorm.weight', 'decoder.layers.6.mlp.down_proj.bias', 'decoder.layers.6.mlp.down_proj.weight', 'decoder.layers.6.mlp.gate_proj.bias', 'decoder.layers.6.mlp.gate_proj.weight', 'decoder.layers.6.mlp.layer_norm.bias', 'decoder.layers.6.mlp.layer_norm.weight', 'decoder.layers.6.self_attn.k_proj.bias', 'decoder.layers.6.self_attn.k_proj.weight', 'decoder.layers.6.self_attn.o_proj.bias', 'decoder.layers.6.self_attn.o_proj.weight', 'decoder.layers.6.self_attn.q_proj.bias', 'decoder.layers.6.self_attn.q_proj.weight', 'decoder.layers.6.self_attn.scaling', 'decoder.layers.6.self_attn.v_proj.bias', 'decoder.layers.6.self_attn.v_proj.weight', 'decoder.layers.7.input_layernorm.weight', 'decoder.layers.7.mlp.down_proj.bias', 'decoder.layers.7.mlp.down_proj.weight', 'decoder.layers.7.mlp.gate_proj.bias', 'decoder.layers.7.mlp.gate_proj.weight', 'decoder.layers.7.mlp.layer_norm.bias', 'decoder.layers.7.mlp.layer_norm.weight', 'decoder.layers.7.self_attn.k_proj.bias', 'decoder.layers.7.self_attn.k_proj.weight', 'decoder.layers.7.self_attn.o_proj.bias', 'decoder.layers.7.self_attn.o_proj.weight', 'decoder.layers.7.self_attn.q_proj.bias', 'decoder.layers.7.self_attn.q_proj.weight', 'decoder.layers.7.self_attn.scaling', 'decoder.layers.7.self_attn.v_proj.bias', 'decoder.layers.7.self_attn.v_proj.weight', 'decoder.layers.8.input_layernorm.weight', 'decoder.layers.8.mlp.down_proj.bias', 'decoder.layers.8.mlp.down_proj.weight', 'decoder.layers.8.mlp.gate_proj.bias', 'decoder.layers.8.mlp.gate_proj.weight', 'decoder.layers.8.mlp.layer_norm.bias', 'decoder.layers.8.mlp.layer_norm.weight', 'decoder.layers.8.self_attn.k_proj.bias', 'decoder.layers.8.self_attn.k_proj.weight', 'decoder.layers.8.self_attn.o_proj.bias', 'decoder.layers.8.self_attn.o_proj.weight', 'decoder.layers.8.self_attn.q_proj.bias', 'decoder.layers.8.self_attn.q_proj.weight', 'decoder.layers.8.self_attn.scaling', 'decoder.layers.8.self_attn.v_proj.bias', 'decoder.layers.8.self_attn.v_proj.weight', 'decoder.layers.9.input_layernorm.weight', 'decoder.layers.9.mlp.down_proj.bias', 'decoder.layers.9.mlp.down_proj.weight', 'decoder.layers.9.mlp.gate_proj.bias', 'decoder.layers.9.mlp.gate_proj.weight', 'decoder.layers.9.mlp.layer_norm.bias', 'decoder.layers.9.mlp.layer_norm.weight', 'decoder.layers.9.self_attn.k_proj.bias', 'decoder.layers.9.self_attn.k_proj.weight', 'decoder.layers.9.self_attn.o_proj.bias', 'decoder.layers.9.self_attn.o_proj.weight', 'decoder.layers.9.self_attn.q_proj.bias', 'decoder.layers.9.self_attn.q_proj.weight', 'decoder.layers.9.self_attn.scaling', 'decoder.layers.9.self_attn.v_proj.bias', 'decoder.layers.9.self_attn.v_proj.weight', 'horizon_ff_layer.input_layer.bias', 'horizon_ff_layer.input_layer.weight', 'horizon_ff_layer.output_layer.bias', 'horizon_ff_layer.output_layer.weight', 'horizon_ff_layer.residual_layer.bias', 'horizon_ff_layer.residual_layer.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n",
            "  Epoch 1/100 train_loss=0.6041 train_acc=0.7967 eval_loss=0.4311 eval_acc=0.8490 (best)\n",
            "  Epoch 2/100 train_loss=0.3827 train_acc=0.8675 eval_loss=0.4564 eval_acc=0.8479 \n",
            "  Epoch 3/100 train_loss=0.3369 train_acc=0.8819 eval_loss=0.4205 eval_acc=0.8666 (best)\n",
            "  Epoch 4/100 train_loss=0.3073 train_acc=0.8870 eval_loss=0.4518 eval_acc=0.8506 \n",
            "  Epoch 5/100 train_loss=0.2810 train_acc=0.9000 eval_loss=0.4067 eval_acc=0.8730 (best)\n",
            "  Epoch 6/100 train_loss=0.2568 train_acc=0.9087 eval_loss=0.4095 eval_acc=0.8724 \n",
            "  Epoch 7/100 train_loss=0.2581 train_acc=0.9089 eval_loss=0.3732 eval_acc=0.8830 (best)\n",
            "  Epoch 8/100 train_loss=0.2418 train_acc=0.9125 eval_loss=0.3473 eval_acc=0.8946 (best)\n",
            "  Epoch 9/100 train_loss=0.2283 train_acc=0.9200 eval_loss=0.3695 eval_acc=0.8969 \n",
            "  Epoch 10/100 train_loss=0.2256 train_acc=0.9188 eval_loss=0.4575 eval_acc=0.8771 \n",
            "  Epoch 11/100 train_loss=0.2212 train_acc=0.9239 eval_loss=0.3661 eval_acc=0.8974 \n",
            "  Epoch 12/100 train_loss=0.2096 train_acc=0.9252 eval_loss=0.4643 eval_acc=0.8815 \n",
            "  Epoch 13/100 train_loss=0.1988 train_acc=0.9304 eval_loss=0.4015 eval_acc=0.8878 \n",
            "  Epoch 14/100 train_loss=0.1760 train_acc=0.9368 eval_loss=0.3769 eval_acc=0.8961 \n",
            "  Epoch 15/100 train_loss=0.1633 train_acc=0.9436 eval_loss=0.4333 eval_acc=0.8955 \n",
            "  Epoch 16/100 train_loss=0.1651 train_acc=0.9420 eval_loss=0.4394 eval_acc=0.8968 \n",
            "  Epoch 17/100 train_loss=0.1605 train_acc=0.9417 eval_loss=0.4232 eval_acc=0.9017 \n",
            "  Epoch 18/100 train_loss=0.1528 train_acc=0.9448 eval_loss=0.5237 eval_acc=0.8782 \n",
            "  Early stopping on google/timesfm-2.5-200m-pytorch: no improvement for 10 epochs (best epoch = 8)\n",
            "    tfm[google/timesfm-2.5-200m-pytorch] train_acc=0.9125 eval_acc=0.87822591103618208308034809306263923645019531\n",
            "    mrh_acc=0.9061 mr+h+kg_acc=0.9144 kg_acc=0.9171 ensemble=0.9173 (w=0.60)\n",
            "  Split 1/1 - accuracy=0.9173 time=9490.4s\n",
            "Completed ElectricDevices: Mean Acc=0.9173\n",
            "\n",
            "=== 28/109 EOGHorizontalSignal ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n",
            "    Gate split 1/5: baseline_loss=0.5176 adaptive_loss=0.5472\n",
            "    Gate split 2/5: baseline_loss=0.4933 adaptive_loss=0.4933\n",
            "    Gate split 3/5: baseline_loss=0.5776 adaptive_loss=0.5652\n",
            "    Gate split 4/5: baseline_loss=0.5477 adaptive_loss=0.5704\n",
            "    Gate split 5/5: baseline_loss=0.5482 adaptive_loss=0.5724\n",
            "  Decision: Adaptive kept (loss 0.5497 vs baseline 0.5369, delta=+0.0128 <= +0.0200); savgol(window=21, poly=3) - high noise (std_diff)\n",
            "\n",
            "=== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at google/timesfm-2.5-200m-pytorch were not used when initializing TimesFmModelForPrediction: ['output_projection_point.hidden_layer.weight', 'output_projection_point.output_layer.weight', 'output_projection_point.residual_layer.weight', 'output_projection_quantiles.hidden_layer.weight', 'output_projection_quantiles.output_layer.weight', 'output_projection_quantiles.residual_layer.weight', 'stacked_xf.0.attn.key_ln.scale', 'stacked_xf.0.attn.out.weight', 'stacked_xf.0.attn.per_dim_scale.per_dim_scale', 'stacked_xf.0.attn.qkv_proj.weight', 'stacked_xf.0.attn.query_ln.scale', 'stacked_xf.0.ff0.weight', 'stacked_xf.0.ff1.weight', 'stacked_xf.0.post_attn_ln.scale', 'stacked_xf.0.post_ff_ln.scale', 'stacked_xf.0.pre_attn_ln.scale', 'stacked_xf.0.pre_ff_ln.scale', 'stacked_xf.1.attn.key_ln.scale', 'stacked_xf.1.attn.out.weight', 'stacked_xf.1.attn.per_dim_scale.per_dim_scale', 'stacked_xf.1.attn.qkv_proj.weight', 'stacked_xf.1.attn.query_ln.scale', 'stacked_xf.1.ff0.weight', 'stacked_xf.1.ff1.weight', 'stacked_xf.1.post_attn_ln.scale', 'stacked_xf.1.post_ff_ln.scale', 'stacked_xf.1.pre_attn_ln.scale', 'stacked_xf.1.pre_ff_ln.scale', 'stacked_xf.10.attn.key_ln.scale', 'stacked_xf.10.attn.out.weight', 'stacked_xf.10.attn.per_dim_scale.per_dim_scale', 'stacked_xf.10.attn.qkv_proj.weight', 'stacked_xf.10.attn.query_ln.scale', 'stacked_xf.10.ff0.weight', 'stacked_xf.10.ff1.weight', 'stacked_xf.10.post_attn_ln.scale', 'stacked_xf.10.post_ff_ln.scale', 'stacked_xf.10.pre_attn_ln.scale', 'stacked_xf.10.pre_ff_ln.scale', 'stacked_xf.11.attn.key_ln.scale', 'stacked_xf.11.attn.out.weight', 'stacked_xf.11.attn.per_dim_scale.per_dim_scale', 'stacked_xf.11.attn.qkv_proj.weight', 'stacked_xf.11.attn.query_ln.scale', 'stacked_xf.11.ff0.weight', 'stacked_xf.11.ff1.weight', 'stacked_xf.11.post_attn_ln.scale', 'stacked_xf.11.post_ff_ln.scale', 'stacked_xf.11.pre_attn_ln.scale', 'stacked_xf.11.pre_ff_ln.scale', 'stacked_xf.12.attn.key_ln.scale', 'stacked_xf.12.attn.out.weight', 'stacked_xf.12.attn.per_dim_scale.per_dim_scale', 'stacked_xf.12.attn.qkv_proj.weight', 'stacked_xf.12.attn.query_ln.scale', 'stacked_xf.12.ff0.weight', 'stacked_xf.12.ff1.weight', 'stacked_xf.12.post_attn_ln.scale', 'stacked_xf.12.post_ff_ln.scale', 'stacked_xf.12.pre_attn_ln.scale', 'stacked_xf.12.pre_ff_ln.scale', 'stacked_xf.13.attn.key_ln.scale', 'stacked_xf.13.attn.out.weight', 'stacked_xf.13.attn.per_dim_scale.per_dim_scale', 'stacked_xf.13.attn.qkv_proj.weight', 'stacked_xf.13.attn.query_ln.scale', 'stacked_xf.13.ff0.weight', 'stacked_xf.13.ff1.weight', 'stacked_xf.13.post_attn_ln.scale', 'stacked_xf.13.post_ff_ln.scale', 'stacked_xf.13.pre_attn_ln.scale', 'stacked_xf.13.pre_ff_ln.scale', 'stacked_xf.14.attn.key_ln.scale', 'stacked_xf.14.attn.out.weight', 'stacked_xf.14.attn.per_dim_scale.per_dim_scale', 'stacked_xf.14.attn.qkv_proj.weight', 'stacked_xf.14.attn.query_ln.scale', 'stacked_xf.14.ff0.weight', 'stacked_xf.14.ff1.weight', 'stacked_xf.14.post_attn_ln.scale', 'stacked_xf.14.post_ff_ln.scale', 'stacked_xf.14.pre_attn_ln.scale', 'stacked_xf.14.pre_ff_ln.scale', 'stacked_xf.15.attn.key_ln.scale', 'stacked_xf.15.attn.out.weight', 'stacked_xf.15.attn.per_dim_scale.per_dim_scale', 'stacked_xf.15.attn.qkv_proj.weight', 'stacked_xf.15.attn.query_ln.scale', 'stacked_xf.15.ff0.weight', 'stacked_xf.15.ff1.weight', 'stacked_xf.15.post_attn_ln.scale', 'stacked_xf.15.post_ff_ln.scale', 'stacked_xf.15.pre_attn_ln.scale', 'stacked_xf.15.pre_ff_ln.scale', 'stacked_xf.16.attn.key_ln.scale', 'stacked_xf.16.attn.out.weight', 'stacked_xf.16.attn.per_dim_scale.per_dim_scale', 'stacked_xf.16.attn.qkv_proj.weight', 'stacked_xf.16.attn.query_ln.scale', 'stacked_xf.16.ff0.weight', 'stacked_xf.16.ff1.weight', 'stacked_xf.16.post_attn_ln.scale', 'stacked_xf.16.post_ff_ln.scale', 'stacked_xf.16.pre_attn_ln.scale', 'stacked_xf.16.pre_ff_ln.scale', 'stacked_xf.17.attn.key_ln.scale', 'stacked_xf.17.attn.out.weight', 'stacked_xf.17.attn.per_dim_scale.per_dim_scale', 'stacked_xf.17.attn.qkv_proj.weight', 'stacked_xf.17.attn.query_ln.scale', 'stacked_xf.17.ff0.weight', 'stacked_xf.17.ff1.weight', 'stacked_xf.17.post_attn_ln.scale', 'stacked_xf.17.post_ff_ln.scale', 'stacked_xf.17.pre_attn_ln.scale', 'stacked_xf.17.pre_ff_ln.scale', 'stacked_xf.18.attn.key_ln.scale', 'stacked_xf.18.attn.out.weight', 'stacked_xf.18.attn.per_dim_scale.per_dim_scale', 'stacked_xf.18.attn.qkv_proj.weight', 'stacked_xf.18.attn.query_ln.scale', 'stacked_xf.18.ff0.weight', 'stacked_xf.18.ff1.weight', 'stacked_xf.18.post_attn_ln.scale', 'stacked_xf.18.post_ff_ln.scale', 'stacked_xf.18.pre_attn_ln.scale', 'stacked_xf.18.pre_ff_ln.scale', 'stacked_xf.19.attn.key_ln.scale', 'stacked_xf.19.attn.out.weight', 'stacked_xf.19.attn.per_dim_scale.per_dim_scale', 'stacked_xf.19.attn.qkv_proj.weight', 'stacked_xf.19.attn.query_ln.scale', 'stacked_xf.19.ff0.weight', 'stacked_xf.19.ff1.weight', 'stacked_xf.19.post_attn_ln.scale', 'stacked_xf.19.post_ff_ln.scale', 'stacked_xf.19.pre_attn_ln.scale', 'stacked_xf.19.pre_ff_ln.scale', 'stacked_xf.2.attn.key_ln.scale', 'stacked_xf.2.attn.out.weight', 'stacked_xf.2.attn.per_dim_scale.per_dim_scale', 'stacked_xf.2.attn.qkv_proj.weight', 'stacked_xf.2.attn.query_ln.scale', 'stacked_xf.2.ff0.weight', 'stacked_xf.2.ff1.weight', 'stacked_xf.2.post_attn_ln.scale', 'stacked_xf.2.post_ff_ln.scale', 'stacked_xf.2.pre_attn_ln.scale', 'stacked_xf.2.pre_ff_ln.scale', 'stacked_xf.3.attn.key_ln.scale', 'stacked_xf.3.attn.out.weight', 'stacked_xf.3.attn.per_dim_scale.per_dim_scale', 'stacked_xf.3.attn.qkv_proj.weight', 'stacked_xf.3.attn.query_ln.scale', 'stacked_xf.3.ff0.weight', 'stacked_xf.3.ff1.weight', 'stacked_xf.3.post_attn_ln.scale', 'stacked_xf.3.post_ff_ln.scale', 'stacked_xf.3.pre_attn_ln.scale', 'stacked_xf.3.pre_ff_ln.scale', 'stacked_xf.4.attn.key_ln.scale', 'stacked_xf.4.attn.out.weight', 'stacked_xf.4.attn.per_dim_scale.per_dim_scale', 'stacked_xf.4.attn.qkv_proj.weight', 'stacked_xf.4.attn.query_ln.scale', 'stacked_xf.4.ff0.weight', 'stacked_xf.4.ff1.weight', 'stacked_xf.4.post_attn_ln.scale', 'stacked_xf.4.post_ff_ln.scale', 'stacked_xf.4.pre_attn_ln.scale', 'stacked_xf.4.pre_ff_ln.scale', 'stacked_xf.5.attn.key_ln.scale', 'stacked_xf.5.attn.out.weight', 'stacked_xf.5.attn.per_dim_scale.per_dim_scale', 'stacked_xf.5.attn.qkv_proj.weight', 'stacked_xf.5.attn.query_ln.scale', 'stacked_xf.5.ff0.weight', 'stacked_xf.5.ff1.weight', 'stacked_xf.5.post_attn_ln.scale', 'stacked_xf.5.post_ff_ln.scale', 'stacked_xf.5.pre_attn_ln.scale', 'stacked_xf.5.pre_ff_ln.scale', 'stacked_xf.6.attn.key_ln.scale', 'stacked_xf.6.attn.out.weight', 'stacked_xf.6.attn.per_dim_scale.per_dim_scale', 'stacked_xf.6.attn.qkv_proj.weight', 'stacked_xf.6.attn.query_ln.scale', 'stacked_xf.6.ff0.weight', 'stacked_xf.6.ff1.weight', 'stacked_xf.6.post_attn_ln.scale', 'stacked_xf.6.post_ff_ln.scale', 'stacked_xf.6.pre_attn_ln.scale', 'stacked_xf.6.pre_ff_ln.scale', 'stacked_xf.7.attn.key_ln.scale', 'stacked_xf.7.attn.out.weight', 'stacked_xf.7.attn.per_dim_scale.per_dim_scale', 'stacked_xf.7.attn.qkv_proj.weight', 'stacked_xf.7.attn.query_ln.scale', 'stacked_xf.7.ff0.weight', 'stacked_xf.7.ff1.weight', 'stacked_xf.7.post_attn_ln.scale', 'stacked_xf.7.post_ff_ln.scale', 'stacked_xf.7.pre_attn_ln.scale', 'stacked_xf.7.pre_ff_ln.scale', 'stacked_xf.8.attn.key_ln.scale', 'stacked_xf.8.attn.out.weight', 'stacked_xf.8.attn.per_dim_scale.per_dim_scale', 'stacked_xf.8.attn.qkv_proj.weight', 'stacked_xf.8.attn.query_ln.scale', 'stacked_xf.8.ff0.weight', 'stacked_xf.8.ff1.weight', 'stacked_xf.8.post_attn_ln.scale', 'stacked_xf.8.post_ff_ln.scale', 'stacked_xf.8.pre_attn_ln.scale', 'stacked_xf.8.pre_ff_ln.scale', 'stacked_xf.9.attn.key_ln.scale', 'stacked_xf.9.attn.out.weight', 'stacked_xf.9.attn.per_dim_scale.per_dim_scale', 'stacked_xf.9.attn.qkv_proj.weight', 'stacked_xf.9.attn.query_ln.scale', 'stacked_xf.9.ff0.weight', 'stacked_xf.9.ff1.weight', 'stacked_xf.9.post_attn_ln.scale', 'stacked_xf.9.post_ff_ln.scale', 'stacked_xf.9.pre_attn_ln.scale', 'stacked_xf.9.pre_ff_ln.scale', 'tokenizer.hidden_layer.bias', 'tokenizer.hidden_layer.weight', 'tokenizer.output_layer.bias', 'tokenizer.output_layer.weight', 'tokenizer.residual_layer.bias', 'tokenizer.residual_layer.weight']\n",
            "- This IS expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of TimesFmModelForPrediction were not initialized from the model checkpoint at google/timesfm-2.5-200m-pytorch and are newly initialized: ['decoder.freq_emb.weight', 'decoder.input_ff_layer.input_layer.bias', 'decoder.input_ff_layer.input_layer.weight', 'decoder.input_ff_layer.output_layer.bias', 'decoder.input_ff_layer.output_layer.weight', 'decoder.input_ff_layer.residual_layer.bias', 'decoder.input_ff_layer.residual_layer.weight', 'decoder.layers.0.input_layernorm.weight', 'decoder.layers.0.mlp.down_proj.bias', 'decoder.layers.0.mlp.down_proj.weight', 'decoder.layers.0.mlp.gate_proj.bias', 'decoder.layers.0.mlp.gate_proj.weight', 'decoder.layers.0.mlp.layer_norm.bias', 'decoder.layers.0.mlp.layer_norm.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.o_proj.bias', 'decoder.layers.0.self_attn.o_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.scaling', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.1.input_layernorm.weight', 'decoder.layers.1.mlp.down_proj.bias', 'decoder.layers.1.mlp.down_proj.weight', 'decoder.layers.1.mlp.gate_proj.bias', 'decoder.layers.1.mlp.gate_proj.weight', 'decoder.layers.1.mlp.layer_norm.bias', 'decoder.layers.1.mlp.layer_norm.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.o_proj.bias', 'decoder.layers.1.self_attn.o_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.scaling', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.10.input_layernorm.weight', 'decoder.layers.10.mlp.down_proj.bias', 'decoder.layers.10.mlp.down_proj.weight', 'decoder.layers.10.mlp.gate_proj.bias', 'decoder.layers.10.mlp.gate_proj.weight', 'decoder.layers.10.mlp.layer_norm.bias', 'decoder.layers.10.mlp.layer_norm.weight', 'decoder.layers.10.self_attn.k_proj.bias', 'decoder.layers.10.self_attn.k_proj.weight', 'decoder.layers.10.self_attn.o_proj.bias', 'decoder.layers.10.self_attn.o_proj.weight', 'decoder.layers.10.self_attn.q_proj.bias', 'decoder.layers.10.self_attn.q_proj.weight', 'decoder.layers.10.self_attn.scaling', 'decoder.layers.10.self_attn.v_proj.bias', 'decoder.layers.10.self_attn.v_proj.weight', 'decoder.layers.11.input_layernorm.weight', 'decoder.layers.11.mlp.down_proj.bias', 'decoder.layers.11.mlp.down_proj.weight', 'decoder.layers.11.mlp.gate_proj.bias', 'decoder.layers.11.mlp.gate_proj.weight', 'decoder.layers.11.mlp.layer_norm.bias', 'decoder.layers.11.mlp.layer_norm.weight', 'decoder.layers.11.self_attn.k_proj.bias', 'decoder.layers.11.self_attn.k_proj.weight', 'decoder.layers.11.self_attn.o_proj.bias', 'decoder.layers.11.self_attn.o_proj.weight', 'decoder.layers.11.self_attn.q_proj.bias', 'decoder.layers.11.self_attn.q_proj.weight', 'decoder.layers.11.self_attn.scaling', 'decoder.layers.11.self_attn.v_proj.bias', 'decoder.layers.11.self_attn.v_proj.weight', 'decoder.layers.12.input_layernorm.weight', 'decoder.layers.12.mlp.down_proj.bias', 'decoder.layers.12.mlp.down_proj.weight', 'decoder.layers.12.mlp.gate_proj.bias', 'decoder.layers.12.mlp.gate_proj.weight', 'decoder.layers.12.mlp.layer_norm.bias', 'decoder.layers.12.mlp.layer_norm.weight', 'decoder.layers.12.self_attn.k_proj.bias', 'decoder.layers.12.self_attn.k_proj.weight', 'decoder.layers.12.self_attn.o_proj.bias', 'decoder.layers.12.self_attn.o_proj.weight', 'decoder.layers.12.self_attn.q_proj.bias', 'decoder.layers.12.self_attn.q_proj.weight', 'decoder.layers.12.self_attn.scaling', 'decoder.layers.12.self_attn.v_proj.bias', 'decoder.layers.12.self_attn.v_proj.weight', 'decoder.layers.13.input_layernorm.weight', 'decoder.layers.13.mlp.down_proj.bias', 'decoder.layers.13.mlp.down_proj.weight', 'decoder.layers.13.mlp.gate_proj.bias', 'decoder.layers.13.mlp.gate_proj.weight', 'decoder.layers.13.mlp.layer_norm.bias', 'decoder.layers.13.mlp.layer_norm.weight', 'decoder.layers.13.self_attn.k_proj.bias', 'decoder.layers.13.self_attn.k_proj.weight', 'decoder.layers.13.self_attn.o_proj.bias', 'decoder.layers.13.self_attn.o_proj.weight', 'decoder.layers.13.self_attn.q_proj.bias', 'decoder.layers.13.self_attn.q_proj.weight', 'decoder.layers.13.self_attn.scaling', 'decoder.layers.13.self_attn.v_proj.bias', 'decoder.layers.13.self_attn.v_proj.weight', 'decoder.layers.14.input_layernorm.weight', 'decoder.layers.14.mlp.down_proj.bias', 'decoder.layers.14.mlp.down_proj.weight', 'decoder.layers.14.mlp.gate_proj.bias', 'decoder.layers.14.mlp.gate_proj.weight', 'decoder.layers.14.mlp.layer_norm.bias', 'decoder.layers.14.mlp.layer_norm.weight', 'decoder.layers.14.self_attn.k_proj.bias', 'decoder.layers.14.self_attn.k_proj.weight', 'decoder.layers.14.self_attn.o_proj.bias', 'decoder.layers.14.self_attn.o_proj.weight', 'decoder.layers.14.self_attn.q_proj.bias', 'decoder.layers.14.self_attn.q_proj.weight', 'decoder.layers.14.self_attn.scaling', 'decoder.layers.14.self_attn.v_proj.bias', 'decoder.layers.14.self_attn.v_proj.weight', 'decoder.layers.15.input_layernorm.weight', 'decoder.layers.15.mlp.down_proj.bias', 'decoder.layers.15.mlp.down_proj.weight', 'decoder.layers.15.mlp.gate_proj.bias', 'decoder.layers.15.mlp.gate_proj.weight', 'decoder.layers.15.mlp.layer_norm.bias', 'decoder.layers.15.mlp.layer_norm.weight', 'decoder.layers.15.self_attn.k_proj.bias', 'decoder.layers.15.self_attn.k_proj.weight', 'decoder.layers.15.self_attn.o_proj.bias', 'decoder.layers.15.self_attn.o_proj.weight', 'decoder.layers.15.self_attn.q_proj.bias', 'decoder.layers.15.self_attn.q_proj.weight', 'decoder.layers.15.self_attn.scaling', 'decoder.layers.15.self_attn.v_proj.bias', 'decoder.layers.15.self_attn.v_proj.weight', 'decoder.layers.16.input_layernorm.weight', 'decoder.layers.16.mlp.down_proj.bias', 'decoder.layers.16.mlp.down_proj.weight', 'decoder.layers.16.mlp.gate_proj.bias', 'decoder.layers.16.mlp.gate_proj.weight', 'decoder.layers.16.mlp.layer_norm.bias', 'decoder.layers.16.mlp.layer_norm.weight', 'decoder.layers.16.self_attn.k_proj.bias', 'decoder.layers.16.self_attn.k_proj.weight', 'decoder.layers.16.self_attn.o_proj.bias', 'decoder.layers.16.self_attn.o_proj.weight', 'decoder.layers.16.self_attn.q_proj.bias', 'decoder.layers.16.self_attn.q_proj.weight', 'decoder.layers.16.self_attn.scaling', 'decoder.layers.16.self_attn.v_proj.bias', 'decoder.layers.16.self_attn.v_proj.weight', 'decoder.layers.17.input_layernorm.weight', 'decoder.layers.17.mlp.down_proj.bias', 'decoder.layers.17.mlp.down_proj.weight', 'decoder.layers.17.mlp.gate_proj.bias', 'decoder.layers.17.mlp.gate_proj.weight', 'decoder.layers.17.mlp.layer_norm.bias', 'decoder.layers.17.mlp.layer_norm.weight', 'decoder.layers.17.self_attn.k_proj.bias', 'decoder.layers.17.self_attn.k_proj.weight', 'decoder.layers.17.self_attn.o_proj.bias', 'decoder.layers.17.self_attn.o_proj.weight', 'decoder.layers.17.self_attn.q_proj.bias', 'decoder.layers.17.self_attn.q_proj.weight', 'decoder.layers.17.self_attn.scaling', 'decoder.layers.17.self_attn.v_proj.bias', 'decoder.layers.17.self_attn.v_proj.weight', 'decoder.layers.18.input_layernorm.weight', 'decoder.layers.18.mlp.down_proj.bias', 'decoder.layers.18.mlp.down_proj.weight', 'decoder.layers.18.mlp.gate_proj.bias', 'decoder.layers.18.mlp.gate_proj.weight', 'decoder.layers.18.mlp.layer_norm.bias', 'decoder.layers.18.mlp.layer_norm.weight', 'decoder.layers.18.self_attn.k_proj.bias', 'decoder.layers.18.self_attn.k_proj.weight', 'decoder.layers.18.self_attn.o_proj.bias', 'decoder.layers.18.self_attn.o_proj.weight', 'decoder.layers.18.self_attn.q_proj.bias', 'decoder.layers.18.self_attn.q_proj.weight', 'decoder.layers.18.self_attn.scaling', 'decoder.layers.18.self_attn.v_proj.bias', 'decoder.layers.18.self_attn.v_proj.weight', 'decoder.layers.19.input_layernorm.weight', 'decoder.layers.19.mlp.down_proj.bias', 'decoder.layers.19.mlp.down_proj.weight', 'decoder.layers.19.mlp.gate_proj.bias', 'decoder.layers.19.mlp.gate_proj.weight', 'decoder.layers.19.mlp.layer_norm.bias', 'decoder.layers.19.mlp.layer_norm.weight', 'decoder.layers.19.self_attn.k_proj.bias', 'decoder.layers.19.self_attn.k_proj.weight', 'decoder.layers.19.self_attn.o_proj.bias', 'decoder.layers.19.self_attn.o_proj.weight', 'decoder.layers.19.self_attn.q_proj.bias', 'decoder.layers.19.self_attn.q_proj.weight', 'decoder.layers.19.self_attn.scaling', 'decoder.layers.19.self_attn.v_proj.bias', 'decoder.layers.19.self_attn.v_proj.weight', 'decoder.layers.2.input_layernorm.weight', 'decoder.layers.2.mlp.down_proj.bias', 'decoder.layers.2.mlp.down_proj.weight', 'decoder.layers.2.mlp.gate_proj.bias', 'decoder.layers.2.mlp.gate_proj.weight', 'decoder.layers.2.mlp.layer_norm.bias', 'decoder.layers.2.mlp.layer_norm.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.o_proj.bias', 'decoder.layers.2.self_attn.o_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.scaling', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.3.input_layernorm.weight', 'decoder.layers.3.mlp.down_proj.bias', 'decoder.layers.3.mlp.down_proj.weight', 'decoder.layers.3.mlp.gate_proj.bias', 'decoder.layers.3.mlp.gate_proj.weight', 'decoder.layers.3.mlp.layer_norm.bias', 'decoder.layers.3.mlp.layer_norm.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.o_proj.bias', 'decoder.layers.3.self_attn.o_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.scaling', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.4.input_layernorm.weight', 'decoder.layers.4.mlp.down_proj.bias', 'decoder.layers.4.mlp.down_proj.weight', 'decoder.layers.4.mlp.gate_proj.bias', 'decoder.layers.4.mlp.gate_proj.weight', 'decoder.layers.4.mlp.layer_norm.bias', 'decoder.layers.4.mlp.layer_norm.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.o_proj.bias', 'decoder.layers.4.self_attn.o_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.scaling', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.5.input_layernorm.weight', 'decoder.layers.5.mlp.down_proj.bias', 'decoder.layers.5.mlp.down_proj.weight', 'decoder.layers.5.mlp.gate_proj.bias', 'decoder.layers.5.mlp.gate_proj.weight', 'decoder.layers.5.mlp.layer_norm.bias', 'decoder.layers.5.mlp.layer_norm.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.o_proj.bias', 'decoder.layers.5.self_attn.o_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.scaling', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.6.input_layernorm.weight', 'decoder.layers.6.mlp.down_proj.bias', 'decoder.layers.6.mlp.down_proj.weight', 'decoder.layers.6.mlp.gate_proj.bias', 'decoder.layers.6.mlp.gate_proj.weight', 'decoder.layers.6.mlp.layer_norm.bias', 'decoder.layers.6.mlp.layer_norm.weight', 'decoder.layers.6.self_attn.k_proj.bias', 'decoder.layers.6.self_attn.k_proj.weight', 'decoder.layers.6.self_attn.o_proj.bias', 'decoder.layers.6.self_attn.o_proj.weight', 'decoder.layers.6.self_attn.q_proj.bias', 'decoder.layers.6.self_attn.q_proj.weight', 'decoder.layers.6.self_attn.scaling', 'decoder.layers.6.self_attn.v_proj.bias', 'decoder.layers.6.self_attn.v_proj.weight', 'decoder.layers.7.input_layernorm.weight', 'decoder.layers.7.mlp.down_proj.bias', 'decoder.layers.7.mlp.down_proj.weight', 'decoder.layers.7.mlp.gate_proj.bias', 'decoder.layers.7.mlp.gate_proj.weight', 'decoder.layers.7.mlp.layer_norm.bias', 'decoder.layers.7.mlp.layer_norm.weight', 'decoder.layers.7.self_attn.k_proj.bias', 'decoder.layers.7.self_attn.k_proj.weight', 'decoder.layers.7.self_attn.o_proj.bias', 'decoder.layers.7.self_attn.o_proj.weight', 'decoder.layers.7.self_attn.q_proj.bias', 'decoder.layers.7.self_attn.q_proj.weight', 'decoder.layers.7.self_attn.scaling', 'decoder.layers.7.self_attn.v_proj.bias', 'decoder.layers.7.self_attn.v_proj.weight', 'decoder.layers.8.input_layernorm.weight', 'decoder.layers.8.mlp.down_proj.bias', 'decoder.layers.8.mlp.down_proj.weight', 'decoder.layers.8.mlp.gate_proj.bias', 'decoder.layers.8.mlp.gate_proj.weight', 'decoder.layers.8.mlp.layer_norm.bias', 'decoder.layers.8.mlp.layer_norm.weight', 'decoder.layers.8.self_attn.k_proj.bias', 'decoder.layers.8.self_attn.k_proj.weight', 'decoder.layers.8.self_attn.o_proj.bias', 'decoder.layers.8.self_attn.o_proj.weight', 'decoder.layers.8.self_attn.q_proj.bias', 'decoder.layers.8.self_attn.q_proj.weight', 'decoder.layers.8.self_attn.scaling', 'decoder.layers.8.self_attn.v_proj.bias', 'decoder.layers.8.self_attn.v_proj.weight', 'decoder.layers.9.input_layernorm.weight', 'decoder.layers.9.mlp.down_proj.bias', 'decoder.layers.9.mlp.down_proj.weight', 'decoder.layers.9.mlp.gate_proj.bias', 'decoder.layers.9.mlp.gate_proj.weight', 'decoder.layers.9.mlp.layer_norm.bias', 'decoder.layers.9.mlp.layer_norm.weight', 'decoder.layers.9.self_attn.k_proj.bias', 'decoder.layers.9.self_attn.k_proj.weight', 'decoder.layers.9.self_attn.o_proj.bias', 'decoder.layers.9.self_attn.o_proj.weight', 'decoder.layers.9.self_attn.q_proj.bias', 'decoder.layers.9.self_attn.q_proj.weight', 'decoder.layers.9.self_attn.scaling', 'decoder.layers.9.self_attn.v_proj.bias', 'decoder.layers.9.self_attn.v_proj.weight', 'horizon_ff_layer.input_layer.bias', 'horizon_ff_layer.input_layer.weight', 'horizon_ff_layer.output_layer.bias', 'horizon_ff_layer.output_layer.weight', 'horizon_ff_layer.residual_layer.bias', 'horizon_ff_layer.residual_layer.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n",
            "  Epoch 1/100 train_loss=1.7885 train_acc=0.3785 eval_loss=1.0523 eval_acc=0.6602 (best)\n",
            "  Epoch 2/100 train_loss=0.7045 train_acc=0.7624 eval_loss=0.8120 eval_acc=0.6961 (best)\n",
            "  Epoch 3/100 train_loss=0.3714 train_acc=0.8702 eval_loss=0.7578 eval_acc=0.7735 (best)\n",
            "  Epoch 4/100 train_loss=0.1874 train_acc=0.9420 eval_loss=0.6885 eval_acc=0.7762 (best)\n",
            "  Epoch 5/100 train_loss=0.1248 train_acc=0.9834 eval_loss=0.9667 eval_acc=0.7597 \n",
            "  Epoch 6/100 train_loss=0.1175 train_acc=0.9724 eval_loss=0.6495 eval_acc=0.8039 (best)\n",
            "  Epoch 7/100 train_loss=0.1172 train_acc=0.9724 eval_loss=0.7247 eval_acc=0.7845 \n",
            "  Epoch 8/100 train_loss=0.1214 train_acc=0.9669 eval_loss=0.6654 eval_acc=0.8343 \n",
            "  Epoch 9/100 train_loss=0.0793 train_acc=0.9834 eval_loss=0.8207 eval_acc=0.7873 \n",
            "  Epoch 10/100 train_loss=0.1305 train_acc=0.9669 eval_loss=1.1259 eval_acc=0.7431 \n",
            "  Epoch 11/100 train_loss=0.1293 train_acc=0.9558 eval_loss=1.0283 eval_acc=0.8094 \n",
            "  Epoch 12/100 train_loss=0.0691 train_acc=0.9807 eval_loss=1.1679 eval_acc=0.7597 \n",
            "  Epoch 13/100 train_loss=0.1033 train_acc=0.9613 eval_loss=1.1329 eval_acc=0.8066 \n",
            "  Epoch 14/100 train_loss=0.0828 train_acc=0.9696 eval_loss=1.3057 eval_acc=0.8039 \n",
            "  Epoch 15/100 train_loss=0.0809 train_acc=0.9779 eval_loss=1.4724 eval_acc=0.7901 \n",
            "  Epoch 16/100 train_loss=0.1104 train_acc=0.9641 eval_loss=1.2179 eval_acc=0.8066 \n",
            "  Early stopping on google/timesfm-2.5-200m-pytorch: no improvement for 10 epochs (best epoch = 6)\n",
            "    tfm[google/timesfm-2.5-200m-pytorch] train_acc=0.9724 eval_acc=0.80662983425414369609285358819761313498020172\n",
            "    mrh_acc=0.8923 mr+h+kg_acc=0.8867 kg_acc=0.8646 ensemble=0.8840 (w=0.60)\n",
            "  Split 1/1 - accuracy=0.8840 time=413.8s\n",
            "Completed EOGHorizontalSignal: Mean Acc=0.8840\n",
            "\n",
            "=== 29/109 EOGVerticalSignal ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n",
            "    Gate split 1/5: baseline_loss=0.5819 adaptive_loss=0.5830\n",
            "    Gate split 2/5: baseline_loss=0.6749 adaptive_loss=0.6784\n",
            "    Gate split 3/5: baseline_loss=0.6562 adaptive_loss=0.6699\n",
            "    Gate split 4/5: baseline_loss=0.6264 adaptive_loss=0.6468\n",
            "    Gate split 5/5: baseline_loss=0.6508 adaptive_loss=0.6482\n",
            "  Decision: Adaptive kept (loss 0.6453 vs baseline 0.6380, delta=+0.0072 <= +0.0200); savgol(window=21, poly=3) - high noise (std_diff)\n",
            "\n",
            "=== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at google/timesfm-2.5-200m-pytorch were not used when initializing TimesFmModelForPrediction: ['output_projection_point.hidden_layer.weight', 'output_projection_point.output_layer.weight', 'output_projection_point.residual_layer.weight', 'output_projection_quantiles.hidden_layer.weight', 'output_projection_quantiles.output_layer.weight', 'output_projection_quantiles.residual_layer.weight', 'stacked_xf.0.attn.key_ln.scale', 'stacked_xf.0.attn.out.weight', 'stacked_xf.0.attn.per_dim_scale.per_dim_scale', 'stacked_xf.0.attn.qkv_proj.weight', 'stacked_xf.0.attn.query_ln.scale', 'stacked_xf.0.ff0.weight', 'stacked_xf.0.ff1.weight', 'stacked_xf.0.post_attn_ln.scale', 'stacked_xf.0.post_ff_ln.scale', 'stacked_xf.0.pre_attn_ln.scale', 'stacked_xf.0.pre_ff_ln.scale', 'stacked_xf.1.attn.key_ln.scale', 'stacked_xf.1.attn.out.weight', 'stacked_xf.1.attn.per_dim_scale.per_dim_scale', 'stacked_xf.1.attn.qkv_proj.weight', 'stacked_xf.1.attn.query_ln.scale', 'stacked_xf.1.ff0.weight', 'stacked_xf.1.ff1.weight', 'stacked_xf.1.post_attn_ln.scale', 'stacked_xf.1.post_ff_ln.scale', 'stacked_xf.1.pre_attn_ln.scale', 'stacked_xf.1.pre_ff_ln.scale', 'stacked_xf.10.attn.key_ln.scale', 'stacked_xf.10.attn.out.weight', 'stacked_xf.10.attn.per_dim_scale.per_dim_scale', 'stacked_xf.10.attn.qkv_proj.weight', 'stacked_xf.10.attn.query_ln.scale', 'stacked_xf.10.ff0.weight', 'stacked_xf.10.ff1.weight', 'stacked_xf.10.post_attn_ln.scale', 'stacked_xf.10.post_ff_ln.scale', 'stacked_xf.10.pre_attn_ln.scale', 'stacked_xf.10.pre_ff_ln.scale', 'stacked_xf.11.attn.key_ln.scale', 'stacked_xf.11.attn.out.weight', 'stacked_xf.11.attn.per_dim_scale.per_dim_scale', 'stacked_xf.11.attn.qkv_proj.weight', 'stacked_xf.11.attn.query_ln.scale', 'stacked_xf.11.ff0.weight', 'stacked_xf.11.ff1.weight', 'stacked_xf.11.post_attn_ln.scale', 'stacked_xf.11.post_ff_ln.scale', 'stacked_xf.11.pre_attn_ln.scale', 'stacked_xf.11.pre_ff_ln.scale', 'stacked_xf.12.attn.key_ln.scale', 'stacked_xf.12.attn.out.weight', 'stacked_xf.12.attn.per_dim_scale.per_dim_scale', 'stacked_xf.12.attn.qkv_proj.weight', 'stacked_xf.12.attn.query_ln.scale', 'stacked_xf.12.ff0.weight', 'stacked_xf.12.ff1.weight', 'stacked_xf.12.post_attn_ln.scale', 'stacked_xf.12.post_ff_ln.scale', 'stacked_xf.12.pre_attn_ln.scale', 'stacked_xf.12.pre_ff_ln.scale', 'stacked_xf.13.attn.key_ln.scale', 'stacked_xf.13.attn.out.weight', 'stacked_xf.13.attn.per_dim_scale.per_dim_scale', 'stacked_xf.13.attn.qkv_proj.weight', 'stacked_xf.13.attn.query_ln.scale', 'stacked_xf.13.ff0.weight', 'stacked_xf.13.ff1.weight', 'stacked_xf.13.post_attn_ln.scale', 'stacked_xf.13.post_ff_ln.scale', 'stacked_xf.13.pre_attn_ln.scale', 'stacked_xf.13.pre_ff_ln.scale', 'stacked_xf.14.attn.key_ln.scale', 'stacked_xf.14.attn.out.weight', 'stacked_xf.14.attn.per_dim_scale.per_dim_scale', 'stacked_xf.14.attn.qkv_proj.weight', 'stacked_xf.14.attn.query_ln.scale', 'stacked_xf.14.ff0.weight', 'stacked_xf.14.ff1.weight', 'stacked_xf.14.post_attn_ln.scale', 'stacked_xf.14.post_ff_ln.scale', 'stacked_xf.14.pre_attn_ln.scale', 'stacked_xf.14.pre_ff_ln.scale', 'stacked_xf.15.attn.key_ln.scale', 'stacked_xf.15.attn.out.weight', 'stacked_xf.15.attn.per_dim_scale.per_dim_scale', 'stacked_xf.15.attn.qkv_proj.weight', 'stacked_xf.15.attn.query_ln.scale', 'stacked_xf.15.ff0.weight', 'stacked_xf.15.ff1.weight', 'stacked_xf.15.post_attn_ln.scale', 'stacked_xf.15.post_ff_ln.scale', 'stacked_xf.15.pre_attn_ln.scale', 'stacked_xf.15.pre_ff_ln.scale', 'stacked_xf.16.attn.key_ln.scale', 'stacked_xf.16.attn.out.weight', 'stacked_xf.16.attn.per_dim_scale.per_dim_scale', 'stacked_xf.16.attn.qkv_proj.weight', 'stacked_xf.16.attn.query_ln.scale', 'stacked_xf.16.ff0.weight', 'stacked_xf.16.ff1.weight', 'stacked_xf.16.post_attn_ln.scale', 'stacked_xf.16.post_ff_ln.scale', 'stacked_xf.16.pre_attn_ln.scale', 'stacked_xf.16.pre_ff_ln.scale', 'stacked_xf.17.attn.key_ln.scale', 'stacked_xf.17.attn.out.weight', 'stacked_xf.17.attn.per_dim_scale.per_dim_scale', 'stacked_xf.17.attn.qkv_proj.weight', 'stacked_xf.17.attn.query_ln.scale', 'stacked_xf.17.ff0.weight', 'stacked_xf.17.ff1.weight', 'stacked_xf.17.post_attn_ln.scale', 'stacked_xf.17.post_ff_ln.scale', 'stacked_xf.17.pre_attn_ln.scale', 'stacked_xf.17.pre_ff_ln.scale', 'stacked_xf.18.attn.key_ln.scale', 'stacked_xf.18.attn.out.weight', 'stacked_xf.18.attn.per_dim_scale.per_dim_scale', 'stacked_xf.18.attn.qkv_proj.weight', 'stacked_xf.18.attn.query_ln.scale', 'stacked_xf.18.ff0.weight', 'stacked_xf.18.ff1.weight', 'stacked_xf.18.post_attn_ln.scale', 'stacked_xf.18.post_ff_ln.scale', 'stacked_xf.18.pre_attn_ln.scale', 'stacked_xf.18.pre_ff_ln.scale', 'stacked_xf.19.attn.key_ln.scale', 'stacked_xf.19.attn.out.weight', 'stacked_xf.19.attn.per_dim_scale.per_dim_scale', 'stacked_xf.19.attn.qkv_proj.weight', 'stacked_xf.19.attn.query_ln.scale', 'stacked_xf.19.ff0.weight', 'stacked_xf.19.ff1.weight', 'stacked_xf.19.post_attn_ln.scale', 'stacked_xf.19.post_ff_ln.scale', 'stacked_xf.19.pre_attn_ln.scale', 'stacked_xf.19.pre_ff_ln.scale', 'stacked_xf.2.attn.key_ln.scale', 'stacked_xf.2.attn.out.weight', 'stacked_xf.2.attn.per_dim_scale.per_dim_scale', 'stacked_xf.2.attn.qkv_proj.weight', 'stacked_xf.2.attn.query_ln.scale', 'stacked_xf.2.ff0.weight', 'stacked_xf.2.ff1.weight', 'stacked_xf.2.post_attn_ln.scale', 'stacked_xf.2.post_ff_ln.scale', 'stacked_xf.2.pre_attn_ln.scale', 'stacked_xf.2.pre_ff_ln.scale', 'stacked_xf.3.attn.key_ln.scale', 'stacked_xf.3.attn.out.weight', 'stacked_xf.3.attn.per_dim_scale.per_dim_scale', 'stacked_xf.3.attn.qkv_proj.weight', 'stacked_xf.3.attn.query_ln.scale', 'stacked_xf.3.ff0.weight', 'stacked_xf.3.ff1.weight', 'stacked_xf.3.post_attn_ln.scale', 'stacked_xf.3.post_ff_ln.scale', 'stacked_xf.3.pre_attn_ln.scale', 'stacked_xf.3.pre_ff_ln.scale', 'stacked_xf.4.attn.key_ln.scale', 'stacked_xf.4.attn.out.weight', 'stacked_xf.4.attn.per_dim_scale.per_dim_scale', 'stacked_xf.4.attn.qkv_proj.weight', 'stacked_xf.4.attn.query_ln.scale', 'stacked_xf.4.ff0.weight', 'stacked_xf.4.ff1.weight', 'stacked_xf.4.post_attn_ln.scale', 'stacked_xf.4.post_ff_ln.scale', 'stacked_xf.4.pre_attn_ln.scale', 'stacked_xf.4.pre_ff_ln.scale', 'stacked_xf.5.attn.key_ln.scale', 'stacked_xf.5.attn.out.weight', 'stacked_xf.5.attn.per_dim_scale.per_dim_scale', 'stacked_xf.5.attn.qkv_proj.weight', 'stacked_xf.5.attn.query_ln.scale', 'stacked_xf.5.ff0.weight', 'stacked_xf.5.ff1.weight', 'stacked_xf.5.post_attn_ln.scale', 'stacked_xf.5.post_ff_ln.scale', 'stacked_xf.5.pre_attn_ln.scale', 'stacked_xf.5.pre_ff_ln.scale', 'stacked_xf.6.attn.key_ln.scale', 'stacked_xf.6.attn.out.weight', 'stacked_xf.6.attn.per_dim_scale.per_dim_scale', 'stacked_xf.6.attn.qkv_proj.weight', 'stacked_xf.6.attn.query_ln.scale', 'stacked_xf.6.ff0.weight', 'stacked_xf.6.ff1.weight', 'stacked_xf.6.post_attn_ln.scale', 'stacked_xf.6.post_ff_ln.scale', 'stacked_xf.6.pre_attn_ln.scale', 'stacked_xf.6.pre_ff_ln.scale', 'stacked_xf.7.attn.key_ln.scale', 'stacked_xf.7.attn.out.weight', 'stacked_xf.7.attn.per_dim_scale.per_dim_scale', 'stacked_xf.7.attn.qkv_proj.weight', 'stacked_xf.7.attn.query_ln.scale', 'stacked_xf.7.ff0.weight', 'stacked_xf.7.ff1.weight', 'stacked_xf.7.post_attn_ln.scale', 'stacked_xf.7.post_ff_ln.scale', 'stacked_xf.7.pre_attn_ln.scale', 'stacked_xf.7.pre_ff_ln.scale', 'stacked_xf.8.attn.key_ln.scale', 'stacked_xf.8.attn.out.weight', 'stacked_xf.8.attn.per_dim_scale.per_dim_scale', 'stacked_xf.8.attn.qkv_proj.weight', 'stacked_xf.8.attn.query_ln.scale', 'stacked_xf.8.ff0.weight', 'stacked_xf.8.ff1.weight', 'stacked_xf.8.post_attn_ln.scale', 'stacked_xf.8.post_ff_ln.scale', 'stacked_xf.8.pre_attn_ln.scale', 'stacked_xf.8.pre_ff_ln.scale', 'stacked_xf.9.attn.key_ln.scale', 'stacked_xf.9.attn.out.weight', 'stacked_xf.9.attn.per_dim_scale.per_dim_scale', 'stacked_xf.9.attn.qkv_proj.weight', 'stacked_xf.9.attn.query_ln.scale', 'stacked_xf.9.ff0.weight', 'stacked_xf.9.ff1.weight', 'stacked_xf.9.post_attn_ln.scale', 'stacked_xf.9.post_ff_ln.scale', 'stacked_xf.9.pre_attn_ln.scale', 'stacked_xf.9.pre_ff_ln.scale', 'tokenizer.hidden_layer.bias', 'tokenizer.hidden_layer.weight', 'tokenizer.output_layer.bias', 'tokenizer.output_layer.weight', 'tokenizer.residual_layer.bias', 'tokenizer.residual_layer.weight']\n",
            "- This IS expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of TimesFmModelForPrediction were not initialized from the model checkpoint at google/timesfm-2.5-200m-pytorch and are newly initialized: ['decoder.freq_emb.weight', 'decoder.input_ff_layer.input_layer.bias', 'decoder.input_ff_layer.input_layer.weight', 'decoder.input_ff_layer.output_layer.bias', 'decoder.input_ff_layer.output_layer.weight', 'decoder.input_ff_layer.residual_layer.bias', 'decoder.input_ff_layer.residual_layer.weight', 'decoder.layers.0.input_layernorm.weight', 'decoder.layers.0.mlp.down_proj.bias', 'decoder.layers.0.mlp.down_proj.weight', 'decoder.layers.0.mlp.gate_proj.bias', 'decoder.layers.0.mlp.gate_proj.weight', 'decoder.layers.0.mlp.layer_norm.bias', 'decoder.layers.0.mlp.layer_norm.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.o_proj.bias', 'decoder.layers.0.self_attn.o_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.scaling', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.1.input_layernorm.weight', 'decoder.layers.1.mlp.down_proj.bias', 'decoder.layers.1.mlp.down_proj.weight', 'decoder.layers.1.mlp.gate_proj.bias', 'decoder.layers.1.mlp.gate_proj.weight', 'decoder.layers.1.mlp.layer_norm.bias', 'decoder.layers.1.mlp.layer_norm.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.o_proj.bias', 'decoder.layers.1.self_attn.o_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.scaling', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.10.input_layernorm.weight', 'decoder.layers.10.mlp.down_proj.bias', 'decoder.layers.10.mlp.down_proj.weight', 'decoder.layers.10.mlp.gate_proj.bias', 'decoder.layers.10.mlp.gate_proj.weight', 'decoder.layers.10.mlp.layer_norm.bias', 'decoder.layers.10.mlp.layer_norm.weight', 'decoder.layers.10.self_attn.k_proj.bias', 'decoder.layers.10.self_attn.k_proj.weight', 'decoder.layers.10.self_attn.o_proj.bias', 'decoder.layers.10.self_attn.o_proj.weight', 'decoder.layers.10.self_attn.q_proj.bias', 'decoder.layers.10.self_attn.q_proj.weight', 'decoder.layers.10.self_attn.scaling', 'decoder.layers.10.self_attn.v_proj.bias', 'decoder.layers.10.self_attn.v_proj.weight', 'decoder.layers.11.input_layernorm.weight', 'decoder.layers.11.mlp.down_proj.bias', 'decoder.layers.11.mlp.down_proj.weight', 'decoder.layers.11.mlp.gate_proj.bias', 'decoder.layers.11.mlp.gate_proj.weight', 'decoder.layers.11.mlp.layer_norm.bias', 'decoder.layers.11.mlp.layer_norm.weight', 'decoder.layers.11.self_attn.k_proj.bias', 'decoder.layers.11.self_attn.k_proj.weight', 'decoder.layers.11.self_attn.o_proj.bias', 'decoder.layers.11.self_attn.o_proj.weight', 'decoder.layers.11.self_attn.q_proj.bias', 'decoder.layers.11.self_attn.q_proj.weight', 'decoder.layers.11.self_attn.scaling', 'decoder.layers.11.self_attn.v_proj.bias', 'decoder.layers.11.self_attn.v_proj.weight', 'decoder.layers.12.input_layernorm.weight', 'decoder.layers.12.mlp.down_proj.bias', 'decoder.layers.12.mlp.down_proj.weight', 'decoder.layers.12.mlp.gate_proj.bias', 'decoder.layers.12.mlp.gate_proj.weight', 'decoder.layers.12.mlp.layer_norm.bias', 'decoder.layers.12.mlp.layer_norm.weight', 'decoder.layers.12.self_attn.k_proj.bias', 'decoder.layers.12.self_attn.k_proj.weight', 'decoder.layers.12.self_attn.o_proj.bias', 'decoder.layers.12.self_attn.o_proj.weight', 'decoder.layers.12.self_attn.q_proj.bias', 'decoder.layers.12.self_attn.q_proj.weight', 'decoder.layers.12.self_attn.scaling', 'decoder.layers.12.self_attn.v_proj.bias', 'decoder.layers.12.self_attn.v_proj.weight', 'decoder.layers.13.input_layernorm.weight', 'decoder.layers.13.mlp.down_proj.bias', 'decoder.layers.13.mlp.down_proj.weight', 'decoder.layers.13.mlp.gate_proj.bias', 'decoder.layers.13.mlp.gate_proj.weight', 'decoder.layers.13.mlp.layer_norm.bias', 'decoder.layers.13.mlp.layer_norm.weight', 'decoder.layers.13.self_attn.k_proj.bias', 'decoder.layers.13.self_attn.k_proj.weight', 'decoder.layers.13.self_attn.o_proj.bias', 'decoder.layers.13.self_attn.o_proj.weight', 'decoder.layers.13.self_attn.q_proj.bias', 'decoder.layers.13.self_attn.q_proj.weight', 'decoder.layers.13.self_attn.scaling', 'decoder.layers.13.self_attn.v_proj.bias', 'decoder.layers.13.self_attn.v_proj.weight', 'decoder.layers.14.input_layernorm.weight', 'decoder.layers.14.mlp.down_proj.bias', 'decoder.layers.14.mlp.down_proj.weight', 'decoder.layers.14.mlp.gate_proj.bias', 'decoder.layers.14.mlp.gate_proj.weight', 'decoder.layers.14.mlp.layer_norm.bias', 'decoder.layers.14.mlp.layer_norm.weight', 'decoder.layers.14.self_attn.k_proj.bias', 'decoder.layers.14.self_attn.k_proj.weight', 'decoder.layers.14.self_attn.o_proj.bias', 'decoder.layers.14.self_attn.o_proj.weight', 'decoder.layers.14.self_attn.q_proj.bias', 'decoder.layers.14.self_attn.q_proj.weight', 'decoder.layers.14.self_attn.scaling', 'decoder.layers.14.self_attn.v_proj.bias', 'decoder.layers.14.self_attn.v_proj.weight', 'decoder.layers.15.input_layernorm.weight', 'decoder.layers.15.mlp.down_proj.bias', 'decoder.layers.15.mlp.down_proj.weight', 'decoder.layers.15.mlp.gate_proj.bias', 'decoder.layers.15.mlp.gate_proj.weight', 'decoder.layers.15.mlp.layer_norm.bias', 'decoder.layers.15.mlp.layer_norm.weight', 'decoder.layers.15.self_attn.k_proj.bias', 'decoder.layers.15.self_attn.k_proj.weight', 'decoder.layers.15.self_attn.o_proj.bias', 'decoder.layers.15.self_attn.o_proj.weight', 'decoder.layers.15.self_attn.q_proj.bias', 'decoder.layers.15.self_attn.q_proj.weight', 'decoder.layers.15.self_attn.scaling', 'decoder.layers.15.self_attn.v_proj.bias', 'decoder.layers.15.self_attn.v_proj.weight', 'decoder.layers.16.input_layernorm.weight', 'decoder.layers.16.mlp.down_proj.bias', 'decoder.layers.16.mlp.down_proj.weight', 'decoder.layers.16.mlp.gate_proj.bias', 'decoder.layers.16.mlp.gate_proj.weight', 'decoder.layers.16.mlp.layer_norm.bias', 'decoder.layers.16.mlp.layer_norm.weight', 'decoder.layers.16.self_attn.k_proj.bias', 'decoder.layers.16.self_attn.k_proj.weight', 'decoder.layers.16.self_attn.o_proj.bias', 'decoder.layers.16.self_attn.o_proj.weight', 'decoder.layers.16.self_attn.q_proj.bias', 'decoder.layers.16.self_attn.q_proj.weight', 'decoder.layers.16.self_attn.scaling', 'decoder.layers.16.self_attn.v_proj.bias', 'decoder.layers.16.self_attn.v_proj.weight', 'decoder.layers.17.input_layernorm.weight', 'decoder.layers.17.mlp.down_proj.bias', 'decoder.layers.17.mlp.down_proj.weight', 'decoder.layers.17.mlp.gate_proj.bias', 'decoder.layers.17.mlp.gate_proj.weight', 'decoder.layers.17.mlp.layer_norm.bias', 'decoder.layers.17.mlp.layer_norm.weight', 'decoder.layers.17.self_attn.k_proj.bias', 'decoder.layers.17.self_attn.k_proj.weight', 'decoder.layers.17.self_attn.o_proj.bias', 'decoder.layers.17.self_attn.o_proj.weight', 'decoder.layers.17.self_attn.q_proj.bias', 'decoder.layers.17.self_attn.q_proj.weight', 'decoder.layers.17.self_attn.scaling', 'decoder.layers.17.self_attn.v_proj.bias', 'decoder.layers.17.self_attn.v_proj.weight', 'decoder.layers.18.input_layernorm.weight', 'decoder.layers.18.mlp.down_proj.bias', 'decoder.layers.18.mlp.down_proj.weight', 'decoder.layers.18.mlp.gate_proj.bias', 'decoder.layers.18.mlp.gate_proj.weight', 'decoder.layers.18.mlp.layer_norm.bias', 'decoder.layers.18.mlp.layer_norm.weight', 'decoder.layers.18.self_attn.k_proj.bias', 'decoder.layers.18.self_attn.k_proj.weight', 'decoder.layers.18.self_attn.o_proj.bias', 'decoder.layers.18.self_attn.o_proj.weight', 'decoder.layers.18.self_attn.q_proj.bias', 'decoder.layers.18.self_attn.q_proj.weight', 'decoder.layers.18.self_attn.scaling', 'decoder.layers.18.self_attn.v_proj.bias', 'decoder.layers.18.self_attn.v_proj.weight', 'decoder.layers.19.input_layernorm.weight', 'decoder.layers.19.mlp.down_proj.bias', 'decoder.layers.19.mlp.down_proj.weight', 'decoder.layers.19.mlp.gate_proj.bias', 'decoder.layers.19.mlp.gate_proj.weight', 'decoder.layers.19.mlp.layer_norm.bias', 'decoder.layers.19.mlp.layer_norm.weight', 'decoder.layers.19.self_attn.k_proj.bias', 'decoder.layers.19.self_attn.k_proj.weight', 'decoder.layers.19.self_attn.o_proj.bias', 'decoder.layers.19.self_attn.o_proj.weight', 'decoder.layers.19.self_attn.q_proj.bias', 'decoder.layers.19.self_attn.q_proj.weight', 'decoder.layers.19.self_attn.scaling', 'decoder.layers.19.self_attn.v_proj.bias', 'decoder.layers.19.self_attn.v_proj.weight', 'decoder.layers.2.input_layernorm.weight', 'decoder.layers.2.mlp.down_proj.bias', 'decoder.layers.2.mlp.down_proj.weight', 'decoder.layers.2.mlp.gate_proj.bias', 'decoder.layers.2.mlp.gate_proj.weight', 'decoder.layers.2.mlp.layer_norm.bias', 'decoder.layers.2.mlp.layer_norm.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.o_proj.bias', 'decoder.layers.2.self_attn.o_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.scaling', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.3.input_layernorm.weight', 'decoder.layers.3.mlp.down_proj.bias', 'decoder.layers.3.mlp.down_proj.weight', 'decoder.layers.3.mlp.gate_proj.bias', 'decoder.layers.3.mlp.gate_proj.weight', 'decoder.layers.3.mlp.layer_norm.bias', 'decoder.layers.3.mlp.layer_norm.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.o_proj.bias', 'decoder.layers.3.self_attn.o_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.scaling', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.4.input_layernorm.weight', 'decoder.layers.4.mlp.down_proj.bias', 'decoder.layers.4.mlp.down_proj.weight', 'decoder.layers.4.mlp.gate_proj.bias', 'decoder.layers.4.mlp.gate_proj.weight', 'decoder.layers.4.mlp.layer_norm.bias', 'decoder.layers.4.mlp.layer_norm.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.o_proj.bias', 'decoder.layers.4.self_attn.o_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.scaling', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.5.input_layernorm.weight', 'decoder.layers.5.mlp.down_proj.bias', 'decoder.layers.5.mlp.down_proj.weight', 'decoder.layers.5.mlp.gate_proj.bias', 'decoder.layers.5.mlp.gate_proj.weight', 'decoder.layers.5.mlp.layer_norm.bias', 'decoder.layers.5.mlp.layer_norm.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.o_proj.bias', 'decoder.layers.5.self_attn.o_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.scaling', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.6.input_layernorm.weight', 'decoder.layers.6.mlp.down_proj.bias', 'decoder.layers.6.mlp.down_proj.weight', 'decoder.layers.6.mlp.gate_proj.bias', 'decoder.layers.6.mlp.gate_proj.weight', 'decoder.layers.6.mlp.layer_norm.bias', 'decoder.layers.6.mlp.layer_norm.weight', 'decoder.layers.6.self_attn.k_proj.bias', 'decoder.layers.6.self_attn.k_proj.weight', 'decoder.layers.6.self_attn.o_proj.bias', 'decoder.layers.6.self_attn.o_proj.weight', 'decoder.layers.6.self_attn.q_proj.bias', 'decoder.layers.6.self_attn.q_proj.weight', 'decoder.layers.6.self_attn.scaling', 'decoder.layers.6.self_attn.v_proj.bias', 'decoder.layers.6.self_attn.v_proj.weight', 'decoder.layers.7.input_layernorm.weight', 'decoder.layers.7.mlp.down_proj.bias', 'decoder.layers.7.mlp.down_proj.weight', 'decoder.layers.7.mlp.gate_proj.bias', 'decoder.layers.7.mlp.gate_proj.weight', 'decoder.layers.7.mlp.layer_norm.bias', 'decoder.layers.7.mlp.layer_norm.weight', 'decoder.layers.7.self_attn.k_proj.bias', 'decoder.layers.7.self_attn.k_proj.weight', 'decoder.layers.7.self_attn.o_proj.bias', 'decoder.layers.7.self_attn.o_proj.weight', 'decoder.layers.7.self_attn.q_proj.bias', 'decoder.layers.7.self_attn.q_proj.weight', 'decoder.layers.7.self_attn.scaling', 'decoder.layers.7.self_attn.v_proj.bias', 'decoder.layers.7.self_attn.v_proj.weight', 'decoder.layers.8.input_layernorm.weight', 'decoder.layers.8.mlp.down_proj.bias', 'decoder.layers.8.mlp.down_proj.weight', 'decoder.layers.8.mlp.gate_proj.bias', 'decoder.layers.8.mlp.gate_proj.weight', 'decoder.layers.8.mlp.layer_norm.bias', 'decoder.layers.8.mlp.layer_norm.weight', 'decoder.layers.8.self_attn.k_proj.bias', 'decoder.layers.8.self_attn.k_proj.weight', 'decoder.layers.8.self_attn.o_proj.bias', 'decoder.layers.8.self_attn.o_proj.weight', 'decoder.layers.8.self_attn.q_proj.bias', 'decoder.layers.8.self_attn.q_proj.weight', 'decoder.layers.8.self_attn.scaling', 'decoder.layers.8.self_attn.v_proj.bias', 'decoder.layers.8.self_attn.v_proj.weight', 'decoder.layers.9.input_layernorm.weight', 'decoder.layers.9.mlp.down_proj.bias', 'decoder.layers.9.mlp.down_proj.weight', 'decoder.layers.9.mlp.gate_proj.bias', 'decoder.layers.9.mlp.gate_proj.weight', 'decoder.layers.9.mlp.layer_norm.bias', 'decoder.layers.9.mlp.layer_norm.weight', 'decoder.layers.9.self_attn.k_proj.bias', 'decoder.layers.9.self_attn.k_proj.weight', 'decoder.layers.9.self_attn.o_proj.bias', 'decoder.layers.9.self_attn.o_proj.weight', 'decoder.layers.9.self_attn.q_proj.bias', 'decoder.layers.9.self_attn.q_proj.weight', 'decoder.layers.9.self_attn.scaling', 'decoder.layers.9.self_attn.v_proj.bias', 'decoder.layers.9.self_attn.v_proj.weight', 'horizon_ff_layer.input_layer.bias', 'horizon_ff_layer.input_layer.weight', 'horizon_ff_layer.output_layer.bias', 'horizon_ff_layer.output_layer.weight', 'horizon_ff_layer.residual_layer.bias', 'horizon_ff_layer.residual_layer.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n",
            "  Epoch 1/100 train_loss=1.9344 train_acc=0.3757 eval_loss=1.2651 eval_acc=0.5691 (best)\n",
            "  Epoch 2/100 train_loss=0.7833 train_acc=0.7735 eval_loss=0.9613 eval_acc=0.6685 (best)\n",
            "  Epoch 3/100 train_loss=0.4136 train_acc=0.8812 eval_loss=0.8669 eval_acc=0.7072 (best)\n",
            "  Epoch 4/100 train_loss=0.2742 train_acc=0.9144 eval_loss=0.8241 eval_acc=0.7265 (best)\n",
            "  Epoch 5/100 train_loss=0.1388 train_acc=0.9669 eval_loss=0.9012 eval_acc=0.7320 \n",
            "  Epoch 6/100 train_loss=0.1545 train_acc=0.9530 eval_loss=0.9607 eval_acc=0.7099 \n",
            "  Epoch 7/100 train_loss=0.1102 train_acc=0.9558 eval_loss=1.4312 eval_acc=0.7127 \n",
            "  Epoch 8/100 train_loss=0.2136 train_acc=0.9365 eval_loss=1.0742 eval_acc=0.7127 \n",
            "  Epoch 9/100 train_loss=0.1112 train_acc=0.9613 eval_loss=1.1107 eval_acc=0.7155 \n",
            "  Epoch 10/100 train_loss=0.1375 train_acc=0.9448 eval_loss=1.3314 eval_acc=0.7155 \n",
            "  Epoch 11/100 train_loss=0.1537 train_acc=0.9530 eval_loss=1.1085 eval_acc=0.7376 \n",
            "  Epoch 12/100 train_loss=0.1056 train_acc=0.9641 eval_loss=1.3548 eval_acc=0.7155 \n",
            "  Epoch 13/100 train_loss=0.1168 train_acc=0.9669 eval_loss=1.2035 eval_acc=0.7044 \n",
            "  Epoch 14/100 train_loss=0.0659 train_acc=0.9834 eval_loss=1.7051 eval_acc=0.6436 \n",
            "  Early stopping on google/timesfm-2.5-200m-pytorch: no improvement for 10 epochs (best epoch = 4)\n",
            "    tfm[google/timesfm-2.5-200m-pytorch] train_acc=0.9144 eval_acc=0.64364640883977897178880311912507750093936920\n",
            "    mrh_acc=0.8039 mr+h+kg_acc=0.8260 kg_acc=0.7928 ensemble=0.8287 (w=0.60)\n",
            "  Split 1/1 - accuracy=0.8287 time=372.0s\n",
            "Completed EOGVerticalSignal: Mean Acc=0.8287\n",
            "\n",
            "=== 30/109 EthanolLevel ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n",
            "    Gate split 1/5: baseline_loss=1.1216 adaptive_loss=1.1802\n",
            "    Gate split 2/5: baseline_loss=0.9088 adaptive_loss=0.9148\n",
            "    Gate split 3/5: baseline_loss=1.0256 adaptive_loss=1.0022\n",
            "    Gate split 4/5: baseline_loss=1.1605 adaptive_loss=1.0735\n",
            "    Gate split 5/5: baseline_loss=0.9997 adaptive_loss=1.0362\n",
            "  Decision: Adaptive kept (loss 1.0414 vs baseline 1.0432, delta=-0.0019 <= +0.0200); savgol(window=21, poly=3) - high noise (std_diff)\n",
            "\n",
            "=== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at google/timesfm-2.5-200m-pytorch were not used when initializing TimesFmModelForPrediction: ['output_projection_point.hidden_layer.weight', 'output_projection_point.output_layer.weight', 'output_projection_point.residual_layer.weight', 'output_projection_quantiles.hidden_layer.weight', 'output_projection_quantiles.output_layer.weight', 'output_projection_quantiles.residual_layer.weight', 'stacked_xf.0.attn.key_ln.scale', 'stacked_xf.0.attn.out.weight', 'stacked_xf.0.attn.per_dim_scale.per_dim_scale', 'stacked_xf.0.attn.qkv_proj.weight', 'stacked_xf.0.attn.query_ln.scale', 'stacked_xf.0.ff0.weight', 'stacked_xf.0.ff1.weight', 'stacked_xf.0.post_attn_ln.scale', 'stacked_xf.0.post_ff_ln.scale', 'stacked_xf.0.pre_attn_ln.scale', 'stacked_xf.0.pre_ff_ln.scale', 'stacked_xf.1.attn.key_ln.scale', 'stacked_xf.1.attn.out.weight', 'stacked_xf.1.attn.per_dim_scale.per_dim_scale', 'stacked_xf.1.attn.qkv_proj.weight', 'stacked_xf.1.attn.query_ln.scale', 'stacked_xf.1.ff0.weight', 'stacked_xf.1.ff1.weight', 'stacked_xf.1.post_attn_ln.scale', 'stacked_xf.1.post_ff_ln.scale', 'stacked_xf.1.pre_attn_ln.scale', 'stacked_xf.1.pre_ff_ln.scale', 'stacked_xf.10.attn.key_ln.scale', 'stacked_xf.10.attn.out.weight', 'stacked_xf.10.attn.per_dim_scale.per_dim_scale', 'stacked_xf.10.attn.qkv_proj.weight', 'stacked_xf.10.attn.query_ln.scale', 'stacked_xf.10.ff0.weight', 'stacked_xf.10.ff1.weight', 'stacked_xf.10.post_attn_ln.scale', 'stacked_xf.10.post_ff_ln.scale', 'stacked_xf.10.pre_attn_ln.scale', 'stacked_xf.10.pre_ff_ln.scale', 'stacked_xf.11.attn.key_ln.scale', 'stacked_xf.11.attn.out.weight', 'stacked_xf.11.attn.per_dim_scale.per_dim_scale', 'stacked_xf.11.attn.qkv_proj.weight', 'stacked_xf.11.attn.query_ln.scale', 'stacked_xf.11.ff0.weight', 'stacked_xf.11.ff1.weight', 'stacked_xf.11.post_attn_ln.scale', 'stacked_xf.11.post_ff_ln.scale', 'stacked_xf.11.pre_attn_ln.scale', 'stacked_xf.11.pre_ff_ln.scale', 'stacked_xf.12.attn.key_ln.scale', 'stacked_xf.12.attn.out.weight', 'stacked_xf.12.attn.per_dim_scale.per_dim_scale', 'stacked_xf.12.attn.qkv_proj.weight', 'stacked_xf.12.attn.query_ln.scale', 'stacked_xf.12.ff0.weight', 'stacked_xf.12.ff1.weight', 'stacked_xf.12.post_attn_ln.scale', 'stacked_xf.12.post_ff_ln.scale', 'stacked_xf.12.pre_attn_ln.scale', 'stacked_xf.12.pre_ff_ln.scale', 'stacked_xf.13.attn.key_ln.scale', 'stacked_xf.13.attn.out.weight', 'stacked_xf.13.attn.per_dim_scale.per_dim_scale', 'stacked_xf.13.attn.qkv_proj.weight', 'stacked_xf.13.attn.query_ln.scale', 'stacked_xf.13.ff0.weight', 'stacked_xf.13.ff1.weight', 'stacked_xf.13.post_attn_ln.scale', 'stacked_xf.13.post_ff_ln.scale', 'stacked_xf.13.pre_attn_ln.scale', 'stacked_xf.13.pre_ff_ln.scale', 'stacked_xf.14.attn.key_ln.scale', 'stacked_xf.14.attn.out.weight', 'stacked_xf.14.attn.per_dim_scale.per_dim_scale', 'stacked_xf.14.attn.qkv_proj.weight', 'stacked_xf.14.attn.query_ln.scale', 'stacked_xf.14.ff0.weight', 'stacked_xf.14.ff1.weight', 'stacked_xf.14.post_attn_ln.scale', 'stacked_xf.14.post_ff_ln.scale', 'stacked_xf.14.pre_attn_ln.scale', 'stacked_xf.14.pre_ff_ln.scale', 'stacked_xf.15.attn.key_ln.scale', 'stacked_xf.15.attn.out.weight', 'stacked_xf.15.attn.per_dim_scale.per_dim_scale', 'stacked_xf.15.attn.qkv_proj.weight', 'stacked_xf.15.attn.query_ln.scale', 'stacked_xf.15.ff0.weight', 'stacked_xf.15.ff1.weight', 'stacked_xf.15.post_attn_ln.scale', 'stacked_xf.15.post_ff_ln.scale', 'stacked_xf.15.pre_attn_ln.scale', 'stacked_xf.15.pre_ff_ln.scale', 'stacked_xf.16.attn.key_ln.scale', 'stacked_xf.16.attn.out.weight', 'stacked_xf.16.attn.per_dim_scale.per_dim_scale', 'stacked_xf.16.attn.qkv_proj.weight', 'stacked_xf.16.attn.query_ln.scale', 'stacked_xf.16.ff0.weight', 'stacked_xf.16.ff1.weight', 'stacked_xf.16.post_attn_ln.scale', 'stacked_xf.16.post_ff_ln.scale', 'stacked_xf.16.pre_attn_ln.scale', 'stacked_xf.16.pre_ff_ln.scale', 'stacked_xf.17.attn.key_ln.scale', 'stacked_xf.17.attn.out.weight', 'stacked_xf.17.attn.per_dim_scale.per_dim_scale', 'stacked_xf.17.attn.qkv_proj.weight', 'stacked_xf.17.attn.query_ln.scale', 'stacked_xf.17.ff0.weight', 'stacked_xf.17.ff1.weight', 'stacked_xf.17.post_attn_ln.scale', 'stacked_xf.17.post_ff_ln.scale', 'stacked_xf.17.pre_attn_ln.scale', 'stacked_xf.17.pre_ff_ln.scale', 'stacked_xf.18.attn.key_ln.scale', 'stacked_xf.18.attn.out.weight', 'stacked_xf.18.attn.per_dim_scale.per_dim_scale', 'stacked_xf.18.attn.qkv_proj.weight', 'stacked_xf.18.attn.query_ln.scale', 'stacked_xf.18.ff0.weight', 'stacked_xf.18.ff1.weight', 'stacked_xf.18.post_attn_ln.scale', 'stacked_xf.18.post_ff_ln.scale', 'stacked_xf.18.pre_attn_ln.scale', 'stacked_xf.18.pre_ff_ln.scale', 'stacked_xf.19.attn.key_ln.scale', 'stacked_xf.19.attn.out.weight', 'stacked_xf.19.attn.per_dim_scale.per_dim_scale', 'stacked_xf.19.attn.qkv_proj.weight', 'stacked_xf.19.attn.query_ln.scale', 'stacked_xf.19.ff0.weight', 'stacked_xf.19.ff1.weight', 'stacked_xf.19.post_attn_ln.scale', 'stacked_xf.19.post_ff_ln.scale', 'stacked_xf.19.pre_attn_ln.scale', 'stacked_xf.19.pre_ff_ln.scale', 'stacked_xf.2.attn.key_ln.scale', 'stacked_xf.2.attn.out.weight', 'stacked_xf.2.attn.per_dim_scale.per_dim_scale', 'stacked_xf.2.attn.qkv_proj.weight', 'stacked_xf.2.attn.query_ln.scale', 'stacked_xf.2.ff0.weight', 'stacked_xf.2.ff1.weight', 'stacked_xf.2.post_attn_ln.scale', 'stacked_xf.2.post_ff_ln.scale', 'stacked_xf.2.pre_attn_ln.scale', 'stacked_xf.2.pre_ff_ln.scale', 'stacked_xf.3.attn.key_ln.scale', 'stacked_xf.3.attn.out.weight', 'stacked_xf.3.attn.per_dim_scale.per_dim_scale', 'stacked_xf.3.attn.qkv_proj.weight', 'stacked_xf.3.attn.query_ln.scale', 'stacked_xf.3.ff0.weight', 'stacked_xf.3.ff1.weight', 'stacked_xf.3.post_attn_ln.scale', 'stacked_xf.3.post_ff_ln.scale', 'stacked_xf.3.pre_attn_ln.scale', 'stacked_xf.3.pre_ff_ln.scale', 'stacked_xf.4.attn.key_ln.scale', 'stacked_xf.4.attn.out.weight', 'stacked_xf.4.attn.per_dim_scale.per_dim_scale', 'stacked_xf.4.attn.qkv_proj.weight', 'stacked_xf.4.attn.query_ln.scale', 'stacked_xf.4.ff0.weight', 'stacked_xf.4.ff1.weight', 'stacked_xf.4.post_attn_ln.scale', 'stacked_xf.4.post_ff_ln.scale', 'stacked_xf.4.pre_attn_ln.scale', 'stacked_xf.4.pre_ff_ln.scale', 'stacked_xf.5.attn.key_ln.scale', 'stacked_xf.5.attn.out.weight', 'stacked_xf.5.attn.per_dim_scale.per_dim_scale', 'stacked_xf.5.attn.qkv_proj.weight', 'stacked_xf.5.attn.query_ln.scale', 'stacked_xf.5.ff0.weight', 'stacked_xf.5.ff1.weight', 'stacked_xf.5.post_attn_ln.scale', 'stacked_xf.5.post_ff_ln.scale', 'stacked_xf.5.pre_attn_ln.scale', 'stacked_xf.5.pre_ff_ln.scale', 'stacked_xf.6.attn.key_ln.scale', 'stacked_xf.6.attn.out.weight', 'stacked_xf.6.attn.per_dim_scale.per_dim_scale', 'stacked_xf.6.attn.qkv_proj.weight', 'stacked_xf.6.attn.query_ln.scale', 'stacked_xf.6.ff0.weight', 'stacked_xf.6.ff1.weight', 'stacked_xf.6.post_attn_ln.scale', 'stacked_xf.6.post_ff_ln.scale', 'stacked_xf.6.pre_attn_ln.scale', 'stacked_xf.6.pre_ff_ln.scale', 'stacked_xf.7.attn.key_ln.scale', 'stacked_xf.7.attn.out.weight', 'stacked_xf.7.attn.per_dim_scale.per_dim_scale', 'stacked_xf.7.attn.qkv_proj.weight', 'stacked_xf.7.attn.query_ln.scale', 'stacked_xf.7.ff0.weight', 'stacked_xf.7.ff1.weight', 'stacked_xf.7.post_attn_ln.scale', 'stacked_xf.7.post_ff_ln.scale', 'stacked_xf.7.pre_attn_ln.scale', 'stacked_xf.7.pre_ff_ln.scale', 'stacked_xf.8.attn.key_ln.scale', 'stacked_xf.8.attn.out.weight', 'stacked_xf.8.attn.per_dim_scale.per_dim_scale', 'stacked_xf.8.attn.qkv_proj.weight', 'stacked_xf.8.attn.query_ln.scale', 'stacked_xf.8.ff0.weight', 'stacked_xf.8.ff1.weight', 'stacked_xf.8.post_attn_ln.scale', 'stacked_xf.8.post_ff_ln.scale', 'stacked_xf.8.pre_attn_ln.scale', 'stacked_xf.8.pre_ff_ln.scale', 'stacked_xf.9.attn.key_ln.scale', 'stacked_xf.9.attn.out.weight', 'stacked_xf.9.attn.per_dim_scale.per_dim_scale', 'stacked_xf.9.attn.qkv_proj.weight', 'stacked_xf.9.attn.query_ln.scale', 'stacked_xf.9.ff0.weight', 'stacked_xf.9.ff1.weight', 'stacked_xf.9.post_attn_ln.scale', 'stacked_xf.9.post_ff_ln.scale', 'stacked_xf.9.pre_attn_ln.scale', 'stacked_xf.9.pre_ff_ln.scale', 'tokenizer.hidden_layer.bias', 'tokenizer.hidden_layer.weight', 'tokenizer.output_layer.bias', 'tokenizer.output_layer.weight', 'tokenizer.residual_layer.bias', 'tokenizer.residual_layer.weight']\n",
            "- This IS expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of TimesFmModelForPrediction were not initialized from the model checkpoint at google/timesfm-2.5-200m-pytorch and are newly initialized: ['decoder.freq_emb.weight', 'decoder.input_ff_layer.input_layer.bias', 'decoder.input_ff_layer.input_layer.weight', 'decoder.input_ff_layer.output_layer.bias', 'decoder.input_ff_layer.output_layer.weight', 'decoder.input_ff_layer.residual_layer.bias', 'decoder.input_ff_layer.residual_layer.weight', 'decoder.layers.0.input_layernorm.weight', 'decoder.layers.0.mlp.down_proj.bias', 'decoder.layers.0.mlp.down_proj.weight', 'decoder.layers.0.mlp.gate_proj.bias', 'decoder.layers.0.mlp.gate_proj.weight', 'decoder.layers.0.mlp.layer_norm.bias', 'decoder.layers.0.mlp.layer_norm.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.o_proj.bias', 'decoder.layers.0.self_attn.o_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.scaling', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.1.input_layernorm.weight', 'decoder.layers.1.mlp.down_proj.bias', 'decoder.layers.1.mlp.down_proj.weight', 'decoder.layers.1.mlp.gate_proj.bias', 'decoder.layers.1.mlp.gate_proj.weight', 'decoder.layers.1.mlp.layer_norm.bias', 'decoder.layers.1.mlp.layer_norm.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.o_proj.bias', 'decoder.layers.1.self_attn.o_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.scaling', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.10.input_layernorm.weight', 'decoder.layers.10.mlp.down_proj.bias', 'decoder.layers.10.mlp.down_proj.weight', 'decoder.layers.10.mlp.gate_proj.bias', 'decoder.layers.10.mlp.gate_proj.weight', 'decoder.layers.10.mlp.layer_norm.bias', 'decoder.layers.10.mlp.layer_norm.weight', 'decoder.layers.10.self_attn.k_proj.bias', 'decoder.layers.10.self_attn.k_proj.weight', 'decoder.layers.10.self_attn.o_proj.bias', 'decoder.layers.10.self_attn.o_proj.weight', 'decoder.layers.10.self_attn.q_proj.bias', 'decoder.layers.10.self_attn.q_proj.weight', 'decoder.layers.10.self_attn.scaling', 'decoder.layers.10.self_attn.v_proj.bias', 'decoder.layers.10.self_attn.v_proj.weight', 'decoder.layers.11.input_layernorm.weight', 'decoder.layers.11.mlp.down_proj.bias', 'decoder.layers.11.mlp.down_proj.weight', 'decoder.layers.11.mlp.gate_proj.bias', 'decoder.layers.11.mlp.gate_proj.weight', 'decoder.layers.11.mlp.layer_norm.bias', 'decoder.layers.11.mlp.layer_norm.weight', 'decoder.layers.11.self_attn.k_proj.bias', 'decoder.layers.11.self_attn.k_proj.weight', 'decoder.layers.11.self_attn.o_proj.bias', 'decoder.layers.11.self_attn.o_proj.weight', 'decoder.layers.11.self_attn.q_proj.bias', 'decoder.layers.11.self_attn.q_proj.weight', 'decoder.layers.11.self_attn.scaling', 'decoder.layers.11.self_attn.v_proj.bias', 'decoder.layers.11.self_attn.v_proj.weight', 'decoder.layers.12.input_layernorm.weight', 'decoder.layers.12.mlp.down_proj.bias', 'decoder.layers.12.mlp.down_proj.weight', 'decoder.layers.12.mlp.gate_proj.bias', 'decoder.layers.12.mlp.gate_proj.weight', 'decoder.layers.12.mlp.layer_norm.bias', 'decoder.layers.12.mlp.layer_norm.weight', 'decoder.layers.12.self_attn.k_proj.bias', 'decoder.layers.12.self_attn.k_proj.weight', 'decoder.layers.12.self_attn.o_proj.bias', 'decoder.layers.12.self_attn.o_proj.weight', 'decoder.layers.12.self_attn.q_proj.bias', 'decoder.layers.12.self_attn.q_proj.weight', 'decoder.layers.12.self_attn.scaling', 'decoder.layers.12.self_attn.v_proj.bias', 'decoder.layers.12.self_attn.v_proj.weight', 'decoder.layers.13.input_layernorm.weight', 'decoder.layers.13.mlp.down_proj.bias', 'decoder.layers.13.mlp.down_proj.weight', 'decoder.layers.13.mlp.gate_proj.bias', 'decoder.layers.13.mlp.gate_proj.weight', 'decoder.layers.13.mlp.layer_norm.bias', 'decoder.layers.13.mlp.layer_norm.weight', 'decoder.layers.13.self_attn.k_proj.bias', 'decoder.layers.13.self_attn.k_proj.weight', 'decoder.layers.13.self_attn.o_proj.bias', 'decoder.layers.13.self_attn.o_proj.weight', 'decoder.layers.13.self_attn.q_proj.bias', 'decoder.layers.13.self_attn.q_proj.weight', 'decoder.layers.13.self_attn.scaling', 'decoder.layers.13.self_attn.v_proj.bias', 'decoder.layers.13.self_attn.v_proj.weight', 'decoder.layers.14.input_layernorm.weight', 'decoder.layers.14.mlp.down_proj.bias', 'decoder.layers.14.mlp.down_proj.weight', 'decoder.layers.14.mlp.gate_proj.bias', 'decoder.layers.14.mlp.gate_proj.weight', 'decoder.layers.14.mlp.layer_norm.bias', 'decoder.layers.14.mlp.layer_norm.weight', 'decoder.layers.14.self_attn.k_proj.bias', 'decoder.layers.14.self_attn.k_proj.weight', 'decoder.layers.14.self_attn.o_proj.bias', 'decoder.layers.14.self_attn.o_proj.weight', 'decoder.layers.14.self_attn.q_proj.bias', 'decoder.layers.14.self_attn.q_proj.weight', 'decoder.layers.14.self_attn.scaling', 'decoder.layers.14.self_attn.v_proj.bias', 'decoder.layers.14.self_attn.v_proj.weight', 'decoder.layers.15.input_layernorm.weight', 'decoder.layers.15.mlp.down_proj.bias', 'decoder.layers.15.mlp.down_proj.weight', 'decoder.layers.15.mlp.gate_proj.bias', 'decoder.layers.15.mlp.gate_proj.weight', 'decoder.layers.15.mlp.layer_norm.bias', 'decoder.layers.15.mlp.layer_norm.weight', 'decoder.layers.15.self_attn.k_proj.bias', 'decoder.layers.15.self_attn.k_proj.weight', 'decoder.layers.15.self_attn.o_proj.bias', 'decoder.layers.15.self_attn.o_proj.weight', 'decoder.layers.15.self_attn.q_proj.bias', 'decoder.layers.15.self_attn.q_proj.weight', 'decoder.layers.15.self_attn.scaling', 'decoder.layers.15.self_attn.v_proj.bias', 'decoder.layers.15.self_attn.v_proj.weight', 'decoder.layers.16.input_layernorm.weight', 'decoder.layers.16.mlp.down_proj.bias', 'decoder.layers.16.mlp.down_proj.weight', 'decoder.layers.16.mlp.gate_proj.bias', 'decoder.layers.16.mlp.gate_proj.weight', 'decoder.layers.16.mlp.layer_norm.bias', 'decoder.layers.16.mlp.layer_norm.weight', 'decoder.layers.16.self_attn.k_proj.bias', 'decoder.layers.16.self_attn.k_proj.weight', 'decoder.layers.16.self_attn.o_proj.bias', 'decoder.layers.16.self_attn.o_proj.weight', 'decoder.layers.16.self_attn.q_proj.bias', 'decoder.layers.16.self_attn.q_proj.weight', 'decoder.layers.16.self_attn.scaling', 'decoder.layers.16.self_attn.v_proj.bias', 'decoder.layers.16.self_attn.v_proj.weight', 'decoder.layers.17.input_layernorm.weight', 'decoder.layers.17.mlp.down_proj.bias', 'decoder.layers.17.mlp.down_proj.weight', 'decoder.layers.17.mlp.gate_proj.bias', 'decoder.layers.17.mlp.gate_proj.weight', 'decoder.layers.17.mlp.layer_norm.bias', 'decoder.layers.17.mlp.layer_norm.weight', 'decoder.layers.17.self_attn.k_proj.bias', 'decoder.layers.17.self_attn.k_proj.weight', 'decoder.layers.17.self_attn.o_proj.bias', 'decoder.layers.17.self_attn.o_proj.weight', 'decoder.layers.17.self_attn.q_proj.bias', 'decoder.layers.17.self_attn.q_proj.weight', 'decoder.layers.17.self_attn.scaling', 'decoder.layers.17.self_attn.v_proj.bias', 'decoder.layers.17.self_attn.v_proj.weight', 'decoder.layers.18.input_layernorm.weight', 'decoder.layers.18.mlp.down_proj.bias', 'decoder.layers.18.mlp.down_proj.weight', 'decoder.layers.18.mlp.gate_proj.bias', 'decoder.layers.18.mlp.gate_proj.weight', 'decoder.layers.18.mlp.layer_norm.bias', 'decoder.layers.18.mlp.layer_norm.weight', 'decoder.layers.18.self_attn.k_proj.bias', 'decoder.layers.18.self_attn.k_proj.weight', 'decoder.layers.18.self_attn.o_proj.bias', 'decoder.layers.18.self_attn.o_proj.weight', 'decoder.layers.18.self_attn.q_proj.bias', 'decoder.layers.18.self_attn.q_proj.weight', 'decoder.layers.18.self_attn.scaling', 'decoder.layers.18.self_attn.v_proj.bias', 'decoder.layers.18.self_attn.v_proj.weight', 'decoder.layers.19.input_layernorm.weight', 'decoder.layers.19.mlp.down_proj.bias', 'decoder.layers.19.mlp.down_proj.weight', 'decoder.layers.19.mlp.gate_proj.bias', 'decoder.layers.19.mlp.gate_proj.weight', 'decoder.layers.19.mlp.layer_norm.bias', 'decoder.layers.19.mlp.layer_norm.weight', 'decoder.layers.19.self_attn.k_proj.bias', 'decoder.layers.19.self_attn.k_proj.weight', 'decoder.layers.19.self_attn.o_proj.bias', 'decoder.layers.19.self_attn.o_proj.weight', 'decoder.layers.19.self_attn.q_proj.bias', 'decoder.layers.19.self_attn.q_proj.weight', 'decoder.layers.19.self_attn.scaling', 'decoder.layers.19.self_attn.v_proj.bias', 'decoder.layers.19.self_attn.v_proj.weight', 'decoder.layers.2.input_layernorm.weight', 'decoder.layers.2.mlp.down_proj.bias', 'decoder.layers.2.mlp.down_proj.weight', 'decoder.layers.2.mlp.gate_proj.bias', 'decoder.layers.2.mlp.gate_proj.weight', 'decoder.layers.2.mlp.layer_norm.bias', 'decoder.layers.2.mlp.layer_norm.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.o_proj.bias', 'decoder.layers.2.self_attn.o_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.scaling', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.3.input_layernorm.weight', 'decoder.layers.3.mlp.down_proj.bias', 'decoder.layers.3.mlp.down_proj.weight', 'decoder.layers.3.mlp.gate_proj.bias', 'decoder.layers.3.mlp.gate_proj.weight', 'decoder.layers.3.mlp.layer_norm.bias', 'decoder.layers.3.mlp.layer_norm.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.o_proj.bias', 'decoder.layers.3.self_attn.o_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.scaling', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.4.input_layernorm.weight', 'decoder.layers.4.mlp.down_proj.bias', 'decoder.layers.4.mlp.down_proj.weight', 'decoder.layers.4.mlp.gate_proj.bias', 'decoder.layers.4.mlp.gate_proj.weight', 'decoder.layers.4.mlp.layer_norm.bias', 'decoder.layers.4.mlp.layer_norm.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.o_proj.bias', 'decoder.layers.4.self_attn.o_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.scaling', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.5.input_layernorm.weight', 'decoder.layers.5.mlp.down_proj.bias', 'decoder.layers.5.mlp.down_proj.weight', 'decoder.layers.5.mlp.gate_proj.bias', 'decoder.layers.5.mlp.gate_proj.weight', 'decoder.layers.5.mlp.layer_norm.bias', 'decoder.layers.5.mlp.layer_norm.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.o_proj.bias', 'decoder.layers.5.self_attn.o_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.scaling', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.6.input_layernorm.weight', 'decoder.layers.6.mlp.down_proj.bias', 'decoder.layers.6.mlp.down_proj.weight', 'decoder.layers.6.mlp.gate_proj.bias', 'decoder.layers.6.mlp.gate_proj.weight', 'decoder.layers.6.mlp.layer_norm.bias', 'decoder.layers.6.mlp.layer_norm.weight', 'decoder.layers.6.self_attn.k_proj.bias', 'decoder.layers.6.self_attn.k_proj.weight', 'decoder.layers.6.self_attn.o_proj.bias', 'decoder.layers.6.self_attn.o_proj.weight', 'decoder.layers.6.self_attn.q_proj.bias', 'decoder.layers.6.self_attn.q_proj.weight', 'decoder.layers.6.self_attn.scaling', 'decoder.layers.6.self_attn.v_proj.bias', 'decoder.layers.6.self_attn.v_proj.weight', 'decoder.layers.7.input_layernorm.weight', 'decoder.layers.7.mlp.down_proj.bias', 'decoder.layers.7.mlp.down_proj.weight', 'decoder.layers.7.mlp.gate_proj.bias', 'decoder.layers.7.mlp.gate_proj.weight', 'decoder.layers.7.mlp.layer_norm.bias', 'decoder.layers.7.mlp.layer_norm.weight', 'decoder.layers.7.self_attn.k_proj.bias', 'decoder.layers.7.self_attn.k_proj.weight', 'decoder.layers.7.self_attn.o_proj.bias', 'decoder.layers.7.self_attn.o_proj.weight', 'decoder.layers.7.self_attn.q_proj.bias', 'decoder.layers.7.self_attn.q_proj.weight', 'decoder.layers.7.self_attn.scaling', 'decoder.layers.7.self_attn.v_proj.bias', 'decoder.layers.7.self_attn.v_proj.weight', 'decoder.layers.8.input_layernorm.weight', 'decoder.layers.8.mlp.down_proj.bias', 'decoder.layers.8.mlp.down_proj.weight', 'decoder.layers.8.mlp.gate_proj.bias', 'decoder.layers.8.mlp.gate_proj.weight', 'decoder.layers.8.mlp.layer_norm.bias', 'decoder.layers.8.mlp.layer_norm.weight', 'decoder.layers.8.self_attn.k_proj.bias', 'decoder.layers.8.self_attn.k_proj.weight', 'decoder.layers.8.self_attn.o_proj.bias', 'decoder.layers.8.self_attn.o_proj.weight', 'decoder.layers.8.self_attn.q_proj.bias', 'decoder.layers.8.self_attn.q_proj.weight', 'decoder.layers.8.self_attn.scaling', 'decoder.layers.8.self_attn.v_proj.bias', 'decoder.layers.8.self_attn.v_proj.weight', 'decoder.layers.9.input_layernorm.weight', 'decoder.layers.9.mlp.down_proj.bias', 'decoder.layers.9.mlp.down_proj.weight', 'decoder.layers.9.mlp.gate_proj.bias', 'decoder.layers.9.mlp.gate_proj.weight', 'decoder.layers.9.mlp.layer_norm.bias', 'decoder.layers.9.mlp.layer_norm.weight', 'decoder.layers.9.self_attn.k_proj.bias', 'decoder.layers.9.self_attn.k_proj.weight', 'decoder.layers.9.self_attn.o_proj.bias', 'decoder.layers.9.self_attn.o_proj.weight', 'decoder.layers.9.self_attn.q_proj.bias', 'decoder.layers.9.self_attn.q_proj.weight', 'decoder.layers.9.self_attn.scaling', 'decoder.layers.9.self_attn.v_proj.bias', 'decoder.layers.9.self_attn.v_proj.weight', 'horizon_ff_layer.input_layer.bias', 'horizon_ff_layer.input_layer.weight', 'horizon_ff_layer.output_layer.bias', 'horizon_ff_layer.output_layer.weight', 'horizon_ff_layer.residual_layer.bias', 'horizon_ff_layer.residual_layer.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n",
            "  Epoch 1/100 train_loss=1.3807 train_acc=0.2798 eval_loss=1.2956 eval_acc=0.4140 (best)\n",
            "  Epoch 2/100 train_loss=1.1444 train_acc=0.4742 eval_loss=1.0687 eval_acc=0.4820 (best)\n",
            "  Epoch 3/100 train_loss=0.7701 train_acc=0.6786 eval_loss=0.8249 eval_acc=0.6200 (best)\n",
            "  Epoch 4/100 train_loss=0.4813 train_acc=0.8036 eval_loss=1.0039 eval_acc=0.6440 \n",
            "  Epoch 5/100 train_loss=0.5673 train_acc=0.7837 eval_loss=1.2441 eval_acc=0.5700 \n",
            "  Epoch 6/100 train_loss=0.3843 train_acc=0.8472 eval_loss=0.9782 eval_acc=0.6360 \n",
            "  Epoch 7/100 train_loss=0.2045 train_acc=0.9246 eval_loss=1.1853 eval_acc=0.6360 \n",
            "  Epoch 8/100 train_loss=0.4118 train_acc=0.8591 eval_loss=1.1778 eval_acc=0.7080 \n",
            "  Epoch 9/100 train_loss=0.2362 train_acc=0.9107 eval_loss=1.1862 eval_acc=0.6420 \n",
            "  Epoch 10/100 train_loss=0.2947 train_acc=0.9107 eval_loss=0.8580 eval_acc=0.7200 \n",
            "  Epoch 11/100 train_loss=0.2182 train_acc=0.9286 eval_loss=0.8543 eval_acc=0.7160 \n",
            "  Epoch 12/100 train_loss=0.1023 train_acc=0.9563 eval_loss=0.9294 eval_acc=0.7640 \n",
            "  Epoch 13/100 train_loss=0.0548 train_acc=0.9762 eval_loss=1.0238 eval_acc=0.7420 \n",
            "  Early stopping on google/timesfm-2.5-200m-pytorch: no improvement for 10 epochs (best epoch = 3)\n",
            "    tfm[google/timesfm-2.5-200m-pytorch] train_acc=0.6786 eval_acc=0.74199999999999999289457264239899814128875732\n",
            "    mrh_acc=0.7540 mr+h+kg_acc=0.7800 kg_acc=0.7740 ensemble=0.7780 (w=0.30)\n",
            "  Split 1/1 - accuracy=0.7780 time=447.7s\n",
            "Completed EthanolLevel: Mean Acc=0.7780\n",
            "\n",
            "=== 31/109 FaceAll ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n",
            "    Gate split 1/5: baseline_loss=0.1680 adaptive_loss=0.1512\n",
            "    Gate split 2/5: baseline_loss=0.1008 adaptive_loss=0.1020\n",
            "    Gate split 3/5: baseline_loss=0.0962 adaptive_loss=0.0752\n",
            "    Gate split 4/5: baseline_loss=0.1137 adaptive_loss=0.1091\n",
            "    Gate split 5/5: baseline_loss=0.1299 adaptive_loss=0.1097\n",
            "  Decision: Adaptive kept (loss 0.1095 vs baseline 0.1217, delta=-0.0123 <= +0.0200); savgol(window=7, poly=2) - high noise (std_diff)\n",
            "\n",
            "=== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at google/timesfm-2.5-200m-pytorch were not used when initializing TimesFmModelForPrediction: ['output_projection_point.hidden_layer.weight', 'output_projection_point.output_layer.weight', 'output_projection_point.residual_layer.weight', 'output_projection_quantiles.hidden_layer.weight', 'output_projection_quantiles.output_layer.weight', 'output_projection_quantiles.residual_layer.weight', 'stacked_xf.0.attn.key_ln.scale', 'stacked_xf.0.attn.out.weight', 'stacked_xf.0.attn.per_dim_scale.per_dim_scale', 'stacked_xf.0.attn.qkv_proj.weight', 'stacked_xf.0.attn.query_ln.scale', 'stacked_xf.0.ff0.weight', 'stacked_xf.0.ff1.weight', 'stacked_xf.0.post_attn_ln.scale', 'stacked_xf.0.post_ff_ln.scale', 'stacked_xf.0.pre_attn_ln.scale', 'stacked_xf.0.pre_ff_ln.scale', 'stacked_xf.1.attn.key_ln.scale', 'stacked_xf.1.attn.out.weight', 'stacked_xf.1.attn.per_dim_scale.per_dim_scale', 'stacked_xf.1.attn.qkv_proj.weight', 'stacked_xf.1.attn.query_ln.scale', 'stacked_xf.1.ff0.weight', 'stacked_xf.1.ff1.weight', 'stacked_xf.1.post_attn_ln.scale', 'stacked_xf.1.post_ff_ln.scale', 'stacked_xf.1.pre_attn_ln.scale', 'stacked_xf.1.pre_ff_ln.scale', 'stacked_xf.10.attn.key_ln.scale', 'stacked_xf.10.attn.out.weight', 'stacked_xf.10.attn.per_dim_scale.per_dim_scale', 'stacked_xf.10.attn.qkv_proj.weight', 'stacked_xf.10.attn.query_ln.scale', 'stacked_xf.10.ff0.weight', 'stacked_xf.10.ff1.weight', 'stacked_xf.10.post_attn_ln.scale', 'stacked_xf.10.post_ff_ln.scale', 'stacked_xf.10.pre_attn_ln.scale', 'stacked_xf.10.pre_ff_ln.scale', 'stacked_xf.11.attn.key_ln.scale', 'stacked_xf.11.attn.out.weight', 'stacked_xf.11.attn.per_dim_scale.per_dim_scale', 'stacked_xf.11.attn.qkv_proj.weight', 'stacked_xf.11.attn.query_ln.scale', 'stacked_xf.11.ff0.weight', 'stacked_xf.11.ff1.weight', 'stacked_xf.11.post_attn_ln.scale', 'stacked_xf.11.post_ff_ln.scale', 'stacked_xf.11.pre_attn_ln.scale', 'stacked_xf.11.pre_ff_ln.scale', 'stacked_xf.12.attn.key_ln.scale', 'stacked_xf.12.attn.out.weight', 'stacked_xf.12.attn.per_dim_scale.per_dim_scale', 'stacked_xf.12.attn.qkv_proj.weight', 'stacked_xf.12.attn.query_ln.scale', 'stacked_xf.12.ff0.weight', 'stacked_xf.12.ff1.weight', 'stacked_xf.12.post_attn_ln.scale', 'stacked_xf.12.post_ff_ln.scale', 'stacked_xf.12.pre_attn_ln.scale', 'stacked_xf.12.pre_ff_ln.scale', 'stacked_xf.13.attn.key_ln.scale', 'stacked_xf.13.attn.out.weight', 'stacked_xf.13.attn.per_dim_scale.per_dim_scale', 'stacked_xf.13.attn.qkv_proj.weight', 'stacked_xf.13.attn.query_ln.scale', 'stacked_xf.13.ff0.weight', 'stacked_xf.13.ff1.weight', 'stacked_xf.13.post_attn_ln.scale', 'stacked_xf.13.post_ff_ln.scale', 'stacked_xf.13.pre_attn_ln.scale', 'stacked_xf.13.pre_ff_ln.scale', 'stacked_xf.14.attn.key_ln.scale', 'stacked_xf.14.attn.out.weight', 'stacked_xf.14.attn.per_dim_scale.per_dim_scale', 'stacked_xf.14.attn.qkv_proj.weight', 'stacked_xf.14.attn.query_ln.scale', 'stacked_xf.14.ff0.weight', 'stacked_xf.14.ff1.weight', 'stacked_xf.14.post_attn_ln.scale', 'stacked_xf.14.post_ff_ln.scale', 'stacked_xf.14.pre_attn_ln.scale', 'stacked_xf.14.pre_ff_ln.scale', 'stacked_xf.15.attn.key_ln.scale', 'stacked_xf.15.attn.out.weight', 'stacked_xf.15.attn.per_dim_scale.per_dim_scale', 'stacked_xf.15.attn.qkv_proj.weight', 'stacked_xf.15.attn.query_ln.scale', 'stacked_xf.15.ff0.weight', 'stacked_xf.15.ff1.weight', 'stacked_xf.15.post_attn_ln.scale', 'stacked_xf.15.post_ff_ln.scale', 'stacked_xf.15.pre_attn_ln.scale', 'stacked_xf.15.pre_ff_ln.scale', 'stacked_xf.16.attn.key_ln.scale', 'stacked_xf.16.attn.out.weight', 'stacked_xf.16.attn.per_dim_scale.per_dim_scale', 'stacked_xf.16.attn.qkv_proj.weight', 'stacked_xf.16.attn.query_ln.scale', 'stacked_xf.16.ff0.weight', 'stacked_xf.16.ff1.weight', 'stacked_xf.16.post_attn_ln.scale', 'stacked_xf.16.post_ff_ln.scale', 'stacked_xf.16.pre_attn_ln.scale', 'stacked_xf.16.pre_ff_ln.scale', 'stacked_xf.17.attn.key_ln.scale', 'stacked_xf.17.attn.out.weight', 'stacked_xf.17.attn.per_dim_scale.per_dim_scale', 'stacked_xf.17.attn.qkv_proj.weight', 'stacked_xf.17.attn.query_ln.scale', 'stacked_xf.17.ff0.weight', 'stacked_xf.17.ff1.weight', 'stacked_xf.17.post_attn_ln.scale', 'stacked_xf.17.post_ff_ln.scale', 'stacked_xf.17.pre_attn_ln.scale', 'stacked_xf.17.pre_ff_ln.scale', 'stacked_xf.18.attn.key_ln.scale', 'stacked_xf.18.attn.out.weight', 'stacked_xf.18.attn.per_dim_scale.per_dim_scale', 'stacked_xf.18.attn.qkv_proj.weight', 'stacked_xf.18.attn.query_ln.scale', 'stacked_xf.18.ff0.weight', 'stacked_xf.18.ff1.weight', 'stacked_xf.18.post_attn_ln.scale', 'stacked_xf.18.post_ff_ln.scale', 'stacked_xf.18.pre_attn_ln.scale', 'stacked_xf.18.pre_ff_ln.scale', 'stacked_xf.19.attn.key_ln.scale', 'stacked_xf.19.attn.out.weight', 'stacked_xf.19.attn.per_dim_scale.per_dim_scale', 'stacked_xf.19.attn.qkv_proj.weight', 'stacked_xf.19.attn.query_ln.scale', 'stacked_xf.19.ff0.weight', 'stacked_xf.19.ff1.weight', 'stacked_xf.19.post_attn_ln.scale', 'stacked_xf.19.post_ff_ln.scale', 'stacked_xf.19.pre_attn_ln.scale', 'stacked_xf.19.pre_ff_ln.scale', 'stacked_xf.2.attn.key_ln.scale', 'stacked_xf.2.attn.out.weight', 'stacked_xf.2.attn.per_dim_scale.per_dim_scale', 'stacked_xf.2.attn.qkv_proj.weight', 'stacked_xf.2.attn.query_ln.scale', 'stacked_xf.2.ff0.weight', 'stacked_xf.2.ff1.weight', 'stacked_xf.2.post_attn_ln.scale', 'stacked_xf.2.post_ff_ln.scale', 'stacked_xf.2.pre_attn_ln.scale', 'stacked_xf.2.pre_ff_ln.scale', 'stacked_xf.3.attn.key_ln.scale', 'stacked_xf.3.attn.out.weight', 'stacked_xf.3.attn.per_dim_scale.per_dim_scale', 'stacked_xf.3.attn.qkv_proj.weight', 'stacked_xf.3.attn.query_ln.scale', 'stacked_xf.3.ff0.weight', 'stacked_xf.3.ff1.weight', 'stacked_xf.3.post_attn_ln.scale', 'stacked_xf.3.post_ff_ln.scale', 'stacked_xf.3.pre_attn_ln.scale', 'stacked_xf.3.pre_ff_ln.scale', 'stacked_xf.4.attn.key_ln.scale', 'stacked_xf.4.attn.out.weight', 'stacked_xf.4.attn.per_dim_scale.per_dim_scale', 'stacked_xf.4.attn.qkv_proj.weight', 'stacked_xf.4.attn.query_ln.scale', 'stacked_xf.4.ff0.weight', 'stacked_xf.4.ff1.weight', 'stacked_xf.4.post_attn_ln.scale', 'stacked_xf.4.post_ff_ln.scale', 'stacked_xf.4.pre_attn_ln.scale', 'stacked_xf.4.pre_ff_ln.scale', 'stacked_xf.5.attn.key_ln.scale', 'stacked_xf.5.attn.out.weight', 'stacked_xf.5.attn.per_dim_scale.per_dim_scale', 'stacked_xf.5.attn.qkv_proj.weight', 'stacked_xf.5.attn.query_ln.scale', 'stacked_xf.5.ff0.weight', 'stacked_xf.5.ff1.weight', 'stacked_xf.5.post_attn_ln.scale', 'stacked_xf.5.post_ff_ln.scale', 'stacked_xf.5.pre_attn_ln.scale', 'stacked_xf.5.pre_ff_ln.scale', 'stacked_xf.6.attn.key_ln.scale', 'stacked_xf.6.attn.out.weight', 'stacked_xf.6.attn.per_dim_scale.per_dim_scale', 'stacked_xf.6.attn.qkv_proj.weight', 'stacked_xf.6.attn.query_ln.scale', 'stacked_xf.6.ff0.weight', 'stacked_xf.6.ff1.weight', 'stacked_xf.6.post_attn_ln.scale', 'stacked_xf.6.post_ff_ln.scale', 'stacked_xf.6.pre_attn_ln.scale', 'stacked_xf.6.pre_ff_ln.scale', 'stacked_xf.7.attn.key_ln.scale', 'stacked_xf.7.attn.out.weight', 'stacked_xf.7.attn.per_dim_scale.per_dim_scale', 'stacked_xf.7.attn.qkv_proj.weight', 'stacked_xf.7.attn.query_ln.scale', 'stacked_xf.7.ff0.weight', 'stacked_xf.7.ff1.weight', 'stacked_xf.7.post_attn_ln.scale', 'stacked_xf.7.post_ff_ln.scale', 'stacked_xf.7.pre_attn_ln.scale', 'stacked_xf.7.pre_ff_ln.scale', 'stacked_xf.8.attn.key_ln.scale', 'stacked_xf.8.attn.out.weight', 'stacked_xf.8.attn.per_dim_scale.per_dim_scale', 'stacked_xf.8.attn.qkv_proj.weight', 'stacked_xf.8.attn.query_ln.scale', 'stacked_xf.8.ff0.weight', 'stacked_xf.8.ff1.weight', 'stacked_xf.8.post_attn_ln.scale', 'stacked_xf.8.post_ff_ln.scale', 'stacked_xf.8.pre_attn_ln.scale', 'stacked_xf.8.pre_ff_ln.scale', 'stacked_xf.9.attn.key_ln.scale', 'stacked_xf.9.attn.out.weight', 'stacked_xf.9.attn.per_dim_scale.per_dim_scale', 'stacked_xf.9.attn.qkv_proj.weight', 'stacked_xf.9.attn.query_ln.scale', 'stacked_xf.9.ff0.weight', 'stacked_xf.9.ff1.weight', 'stacked_xf.9.post_attn_ln.scale', 'stacked_xf.9.post_ff_ln.scale', 'stacked_xf.9.pre_attn_ln.scale', 'stacked_xf.9.pre_ff_ln.scale', 'tokenizer.hidden_layer.bias', 'tokenizer.hidden_layer.weight', 'tokenizer.output_layer.bias', 'tokenizer.output_layer.weight', 'tokenizer.residual_layer.bias', 'tokenizer.residual_layer.weight']\n",
            "- This IS expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of TimesFmModelForPrediction were not initialized from the model checkpoint at google/timesfm-2.5-200m-pytorch and are newly initialized: ['decoder.freq_emb.weight', 'decoder.input_ff_layer.input_layer.bias', 'decoder.input_ff_layer.input_layer.weight', 'decoder.input_ff_layer.output_layer.bias', 'decoder.input_ff_layer.output_layer.weight', 'decoder.input_ff_layer.residual_layer.bias', 'decoder.input_ff_layer.residual_layer.weight', 'decoder.layers.0.input_layernorm.weight', 'decoder.layers.0.mlp.down_proj.bias', 'decoder.layers.0.mlp.down_proj.weight', 'decoder.layers.0.mlp.gate_proj.bias', 'decoder.layers.0.mlp.gate_proj.weight', 'decoder.layers.0.mlp.layer_norm.bias', 'decoder.layers.0.mlp.layer_norm.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.o_proj.bias', 'decoder.layers.0.self_attn.o_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.scaling', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.1.input_layernorm.weight', 'decoder.layers.1.mlp.down_proj.bias', 'decoder.layers.1.mlp.down_proj.weight', 'decoder.layers.1.mlp.gate_proj.bias', 'decoder.layers.1.mlp.gate_proj.weight', 'decoder.layers.1.mlp.layer_norm.bias', 'decoder.layers.1.mlp.layer_norm.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.o_proj.bias', 'decoder.layers.1.self_attn.o_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.scaling', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.10.input_layernorm.weight', 'decoder.layers.10.mlp.down_proj.bias', 'decoder.layers.10.mlp.down_proj.weight', 'decoder.layers.10.mlp.gate_proj.bias', 'decoder.layers.10.mlp.gate_proj.weight', 'decoder.layers.10.mlp.layer_norm.bias', 'decoder.layers.10.mlp.layer_norm.weight', 'decoder.layers.10.self_attn.k_proj.bias', 'decoder.layers.10.self_attn.k_proj.weight', 'decoder.layers.10.self_attn.o_proj.bias', 'decoder.layers.10.self_attn.o_proj.weight', 'decoder.layers.10.self_attn.q_proj.bias', 'decoder.layers.10.self_attn.q_proj.weight', 'decoder.layers.10.self_attn.scaling', 'decoder.layers.10.self_attn.v_proj.bias', 'decoder.layers.10.self_attn.v_proj.weight', 'decoder.layers.11.input_layernorm.weight', 'decoder.layers.11.mlp.down_proj.bias', 'decoder.layers.11.mlp.down_proj.weight', 'decoder.layers.11.mlp.gate_proj.bias', 'decoder.layers.11.mlp.gate_proj.weight', 'decoder.layers.11.mlp.layer_norm.bias', 'decoder.layers.11.mlp.layer_norm.weight', 'decoder.layers.11.self_attn.k_proj.bias', 'decoder.layers.11.self_attn.k_proj.weight', 'decoder.layers.11.self_attn.o_proj.bias', 'decoder.layers.11.self_attn.o_proj.weight', 'decoder.layers.11.self_attn.q_proj.bias', 'decoder.layers.11.self_attn.q_proj.weight', 'decoder.layers.11.self_attn.scaling', 'decoder.layers.11.self_attn.v_proj.bias', 'decoder.layers.11.self_attn.v_proj.weight', 'decoder.layers.12.input_layernorm.weight', 'decoder.layers.12.mlp.down_proj.bias', 'decoder.layers.12.mlp.down_proj.weight', 'decoder.layers.12.mlp.gate_proj.bias', 'decoder.layers.12.mlp.gate_proj.weight', 'decoder.layers.12.mlp.layer_norm.bias', 'decoder.layers.12.mlp.layer_norm.weight', 'decoder.layers.12.self_attn.k_proj.bias', 'decoder.layers.12.self_attn.k_proj.weight', 'decoder.layers.12.self_attn.o_proj.bias', 'decoder.layers.12.self_attn.o_proj.weight', 'decoder.layers.12.self_attn.q_proj.bias', 'decoder.layers.12.self_attn.q_proj.weight', 'decoder.layers.12.self_attn.scaling', 'decoder.layers.12.self_attn.v_proj.bias', 'decoder.layers.12.self_attn.v_proj.weight', 'decoder.layers.13.input_layernorm.weight', 'decoder.layers.13.mlp.down_proj.bias', 'decoder.layers.13.mlp.down_proj.weight', 'decoder.layers.13.mlp.gate_proj.bias', 'decoder.layers.13.mlp.gate_proj.weight', 'decoder.layers.13.mlp.layer_norm.bias', 'decoder.layers.13.mlp.layer_norm.weight', 'decoder.layers.13.self_attn.k_proj.bias', 'decoder.layers.13.self_attn.k_proj.weight', 'decoder.layers.13.self_attn.o_proj.bias', 'decoder.layers.13.self_attn.o_proj.weight', 'decoder.layers.13.self_attn.q_proj.bias', 'decoder.layers.13.self_attn.q_proj.weight', 'decoder.layers.13.self_attn.scaling', 'decoder.layers.13.self_attn.v_proj.bias', 'decoder.layers.13.self_attn.v_proj.weight', 'decoder.layers.14.input_layernorm.weight', 'decoder.layers.14.mlp.down_proj.bias', 'decoder.layers.14.mlp.down_proj.weight', 'decoder.layers.14.mlp.gate_proj.bias', 'decoder.layers.14.mlp.gate_proj.weight', 'decoder.layers.14.mlp.layer_norm.bias', 'decoder.layers.14.mlp.layer_norm.weight', 'decoder.layers.14.self_attn.k_proj.bias', 'decoder.layers.14.self_attn.k_proj.weight', 'decoder.layers.14.self_attn.o_proj.bias', 'decoder.layers.14.self_attn.o_proj.weight', 'decoder.layers.14.self_attn.q_proj.bias', 'decoder.layers.14.self_attn.q_proj.weight', 'decoder.layers.14.self_attn.scaling', 'decoder.layers.14.self_attn.v_proj.bias', 'decoder.layers.14.self_attn.v_proj.weight', 'decoder.layers.15.input_layernorm.weight', 'decoder.layers.15.mlp.down_proj.bias', 'decoder.layers.15.mlp.down_proj.weight', 'decoder.layers.15.mlp.gate_proj.bias', 'decoder.layers.15.mlp.gate_proj.weight', 'decoder.layers.15.mlp.layer_norm.bias', 'decoder.layers.15.mlp.layer_norm.weight', 'decoder.layers.15.self_attn.k_proj.bias', 'decoder.layers.15.self_attn.k_proj.weight', 'decoder.layers.15.self_attn.o_proj.bias', 'decoder.layers.15.self_attn.o_proj.weight', 'decoder.layers.15.self_attn.q_proj.bias', 'decoder.layers.15.self_attn.q_proj.weight', 'decoder.layers.15.self_attn.scaling', 'decoder.layers.15.self_attn.v_proj.bias', 'decoder.layers.15.self_attn.v_proj.weight', 'decoder.layers.16.input_layernorm.weight', 'decoder.layers.16.mlp.down_proj.bias', 'decoder.layers.16.mlp.down_proj.weight', 'decoder.layers.16.mlp.gate_proj.bias', 'decoder.layers.16.mlp.gate_proj.weight', 'decoder.layers.16.mlp.layer_norm.bias', 'decoder.layers.16.mlp.layer_norm.weight', 'decoder.layers.16.self_attn.k_proj.bias', 'decoder.layers.16.self_attn.k_proj.weight', 'decoder.layers.16.self_attn.o_proj.bias', 'decoder.layers.16.self_attn.o_proj.weight', 'decoder.layers.16.self_attn.q_proj.bias', 'decoder.layers.16.self_attn.q_proj.weight', 'decoder.layers.16.self_attn.scaling', 'decoder.layers.16.self_attn.v_proj.bias', 'decoder.layers.16.self_attn.v_proj.weight', 'decoder.layers.17.input_layernorm.weight', 'decoder.layers.17.mlp.down_proj.bias', 'decoder.layers.17.mlp.down_proj.weight', 'decoder.layers.17.mlp.gate_proj.bias', 'decoder.layers.17.mlp.gate_proj.weight', 'decoder.layers.17.mlp.layer_norm.bias', 'decoder.layers.17.mlp.layer_norm.weight', 'decoder.layers.17.self_attn.k_proj.bias', 'decoder.layers.17.self_attn.k_proj.weight', 'decoder.layers.17.self_attn.o_proj.bias', 'decoder.layers.17.self_attn.o_proj.weight', 'decoder.layers.17.self_attn.q_proj.bias', 'decoder.layers.17.self_attn.q_proj.weight', 'decoder.layers.17.self_attn.scaling', 'decoder.layers.17.self_attn.v_proj.bias', 'decoder.layers.17.self_attn.v_proj.weight', 'decoder.layers.18.input_layernorm.weight', 'decoder.layers.18.mlp.down_proj.bias', 'decoder.layers.18.mlp.down_proj.weight', 'decoder.layers.18.mlp.gate_proj.bias', 'decoder.layers.18.mlp.gate_proj.weight', 'decoder.layers.18.mlp.layer_norm.bias', 'decoder.layers.18.mlp.layer_norm.weight', 'decoder.layers.18.self_attn.k_proj.bias', 'decoder.layers.18.self_attn.k_proj.weight', 'decoder.layers.18.self_attn.o_proj.bias', 'decoder.layers.18.self_attn.o_proj.weight', 'decoder.layers.18.self_attn.q_proj.bias', 'decoder.layers.18.self_attn.q_proj.weight', 'decoder.layers.18.self_attn.scaling', 'decoder.layers.18.self_attn.v_proj.bias', 'decoder.layers.18.self_attn.v_proj.weight', 'decoder.layers.19.input_layernorm.weight', 'decoder.layers.19.mlp.down_proj.bias', 'decoder.layers.19.mlp.down_proj.weight', 'decoder.layers.19.mlp.gate_proj.bias', 'decoder.layers.19.mlp.gate_proj.weight', 'decoder.layers.19.mlp.layer_norm.bias', 'decoder.layers.19.mlp.layer_norm.weight', 'decoder.layers.19.self_attn.k_proj.bias', 'decoder.layers.19.self_attn.k_proj.weight', 'decoder.layers.19.self_attn.o_proj.bias', 'decoder.layers.19.self_attn.o_proj.weight', 'decoder.layers.19.self_attn.q_proj.bias', 'decoder.layers.19.self_attn.q_proj.weight', 'decoder.layers.19.self_attn.scaling', 'decoder.layers.19.self_attn.v_proj.bias', 'decoder.layers.19.self_attn.v_proj.weight', 'decoder.layers.2.input_layernorm.weight', 'decoder.layers.2.mlp.down_proj.bias', 'decoder.layers.2.mlp.down_proj.weight', 'decoder.layers.2.mlp.gate_proj.bias', 'decoder.layers.2.mlp.gate_proj.weight', 'decoder.layers.2.mlp.layer_norm.bias', 'decoder.layers.2.mlp.layer_norm.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.o_proj.bias', 'decoder.layers.2.self_attn.o_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.scaling', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.3.input_layernorm.weight', 'decoder.layers.3.mlp.down_proj.bias', 'decoder.layers.3.mlp.down_proj.weight', 'decoder.layers.3.mlp.gate_proj.bias', 'decoder.layers.3.mlp.gate_proj.weight', 'decoder.layers.3.mlp.layer_norm.bias', 'decoder.layers.3.mlp.layer_norm.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.o_proj.bias', 'decoder.layers.3.self_attn.o_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.scaling', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.4.input_layernorm.weight', 'decoder.layers.4.mlp.down_proj.bias', 'decoder.layers.4.mlp.down_proj.weight', 'decoder.layers.4.mlp.gate_proj.bias', 'decoder.layers.4.mlp.gate_proj.weight', 'decoder.layers.4.mlp.layer_norm.bias', 'decoder.layers.4.mlp.layer_norm.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.o_proj.bias', 'decoder.layers.4.self_attn.o_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.scaling', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.5.input_layernorm.weight', 'decoder.layers.5.mlp.down_proj.bias', 'decoder.layers.5.mlp.down_proj.weight', 'decoder.layers.5.mlp.gate_proj.bias', 'decoder.layers.5.mlp.gate_proj.weight', 'decoder.layers.5.mlp.layer_norm.bias', 'decoder.layers.5.mlp.layer_norm.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.o_proj.bias', 'decoder.layers.5.self_attn.o_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.scaling', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.6.input_layernorm.weight', 'decoder.layers.6.mlp.down_proj.bias', 'decoder.layers.6.mlp.down_proj.weight', 'decoder.layers.6.mlp.gate_proj.bias', 'decoder.layers.6.mlp.gate_proj.weight', 'decoder.layers.6.mlp.layer_norm.bias', 'decoder.layers.6.mlp.layer_norm.weight', 'decoder.layers.6.self_attn.k_proj.bias', 'decoder.layers.6.self_attn.k_proj.weight', 'decoder.layers.6.self_attn.o_proj.bias', 'decoder.layers.6.self_attn.o_proj.weight', 'decoder.layers.6.self_attn.q_proj.bias', 'decoder.layers.6.self_attn.q_proj.weight', 'decoder.layers.6.self_attn.scaling', 'decoder.layers.6.self_attn.v_proj.bias', 'decoder.layers.6.self_attn.v_proj.weight', 'decoder.layers.7.input_layernorm.weight', 'decoder.layers.7.mlp.down_proj.bias', 'decoder.layers.7.mlp.down_proj.weight', 'decoder.layers.7.mlp.gate_proj.bias', 'decoder.layers.7.mlp.gate_proj.weight', 'decoder.layers.7.mlp.layer_norm.bias', 'decoder.layers.7.mlp.layer_norm.weight', 'decoder.layers.7.self_attn.k_proj.bias', 'decoder.layers.7.self_attn.k_proj.weight', 'decoder.layers.7.self_attn.o_proj.bias', 'decoder.layers.7.self_attn.o_proj.weight', 'decoder.layers.7.self_attn.q_proj.bias', 'decoder.layers.7.self_attn.q_proj.weight', 'decoder.layers.7.self_attn.scaling', 'decoder.layers.7.self_attn.v_proj.bias', 'decoder.layers.7.self_attn.v_proj.weight', 'decoder.layers.8.input_layernorm.weight', 'decoder.layers.8.mlp.down_proj.bias', 'decoder.layers.8.mlp.down_proj.weight', 'decoder.layers.8.mlp.gate_proj.bias', 'decoder.layers.8.mlp.gate_proj.weight', 'decoder.layers.8.mlp.layer_norm.bias', 'decoder.layers.8.mlp.layer_norm.weight', 'decoder.layers.8.self_attn.k_proj.bias', 'decoder.layers.8.self_attn.k_proj.weight', 'decoder.layers.8.self_attn.o_proj.bias', 'decoder.layers.8.self_attn.o_proj.weight', 'decoder.layers.8.self_attn.q_proj.bias', 'decoder.layers.8.self_attn.q_proj.weight', 'decoder.layers.8.self_attn.scaling', 'decoder.layers.8.self_attn.v_proj.bias', 'decoder.layers.8.self_attn.v_proj.weight', 'decoder.layers.9.input_layernorm.weight', 'decoder.layers.9.mlp.down_proj.bias', 'decoder.layers.9.mlp.down_proj.weight', 'decoder.layers.9.mlp.gate_proj.bias', 'decoder.layers.9.mlp.gate_proj.weight', 'decoder.layers.9.mlp.layer_norm.bias', 'decoder.layers.9.mlp.layer_norm.weight', 'decoder.layers.9.self_attn.k_proj.bias', 'decoder.layers.9.self_attn.k_proj.weight', 'decoder.layers.9.self_attn.o_proj.bias', 'decoder.layers.9.self_attn.o_proj.weight', 'decoder.layers.9.self_attn.q_proj.bias', 'decoder.layers.9.self_attn.q_proj.weight', 'decoder.layers.9.self_attn.scaling', 'decoder.layers.9.self_attn.v_proj.bias', 'decoder.layers.9.self_attn.v_proj.weight', 'horizon_ff_layer.input_layer.bias', 'horizon_ff_layer.input_layer.weight', 'horizon_ff_layer.output_layer.bias', 'horizon_ff_layer.output_layer.weight', 'horizon_ff_layer.residual_layer.bias', 'horizon_ff_layer.residual_layer.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n",
            "  Epoch 1/100 train_loss=1.2114 train_acc=0.6964 eval_loss=0.2866 eval_acc=0.9485 (best)\n",
            "  Epoch 2/100 train_loss=0.1100 train_acc=0.9821 eval_loss=0.0927 eval_acc=0.9775 (best)\n",
            "  Epoch 3/100 train_loss=0.0244 train_acc=0.9946 eval_loss=0.1445 eval_acc=0.9604 \n",
            "  Epoch 4/100 train_loss=0.0176 train_acc=0.9929 eval_loss=0.1760 eval_acc=0.9462 \n",
            "  Epoch 5/100 train_loss=0.0050 train_acc=1.0000 eval_loss=0.1098 eval_acc=0.9710 \n",
            "  Epoch 6/100 train_loss=0.0009 train_acc=1.0000 eval_loss=0.0828 eval_acc=0.9799 (best)\n",
            "  Epoch 7/100 train_loss=0.0001 train_acc=1.0000 eval_loss=0.0826 eval_acc=0.9787 (best)\n",
            "  Epoch 8/100 train_loss=0.0001 train_acc=1.0000 eval_loss=0.0789 eval_acc=0.9817 (best)\n",
            "  Epoch 9/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0768 eval_acc=0.9852 (best)\n",
            "  Epoch 10/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0759 eval_acc=0.9852 (best)\n",
            "  Epoch 11/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0753 eval_acc=0.9846 (best)\n",
            "  Epoch 12/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0750 eval_acc=0.9846 (best)\n",
            "  Epoch 13/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0748 eval_acc=0.9840 (best)\n",
            "  Epoch 14/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0748 eval_acc=0.9840 (best)\n",
            "  Epoch 15/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0748 eval_acc=0.9834 \n",
            "  Epoch 16/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0747 eval_acc=0.9828 (best)\n",
            "  Epoch 17/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0747 eval_acc=0.9828 \n",
            "  Epoch 18/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0747 eval_acc=0.9828 (best)\n",
            "  Epoch 19/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0748 eval_acc=0.9828 \n",
            "  Epoch 20/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0747 eval_acc=0.9828 \n",
            "  Epoch 21/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0748 eval_acc=0.9828 \n",
            "  Epoch 22/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0749 eval_acc=0.9828 \n",
            "  Epoch 23/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0750 eval_acc=0.9828 \n",
            "  Epoch 24/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0751 eval_acc=0.9828 \n",
            "  Epoch 25/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0751 eval_acc=0.9828 \n",
            "  Epoch 26/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0752 eval_acc=0.9828 \n",
            "  Epoch 27/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0753 eval_acc=0.9828 \n",
            "  Epoch 28/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0753 eval_acc=0.9834 \n",
            "  Early stopping on google/timesfm-2.5-200m-pytorch: no improvement for 10 epochs (best epoch = 18)\n",
            "    tfm[google/timesfm-2.5-200m-pytorch] train_acc=1.0000 eval_acc=0.98343195266272187549105865400633774697780609\n",
            "    mrh_acc=0.9905 mr+h+kg_acc=0.9911 kg_acc=0.9917 ensemble=0.9911 (w=0.60)\n",
            "  Split 1/1 - accuracy=0.9911 time=1415.1s\n",
            "Completed FaceAll: Mean Acc=0.9911\n",
            "\n",
            "=== 32/109 FaceFour ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n",
            "    Gate split 1/5: baseline_loss=0.2918 adaptive_loss=0.1460\n",
            "    Gate split 2/5: baseline_loss=0.2950 adaptive_loss=0.2206\n",
            "    Gate split 3/5: baseline_loss=0.0656 adaptive_loss=0.0064\n",
            "    Gate split 4/5: baseline_loss=0.5802 adaptive_loss=0.3453\n",
            "    Gate split 5/5: baseline_loss=0.5311 adaptive_loss=0.3880\n",
            "  Decision: Adaptive kept (loss 0.2212 vs baseline 0.3527, delta=-0.1315 <= +0.0200); savgol(window=11, poly=2) - high noise (std_diff)\n",
            "\n",
            "=== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at google/timesfm-2.5-200m-pytorch were not used when initializing TimesFmModelForPrediction: ['output_projection_point.hidden_layer.weight', 'output_projection_point.output_layer.weight', 'output_projection_point.residual_layer.weight', 'output_projection_quantiles.hidden_layer.weight', 'output_projection_quantiles.output_layer.weight', 'output_projection_quantiles.residual_layer.weight', 'stacked_xf.0.attn.key_ln.scale', 'stacked_xf.0.attn.out.weight', 'stacked_xf.0.attn.per_dim_scale.per_dim_scale', 'stacked_xf.0.attn.qkv_proj.weight', 'stacked_xf.0.attn.query_ln.scale', 'stacked_xf.0.ff0.weight', 'stacked_xf.0.ff1.weight', 'stacked_xf.0.post_attn_ln.scale', 'stacked_xf.0.post_ff_ln.scale', 'stacked_xf.0.pre_attn_ln.scale', 'stacked_xf.0.pre_ff_ln.scale', 'stacked_xf.1.attn.key_ln.scale', 'stacked_xf.1.attn.out.weight', 'stacked_xf.1.attn.per_dim_scale.per_dim_scale', 'stacked_xf.1.attn.qkv_proj.weight', 'stacked_xf.1.attn.query_ln.scale', 'stacked_xf.1.ff0.weight', 'stacked_xf.1.ff1.weight', 'stacked_xf.1.post_attn_ln.scale', 'stacked_xf.1.post_ff_ln.scale', 'stacked_xf.1.pre_attn_ln.scale', 'stacked_xf.1.pre_ff_ln.scale', 'stacked_xf.10.attn.key_ln.scale', 'stacked_xf.10.attn.out.weight', 'stacked_xf.10.attn.per_dim_scale.per_dim_scale', 'stacked_xf.10.attn.qkv_proj.weight', 'stacked_xf.10.attn.query_ln.scale', 'stacked_xf.10.ff0.weight', 'stacked_xf.10.ff1.weight', 'stacked_xf.10.post_attn_ln.scale', 'stacked_xf.10.post_ff_ln.scale', 'stacked_xf.10.pre_attn_ln.scale', 'stacked_xf.10.pre_ff_ln.scale', 'stacked_xf.11.attn.key_ln.scale', 'stacked_xf.11.attn.out.weight', 'stacked_xf.11.attn.per_dim_scale.per_dim_scale', 'stacked_xf.11.attn.qkv_proj.weight', 'stacked_xf.11.attn.query_ln.scale', 'stacked_xf.11.ff0.weight', 'stacked_xf.11.ff1.weight', 'stacked_xf.11.post_attn_ln.scale', 'stacked_xf.11.post_ff_ln.scale', 'stacked_xf.11.pre_attn_ln.scale', 'stacked_xf.11.pre_ff_ln.scale', 'stacked_xf.12.attn.key_ln.scale', 'stacked_xf.12.attn.out.weight', 'stacked_xf.12.attn.per_dim_scale.per_dim_scale', 'stacked_xf.12.attn.qkv_proj.weight', 'stacked_xf.12.attn.query_ln.scale', 'stacked_xf.12.ff0.weight', 'stacked_xf.12.ff1.weight', 'stacked_xf.12.post_attn_ln.scale', 'stacked_xf.12.post_ff_ln.scale', 'stacked_xf.12.pre_attn_ln.scale', 'stacked_xf.12.pre_ff_ln.scale', 'stacked_xf.13.attn.key_ln.scale', 'stacked_xf.13.attn.out.weight', 'stacked_xf.13.attn.per_dim_scale.per_dim_scale', 'stacked_xf.13.attn.qkv_proj.weight', 'stacked_xf.13.attn.query_ln.scale', 'stacked_xf.13.ff0.weight', 'stacked_xf.13.ff1.weight', 'stacked_xf.13.post_attn_ln.scale', 'stacked_xf.13.post_ff_ln.scale', 'stacked_xf.13.pre_attn_ln.scale', 'stacked_xf.13.pre_ff_ln.scale', 'stacked_xf.14.attn.key_ln.scale', 'stacked_xf.14.attn.out.weight', 'stacked_xf.14.attn.per_dim_scale.per_dim_scale', 'stacked_xf.14.attn.qkv_proj.weight', 'stacked_xf.14.attn.query_ln.scale', 'stacked_xf.14.ff0.weight', 'stacked_xf.14.ff1.weight', 'stacked_xf.14.post_attn_ln.scale', 'stacked_xf.14.post_ff_ln.scale', 'stacked_xf.14.pre_attn_ln.scale', 'stacked_xf.14.pre_ff_ln.scale', 'stacked_xf.15.attn.key_ln.scale', 'stacked_xf.15.attn.out.weight', 'stacked_xf.15.attn.per_dim_scale.per_dim_scale', 'stacked_xf.15.attn.qkv_proj.weight', 'stacked_xf.15.attn.query_ln.scale', 'stacked_xf.15.ff0.weight', 'stacked_xf.15.ff1.weight', 'stacked_xf.15.post_attn_ln.scale', 'stacked_xf.15.post_ff_ln.scale', 'stacked_xf.15.pre_attn_ln.scale', 'stacked_xf.15.pre_ff_ln.scale', 'stacked_xf.16.attn.key_ln.scale', 'stacked_xf.16.attn.out.weight', 'stacked_xf.16.attn.per_dim_scale.per_dim_scale', 'stacked_xf.16.attn.qkv_proj.weight', 'stacked_xf.16.attn.query_ln.scale', 'stacked_xf.16.ff0.weight', 'stacked_xf.16.ff1.weight', 'stacked_xf.16.post_attn_ln.scale', 'stacked_xf.16.post_ff_ln.scale', 'stacked_xf.16.pre_attn_ln.scale', 'stacked_xf.16.pre_ff_ln.scale', 'stacked_xf.17.attn.key_ln.scale', 'stacked_xf.17.attn.out.weight', 'stacked_xf.17.attn.per_dim_scale.per_dim_scale', 'stacked_xf.17.attn.qkv_proj.weight', 'stacked_xf.17.attn.query_ln.scale', 'stacked_xf.17.ff0.weight', 'stacked_xf.17.ff1.weight', 'stacked_xf.17.post_attn_ln.scale', 'stacked_xf.17.post_ff_ln.scale', 'stacked_xf.17.pre_attn_ln.scale', 'stacked_xf.17.pre_ff_ln.scale', 'stacked_xf.18.attn.key_ln.scale', 'stacked_xf.18.attn.out.weight', 'stacked_xf.18.attn.per_dim_scale.per_dim_scale', 'stacked_xf.18.attn.qkv_proj.weight', 'stacked_xf.18.attn.query_ln.scale', 'stacked_xf.18.ff0.weight', 'stacked_xf.18.ff1.weight', 'stacked_xf.18.post_attn_ln.scale', 'stacked_xf.18.post_ff_ln.scale', 'stacked_xf.18.pre_attn_ln.scale', 'stacked_xf.18.pre_ff_ln.scale', 'stacked_xf.19.attn.key_ln.scale', 'stacked_xf.19.attn.out.weight', 'stacked_xf.19.attn.per_dim_scale.per_dim_scale', 'stacked_xf.19.attn.qkv_proj.weight', 'stacked_xf.19.attn.query_ln.scale', 'stacked_xf.19.ff0.weight', 'stacked_xf.19.ff1.weight', 'stacked_xf.19.post_attn_ln.scale', 'stacked_xf.19.post_ff_ln.scale', 'stacked_xf.19.pre_attn_ln.scale', 'stacked_xf.19.pre_ff_ln.scale', 'stacked_xf.2.attn.key_ln.scale', 'stacked_xf.2.attn.out.weight', 'stacked_xf.2.attn.per_dim_scale.per_dim_scale', 'stacked_xf.2.attn.qkv_proj.weight', 'stacked_xf.2.attn.query_ln.scale', 'stacked_xf.2.ff0.weight', 'stacked_xf.2.ff1.weight', 'stacked_xf.2.post_attn_ln.scale', 'stacked_xf.2.post_ff_ln.scale', 'stacked_xf.2.pre_attn_ln.scale', 'stacked_xf.2.pre_ff_ln.scale', 'stacked_xf.3.attn.key_ln.scale', 'stacked_xf.3.attn.out.weight', 'stacked_xf.3.attn.per_dim_scale.per_dim_scale', 'stacked_xf.3.attn.qkv_proj.weight', 'stacked_xf.3.attn.query_ln.scale', 'stacked_xf.3.ff0.weight', 'stacked_xf.3.ff1.weight', 'stacked_xf.3.post_attn_ln.scale', 'stacked_xf.3.post_ff_ln.scale', 'stacked_xf.3.pre_attn_ln.scale', 'stacked_xf.3.pre_ff_ln.scale', 'stacked_xf.4.attn.key_ln.scale', 'stacked_xf.4.attn.out.weight', 'stacked_xf.4.attn.per_dim_scale.per_dim_scale', 'stacked_xf.4.attn.qkv_proj.weight', 'stacked_xf.4.attn.query_ln.scale', 'stacked_xf.4.ff0.weight', 'stacked_xf.4.ff1.weight', 'stacked_xf.4.post_attn_ln.scale', 'stacked_xf.4.post_ff_ln.scale', 'stacked_xf.4.pre_attn_ln.scale', 'stacked_xf.4.pre_ff_ln.scale', 'stacked_xf.5.attn.key_ln.scale', 'stacked_xf.5.attn.out.weight', 'stacked_xf.5.attn.per_dim_scale.per_dim_scale', 'stacked_xf.5.attn.qkv_proj.weight', 'stacked_xf.5.attn.query_ln.scale', 'stacked_xf.5.ff0.weight', 'stacked_xf.5.ff1.weight', 'stacked_xf.5.post_attn_ln.scale', 'stacked_xf.5.post_ff_ln.scale', 'stacked_xf.5.pre_attn_ln.scale', 'stacked_xf.5.pre_ff_ln.scale', 'stacked_xf.6.attn.key_ln.scale', 'stacked_xf.6.attn.out.weight', 'stacked_xf.6.attn.per_dim_scale.per_dim_scale', 'stacked_xf.6.attn.qkv_proj.weight', 'stacked_xf.6.attn.query_ln.scale', 'stacked_xf.6.ff0.weight', 'stacked_xf.6.ff1.weight', 'stacked_xf.6.post_attn_ln.scale', 'stacked_xf.6.post_ff_ln.scale', 'stacked_xf.6.pre_attn_ln.scale', 'stacked_xf.6.pre_ff_ln.scale', 'stacked_xf.7.attn.key_ln.scale', 'stacked_xf.7.attn.out.weight', 'stacked_xf.7.attn.per_dim_scale.per_dim_scale', 'stacked_xf.7.attn.qkv_proj.weight', 'stacked_xf.7.attn.query_ln.scale', 'stacked_xf.7.ff0.weight', 'stacked_xf.7.ff1.weight', 'stacked_xf.7.post_attn_ln.scale', 'stacked_xf.7.post_ff_ln.scale', 'stacked_xf.7.pre_attn_ln.scale', 'stacked_xf.7.pre_ff_ln.scale', 'stacked_xf.8.attn.key_ln.scale', 'stacked_xf.8.attn.out.weight', 'stacked_xf.8.attn.per_dim_scale.per_dim_scale', 'stacked_xf.8.attn.qkv_proj.weight', 'stacked_xf.8.attn.query_ln.scale', 'stacked_xf.8.ff0.weight', 'stacked_xf.8.ff1.weight', 'stacked_xf.8.post_attn_ln.scale', 'stacked_xf.8.post_ff_ln.scale', 'stacked_xf.8.pre_attn_ln.scale', 'stacked_xf.8.pre_ff_ln.scale', 'stacked_xf.9.attn.key_ln.scale', 'stacked_xf.9.attn.out.weight', 'stacked_xf.9.attn.per_dim_scale.per_dim_scale', 'stacked_xf.9.attn.qkv_proj.weight', 'stacked_xf.9.attn.query_ln.scale', 'stacked_xf.9.ff0.weight', 'stacked_xf.9.ff1.weight', 'stacked_xf.9.post_attn_ln.scale', 'stacked_xf.9.post_ff_ln.scale', 'stacked_xf.9.pre_attn_ln.scale', 'stacked_xf.9.pre_ff_ln.scale', 'tokenizer.hidden_layer.bias', 'tokenizer.hidden_layer.weight', 'tokenizer.output_layer.bias', 'tokenizer.output_layer.weight', 'tokenizer.residual_layer.bias', 'tokenizer.residual_layer.weight']\n",
            "- This IS expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of TimesFmModelForPrediction were not initialized from the model checkpoint at google/timesfm-2.5-200m-pytorch and are newly initialized: ['decoder.freq_emb.weight', 'decoder.input_ff_layer.input_layer.bias', 'decoder.input_ff_layer.input_layer.weight', 'decoder.input_ff_layer.output_layer.bias', 'decoder.input_ff_layer.output_layer.weight', 'decoder.input_ff_layer.residual_layer.bias', 'decoder.input_ff_layer.residual_layer.weight', 'decoder.layers.0.input_layernorm.weight', 'decoder.layers.0.mlp.down_proj.bias', 'decoder.layers.0.mlp.down_proj.weight', 'decoder.layers.0.mlp.gate_proj.bias', 'decoder.layers.0.mlp.gate_proj.weight', 'decoder.layers.0.mlp.layer_norm.bias', 'decoder.layers.0.mlp.layer_norm.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.o_proj.bias', 'decoder.layers.0.self_attn.o_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.scaling', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.1.input_layernorm.weight', 'decoder.layers.1.mlp.down_proj.bias', 'decoder.layers.1.mlp.down_proj.weight', 'decoder.layers.1.mlp.gate_proj.bias', 'decoder.layers.1.mlp.gate_proj.weight', 'decoder.layers.1.mlp.layer_norm.bias', 'decoder.layers.1.mlp.layer_norm.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.o_proj.bias', 'decoder.layers.1.self_attn.o_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.scaling', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.10.input_layernorm.weight', 'decoder.layers.10.mlp.down_proj.bias', 'decoder.layers.10.mlp.down_proj.weight', 'decoder.layers.10.mlp.gate_proj.bias', 'decoder.layers.10.mlp.gate_proj.weight', 'decoder.layers.10.mlp.layer_norm.bias', 'decoder.layers.10.mlp.layer_norm.weight', 'decoder.layers.10.self_attn.k_proj.bias', 'decoder.layers.10.self_attn.k_proj.weight', 'decoder.layers.10.self_attn.o_proj.bias', 'decoder.layers.10.self_attn.o_proj.weight', 'decoder.layers.10.self_attn.q_proj.bias', 'decoder.layers.10.self_attn.q_proj.weight', 'decoder.layers.10.self_attn.scaling', 'decoder.layers.10.self_attn.v_proj.bias', 'decoder.layers.10.self_attn.v_proj.weight', 'decoder.layers.11.input_layernorm.weight', 'decoder.layers.11.mlp.down_proj.bias', 'decoder.layers.11.mlp.down_proj.weight', 'decoder.layers.11.mlp.gate_proj.bias', 'decoder.layers.11.mlp.gate_proj.weight', 'decoder.layers.11.mlp.layer_norm.bias', 'decoder.layers.11.mlp.layer_norm.weight', 'decoder.layers.11.self_attn.k_proj.bias', 'decoder.layers.11.self_attn.k_proj.weight', 'decoder.layers.11.self_attn.o_proj.bias', 'decoder.layers.11.self_attn.o_proj.weight', 'decoder.layers.11.self_attn.q_proj.bias', 'decoder.layers.11.self_attn.q_proj.weight', 'decoder.layers.11.self_attn.scaling', 'decoder.layers.11.self_attn.v_proj.bias', 'decoder.layers.11.self_attn.v_proj.weight', 'decoder.layers.12.input_layernorm.weight', 'decoder.layers.12.mlp.down_proj.bias', 'decoder.layers.12.mlp.down_proj.weight', 'decoder.layers.12.mlp.gate_proj.bias', 'decoder.layers.12.mlp.gate_proj.weight', 'decoder.layers.12.mlp.layer_norm.bias', 'decoder.layers.12.mlp.layer_norm.weight', 'decoder.layers.12.self_attn.k_proj.bias', 'decoder.layers.12.self_attn.k_proj.weight', 'decoder.layers.12.self_attn.o_proj.bias', 'decoder.layers.12.self_attn.o_proj.weight', 'decoder.layers.12.self_attn.q_proj.bias', 'decoder.layers.12.self_attn.q_proj.weight', 'decoder.layers.12.self_attn.scaling', 'decoder.layers.12.self_attn.v_proj.bias', 'decoder.layers.12.self_attn.v_proj.weight', 'decoder.layers.13.input_layernorm.weight', 'decoder.layers.13.mlp.down_proj.bias', 'decoder.layers.13.mlp.down_proj.weight', 'decoder.layers.13.mlp.gate_proj.bias', 'decoder.layers.13.mlp.gate_proj.weight', 'decoder.layers.13.mlp.layer_norm.bias', 'decoder.layers.13.mlp.layer_norm.weight', 'decoder.layers.13.self_attn.k_proj.bias', 'decoder.layers.13.self_attn.k_proj.weight', 'decoder.layers.13.self_attn.o_proj.bias', 'decoder.layers.13.self_attn.o_proj.weight', 'decoder.layers.13.self_attn.q_proj.bias', 'decoder.layers.13.self_attn.q_proj.weight', 'decoder.layers.13.self_attn.scaling', 'decoder.layers.13.self_attn.v_proj.bias', 'decoder.layers.13.self_attn.v_proj.weight', 'decoder.layers.14.input_layernorm.weight', 'decoder.layers.14.mlp.down_proj.bias', 'decoder.layers.14.mlp.down_proj.weight', 'decoder.layers.14.mlp.gate_proj.bias', 'decoder.layers.14.mlp.gate_proj.weight', 'decoder.layers.14.mlp.layer_norm.bias', 'decoder.layers.14.mlp.layer_norm.weight', 'decoder.layers.14.self_attn.k_proj.bias', 'decoder.layers.14.self_attn.k_proj.weight', 'decoder.layers.14.self_attn.o_proj.bias', 'decoder.layers.14.self_attn.o_proj.weight', 'decoder.layers.14.self_attn.q_proj.bias', 'decoder.layers.14.self_attn.q_proj.weight', 'decoder.layers.14.self_attn.scaling', 'decoder.layers.14.self_attn.v_proj.bias', 'decoder.layers.14.self_attn.v_proj.weight', 'decoder.layers.15.input_layernorm.weight', 'decoder.layers.15.mlp.down_proj.bias', 'decoder.layers.15.mlp.down_proj.weight', 'decoder.layers.15.mlp.gate_proj.bias', 'decoder.layers.15.mlp.gate_proj.weight', 'decoder.layers.15.mlp.layer_norm.bias', 'decoder.layers.15.mlp.layer_norm.weight', 'decoder.layers.15.self_attn.k_proj.bias', 'decoder.layers.15.self_attn.k_proj.weight', 'decoder.layers.15.self_attn.o_proj.bias', 'decoder.layers.15.self_attn.o_proj.weight', 'decoder.layers.15.self_attn.q_proj.bias', 'decoder.layers.15.self_attn.q_proj.weight', 'decoder.layers.15.self_attn.scaling', 'decoder.layers.15.self_attn.v_proj.bias', 'decoder.layers.15.self_attn.v_proj.weight', 'decoder.layers.16.input_layernorm.weight', 'decoder.layers.16.mlp.down_proj.bias', 'decoder.layers.16.mlp.down_proj.weight', 'decoder.layers.16.mlp.gate_proj.bias', 'decoder.layers.16.mlp.gate_proj.weight', 'decoder.layers.16.mlp.layer_norm.bias', 'decoder.layers.16.mlp.layer_norm.weight', 'decoder.layers.16.self_attn.k_proj.bias', 'decoder.layers.16.self_attn.k_proj.weight', 'decoder.layers.16.self_attn.o_proj.bias', 'decoder.layers.16.self_attn.o_proj.weight', 'decoder.layers.16.self_attn.q_proj.bias', 'decoder.layers.16.self_attn.q_proj.weight', 'decoder.layers.16.self_attn.scaling', 'decoder.layers.16.self_attn.v_proj.bias', 'decoder.layers.16.self_attn.v_proj.weight', 'decoder.layers.17.input_layernorm.weight', 'decoder.layers.17.mlp.down_proj.bias', 'decoder.layers.17.mlp.down_proj.weight', 'decoder.layers.17.mlp.gate_proj.bias', 'decoder.layers.17.mlp.gate_proj.weight', 'decoder.layers.17.mlp.layer_norm.bias', 'decoder.layers.17.mlp.layer_norm.weight', 'decoder.layers.17.self_attn.k_proj.bias', 'decoder.layers.17.self_attn.k_proj.weight', 'decoder.layers.17.self_attn.o_proj.bias', 'decoder.layers.17.self_attn.o_proj.weight', 'decoder.layers.17.self_attn.q_proj.bias', 'decoder.layers.17.self_attn.q_proj.weight', 'decoder.layers.17.self_attn.scaling', 'decoder.layers.17.self_attn.v_proj.bias', 'decoder.layers.17.self_attn.v_proj.weight', 'decoder.layers.18.input_layernorm.weight', 'decoder.layers.18.mlp.down_proj.bias', 'decoder.layers.18.mlp.down_proj.weight', 'decoder.layers.18.mlp.gate_proj.bias', 'decoder.layers.18.mlp.gate_proj.weight', 'decoder.layers.18.mlp.layer_norm.bias', 'decoder.layers.18.mlp.layer_norm.weight', 'decoder.layers.18.self_attn.k_proj.bias', 'decoder.layers.18.self_attn.k_proj.weight', 'decoder.layers.18.self_attn.o_proj.bias', 'decoder.layers.18.self_attn.o_proj.weight', 'decoder.layers.18.self_attn.q_proj.bias', 'decoder.layers.18.self_attn.q_proj.weight', 'decoder.layers.18.self_attn.scaling', 'decoder.layers.18.self_attn.v_proj.bias', 'decoder.layers.18.self_attn.v_proj.weight', 'decoder.layers.19.input_layernorm.weight', 'decoder.layers.19.mlp.down_proj.bias', 'decoder.layers.19.mlp.down_proj.weight', 'decoder.layers.19.mlp.gate_proj.bias', 'decoder.layers.19.mlp.gate_proj.weight', 'decoder.layers.19.mlp.layer_norm.bias', 'decoder.layers.19.mlp.layer_norm.weight', 'decoder.layers.19.self_attn.k_proj.bias', 'decoder.layers.19.self_attn.k_proj.weight', 'decoder.layers.19.self_attn.o_proj.bias', 'decoder.layers.19.self_attn.o_proj.weight', 'decoder.layers.19.self_attn.q_proj.bias', 'decoder.layers.19.self_attn.q_proj.weight', 'decoder.layers.19.self_attn.scaling', 'decoder.layers.19.self_attn.v_proj.bias', 'decoder.layers.19.self_attn.v_proj.weight', 'decoder.layers.2.input_layernorm.weight', 'decoder.layers.2.mlp.down_proj.bias', 'decoder.layers.2.mlp.down_proj.weight', 'decoder.layers.2.mlp.gate_proj.bias', 'decoder.layers.2.mlp.gate_proj.weight', 'decoder.layers.2.mlp.layer_norm.bias', 'decoder.layers.2.mlp.layer_norm.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.o_proj.bias', 'decoder.layers.2.self_attn.o_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.scaling', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.3.input_layernorm.weight', 'decoder.layers.3.mlp.down_proj.bias', 'decoder.layers.3.mlp.down_proj.weight', 'decoder.layers.3.mlp.gate_proj.bias', 'decoder.layers.3.mlp.gate_proj.weight', 'decoder.layers.3.mlp.layer_norm.bias', 'decoder.layers.3.mlp.layer_norm.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.o_proj.bias', 'decoder.layers.3.self_attn.o_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.scaling', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.4.input_layernorm.weight', 'decoder.layers.4.mlp.down_proj.bias', 'decoder.layers.4.mlp.down_proj.weight', 'decoder.layers.4.mlp.gate_proj.bias', 'decoder.layers.4.mlp.gate_proj.weight', 'decoder.layers.4.mlp.layer_norm.bias', 'decoder.layers.4.mlp.layer_norm.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.o_proj.bias', 'decoder.layers.4.self_attn.o_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.scaling', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.5.input_layernorm.weight', 'decoder.layers.5.mlp.down_proj.bias', 'decoder.layers.5.mlp.down_proj.weight', 'decoder.layers.5.mlp.gate_proj.bias', 'decoder.layers.5.mlp.gate_proj.weight', 'decoder.layers.5.mlp.layer_norm.bias', 'decoder.layers.5.mlp.layer_norm.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.o_proj.bias', 'decoder.layers.5.self_attn.o_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.scaling', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.6.input_layernorm.weight', 'decoder.layers.6.mlp.down_proj.bias', 'decoder.layers.6.mlp.down_proj.weight', 'decoder.layers.6.mlp.gate_proj.bias', 'decoder.layers.6.mlp.gate_proj.weight', 'decoder.layers.6.mlp.layer_norm.bias', 'decoder.layers.6.mlp.layer_norm.weight', 'decoder.layers.6.self_attn.k_proj.bias', 'decoder.layers.6.self_attn.k_proj.weight', 'decoder.layers.6.self_attn.o_proj.bias', 'decoder.layers.6.self_attn.o_proj.weight', 'decoder.layers.6.self_attn.q_proj.bias', 'decoder.layers.6.self_attn.q_proj.weight', 'decoder.layers.6.self_attn.scaling', 'decoder.layers.6.self_attn.v_proj.bias', 'decoder.layers.6.self_attn.v_proj.weight', 'decoder.layers.7.input_layernorm.weight', 'decoder.layers.7.mlp.down_proj.bias', 'decoder.layers.7.mlp.down_proj.weight', 'decoder.layers.7.mlp.gate_proj.bias', 'decoder.layers.7.mlp.gate_proj.weight', 'decoder.layers.7.mlp.layer_norm.bias', 'decoder.layers.7.mlp.layer_norm.weight', 'decoder.layers.7.self_attn.k_proj.bias', 'decoder.layers.7.self_attn.k_proj.weight', 'decoder.layers.7.self_attn.o_proj.bias', 'decoder.layers.7.self_attn.o_proj.weight', 'decoder.layers.7.self_attn.q_proj.bias', 'decoder.layers.7.self_attn.q_proj.weight', 'decoder.layers.7.self_attn.scaling', 'decoder.layers.7.self_attn.v_proj.bias', 'decoder.layers.7.self_attn.v_proj.weight', 'decoder.layers.8.input_layernorm.weight', 'decoder.layers.8.mlp.down_proj.bias', 'decoder.layers.8.mlp.down_proj.weight', 'decoder.layers.8.mlp.gate_proj.bias', 'decoder.layers.8.mlp.gate_proj.weight', 'decoder.layers.8.mlp.layer_norm.bias', 'decoder.layers.8.mlp.layer_norm.weight', 'decoder.layers.8.self_attn.k_proj.bias', 'decoder.layers.8.self_attn.k_proj.weight', 'decoder.layers.8.self_attn.o_proj.bias', 'decoder.layers.8.self_attn.o_proj.weight', 'decoder.layers.8.self_attn.q_proj.bias', 'decoder.layers.8.self_attn.q_proj.weight', 'decoder.layers.8.self_attn.scaling', 'decoder.layers.8.self_attn.v_proj.bias', 'decoder.layers.8.self_attn.v_proj.weight', 'decoder.layers.9.input_layernorm.weight', 'decoder.layers.9.mlp.down_proj.bias', 'decoder.layers.9.mlp.down_proj.weight', 'decoder.layers.9.mlp.gate_proj.bias', 'decoder.layers.9.mlp.gate_proj.weight', 'decoder.layers.9.mlp.layer_norm.bias', 'decoder.layers.9.mlp.layer_norm.weight', 'decoder.layers.9.self_attn.k_proj.bias', 'decoder.layers.9.self_attn.k_proj.weight', 'decoder.layers.9.self_attn.o_proj.bias', 'decoder.layers.9.self_attn.o_proj.weight', 'decoder.layers.9.self_attn.q_proj.bias', 'decoder.layers.9.self_attn.q_proj.weight', 'decoder.layers.9.self_attn.scaling', 'decoder.layers.9.self_attn.v_proj.bias', 'decoder.layers.9.self_attn.v_proj.weight', 'horizon_ff_layer.input_layer.bias', 'horizon_ff_layer.input_layer.weight', 'horizon_ff_layer.output_layer.bias', 'horizon_ff_layer.output_layer.weight', 'horizon_ff_layer.residual_layer.bias', 'horizon_ff_layer.residual_layer.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n",
            "  Epoch 1/100 train_loss=1.3315 train_acc=0.2917 eval_loss=1.3273 eval_acc=0.3523 (best)\n",
            "  Epoch 2/100 train_loss=1.3492 train_acc=0.2917 eval_loss=0.2942 eval_acc=0.8523 (best)\n",
            "  Epoch 3/100 train_loss=0.1078 train_acc=0.9583 eval_loss=0.1376 eval_acc=0.9659 (best)\n",
            "  Epoch 4/100 train_loss=0.0135 train_acc=1.0000 eval_loss=0.1559 eval_acc=0.9432 \n",
            "  Epoch 5/100 train_loss=0.0060 train_acc=1.0000 eval_loss=0.1763 eval_acc=0.9318 \n",
            "  Epoch 6/100 train_loss=0.0025 train_acc=1.0000 eval_loss=0.1974 eval_acc=0.9318 \n",
            "  Epoch 7/100 train_loss=0.0011 train_acc=1.0000 eval_loss=0.2200 eval_acc=0.9318 \n",
            "  Epoch 8/100 train_loss=0.0004 train_acc=1.0000 eval_loss=0.2443 eval_acc=0.9318 \n",
            "  Epoch 9/100 train_loss=0.0002 train_acc=1.0000 eval_loss=0.2695 eval_acc=0.9318 \n",
            "  Epoch 10/100 train_loss=0.0001 train_acc=1.0000 eval_loss=0.2954 eval_acc=0.9318 \n",
            "  Epoch 11/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.3213 eval_acc=0.9318 \n",
            "  Epoch 12/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.3446 eval_acc=0.9318 \n",
            "  Epoch 13/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.3653 eval_acc=0.9318 \n",
            "  Early stopping on google/timesfm-2.5-200m-pytorch: no improvement for 10 epochs (best epoch = 3)\n",
            "    tfm[google/timesfm-2.5-200m-pytorch] train_acc=0.9583 eval_acc=0.93181818181818176771713524431106634438037872\n",
            "    mrh_acc=0.9773 mr+h+kg_acc=0.9886 kg_acc=0.9773 ensemble=0.9886 (w=0.60)\n",
            "  Split 1/1 - accuracy=0.9886 time=39.1s\n",
            "Completed FaceFour: Mean Acc=0.9886\n",
            "\n",
            "=== 33/109 FacesUCR ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n",
            "    Gate split 1/5: baseline_loss=0.1600 adaptive_loss=0.1496\n",
            "    Gate split 2/5: baseline_loss=0.1507 adaptive_loss=0.1463\n",
            "    Gate split 3/5: baseline_loss=0.2188 adaptive_loss=0.1942\n",
            "    Gate split 4/5: baseline_loss=0.1833 adaptive_loss=0.1867\n",
            "    Gate split 5/5: baseline_loss=0.1616 adaptive_loss=0.1523\n",
            "  Decision: Adaptive kept (loss 0.1658 vs baseline 0.1749, delta=-0.0091 <= +0.0200); savgol(window=7, poly=2) - high noise (std_diff)\n",
            "\n",
            "=== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at google/timesfm-2.5-200m-pytorch were not used when initializing TimesFmModelForPrediction: ['output_projection_point.hidden_layer.weight', 'output_projection_point.output_layer.weight', 'output_projection_point.residual_layer.weight', 'output_projection_quantiles.hidden_layer.weight', 'output_projection_quantiles.output_layer.weight', 'output_projection_quantiles.residual_layer.weight', 'stacked_xf.0.attn.key_ln.scale', 'stacked_xf.0.attn.out.weight', 'stacked_xf.0.attn.per_dim_scale.per_dim_scale', 'stacked_xf.0.attn.qkv_proj.weight', 'stacked_xf.0.attn.query_ln.scale', 'stacked_xf.0.ff0.weight', 'stacked_xf.0.ff1.weight', 'stacked_xf.0.post_attn_ln.scale', 'stacked_xf.0.post_ff_ln.scale', 'stacked_xf.0.pre_attn_ln.scale', 'stacked_xf.0.pre_ff_ln.scale', 'stacked_xf.1.attn.key_ln.scale', 'stacked_xf.1.attn.out.weight', 'stacked_xf.1.attn.per_dim_scale.per_dim_scale', 'stacked_xf.1.attn.qkv_proj.weight', 'stacked_xf.1.attn.query_ln.scale', 'stacked_xf.1.ff0.weight', 'stacked_xf.1.ff1.weight', 'stacked_xf.1.post_attn_ln.scale', 'stacked_xf.1.post_ff_ln.scale', 'stacked_xf.1.pre_attn_ln.scale', 'stacked_xf.1.pre_ff_ln.scale', 'stacked_xf.10.attn.key_ln.scale', 'stacked_xf.10.attn.out.weight', 'stacked_xf.10.attn.per_dim_scale.per_dim_scale', 'stacked_xf.10.attn.qkv_proj.weight', 'stacked_xf.10.attn.query_ln.scale', 'stacked_xf.10.ff0.weight', 'stacked_xf.10.ff1.weight', 'stacked_xf.10.post_attn_ln.scale', 'stacked_xf.10.post_ff_ln.scale', 'stacked_xf.10.pre_attn_ln.scale', 'stacked_xf.10.pre_ff_ln.scale', 'stacked_xf.11.attn.key_ln.scale', 'stacked_xf.11.attn.out.weight', 'stacked_xf.11.attn.per_dim_scale.per_dim_scale', 'stacked_xf.11.attn.qkv_proj.weight', 'stacked_xf.11.attn.query_ln.scale', 'stacked_xf.11.ff0.weight', 'stacked_xf.11.ff1.weight', 'stacked_xf.11.post_attn_ln.scale', 'stacked_xf.11.post_ff_ln.scale', 'stacked_xf.11.pre_attn_ln.scale', 'stacked_xf.11.pre_ff_ln.scale', 'stacked_xf.12.attn.key_ln.scale', 'stacked_xf.12.attn.out.weight', 'stacked_xf.12.attn.per_dim_scale.per_dim_scale', 'stacked_xf.12.attn.qkv_proj.weight', 'stacked_xf.12.attn.query_ln.scale', 'stacked_xf.12.ff0.weight', 'stacked_xf.12.ff1.weight', 'stacked_xf.12.post_attn_ln.scale', 'stacked_xf.12.post_ff_ln.scale', 'stacked_xf.12.pre_attn_ln.scale', 'stacked_xf.12.pre_ff_ln.scale', 'stacked_xf.13.attn.key_ln.scale', 'stacked_xf.13.attn.out.weight', 'stacked_xf.13.attn.per_dim_scale.per_dim_scale', 'stacked_xf.13.attn.qkv_proj.weight', 'stacked_xf.13.attn.query_ln.scale', 'stacked_xf.13.ff0.weight', 'stacked_xf.13.ff1.weight', 'stacked_xf.13.post_attn_ln.scale', 'stacked_xf.13.post_ff_ln.scale', 'stacked_xf.13.pre_attn_ln.scale', 'stacked_xf.13.pre_ff_ln.scale', 'stacked_xf.14.attn.key_ln.scale', 'stacked_xf.14.attn.out.weight', 'stacked_xf.14.attn.per_dim_scale.per_dim_scale', 'stacked_xf.14.attn.qkv_proj.weight', 'stacked_xf.14.attn.query_ln.scale', 'stacked_xf.14.ff0.weight', 'stacked_xf.14.ff1.weight', 'stacked_xf.14.post_attn_ln.scale', 'stacked_xf.14.post_ff_ln.scale', 'stacked_xf.14.pre_attn_ln.scale', 'stacked_xf.14.pre_ff_ln.scale', 'stacked_xf.15.attn.key_ln.scale', 'stacked_xf.15.attn.out.weight', 'stacked_xf.15.attn.per_dim_scale.per_dim_scale', 'stacked_xf.15.attn.qkv_proj.weight', 'stacked_xf.15.attn.query_ln.scale', 'stacked_xf.15.ff0.weight', 'stacked_xf.15.ff1.weight', 'stacked_xf.15.post_attn_ln.scale', 'stacked_xf.15.post_ff_ln.scale', 'stacked_xf.15.pre_attn_ln.scale', 'stacked_xf.15.pre_ff_ln.scale', 'stacked_xf.16.attn.key_ln.scale', 'stacked_xf.16.attn.out.weight', 'stacked_xf.16.attn.per_dim_scale.per_dim_scale', 'stacked_xf.16.attn.qkv_proj.weight', 'stacked_xf.16.attn.query_ln.scale', 'stacked_xf.16.ff0.weight', 'stacked_xf.16.ff1.weight', 'stacked_xf.16.post_attn_ln.scale', 'stacked_xf.16.post_ff_ln.scale', 'stacked_xf.16.pre_attn_ln.scale', 'stacked_xf.16.pre_ff_ln.scale', 'stacked_xf.17.attn.key_ln.scale', 'stacked_xf.17.attn.out.weight', 'stacked_xf.17.attn.per_dim_scale.per_dim_scale', 'stacked_xf.17.attn.qkv_proj.weight', 'stacked_xf.17.attn.query_ln.scale', 'stacked_xf.17.ff0.weight', 'stacked_xf.17.ff1.weight', 'stacked_xf.17.post_attn_ln.scale', 'stacked_xf.17.post_ff_ln.scale', 'stacked_xf.17.pre_attn_ln.scale', 'stacked_xf.17.pre_ff_ln.scale', 'stacked_xf.18.attn.key_ln.scale', 'stacked_xf.18.attn.out.weight', 'stacked_xf.18.attn.per_dim_scale.per_dim_scale', 'stacked_xf.18.attn.qkv_proj.weight', 'stacked_xf.18.attn.query_ln.scale', 'stacked_xf.18.ff0.weight', 'stacked_xf.18.ff1.weight', 'stacked_xf.18.post_attn_ln.scale', 'stacked_xf.18.post_ff_ln.scale', 'stacked_xf.18.pre_attn_ln.scale', 'stacked_xf.18.pre_ff_ln.scale', 'stacked_xf.19.attn.key_ln.scale', 'stacked_xf.19.attn.out.weight', 'stacked_xf.19.attn.per_dim_scale.per_dim_scale', 'stacked_xf.19.attn.qkv_proj.weight', 'stacked_xf.19.attn.query_ln.scale', 'stacked_xf.19.ff0.weight', 'stacked_xf.19.ff1.weight', 'stacked_xf.19.post_attn_ln.scale', 'stacked_xf.19.post_ff_ln.scale', 'stacked_xf.19.pre_attn_ln.scale', 'stacked_xf.19.pre_ff_ln.scale', 'stacked_xf.2.attn.key_ln.scale', 'stacked_xf.2.attn.out.weight', 'stacked_xf.2.attn.per_dim_scale.per_dim_scale', 'stacked_xf.2.attn.qkv_proj.weight', 'stacked_xf.2.attn.query_ln.scale', 'stacked_xf.2.ff0.weight', 'stacked_xf.2.ff1.weight', 'stacked_xf.2.post_attn_ln.scale', 'stacked_xf.2.post_ff_ln.scale', 'stacked_xf.2.pre_attn_ln.scale', 'stacked_xf.2.pre_ff_ln.scale', 'stacked_xf.3.attn.key_ln.scale', 'stacked_xf.3.attn.out.weight', 'stacked_xf.3.attn.per_dim_scale.per_dim_scale', 'stacked_xf.3.attn.qkv_proj.weight', 'stacked_xf.3.attn.query_ln.scale', 'stacked_xf.3.ff0.weight', 'stacked_xf.3.ff1.weight', 'stacked_xf.3.post_attn_ln.scale', 'stacked_xf.3.post_ff_ln.scale', 'stacked_xf.3.pre_attn_ln.scale', 'stacked_xf.3.pre_ff_ln.scale', 'stacked_xf.4.attn.key_ln.scale', 'stacked_xf.4.attn.out.weight', 'stacked_xf.4.attn.per_dim_scale.per_dim_scale', 'stacked_xf.4.attn.qkv_proj.weight', 'stacked_xf.4.attn.query_ln.scale', 'stacked_xf.4.ff0.weight', 'stacked_xf.4.ff1.weight', 'stacked_xf.4.post_attn_ln.scale', 'stacked_xf.4.post_ff_ln.scale', 'stacked_xf.4.pre_attn_ln.scale', 'stacked_xf.4.pre_ff_ln.scale', 'stacked_xf.5.attn.key_ln.scale', 'stacked_xf.5.attn.out.weight', 'stacked_xf.5.attn.per_dim_scale.per_dim_scale', 'stacked_xf.5.attn.qkv_proj.weight', 'stacked_xf.5.attn.query_ln.scale', 'stacked_xf.5.ff0.weight', 'stacked_xf.5.ff1.weight', 'stacked_xf.5.post_attn_ln.scale', 'stacked_xf.5.post_ff_ln.scale', 'stacked_xf.5.pre_attn_ln.scale', 'stacked_xf.5.pre_ff_ln.scale', 'stacked_xf.6.attn.key_ln.scale', 'stacked_xf.6.attn.out.weight', 'stacked_xf.6.attn.per_dim_scale.per_dim_scale', 'stacked_xf.6.attn.qkv_proj.weight', 'stacked_xf.6.attn.query_ln.scale', 'stacked_xf.6.ff0.weight', 'stacked_xf.6.ff1.weight', 'stacked_xf.6.post_attn_ln.scale', 'stacked_xf.6.post_ff_ln.scale', 'stacked_xf.6.pre_attn_ln.scale', 'stacked_xf.6.pre_ff_ln.scale', 'stacked_xf.7.attn.key_ln.scale', 'stacked_xf.7.attn.out.weight', 'stacked_xf.7.attn.per_dim_scale.per_dim_scale', 'stacked_xf.7.attn.qkv_proj.weight', 'stacked_xf.7.attn.query_ln.scale', 'stacked_xf.7.ff0.weight', 'stacked_xf.7.ff1.weight', 'stacked_xf.7.post_attn_ln.scale', 'stacked_xf.7.post_ff_ln.scale', 'stacked_xf.7.pre_attn_ln.scale', 'stacked_xf.7.pre_ff_ln.scale', 'stacked_xf.8.attn.key_ln.scale', 'stacked_xf.8.attn.out.weight', 'stacked_xf.8.attn.per_dim_scale.per_dim_scale', 'stacked_xf.8.attn.qkv_proj.weight', 'stacked_xf.8.attn.query_ln.scale', 'stacked_xf.8.ff0.weight', 'stacked_xf.8.ff1.weight', 'stacked_xf.8.post_attn_ln.scale', 'stacked_xf.8.post_ff_ln.scale', 'stacked_xf.8.pre_attn_ln.scale', 'stacked_xf.8.pre_ff_ln.scale', 'stacked_xf.9.attn.key_ln.scale', 'stacked_xf.9.attn.out.weight', 'stacked_xf.9.attn.per_dim_scale.per_dim_scale', 'stacked_xf.9.attn.qkv_proj.weight', 'stacked_xf.9.attn.query_ln.scale', 'stacked_xf.9.ff0.weight', 'stacked_xf.9.ff1.weight', 'stacked_xf.9.post_attn_ln.scale', 'stacked_xf.9.post_ff_ln.scale', 'stacked_xf.9.pre_attn_ln.scale', 'stacked_xf.9.pre_ff_ln.scale', 'tokenizer.hidden_layer.bias', 'tokenizer.hidden_layer.weight', 'tokenizer.output_layer.bias', 'tokenizer.output_layer.weight', 'tokenizer.residual_layer.bias', 'tokenizer.residual_layer.weight']\n",
            "- This IS expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of TimesFmModelForPrediction were not initialized from the model checkpoint at google/timesfm-2.5-200m-pytorch and are newly initialized: ['decoder.freq_emb.weight', 'decoder.input_ff_layer.input_layer.bias', 'decoder.input_ff_layer.input_layer.weight', 'decoder.input_ff_layer.output_layer.bias', 'decoder.input_ff_layer.output_layer.weight', 'decoder.input_ff_layer.residual_layer.bias', 'decoder.input_ff_layer.residual_layer.weight', 'decoder.layers.0.input_layernorm.weight', 'decoder.layers.0.mlp.down_proj.bias', 'decoder.layers.0.mlp.down_proj.weight', 'decoder.layers.0.mlp.gate_proj.bias', 'decoder.layers.0.mlp.gate_proj.weight', 'decoder.layers.0.mlp.layer_norm.bias', 'decoder.layers.0.mlp.layer_norm.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.o_proj.bias', 'decoder.layers.0.self_attn.o_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.scaling', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.1.input_layernorm.weight', 'decoder.layers.1.mlp.down_proj.bias', 'decoder.layers.1.mlp.down_proj.weight', 'decoder.layers.1.mlp.gate_proj.bias', 'decoder.layers.1.mlp.gate_proj.weight', 'decoder.layers.1.mlp.layer_norm.bias', 'decoder.layers.1.mlp.layer_norm.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.o_proj.bias', 'decoder.layers.1.self_attn.o_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.scaling', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.10.input_layernorm.weight', 'decoder.layers.10.mlp.down_proj.bias', 'decoder.layers.10.mlp.down_proj.weight', 'decoder.layers.10.mlp.gate_proj.bias', 'decoder.layers.10.mlp.gate_proj.weight', 'decoder.layers.10.mlp.layer_norm.bias', 'decoder.layers.10.mlp.layer_norm.weight', 'decoder.layers.10.self_attn.k_proj.bias', 'decoder.layers.10.self_attn.k_proj.weight', 'decoder.layers.10.self_attn.o_proj.bias', 'decoder.layers.10.self_attn.o_proj.weight', 'decoder.layers.10.self_attn.q_proj.bias', 'decoder.layers.10.self_attn.q_proj.weight', 'decoder.layers.10.self_attn.scaling', 'decoder.layers.10.self_attn.v_proj.bias', 'decoder.layers.10.self_attn.v_proj.weight', 'decoder.layers.11.input_layernorm.weight', 'decoder.layers.11.mlp.down_proj.bias', 'decoder.layers.11.mlp.down_proj.weight', 'decoder.layers.11.mlp.gate_proj.bias', 'decoder.layers.11.mlp.gate_proj.weight', 'decoder.layers.11.mlp.layer_norm.bias', 'decoder.layers.11.mlp.layer_norm.weight', 'decoder.layers.11.self_attn.k_proj.bias', 'decoder.layers.11.self_attn.k_proj.weight', 'decoder.layers.11.self_attn.o_proj.bias', 'decoder.layers.11.self_attn.o_proj.weight', 'decoder.layers.11.self_attn.q_proj.bias', 'decoder.layers.11.self_attn.q_proj.weight', 'decoder.layers.11.self_attn.scaling', 'decoder.layers.11.self_attn.v_proj.bias', 'decoder.layers.11.self_attn.v_proj.weight', 'decoder.layers.12.input_layernorm.weight', 'decoder.layers.12.mlp.down_proj.bias', 'decoder.layers.12.mlp.down_proj.weight', 'decoder.layers.12.mlp.gate_proj.bias', 'decoder.layers.12.mlp.gate_proj.weight', 'decoder.layers.12.mlp.layer_norm.bias', 'decoder.layers.12.mlp.layer_norm.weight', 'decoder.layers.12.self_attn.k_proj.bias', 'decoder.layers.12.self_attn.k_proj.weight', 'decoder.layers.12.self_attn.o_proj.bias', 'decoder.layers.12.self_attn.o_proj.weight', 'decoder.layers.12.self_attn.q_proj.bias', 'decoder.layers.12.self_attn.q_proj.weight', 'decoder.layers.12.self_attn.scaling', 'decoder.layers.12.self_attn.v_proj.bias', 'decoder.layers.12.self_attn.v_proj.weight', 'decoder.layers.13.input_layernorm.weight', 'decoder.layers.13.mlp.down_proj.bias', 'decoder.layers.13.mlp.down_proj.weight', 'decoder.layers.13.mlp.gate_proj.bias', 'decoder.layers.13.mlp.gate_proj.weight', 'decoder.layers.13.mlp.layer_norm.bias', 'decoder.layers.13.mlp.layer_norm.weight', 'decoder.layers.13.self_attn.k_proj.bias', 'decoder.layers.13.self_attn.k_proj.weight', 'decoder.layers.13.self_attn.o_proj.bias', 'decoder.layers.13.self_attn.o_proj.weight', 'decoder.layers.13.self_attn.q_proj.bias', 'decoder.layers.13.self_attn.q_proj.weight', 'decoder.layers.13.self_attn.scaling', 'decoder.layers.13.self_attn.v_proj.bias', 'decoder.layers.13.self_attn.v_proj.weight', 'decoder.layers.14.input_layernorm.weight', 'decoder.layers.14.mlp.down_proj.bias', 'decoder.layers.14.mlp.down_proj.weight', 'decoder.layers.14.mlp.gate_proj.bias', 'decoder.layers.14.mlp.gate_proj.weight', 'decoder.layers.14.mlp.layer_norm.bias', 'decoder.layers.14.mlp.layer_norm.weight', 'decoder.layers.14.self_attn.k_proj.bias', 'decoder.layers.14.self_attn.k_proj.weight', 'decoder.layers.14.self_attn.o_proj.bias', 'decoder.layers.14.self_attn.o_proj.weight', 'decoder.layers.14.self_attn.q_proj.bias', 'decoder.layers.14.self_attn.q_proj.weight', 'decoder.layers.14.self_attn.scaling', 'decoder.layers.14.self_attn.v_proj.bias', 'decoder.layers.14.self_attn.v_proj.weight', 'decoder.layers.15.input_layernorm.weight', 'decoder.layers.15.mlp.down_proj.bias', 'decoder.layers.15.mlp.down_proj.weight', 'decoder.layers.15.mlp.gate_proj.bias', 'decoder.layers.15.mlp.gate_proj.weight', 'decoder.layers.15.mlp.layer_norm.bias', 'decoder.layers.15.mlp.layer_norm.weight', 'decoder.layers.15.self_attn.k_proj.bias', 'decoder.layers.15.self_attn.k_proj.weight', 'decoder.layers.15.self_attn.o_proj.bias', 'decoder.layers.15.self_attn.o_proj.weight', 'decoder.layers.15.self_attn.q_proj.bias', 'decoder.layers.15.self_attn.q_proj.weight', 'decoder.layers.15.self_attn.scaling', 'decoder.layers.15.self_attn.v_proj.bias', 'decoder.layers.15.self_attn.v_proj.weight', 'decoder.layers.16.input_layernorm.weight', 'decoder.layers.16.mlp.down_proj.bias', 'decoder.layers.16.mlp.down_proj.weight', 'decoder.layers.16.mlp.gate_proj.bias', 'decoder.layers.16.mlp.gate_proj.weight', 'decoder.layers.16.mlp.layer_norm.bias', 'decoder.layers.16.mlp.layer_norm.weight', 'decoder.layers.16.self_attn.k_proj.bias', 'decoder.layers.16.self_attn.k_proj.weight', 'decoder.layers.16.self_attn.o_proj.bias', 'decoder.layers.16.self_attn.o_proj.weight', 'decoder.layers.16.self_attn.q_proj.bias', 'decoder.layers.16.self_attn.q_proj.weight', 'decoder.layers.16.self_attn.scaling', 'decoder.layers.16.self_attn.v_proj.bias', 'decoder.layers.16.self_attn.v_proj.weight', 'decoder.layers.17.input_layernorm.weight', 'decoder.layers.17.mlp.down_proj.bias', 'decoder.layers.17.mlp.down_proj.weight', 'decoder.layers.17.mlp.gate_proj.bias', 'decoder.layers.17.mlp.gate_proj.weight', 'decoder.layers.17.mlp.layer_norm.bias', 'decoder.layers.17.mlp.layer_norm.weight', 'decoder.layers.17.self_attn.k_proj.bias', 'decoder.layers.17.self_attn.k_proj.weight', 'decoder.layers.17.self_attn.o_proj.bias', 'decoder.layers.17.self_attn.o_proj.weight', 'decoder.layers.17.self_attn.q_proj.bias', 'decoder.layers.17.self_attn.q_proj.weight', 'decoder.layers.17.self_attn.scaling', 'decoder.layers.17.self_attn.v_proj.bias', 'decoder.layers.17.self_attn.v_proj.weight', 'decoder.layers.18.input_layernorm.weight', 'decoder.layers.18.mlp.down_proj.bias', 'decoder.layers.18.mlp.down_proj.weight', 'decoder.layers.18.mlp.gate_proj.bias', 'decoder.layers.18.mlp.gate_proj.weight', 'decoder.layers.18.mlp.layer_norm.bias', 'decoder.layers.18.mlp.layer_norm.weight', 'decoder.layers.18.self_attn.k_proj.bias', 'decoder.layers.18.self_attn.k_proj.weight', 'decoder.layers.18.self_attn.o_proj.bias', 'decoder.layers.18.self_attn.o_proj.weight', 'decoder.layers.18.self_attn.q_proj.bias', 'decoder.layers.18.self_attn.q_proj.weight', 'decoder.layers.18.self_attn.scaling', 'decoder.layers.18.self_attn.v_proj.bias', 'decoder.layers.18.self_attn.v_proj.weight', 'decoder.layers.19.input_layernorm.weight', 'decoder.layers.19.mlp.down_proj.bias', 'decoder.layers.19.mlp.down_proj.weight', 'decoder.layers.19.mlp.gate_proj.bias', 'decoder.layers.19.mlp.gate_proj.weight', 'decoder.layers.19.mlp.layer_norm.bias', 'decoder.layers.19.mlp.layer_norm.weight', 'decoder.layers.19.self_attn.k_proj.bias', 'decoder.layers.19.self_attn.k_proj.weight', 'decoder.layers.19.self_attn.o_proj.bias', 'decoder.layers.19.self_attn.o_proj.weight', 'decoder.layers.19.self_attn.q_proj.bias', 'decoder.layers.19.self_attn.q_proj.weight', 'decoder.layers.19.self_attn.scaling', 'decoder.layers.19.self_attn.v_proj.bias', 'decoder.layers.19.self_attn.v_proj.weight', 'decoder.layers.2.input_layernorm.weight', 'decoder.layers.2.mlp.down_proj.bias', 'decoder.layers.2.mlp.down_proj.weight', 'decoder.layers.2.mlp.gate_proj.bias', 'decoder.layers.2.mlp.gate_proj.weight', 'decoder.layers.2.mlp.layer_norm.bias', 'decoder.layers.2.mlp.layer_norm.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.o_proj.bias', 'decoder.layers.2.self_attn.o_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.scaling', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.3.input_layernorm.weight', 'decoder.layers.3.mlp.down_proj.bias', 'decoder.layers.3.mlp.down_proj.weight', 'decoder.layers.3.mlp.gate_proj.bias', 'decoder.layers.3.mlp.gate_proj.weight', 'decoder.layers.3.mlp.layer_norm.bias', 'decoder.layers.3.mlp.layer_norm.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.o_proj.bias', 'decoder.layers.3.self_attn.o_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.scaling', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.4.input_layernorm.weight', 'decoder.layers.4.mlp.down_proj.bias', 'decoder.layers.4.mlp.down_proj.weight', 'decoder.layers.4.mlp.gate_proj.bias', 'decoder.layers.4.mlp.gate_proj.weight', 'decoder.layers.4.mlp.layer_norm.bias', 'decoder.layers.4.mlp.layer_norm.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.o_proj.bias', 'decoder.layers.4.self_attn.o_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.scaling', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.5.input_layernorm.weight', 'decoder.layers.5.mlp.down_proj.bias', 'decoder.layers.5.mlp.down_proj.weight', 'decoder.layers.5.mlp.gate_proj.bias', 'decoder.layers.5.mlp.gate_proj.weight', 'decoder.layers.5.mlp.layer_norm.bias', 'decoder.layers.5.mlp.layer_norm.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.o_proj.bias', 'decoder.layers.5.self_attn.o_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.scaling', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.6.input_layernorm.weight', 'decoder.layers.6.mlp.down_proj.bias', 'decoder.layers.6.mlp.down_proj.weight', 'decoder.layers.6.mlp.gate_proj.bias', 'decoder.layers.6.mlp.gate_proj.weight', 'decoder.layers.6.mlp.layer_norm.bias', 'decoder.layers.6.mlp.layer_norm.weight', 'decoder.layers.6.self_attn.k_proj.bias', 'decoder.layers.6.self_attn.k_proj.weight', 'decoder.layers.6.self_attn.o_proj.bias', 'decoder.layers.6.self_attn.o_proj.weight', 'decoder.layers.6.self_attn.q_proj.bias', 'decoder.layers.6.self_attn.q_proj.weight', 'decoder.layers.6.self_attn.scaling', 'decoder.layers.6.self_attn.v_proj.bias', 'decoder.layers.6.self_attn.v_proj.weight', 'decoder.layers.7.input_layernorm.weight', 'decoder.layers.7.mlp.down_proj.bias', 'decoder.layers.7.mlp.down_proj.weight', 'decoder.layers.7.mlp.gate_proj.bias', 'decoder.layers.7.mlp.gate_proj.weight', 'decoder.layers.7.mlp.layer_norm.bias', 'decoder.layers.7.mlp.layer_norm.weight', 'decoder.layers.7.self_attn.k_proj.bias', 'decoder.layers.7.self_attn.k_proj.weight', 'decoder.layers.7.self_attn.o_proj.bias', 'decoder.layers.7.self_attn.o_proj.weight', 'decoder.layers.7.self_attn.q_proj.bias', 'decoder.layers.7.self_attn.q_proj.weight', 'decoder.layers.7.self_attn.scaling', 'decoder.layers.7.self_attn.v_proj.bias', 'decoder.layers.7.self_attn.v_proj.weight', 'decoder.layers.8.input_layernorm.weight', 'decoder.layers.8.mlp.down_proj.bias', 'decoder.layers.8.mlp.down_proj.weight', 'decoder.layers.8.mlp.gate_proj.bias', 'decoder.layers.8.mlp.gate_proj.weight', 'decoder.layers.8.mlp.layer_norm.bias', 'decoder.layers.8.mlp.layer_norm.weight', 'decoder.layers.8.self_attn.k_proj.bias', 'decoder.layers.8.self_attn.k_proj.weight', 'decoder.layers.8.self_attn.o_proj.bias', 'decoder.layers.8.self_attn.o_proj.weight', 'decoder.layers.8.self_attn.q_proj.bias', 'decoder.layers.8.self_attn.q_proj.weight', 'decoder.layers.8.self_attn.scaling', 'decoder.layers.8.self_attn.v_proj.bias', 'decoder.layers.8.self_attn.v_proj.weight', 'decoder.layers.9.input_layernorm.weight', 'decoder.layers.9.mlp.down_proj.bias', 'decoder.layers.9.mlp.down_proj.weight', 'decoder.layers.9.mlp.gate_proj.bias', 'decoder.layers.9.mlp.gate_proj.weight', 'decoder.layers.9.mlp.layer_norm.bias', 'decoder.layers.9.mlp.layer_norm.weight', 'decoder.layers.9.self_attn.k_proj.bias', 'decoder.layers.9.self_attn.k_proj.weight', 'decoder.layers.9.self_attn.o_proj.bias', 'decoder.layers.9.self_attn.o_proj.weight', 'decoder.layers.9.self_attn.q_proj.bias', 'decoder.layers.9.self_attn.q_proj.weight', 'decoder.layers.9.self_attn.scaling', 'decoder.layers.9.self_attn.v_proj.bias', 'decoder.layers.9.self_attn.v_proj.weight', 'horizon_ff_layer.input_layer.bias', 'horizon_ff_layer.input_layer.weight', 'horizon_ff_layer.output_layer.bias', 'horizon_ff_layer.output_layer.weight', 'horizon_ff_layer.residual_layer.bias', 'horizon_ff_layer.residual_layer.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n",
            "  Epoch 1/100 train_loss=2.0263 train_acc=0.4000 eval_loss=0.8251 eval_acc=0.8171 (best)\n",
            "  Epoch 2/100 train_loss=0.3472 train_acc=0.9550 eval_loss=0.4094 eval_acc=0.8780 (best)\n",
            "  Epoch 3/100 train_loss=0.0880 train_acc=0.9850 eval_loss=0.2113 eval_acc=0.9493 (best)\n",
            "  Epoch 4/100 train_loss=0.0202 train_acc=0.9950 eval_loss=0.2316 eval_acc=0.9283 \n",
            "  Epoch 5/100 train_loss=0.0070 train_acc=1.0000 eval_loss=0.1745 eval_acc=0.9551 (best)\n",
            "  Epoch 6/100 train_loss=0.0009 train_acc=1.0000 eval_loss=0.2678 eval_acc=0.9288 \n",
            "  Epoch 7/100 train_loss=0.0006 train_acc=1.0000 eval_loss=0.2232 eval_acc=0.9439 \n",
            "  Epoch 8/100 train_loss=0.0001 train_acc=1.0000 eval_loss=0.1959 eval_acc=0.9546 \n",
            "  Epoch 9/100 train_loss=0.0001 train_acc=1.0000 eval_loss=0.1892 eval_acc=0.9585 \n",
            "  Epoch 10/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.1878 eval_acc=0.9580 \n",
            "  Epoch 11/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.1874 eval_acc=0.9595 \n",
            "  Epoch 12/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.1868 eval_acc=0.9595 \n",
            "  Epoch 13/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.1863 eval_acc=0.9595 \n",
            "  Epoch 14/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.1860 eval_acc=0.9595 \n",
            "  Epoch 15/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.1857 eval_acc=0.9595 \n",
            "  Early stopping on google/timesfm-2.5-200m-pytorch: no improvement for 10 epochs (best epoch = 5)\n",
            "    tfm[google/timesfm-2.5-200m-pytorch] train_acc=1.0000 eval_acc=0.95951219512195118355180056823883205652236938\n",
            "    mrh_acc=0.9737 mr+h+kg_acc=0.9776 kg_acc=0.9795 ensemble=0.9785 (w=0.60)\n",
            "  Split 1/1 - accuracy=0.9785 time=620.3s\n",
            "Completed FacesUCR: Mean Acc=0.9785\n",
            "\n",
            "=== 34/109 FiftyWords ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n",
            "    Gate split 1/5: baseline_loss=0.5261 adaptive_loss=0.5289\n",
            "    Gate split 2/5: baseline_loss=0.4669 adaptive_loss=0.4711\n",
            "    Gate split 3/5: baseline_loss=0.5024 adaptive_loss=0.4991\n",
            "    Gate split 4/5: baseline_loss=0.4592 adaptive_loss=0.4642\n",
            "    Gate split 5/5: baseline_loss=0.4657 adaptive_loss=0.4872\n",
            "  Decision: Adaptive kept (loss 0.4901 vs baseline 0.4841, delta=+0.0060 <= +0.0200); savgol(window=11, poly=2) - high noise (std_diff)\n",
            "\n",
            "=== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at google/timesfm-2.5-200m-pytorch were not used when initializing TimesFmModelForPrediction: ['output_projection_point.hidden_layer.weight', 'output_projection_point.output_layer.weight', 'output_projection_point.residual_layer.weight', 'output_projection_quantiles.hidden_layer.weight', 'output_projection_quantiles.output_layer.weight', 'output_projection_quantiles.residual_layer.weight', 'stacked_xf.0.attn.key_ln.scale', 'stacked_xf.0.attn.out.weight', 'stacked_xf.0.attn.per_dim_scale.per_dim_scale', 'stacked_xf.0.attn.qkv_proj.weight', 'stacked_xf.0.attn.query_ln.scale', 'stacked_xf.0.ff0.weight', 'stacked_xf.0.ff1.weight', 'stacked_xf.0.post_attn_ln.scale', 'stacked_xf.0.post_ff_ln.scale', 'stacked_xf.0.pre_attn_ln.scale', 'stacked_xf.0.pre_ff_ln.scale', 'stacked_xf.1.attn.key_ln.scale', 'stacked_xf.1.attn.out.weight', 'stacked_xf.1.attn.per_dim_scale.per_dim_scale', 'stacked_xf.1.attn.qkv_proj.weight', 'stacked_xf.1.attn.query_ln.scale', 'stacked_xf.1.ff0.weight', 'stacked_xf.1.ff1.weight', 'stacked_xf.1.post_attn_ln.scale', 'stacked_xf.1.post_ff_ln.scale', 'stacked_xf.1.pre_attn_ln.scale', 'stacked_xf.1.pre_ff_ln.scale', 'stacked_xf.10.attn.key_ln.scale', 'stacked_xf.10.attn.out.weight', 'stacked_xf.10.attn.per_dim_scale.per_dim_scale', 'stacked_xf.10.attn.qkv_proj.weight', 'stacked_xf.10.attn.query_ln.scale', 'stacked_xf.10.ff0.weight', 'stacked_xf.10.ff1.weight', 'stacked_xf.10.post_attn_ln.scale', 'stacked_xf.10.post_ff_ln.scale', 'stacked_xf.10.pre_attn_ln.scale', 'stacked_xf.10.pre_ff_ln.scale', 'stacked_xf.11.attn.key_ln.scale', 'stacked_xf.11.attn.out.weight', 'stacked_xf.11.attn.per_dim_scale.per_dim_scale', 'stacked_xf.11.attn.qkv_proj.weight', 'stacked_xf.11.attn.query_ln.scale', 'stacked_xf.11.ff0.weight', 'stacked_xf.11.ff1.weight', 'stacked_xf.11.post_attn_ln.scale', 'stacked_xf.11.post_ff_ln.scale', 'stacked_xf.11.pre_attn_ln.scale', 'stacked_xf.11.pre_ff_ln.scale', 'stacked_xf.12.attn.key_ln.scale', 'stacked_xf.12.attn.out.weight', 'stacked_xf.12.attn.per_dim_scale.per_dim_scale', 'stacked_xf.12.attn.qkv_proj.weight', 'stacked_xf.12.attn.query_ln.scale', 'stacked_xf.12.ff0.weight', 'stacked_xf.12.ff1.weight', 'stacked_xf.12.post_attn_ln.scale', 'stacked_xf.12.post_ff_ln.scale', 'stacked_xf.12.pre_attn_ln.scale', 'stacked_xf.12.pre_ff_ln.scale', 'stacked_xf.13.attn.key_ln.scale', 'stacked_xf.13.attn.out.weight', 'stacked_xf.13.attn.per_dim_scale.per_dim_scale', 'stacked_xf.13.attn.qkv_proj.weight', 'stacked_xf.13.attn.query_ln.scale', 'stacked_xf.13.ff0.weight', 'stacked_xf.13.ff1.weight', 'stacked_xf.13.post_attn_ln.scale', 'stacked_xf.13.post_ff_ln.scale', 'stacked_xf.13.pre_attn_ln.scale', 'stacked_xf.13.pre_ff_ln.scale', 'stacked_xf.14.attn.key_ln.scale', 'stacked_xf.14.attn.out.weight', 'stacked_xf.14.attn.per_dim_scale.per_dim_scale', 'stacked_xf.14.attn.qkv_proj.weight', 'stacked_xf.14.attn.query_ln.scale', 'stacked_xf.14.ff0.weight', 'stacked_xf.14.ff1.weight', 'stacked_xf.14.post_attn_ln.scale', 'stacked_xf.14.post_ff_ln.scale', 'stacked_xf.14.pre_attn_ln.scale', 'stacked_xf.14.pre_ff_ln.scale', 'stacked_xf.15.attn.key_ln.scale', 'stacked_xf.15.attn.out.weight', 'stacked_xf.15.attn.per_dim_scale.per_dim_scale', 'stacked_xf.15.attn.qkv_proj.weight', 'stacked_xf.15.attn.query_ln.scale', 'stacked_xf.15.ff0.weight', 'stacked_xf.15.ff1.weight', 'stacked_xf.15.post_attn_ln.scale', 'stacked_xf.15.post_ff_ln.scale', 'stacked_xf.15.pre_attn_ln.scale', 'stacked_xf.15.pre_ff_ln.scale', 'stacked_xf.16.attn.key_ln.scale', 'stacked_xf.16.attn.out.weight', 'stacked_xf.16.attn.per_dim_scale.per_dim_scale', 'stacked_xf.16.attn.qkv_proj.weight', 'stacked_xf.16.attn.query_ln.scale', 'stacked_xf.16.ff0.weight', 'stacked_xf.16.ff1.weight', 'stacked_xf.16.post_attn_ln.scale', 'stacked_xf.16.post_ff_ln.scale', 'stacked_xf.16.pre_attn_ln.scale', 'stacked_xf.16.pre_ff_ln.scale', 'stacked_xf.17.attn.key_ln.scale', 'stacked_xf.17.attn.out.weight', 'stacked_xf.17.attn.per_dim_scale.per_dim_scale', 'stacked_xf.17.attn.qkv_proj.weight', 'stacked_xf.17.attn.query_ln.scale', 'stacked_xf.17.ff0.weight', 'stacked_xf.17.ff1.weight', 'stacked_xf.17.post_attn_ln.scale', 'stacked_xf.17.post_ff_ln.scale', 'stacked_xf.17.pre_attn_ln.scale', 'stacked_xf.17.pre_ff_ln.scale', 'stacked_xf.18.attn.key_ln.scale', 'stacked_xf.18.attn.out.weight', 'stacked_xf.18.attn.per_dim_scale.per_dim_scale', 'stacked_xf.18.attn.qkv_proj.weight', 'stacked_xf.18.attn.query_ln.scale', 'stacked_xf.18.ff0.weight', 'stacked_xf.18.ff1.weight', 'stacked_xf.18.post_attn_ln.scale', 'stacked_xf.18.post_ff_ln.scale', 'stacked_xf.18.pre_attn_ln.scale', 'stacked_xf.18.pre_ff_ln.scale', 'stacked_xf.19.attn.key_ln.scale', 'stacked_xf.19.attn.out.weight', 'stacked_xf.19.attn.per_dim_scale.per_dim_scale', 'stacked_xf.19.attn.qkv_proj.weight', 'stacked_xf.19.attn.query_ln.scale', 'stacked_xf.19.ff0.weight', 'stacked_xf.19.ff1.weight', 'stacked_xf.19.post_attn_ln.scale', 'stacked_xf.19.post_ff_ln.scale', 'stacked_xf.19.pre_attn_ln.scale', 'stacked_xf.19.pre_ff_ln.scale', 'stacked_xf.2.attn.key_ln.scale', 'stacked_xf.2.attn.out.weight', 'stacked_xf.2.attn.per_dim_scale.per_dim_scale', 'stacked_xf.2.attn.qkv_proj.weight', 'stacked_xf.2.attn.query_ln.scale', 'stacked_xf.2.ff0.weight', 'stacked_xf.2.ff1.weight', 'stacked_xf.2.post_attn_ln.scale', 'stacked_xf.2.post_ff_ln.scale', 'stacked_xf.2.pre_attn_ln.scale', 'stacked_xf.2.pre_ff_ln.scale', 'stacked_xf.3.attn.key_ln.scale', 'stacked_xf.3.attn.out.weight', 'stacked_xf.3.attn.per_dim_scale.per_dim_scale', 'stacked_xf.3.attn.qkv_proj.weight', 'stacked_xf.3.attn.query_ln.scale', 'stacked_xf.3.ff0.weight', 'stacked_xf.3.ff1.weight', 'stacked_xf.3.post_attn_ln.scale', 'stacked_xf.3.post_ff_ln.scale', 'stacked_xf.3.pre_attn_ln.scale', 'stacked_xf.3.pre_ff_ln.scale', 'stacked_xf.4.attn.key_ln.scale', 'stacked_xf.4.attn.out.weight', 'stacked_xf.4.attn.per_dim_scale.per_dim_scale', 'stacked_xf.4.attn.qkv_proj.weight', 'stacked_xf.4.attn.query_ln.scale', 'stacked_xf.4.ff0.weight', 'stacked_xf.4.ff1.weight', 'stacked_xf.4.post_attn_ln.scale', 'stacked_xf.4.post_ff_ln.scale', 'stacked_xf.4.pre_attn_ln.scale', 'stacked_xf.4.pre_ff_ln.scale', 'stacked_xf.5.attn.key_ln.scale', 'stacked_xf.5.attn.out.weight', 'stacked_xf.5.attn.per_dim_scale.per_dim_scale', 'stacked_xf.5.attn.qkv_proj.weight', 'stacked_xf.5.attn.query_ln.scale', 'stacked_xf.5.ff0.weight', 'stacked_xf.5.ff1.weight', 'stacked_xf.5.post_attn_ln.scale', 'stacked_xf.5.post_ff_ln.scale', 'stacked_xf.5.pre_attn_ln.scale', 'stacked_xf.5.pre_ff_ln.scale', 'stacked_xf.6.attn.key_ln.scale', 'stacked_xf.6.attn.out.weight', 'stacked_xf.6.attn.per_dim_scale.per_dim_scale', 'stacked_xf.6.attn.qkv_proj.weight', 'stacked_xf.6.attn.query_ln.scale', 'stacked_xf.6.ff0.weight', 'stacked_xf.6.ff1.weight', 'stacked_xf.6.post_attn_ln.scale', 'stacked_xf.6.post_ff_ln.scale', 'stacked_xf.6.pre_attn_ln.scale', 'stacked_xf.6.pre_ff_ln.scale', 'stacked_xf.7.attn.key_ln.scale', 'stacked_xf.7.attn.out.weight', 'stacked_xf.7.attn.per_dim_scale.per_dim_scale', 'stacked_xf.7.attn.qkv_proj.weight', 'stacked_xf.7.attn.query_ln.scale', 'stacked_xf.7.ff0.weight', 'stacked_xf.7.ff1.weight', 'stacked_xf.7.post_attn_ln.scale', 'stacked_xf.7.post_ff_ln.scale', 'stacked_xf.7.pre_attn_ln.scale', 'stacked_xf.7.pre_ff_ln.scale', 'stacked_xf.8.attn.key_ln.scale', 'stacked_xf.8.attn.out.weight', 'stacked_xf.8.attn.per_dim_scale.per_dim_scale', 'stacked_xf.8.attn.qkv_proj.weight', 'stacked_xf.8.attn.query_ln.scale', 'stacked_xf.8.ff0.weight', 'stacked_xf.8.ff1.weight', 'stacked_xf.8.post_attn_ln.scale', 'stacked_xf.8.post_ff_ln.scale', 'stacked_xf.8.pre_attn_ln.scale', 'stacked_xf.8.pre_ff_ln.scale', 'stacked_xf.9.attn.key_ln.scale', 'stacked_xf.9.attn.out.weight', 'stacked_xf.9.attn.per_dim_scale.per_dim_scale', 'stacked_xf.9.attn.qkv_proj.weight', 'stacked_xf.9.attn.query_ln.scale', 'stacked_xf.9.ff0.weight', 'stacked_xf.9.ff1.weight', 'stacked_xf.9.post_attn_ln.scale', 'stacked_xf.9.post_ff_ln.scale', 'stacked_xf.9.pre_attn_ln.scale', 'stacked_xf.9.pre_ff_ln.scale', 'tokenizer.hidden_layer.bias', 'tokenizer.hidden_layer.weight', 'tokenizer.output_layer.bias', 'tokenizer.output_layer.weight', 'tokenizer.residual_layer.bias', 'tokenizer.residual_layer.weight']\n",
            "- This IS expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of TimesFmModelForPrediction were not initialized from the model checkpoint at google/timesfm-2.5-200m-pytorch and are newly initialized: ['decoder.freq_emb.weight', 'decoder.input_ff_layer.input_layer.bias', 'decoder.input_ff_layer.input_layer.weight', 'decoder.input_ff_layer.output_layer.bias', 'decoder.input_ff_layer.output_layer.weight', 'decoder.input_ff_layer.residual_layer.bias', 'decoder.input_ff_layer.residual_layer.weight', 'decoder.layers.0.input_layernorm.weight', 'decoder.layers.0.mlp.down_proj.bias', 'decoder.layers.0.mlp.down_proj.weight', 'decoder.layers.0.mlp.gate_proj.bias', 'decoder.layers.0.mlp.gate_proj.weight', 'decoder.layers.0.mlp.layer_norm.bias', 'decoder.layers.0.mlp.layer_norm.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.o_proj.bias', 'decoder.layers.0.self_attn.o_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.scaling', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.1.input_layernorm.weight', 'decoder.layers.1.mlp.down_proj.bias', 'decoder.layers.1.mlp.down_proj.weight', 'decoder.layers.1.mlp.gate_proj.bias', 'decoder.layers.1.mlp.gate_proj.weight', 'decoder.layers.1.mlp.layer_norm.bias', 'decoder.layers.1.mlp.layer_norm.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.o_proj.bias', 'decoder.layers.1.self_attn.o_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.scaling', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.10.input_layernorm.weight', 'decoder.layers.10.mlp.down_proj.bias', 'decoder.layers.10.mlp.down_proj.weight', 'decoder.layers.10.mlp.gate_proj.bias', 'decoder.layers.10.mlp.gate_proj.weight', 'decoder.layers.10.mlp.layer_norm.bias', 'decoder.layers.10.mlp.layer_norm.weight', 'decoder.layers.10.self_attn.k_proj.bias', 'decoder.layers.10.self_attn.k_proj.weight', 'decoder.layers.10.self_attn.o_proj.bias', 'decoder.layers.10.self_attn.o_proj.weight', 'decoder.layers.10.self_attn.q_proj.bias', 'decoder.layers.10.self_attn.q_proj.weight', 'decoder.layers.10.self_attn.scaling', 'decoder.layers.10.self_attn.v_proj.bias', 'decoder.layers.10.self_attn.v_proj.weight', 'decoder.layers.11.input_layernorm.weight', 'decoder.layers.11.mlp.down_proj.bias', 'decoder.layers.11.mlp.down_proj.weight', 'decoder.layers.11.mlp.gate_proj.bias', 'decoder.layers.11.mlp.gate_proj.weight', 'decoder.layers.11.mlp.layer_norm.bias', 'decoder.layers.11.mlp.layer_norm.weight', 'decoder.layers.11.self_attn.k_proj.bias', 'decoder.layers.11.self_attn.k_proj.weight', 'decoder.layers.11.self_attn.o_proj.bias', 'decoder.layers.11.self_attn.o_proj.weight', 'decoder.layers.11.self_attn.q_proj.bias', 'decoder.layers.11.self_attn.q_proj.weight', 'decoder.layers.11.self_attn.scaling', 'decoder.layers.11.self_attn.v_proj.bias', 'decoder.layers.11.self_attn.v_proj.weight', 'decoder.layers.12.input_layernorm.weight', 'decoder.layers.12.mlp.down_proj.bias', 'decoder.layers.12.mlp.down_proj.weight', 'decoder.layers.12.mlp.gate_proj.bias', 'decoder.layers.12.mlp.gate_proj.weight', 'decoder.layers.12.mlp.layer_norm.bias', 'decoder.layers.12.mlp.layer_norm.weight', 'decoder.layers.12.self_attn.k_proj.bias', 'decoder.layers.12.self_attn.k_proj.weight', 'decoder.layers.12.self_attn.o_proj.bias', 'decoder.layers.12.self_attn.o_proj.weight', 'decoder.layers.12.self_attn.q_proj.bias', 'decoder.layers.12.self_attn.q_proj.weight', 'decoder.layers.12.self_attn.scaling', 'decoder.layers.12.self_attn.v_proj.bias', 'decoder.layers.12.self_attn.v_proj.weight', 'decoder.layers.13.input_layernorm.weight', 'decoder.layers.13.mlp.down_proj.bias', 'decoder.layers.13.mlp.down_proj.weight', 'decoder.layers.13.mlp.gate_proj.bias', 'decoder.layers.13.mlp.gate_proj.weight', 'decoder.layers.13.mlp.layer_norm.bias', 'decoder.layers.13.mlp.layer_norm.weight', 'decoder.layers.13.self_attn.k_proj.bias', 'decoder.layers.13.self_attn.k_proj.weight', 'decoder.layers.13.self_attn.o_proj.bias', 'decoder.layers.13.self_attn.o_proj.weight', 'decoder.layers.13.self_attn.q_proj.bias', 'decoder.layers.13.self_attn.q_proj.weight', 'decoder.layers.13.self_attn.scaling', 'decoder.layers.13.self_attn.v_proj.bias', 'decoder.layers.13.self_attn.v_proj.weight', 'decoder.layers.14.input_layernorm.weight', 'decoder.layers.14.mlp.down_proj.bias', 'decoder.layers.14.mlp.down_proj.weight', 'decoder.layers.14.mlp.gate_proj.bias', 'decoder.layers.14.mlp.gate_proj.weight', 'decoder.layers.14.mlp.layer_norm.bias', 'decoder.layers.14.mlp.layer_norm.weight', 'decoder.layers.14.self_attn.k_proj.bias', 'decoder.layers.14.self_attn.k_proj.weight', 'decoder.layers.14.self_attn.o_proj.bias', 'decoder.layers.14.self_attn.o_proj.weight', 'decoder.layers.14.self_attn.q_proj.bias', 'decoder.layers.14.self_attn.q_proj.weight', 'decoder.layers.14.self_attn.scaling', 'decoder.layers.14.self_attn.v_proj.bias', 'decoder.layers.14.self_attn.v_proj.weight', 'decoder.layers.15.input_layernorm.weight', 'decoder.layers.15.mlp.down_proj.bias', 'decoder.layers.15.mlp.down_proj.weight', 'decoder.layers.15.mlp.gate_proj.bias', 'decoder.layers.15.mlp.gate_proj.weight', 'decoder.layers.15.mlp.layer_norm.bias', 'decoder.layers.15.mlp.layer_norm.weight', 'decoder.layers.15.self_attn.k_proj.bias', 'decoder.layers.15.self_attn.k_proj.weight', 'decoder.layers.15.self_attn.o_proj.bias', 'decoder.layers.15.self_attn.o_proj.weight', 'decoder.layers.15.self_attn.q_proj.bias', 'decoder.layers.15.self_attn.q_proj.weight', 'decoder.layers.15.self_attn.scaling', 'decoder.layers.15.self_attn.v_proj.bias', 'decoder.layers.15.self_attn.v_proj.weight', 'decoder.layers.16.input_layernorm.weight', 'decoder.layers.16.mlp.down_proj.bias', 'decoder.layers.16.mlp.down_proj.weight', 'decoder.layers.16.mlp.gate_proj.bias', 'decoder.layers.16.mlp.gate_proj.weight', 'decoder.layers.16.mlp.layer_norm.bias', 'decoder.layers.16.mlp.layer_norm.weight', 'decoder.layers.16.self_attn.k_proj.bias', 'decoder.layers.16.self_attn.k_proj.weight', 'decoder.layers.16.self_attn.o_proj.bias', 'decoder.layers.16.self_attn.o_proj.weight', 'decoder.layers.16.self_attn.q_proj.bias', 'decoder.layers.16.self_attn.q_proj.weight', 'decoder.layers.16.self_attn.scaling', 'decoder.layers.16.self_attn.v_proj.bias', 'decoder.layers.16.self_attn.v_proj.weight', 'decoder.layers.17.input_layernorm.weight', 'decoder.layers.17.mlp.down_proj.bias', 'decoder.layers.17.mlp.down_proj.weight', 'decoder.layers.17.mlp.gate_proj.bias', 'decoder.layers.17.mlp.gate_proj.weight', 'decoder.layers.17.mlp.layer_norm.bias', 'decoder.layers.17.mlp.layer_norm.weight', 'decoder.layers.17.self_attn.k_proj.bias', 'decoder.layers.17.self_attn.k_proj.weight', 'decoder.layers.17.self_attn.o_proj.bias', 'decoder.layers.17.self_attn.o_proj.weight', 'decoder.layers.17.self_attn.q_proj.bias', 'decoder.layers.17.self_attn.q_proj.weight', 'decoder.layers.17.self_attn.scaling', 'decoder.layers.17.self_attn.v_proj.bias', 'decoder.layers.17.self_attn.v_proj.weight', 'decoder.layers.18.input_layernorm.weight', 'decoder.layers.18.mlp.down_proj.bias', 'decoder.layers.18.mlp.down_proj.weight', 'decoder.layers.18.mlp.gate_proj.bias', 'decoder.layers.18.mlp.gate_proj.weight', 'decoder.layers.18.mlp.layer_norm.bias', 'decoder.layers.18.mlp.layer_norm.weight', 'decoder.layers.18.self_attn.k_proj.bias', 'decoder.layers.18.self_attn.k_proj.weight', 'decoder.layers.18.self_attn.o_proj.bias', 'decoder.layers.18.self_attn.o_proj.weight', 'decoder.layers.18.self_attn.q_proj.bias', 'decoder.layers.18.self_attn.q_proj.weight', 'decoder.layers.18.self_attn.scaling', 'decoder.layers.18.self_attn.v_proj.bias', 'decoder.layers.18.self_attn.v_proj.weight', 'decoder.layers.19.input_layernorm.weight', 'decoder.layers.19.mlp.down_proj.bias', 'decoder.layers.19.mlp.down_proj.weight', 'decoder.layers.19.mlp.gate_proj.bias', 'decoder.layers.19.mlp.gate_proj.weight', 'decoder.layers.19.mlp.layer_norm.bias', 'decoder.layers.19.mlp.layer_norm.weight', 'decoder.layers.19.self_attn.k_proj.bias', 'decoder.layers.19.self_attn.k_proj.weight', 'decoder.layers.19.self_attn.o_proj.bias', 'decoder.layers.19.self_attn.o_proj.weight', 'decoder.layers.19.self_attn.q_proj.bias', 'decoder.layers.19.self_attn.q_proj.weight', 'decoder.layers.19.self_attn.scaling', 'decoder.layers.19.self_attn.v_proj.bias', 'decoder.layers.19.self_attn.v_proj.weight', 'decoder.layers.2.input_layernorm.weight', 'decoder.layers.2.mlp.down_proj.bias', 'decoder.layers.2.mlp.down_proj.weight', 'decoder.layers.2.mlp.gate_proj.bias', 'decoder.layers.2.mlp.gate_proj.weight', 'decoder.layers.2.mlp.layer_norm.bias', 'decoder.layers.2.mlp.layer_norm.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.o_proj.bias', 'decoder.layers.2.self_attn.o_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.scaling', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.3.input_layernorm.weight', 'decoder.layers.3.mlp.down_proj.bias', 'decoder.layers.3.mlp.down_proj.weight', 'decoder.layers.3.mlp.gate_proj.bias', 'decoder.layers.3.mlp.gate_proj.weight', 'decoder.layers.3.mlp.layer_norm.bias', 'decoder.layers.3.mlp.layer_norm.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.o_proj.bias', 'decoder.layers.3.self_attn.o_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.scaling', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.4.input_layernorm.weight', 'decoder.layers.4.mlp.down_proj.bias', 'decoder.layers.4.mlp.down_proj.weight', 'decoder.layers.4.mlp.gate_proj.bias', 'decoder.layers.4.mlp.gate_proj.weight', 'decoder.layers.4.mlp.layer_norm.bias', 'decoder.layers.4.mlp.layer_norm.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.o_proj.bias', 'decoder.layers.4.self_attn.o_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.scaling', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.5.input_layernorm.weight', 'decoder.layers.5.mlp.down_proj.bias', 'decoder.layers.5.mlp.down_proj.weight', 'decoder.layers.5.mlp.gate_proj.bias', 'decoder.layers.5.mlp.gate_proj.weight', 'decoder.layers.5.mlp.layer_norm.bias', 'decoder.layers.5.mlp.layer_norm.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.o_proj.bias', 'decoder.layers.5.self_attn.o_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.scaling', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.6.input_layernorm.weight', 'decoder.layers.6.mlp.down_proj.bias', 'decoder.layers.6.mlp.down_proj.weight', 'decoder.layers.6.mlp.gate_proj.bias', 'decoder.layers.6.mlp.gate_proj.weight', 'decoder.layers.6.mlp.layer_norm.bias', 'decoder.layers.6.mlp.layer_norm.weight', 'decoder.layers.6.self_attn.k_proj.bias', 'decoder.layers.6.self_attn.k_proj.weight', 'decoder.layers.6.self_attn.o_proj.bias', 'decoder.layers.6.self_attn.o_proj.weight', 'decoder.layers.6.self_attn.q_proj.bias', 'decoder.layers.6.self_attn.q_proj.weight', 'decoder.layers.6.self_attn.scaling', 'decoder.layers.6.self_attn.v_proj.bias', 'decoder.layers.6.self_attn.v_proj.weight', 'decoder.layers.7.input_layernorm.weight', 'decoder.layers.7.mlp.down_proj.bias', 'decoder.layers.7.mlp.down_proj.weight', 'decoder.layers.7.mlp.gate_proj.bias', 'decoder.layers.7.mlp.gate_proj.weight', 'decoder.layers.7.mlp.layer_norm.bias', 'decoder.layers.7.mlp.layer_norm.weight', 'decoder.layers.7.self_attn.k_proj.bias', 'decoder.layers.7.self_attn.k_proj.weight', 'decoder.layers.7.self_attn.o_proj.bias', 'decoder.layers.7.self_attn.o_proj.weight', 'decoder.layers.7.self_attn.q_proj.bias', 'decoder.layers.7.self_attn.q_proj.weight', 'decoder.layers.7.self_attn.scaling', 'decoder.layers.7.self_attn.v_proj.bias', 'decoder.layers.7.self_attn.v_proj.weight', 'decoder.layers.8.input_layernorm.weight', 'decoder.layers.8.mlp.down_proj.bias', 'decoder.layers.8.mlp.down_proj.weight', 'decoder.layers.8.mlp.gate_proj.bias', 'decoder.layers.8.mlp.gate_proj.weight', 'decoder.layers.8.mlp.layer_norm.bias', 'decoder.layers.8.mlp.layer_norm.weight', 'decoder.layers.8.self_attn.k_proj.bias', 'decoder.layers.8.self_attn.k_proj.weight', 'decoder.layers.8.self_attn.o_proj.bias', 'decoder.layers.8.self_attn.o_proj.weight', 'decoder.layers.8.self_attn.q_proj.bias', 'decoder.layers.8.self_attn.q_proj.weight', 'decoder.layers.8.self_attn.scaling', 'decoder.layers.8.self_attn.v_proj.bias', 'decoder.layers.8.self_attn.v_proj.weight', 'decoder.layers.9.input_layernorm.weight', 'decoder.layers.9.mlp.down_proj.bias', 'decoder.layers.9.mlp.down_proj.weight', 'decoder.layers.9.mlp.gate_proj.bias', 'decoder.layers.9.mlp.gate_proj.weight', 'decoder.layers.9.mlp.layer_norm.bias', 'decoder.layers.9.mlp.layer_norm.weight', 'decoder.layers.9.self_attn.k_proj.bias', 'decoder.layers.9.self_attn.k_proj.weight', 'decoder.layers.9.self_attn.o_proj.bias', 'decoder.layers.9.self_attn.o_proj.weight', 'decoder.layers.9.self_attn.q_proj.bias', 'decoder.layers.9.self_attn.q_proj.weight', 'decoder.layers.9.self_attn.scaling', 'decoder.layers.9.self_attn.v_proj.bias', 'decoder.layers.9.self_attn.v_proj.weight', 'horizon_ff_layer.input_layer.bias', 'horizon_ff_layer.input_layer.weight', 'horizon_ff_layer.output_layer.bias', 'horizon_ff_layer.output_layer.weight', 'horizon_ff_layer.residual_layer.bias', 'horizon_ff_layer.residual_layer.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n",
            "  Epoch 1/100 train_loss=2.8647 train_acc=0.3489 eval_loss=1.8600 eval_acc=0.5407 (best)\n",
            "  Epoch 2/100 train_loss=1.3714 train_acc=0.6844 eval_loss=1.1385 eval_acc=0.7187 (best)\n",
            "  Epoch 3/100 train_loss=0.5610 train_acc=0.9089 eval_loss=0.7681 eval_acc=0.7868 (best)\n",
            "  Epoch 4/100 train_loss=0.2296 train_acc=0.9667 eval_loss=0.7918 eval_acc=0.7736 \n",
            "  Epoch 5/100 train_loss=0.1217 train_acc=0.9644 eval_loss=0.8554 eval_acc=0.7648 \n",
            "  Epoch 6/100 train_loss=0.1012 train_acc=0.9667 eval_loss=1.0291 eval_acc=0.7319 \n",
            "  Epoch 7/100 train_loss=0.1237 train_acc=0.9644 eval_loss=1.0584 eval_acc=0.7495 \n",
            "  Epoch 8/100 train_loss=0.2060 train_acc=0.9489 eval_loss=0.9480 eval_acc=0.7604 \n",
            "  Epoch 9/100 train_loss=0.1127 train_acc=0.9622 eval_loss=1.0665 eval_acc=0.7297 \n",
            "  Epoch 10/100 train_loss=0.1315 train_acc=0.9689 eval_loss=1.1676 eval_acc=0.7604 \n",
            "  Epoch 11/100 train_loss=0.0795 train_acc=0.9778 eval_loss=1.0159 eval_acc=0.7473 \n",
            "  Epoch 12/100 train_loss=0.0965 train_acc=0.9644 eval_loss=1.2184 eval_acc=0.7495 \n",
            "  Epoch 13/100 train_loss=0.0895 train_acc=0.9756 eval_loss=1.1928 eval_acc=0.7868 \n",
            "  Early stopping on google/timesfm-2.5-200m-pytorch: no improvement for 10 epochs (best epoch = 3)\n",
            "    tfm[google/timesfm-2.5-200m-pytorch] train_acc=0.9089 eval_acc=0.78681318681318679342240329788182862102985382\n",
            "    mrh_acc=0.8769 mr+h+kg_acc=0.8769 kg_acc=0.8615 ensemble=0.8747 (w=0.60)\n",
            "  Split 1/1 - accuracy=0.8747 time=383.6s\n",
            "Completed FiftyWords: Mean Acc=0.8747\n",
            "\n",
            "=== 35/109 Fish ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  Decision: Heuristic says no filter (clean signal (no filtering))\n",
            "\n",
            "=== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at google/timesfm-2.5-200m-pytorch were not used when initializing TimesFmModelForPrediction: ['output_projection_point.hidden_layer.weight', 'output_projection_point.output_layer.weight', 'output_projection_point.residual_layer.weight', 'output_projection_quantiles.hidden_layer.weight', 'output_projection_quantiles.output_layer.weight', 'output_projection_quantiles.residual_layer.weight', 'stacked_xf.0.attn.key_ln.scale', 'stacked_xf.0.attn.out.weight', 'stacked_xf.0.attn.per_dim_scale.per_dim_scale', 'stacked_xf.0.attn.qkv_proj.weight', 'stacked_xf.0.attn.query_ln.scale', 'stacked_xf.0.ff0.weight', 'stacked_xf.0.ff1.weight', 'stacked_xf.0.post_attn_ln.scale', 'stacked_xf.0.post_ff_ln.scale', 'stacked_xf.0.pre_attn_ln.scale', 'stacked_xf.0.pre_ff_ln.scale', 'stacked_xf.1.attn.key_ln.scale', 'stacked_xf.1.attn.out.weight', 'stacked_xf.1.attn.per_dim_scale.per_dim_scale', 'stacked_xf.1.attn.qkv_proj.weight', 'stacked_xf.1.attn.query_ln.scale', 'stacked_xf.1.ff0.weight', 'stacked_xf.1.ff1.weight', 'stacked_xf.1.post_attn_ln.scale', 'stacked_xf.1.post_ff_ln.scale', 'stacked_xf.1.pre_attn_ln.scale', 'stacked_xf.1.pre_ff_ln.scale', 'stacked_xf.10.attn.key_ln.scale', 'stacked_xf.10.attn.out.weight', 'stacked_xf.10.attn.per_dim_scale.per_dim_scale', 'stacked_xf.10.attn.qkv_proj.weight', 'stacked_xf.10.attn.query_ln.scale', 'stacked_xf.10.ff0.weight', 'stacked_xf.10.ff1.weight', 'stacked_xf.10.post_attn_ln.scale', 'stacked_xf.10.post_ff_ln.scale', 'stacked_xf.10.pre_attn_ln.scale', 'stacked_xf.10.pre_ff_ln.scale', 'stacked_xf.11.attn.key_ln.scale', 'stacked_xf.11.attn.out.weight', 'stacked_xf.11.attn.per_dim_scale.per_dim_scale', 'stacked_xf.11.attn.qkv_proj.weight', 'stacked_xf.11.attn.query_ln.scale', 'stacked_xf.11.ff0.weight', 'stacked_xf.11.ff1.weight', 'stacked_xf.11.post_attn_ln.scale', 'stacked_xf.11.post_ff_ln.scale', 'stacked_xf.11.pre_attn_ln.scale', 'stacked_xf.11.pre_ff_ln.scale', 'stacked_xf.12.attn.key_ln.scale', 'stacked_xf.12.attn.out.weight', 'stacked_xf.12.attn.per_dim_scale.per_dim_scale', 'stacked_xf.12.attn.qkv_proj.weight', 'stacked_xf.12.attn.query_ln.scale', 'stacked_xf.12.ff0.weight', 'stacked_xf.12.ff1.weight', 'stacked_xf.12.post_attn_ln.scale', 'stacked_xf.12.post_ff_ln.scale', 'stacked_xf.12.pre_attn_ln.scale', 'stacked_xf.12.pre_ff_ln.scale', 'stacked_xf.13.attn.key_ln.scale', 'stacked_xf.13.attn.out.weight', 'stacked_xf.13.attn.per_dim_scale.per_dim_scale', 'stacked_xf.13.attn.qkv_proj.weight', 'stacked_xf.13.attn.query_ln.scale', 'stacked_xf.13.ff0.weight', 'stacked_xf.13.ff1.weight', 'stacked_xf.13.post_attn_ln.scale', 'stacked_xf.13.post_ff_ln.scale', 'stacked_xf.13.pre_attn_ln.scale', 'stacked_xf.13.pre_ff_ln.scale', 'stacked_xf.14.attn.key_ln.scale', 'stacked_xf.14.attn.out.weight', 'stacked_xf.14.attn.per_dim_scale.per_dim_scale', 'stacked_xf.14.attn.qkv_proj.weight', 'stacked_xf.14.attn.query_ln.scale', 'stacked_xf.14.ff0.weight', 'stacked_xf.14.ff1.weight', 'stacked_xf.14.post_attn_ln.scale', 'stacked_xf.14.post_ff_ln.scale', 'stacked_xf.14.pre_attn_ln.scale', 'stacked_xf.14.pre_ff_ln.scale', 'stacked_xf.15.attn.key_ln.scale', 'stacked_xf.15.attn.out.weight', 'stacked_xf.15.attn.per_dim_scale.per_dim_scale', 'stacked_xf.15.attn.qkv_proj.weight', 'stacked_xf.15.attn.query_ln.scale', 'stacked_xf.15.ff0.weight', 'stacked_xf.15.ff1.weight', 'stacked_xf.15.post_attn_ln.scale', 'stacked_xf.15.post_ff_ln.scale', 'stacked_xf.15.pre_attn_ln.scale', 'stacked_xf.15.pre_ff_ln.scale', 'stacked_xf.16.attn.key_ln.scale', 'stacked_xf.16.attn.out.weight', 'stacked_xf.16.attn.per_dim_scale.per_dim_scale', 'stacked_xf.16.attn.qkv_proj.weight', 'stacked_xf.16.attn.query_ln.scale', 'stacked_xf.16.ff0.weight', 'stacked_xf.16.ff1.weight', 'stacked_xf.16.post_attn_ln.scale', 'stacked_xf.16.post_ff_ln.scale', 'stacked_xf.16.pre_attn_ln.scale', 'stacked_xf.16.pre_ff_ln.scale', 'stacked_xf.17.attn.key_ln.scale', 'stacked_xf.17.attn.out.weight', 'stacked_xf.17.attn.per_dim_scale.per_dim_scale', 'stacked_xf.17.attn.qkv_proj.weight', 'stacked_xf.17.attn.query_ln.scale', 'stacked_xf.17.ff0.weight', 'stacked_xf.17.ff1.weight', 'stacked_xf.17.post_attn_ln.scale', 'stacked_xf.17.post_ff_ln.scale', 'stacked_xf.17.pre_attn_ln.scale', 'stacked_xf.17.pre_ff_ln.scale', 'stacked_xf.18.attn.key_ln.scale', 'stacked_xf.18.attn.out.weight', 'stacked_xf.18.attn.per_dim_scale.per_dim_scale', 'stacked_xf.18.attn.qkv_proj.weight', 'stacked_xf.18.attn.query_ln.scale', 'stacked_xf.18.ff0.weight', 'stacked_xf.18.ff1.weight', 'stacked_xf.18.post_attn_ln.scale', 'stacked_xf.18.post_ff_ln.scale', 'stacked_xf.18.pre_attn_ln.scale', 'stacked_xf.18.pre_ff_ln.scale', 'stacked_xf.19.attn.key_ln.scale', 'stacked_xf.19.attn.out.weight', 'stacked_xf.19.attn.per_dim_scale.per_dim_scale', 'stacked_xf.19.attn.qkv_proj.weight', 'stacked_xf.19.attn.query_ln.scale', 'stacked_xf.19.ff0.weight', 'stacked_xf.19.ff1.weight', 'stacked_xf.19.post_attn_ln.scale', 'stacked_xf.19.post_ff_ln.scale', 'stacked_xf.19.pre_attn_ln.scale', 'stacked_xf.19.pre_ff_ln.scale', 'stacked_xf.2.attn.key_ln.scale', 'stacked_xf.2.attn.out.weight', 'stacked_xf.2.attn.per_dim_scale.per_dim_scale', 'stacked_xf.2.attn.qkv_proj.weight', 'stacked_xf.2.attn.query_ln.scale', 'stacked_xf.2.ff0.weight', 'stacked_xf.2.ff1.weight', 'stacked_xf.2.post_attn_ln.scale', 'stacked_xf.2.post_ff_ln.scale', 'stacked_xf.2.pre_attn_ln.scale', 'stacked_xf.2.pre_ff_ln.scale', 'stacked_xf.3.attn.key_ln.scale', 'stacked_xf.3.attn.out.weight', 'stacked_xf.3.attn.per_dim_scale.per_dim_scale', 'stacked_xf.3.attn.qkv_proj.weight', 'stacked_xf.3.attn.query_ln.scale', 'stacked_xf.3.ff0.weight', 'stacked_xf.3.ff1.weight', 'stacked_xf.3.post_attn_ln.scale', 'stacked_xf.3.post_ff_ln.scale', 'stacked_xf.3.pre_attn_ln.scale', 'stacked_xf.3.pre_ff_ln.scale', 'stacked_xf.4.attn.key_ln.scale', 'stacked_xf.4.attn.out.weight', 'stacked_xf.4.attn.per_dim_scale.per_dim_scale', 'stacked_xf.4.attn.qkv_proj.weight', 'stacked_xf.4.attn.query_ln.scale', 'stacked_xf.4.ff0.weight', 'stacked_xf.4.ff1.weight', 'stacked_xf.4.post_attn_ln.scale', 'stacked_xf.4.post_ff_ln.scale', 'stacked_xf.4.pre_attn_ln.scale', 'stacked_xf.4.pre_ff_ln.scale', 'stacked_xf.5.attn.key_ln.scale', 'stacked_xf.5.attn.out.weight', 'stacked_xf.5.attn.per_dim_scale.per_dim_scale', 'stacked_xf.5.attn.qkv_proj.weight', 'stacked_xf.5.attn.query_ln.scale', 'stacked_xf.5.ff0.weight', 'stacked_xf.5.ff1.weight', 'stacked_xf.5.post_attn_ln.scale', 'stacked_xf.5.post_ff_ln.scale', 'stacked_xf.5.pre_attn_ln.scale', 'stacked_xf.5.pre_ff_ln.scale', 'stacked_xf.6.attn.key_ln.scale', 'stacked_xf.6.attn.out.weight', 'stacked_xf.6.attn.per_dim_scale.per_dim_scale', 'stacked_xf.6.attn.qkv_proj.weight', 'stacked_xf.6.attn.query_ln.scale', 'stacked_xf.6.ff0.weight', 'stacked_xf.6.ff1.weight', 'stacked_xf.6.post_attn_ln.scale', 'stacked_xf.6.post_ff_ln.scale', 'stacked_xf.6.pre_attn_ln.scale', 'stacked_xf.6.pre_ff_ln.scale', 'stacked_xf.7.attn.key_ln.scale', 'stacked_xf.7.attn.out.weight', 'stacked_xf.7.attn.per_dim_scale.per_dim_scale', 'stacked_xf.7.attn.qkv_proj.weight', 'stacked_xf.7.attn.query_ln.scale', 'stacked_xf.7.ff0.weight', 'stacked_xf.7.ff1.weight', 'stacked_xf.7.post_attn_ln.scale', 'stacked_xf.7.post_ff_ln.scale', 'stacked_xf.7.pre_attn_ln.scale', 'stacked_xf.7.pre_ff_ln.scale', 'stacked_xf.8.attn.key_ln.scale', 'stacked_xf.8.attn.out.weight', 'stacked_xf.8.attn.per_dim_scale.per_dim_scale', 'stacked_xf.8.attn.qkv_proj.weight', 'stacked_xf.8.attn.query_ln.scale', 'stacked_xf.8.ff0.weight', 'stacked_xf.8.ff1.weight', 'stacked_xf.8.post_attn_ln.scale', 'stacked_xf.8.post_ff_ln.scale', 'stacked_xf.8.pre_attn_ln.scale', 'stacked_xf.8.pre_ff_ln.scale', 'stacked_xf.9.attn.key_ln.scale', 'stacked_xf.9.attn.out.weight', 'stacked_xf.9.attn.per_dim_scale.per_dim_scale', 'stacked_xf.9.attn.qkv_proj.weight', 'stacked_xf.9.attn.query_ln.scale', 'stacked_xf.9.ff0.weight', 'stacked_xf.9.ff1.weight', 'stacked_xf.9.post_attn_ln.scale', 'stacked_xf.9.post_ff_ln.scale', 'stacked_xf.9.pre_attn_ln.scale', 'stacked_xf.9.pre_ff_ln.scale', 'tokenizer.hidden_layer.bias', 'tokenizer.hidden_layer.weight', 'tokenizer.output_layer.bias', 'tokenizer.output_layer.weight', 'tokenizer.residual_layer.bias', 'tokenizer.residual_layer.weight']\n",
            "- This IS expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of TimesFmModelForPrediction were not initialized from the model checkpoint at google/timesfm-2.5-200m-pytorch and are newly initialized: ['decoder.freq_emb.weight', 'decoder.input_ff_layer.input_layer.bias', 'decoder.input_ff_layer.input_layer.weight', 'decoder.input_ff_layer.output_layer.bias', 'decoder.input_ff_layer.output_layer.weight', 'decoder.input_ff_layer.residual_layer.bias', 'decoder.input_ff_layer.residual_layer.weight', 'decoder.layers.0.input_layernorm.weight', 'decoder.layers.0.mlp.down_proj.bias', 'decoder.layers.0.mlp.down_proj.weight', 'decoder.layers.0.mlp.gate_proj.bias', 'decoder.layers.0.mlp.gate_proj.weight', 'decoder.layers.0.mlp.layer_norm.bias', 'decoder.layers.0.mlp.layer_norm.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.o_proj.bias', 'decoder.layers.0.self_attn.o_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.scaling', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.1.input_layernorm.weight', 'decoder.layers.1.mlp.down_proj.bias', 'decoder.layers.1.mlp.down_proj.weight', 'decoder.layers.1.mlp.gate_proj.bias', 'decoder.layers.1.mlp.gate_proj.weight', 'decoder.layers.1.mlp.layer_norm.bias', 'decoder.layers.1.mlp.layer_norm.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.o_proj.bias', 'decoder.layers.1.self_attn.o_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.scaling', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.10.input_layernorm.weight', 'decoder.layers.10.mlp.down_proj.bias', 'decoder.layers.10.mlp.down_proj.weight', 'decoder.layers.10.mlp.gate_proj.bias', 'decoder.layers.10.mlp.gate_proj.weight', 'decoder.layers.10.mlp.layer_norm.bias', 'decoder.layers.10.mlp.layer_norm.weight', 'decoder.layers.10.self_attn.k_proj.bias', 'decoder.layers.10.self_attn.k_proj.weight', 'decoder.layers.10.self_attn.o_proj.bias', 'decoder.layers.10.self_attn.o_proj.weight', 'decoder.layers.10.self_attn.q_proj.bias', 'decoder.layers.10.self_attn.q_proj.weight', 'decoder.layers.10.self_attn.scaling', 'decoder.layers.10.self_attn.v_proj.bias', 'decoder.layers.10.self_attn.v_proj.weight', 'decoder.layers.11.input_layernorm.weight', 'decoder.layers.11.mlp.down_proj.bias', 'decoder.layers.11.mlp.down_proj.weight', 'decoder.layers.11.mlp.gate_proj.bias', 'decoder.layers.11.mlp.gate_proj.weight', 'decoder.layers.11.mlp.layer_norm.bias', 'decoder.layers.11.mlp.layer_norm.weight', 'decoder.layers.11.self_attn.k_proj.bias', 'decoder.layers.11.self_attn.k_proj.weight', 'decoder.layers.11.self_attn.o_proj.bias', 'decoder.layers.11.self_attn.o_proj.weight', 'decoder.layers.11.self_attn.q_proj.bias', 'decoder.layers.11.self_attn.q_proj.weight', 'decoder.layers.11.self_attn.scaling', 'decoder.layers.11.self_attn.v_proj.bias', 'decoder.layers.11.self_attn.v_proj.weight', 'decoder.layers.12.input_layernorm.weight', 'decoder.layers.12.mlp.down_proj.bias', 'decoder.layers.12.mlp.down_proj.weight', 'decoder.layers.12.mlp.gate_proj.bias', 'decoder.layers.12.mlp.gate_proj.weight', 'decoder.layers.12.mlp.layer_norm.bias', 'decoder.layers.12.mlp.layer_norm.weight', 'decoder.layers.12.self_attn.k_proj.bias', 'decoder.layers.12.self_attn.k_proj.weight', 'decoder.layers.12.self_attn.o_proj.bias', 'decoder.layers.12.self_attn.o_proj.weight', 'decoder.layers.12.self_attn.q_proj.bias', 'decoder.layers.12.self_attn.q_proj.weight', 'decoder.layers.12.self_attn.scaling', 'decoder.layers.12.self_attn.v_proj.bias', 'decoder.layers.12.self_attn.v_proj.weight', 'decoder.layers.13.input_layernorm.weight', 'decoder.layers.13.mlp.down_proj.bias', 'decoder.layers.13.mlp.down_proj.weight', 'decoder.layers.13.mlp.gate_proj.bias', 'decoder.layers.13.mlp.gate_proj.weight', 'decoder.layers.13.mlp.layer_norm.bias', 'decoder.layers.13.mlp.layer_norm.weight', 'decoder.layers.13.self_attn.k_proj.bias', 'decoder.layers.13.self_attn.k_proj.weight', 'decoder.layers.13.self_attn.o_proj.bias', 'decoder.layers.13.self_attn.o_proj.weight', 'decoder.layers.13.self_attn.q_proj.bias', 'decoder.layers.13.self_attn.q_proj.weight', 'decoder.layers.13.self_attn.scaling', 'decoder.layers.13.self_attn.v_proj.bias', 'decoder.layers.13.self_attn.v_proj.weight', 'decoder.layers.14.input_layernorm.weight', 'decoder.layers.14.mlp.down_proj.bias', 'decoder.layers.14.mlp.down_proj.weight', 'decoder.layers.14.mlp.gate_proj.bias', 'decoder.layers.14.mlp.gate_proj.weight', 'decoder.layers.14.mlp.layer_norm.bias', 'decoder.layers.14.mlp.layer_norm.weight', 'decoder.layers.14.self_attn.k_proj.bias', 'decoder.layers.14.self_attn.k_proj.weight', 'decoder.layers.14.self_attn.o_proj.bias', 'decoder.layers.14.self_attn.o_proj.weight', 'decoder.layers.14.self_attn.q_proj.bias', 'decoder.layers.14.self_attn.q_proj.weight', 'decoder.layers.14.self_attn.scaling', 'decoder.layers.14.self_attn.v_proj.bias', 'decoder.layers.14.self_attn.v_proj.weight', 'decoder.layers.15.input_layernorm.weight', 'decoder.layers.15.mlp.down_proj.bias', 'decoder.layers.15.mlp.down_proj.weight', 'decoder.layers.15.mlp.gate_proj.bias', 'decoder.layers.15.mlp.gate_proj.weight', 'decoder.layers.15.mlp.layer_norm.bias', 'decoder.layers.15.mlp.layer_norm.weight', 'decoder.layers.15.self_attn.k_proj.bias', 'decoder.layers.15.self_attn.k_proj.weight', 'decoder.layers.15.self_attn.o_proj.bias', 'decoder.layers.15.self_attn.o_proj.weight', 'decoder.layers.15.self_attn.q_proj.bias', 'decoder.layers.15.self_attn.q_proj.weight', 'decoder.layers.15.self_attn.scaling', 'decoder.layers.15.self_attn.v_proj.bias', 'decoder.layers.15.self_attn.v_proj.weight', 'decoder.layers.16.input_layernorm.weight', 'decoder.layers.16.mlp.down_proj.bias', 'decoder.layers.16.mlp.down_proj.weight', 'decoder.layers.16.mlp.gate_proj.bias', 'decoder.layers.16.mlp.gate_proj.weight', 'decoder.layers.16.mlp.layer_norm.bias', 'decoder.layers.16.mlp.layer_norm.weight', 'decoder.layers.16.self_attn.k_proj.bias', 'decoder.layers.16.self_attn.k_proj.weight', 'decoder.layers.16.self_attn.o_proj.bias', 'decoder.layers.16.self_attn.o_proj.weight', 'decoder.layers.16.self_attn.q_proj.bias', 'decoder.layers.16.self_attn.q_proj.weight', 'decoder.layers.16.self_attn.scaling', 'decoder.layers.16.self_attn.v_proj.bias', 'decoder.layers.16.self_attn.v_proj.weight', 'decoder.layers.17.input_layernorm.weight', 'decoder.layers.17.mlp.down_proj.bias', 'decoder.layers.17.mlp.down_proj.weight', 'decoder.layers.17.mlp.gate_proj.bias', 'decoder.layers.17.mlp.gate_proj.weight', 'decoder.layers.17.mlp.layer_norm.bias', 'decoder.layers.17.mlp.layer_norm.weight', 'decoder.layers.17.self_attn.k_proj.bias', 'decoder.layers.17.self_attn.k_proj.weight', 'decoder.layers.17.self_attn.o_proj.bias', 'decoder.layers.17.self_attn.o_proj.weight', 'decoder.layers.17.self_attn.q_proj.bias', 'decoder.layers.17.self_attn.q_proj.weight', 'decoder.layers.17.self_attn.scaling', 'decoder.layers.17.self_attn.v_proj.bias', 'decoder.layers.17.self_attn.v_proj.weight', 'decoder.layers.18.input_layernorm.weight', 'decoder.layers.18.mlp.down_proj.bias', 'decoder.layers.18.mlp.down_proj.weight', 'decoder.layers.18.mlp.gate_proj.bias', 'decoder.layers.18.mlp.gate_proj.weight', 'decoder.layers.18.mlp.layer_norm.bias', 'decoder.layers.18.mlp.layer_norm.weight', 'decoder.layers.18.self_attn.k_proj.bias', 'decoder.layers.18.self_attn.k_proj.weight', 'decoder.layers.18.self_attn.o_proj.bias', 'decoder.layers.18.self_attn.o_proj.weight', 'decoder.layers.18.self_attn.q_proj.bias', 'decoder.layers.18.self_attn.q_proj.weight', 'decoder.layers.18.self_attn.scaling', 'decoder.layers.18.self_attn.v_proj.bias', 'decoder.layers.18.self_attn.v_proj.weight', 'decoder.layers.19.input_layernorm.weight', 'decoder.layers.19.mlp.down_proj.bias', 'decoder.layers.19.mlp.down_proj.weight', 'decoder.layers.19.mlp.gate_proj.bias', 'decoder.layers.19.mlp.gate_proj.weight', 'decoder.layers.19.mlp.layer_norm.bias', 'decoder.layers.19.mlp.layer_norm.weight', 'decoder.layers.19.self_attn.k_proj.bias', 'decoder.layers.19.self_attn.k_proj.weight', 'decoder.layers.19.self_attn.o_proj.bias', 'decoder.layers.19.self_attn.o_proj.weight', 'decoder.layers.19.self_attn.q_proj.bias', 'decoder.layers.19.self_attn.q_proj.weight', 'decoder.layers.19.self_attn.scaling', 'decoder.layers.19.self_attn.v_proj.bias', 'decoder.layers.19.self_attn.v_proj.weight', 'decoder.layers.2.input_layernorm.weight', 'decoder.layers.2.mlp.down_proj.bias', 'decoder.layers.2.mlp.down_proj.weight', 'decoder.layers.2.mlp.gate_proj.bias', 'decoder.layers.2.mlp.gate_proj.weight', 'decoder.layers.2.mlp.layer_norm.bias', 'decoder.layers.2.mlp.layer_norm.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.o_proj.bias', 'decoder.layers.2.self_attn.o_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.scaling', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.3.input_layernorm.weight', 'decoder.layers.3.mlp.down_proj.bias', 'decoder.layers.3.mlp.down_proj.weight', 'decoder.layers.3.mlp.gate_proj.bias', 'decoder.layers.3.mlp.gate_proj.weight', 'decoder.layers.3.mlp.layer_norm.bias', 'decoder.layers.3.mlp.layer_norm.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.o_proj.bias', 'decoder.layers.3.self_attn.o_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.scaling', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.4.input_layernorm.weight', 'decoder.layers.4.mlp.down_proj.bias', 'decoder.layers.4.mlp.down_proj.weight', 'decoder.layers.4.mlp.gate_proj.bias', 'decoder.layers.4.mlp.gate_proj.weight', 'decoder.layers.4.mlp.layer_norm.bias', 'decoder.layers.4.mlp.layer_norm.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.o_proj.bias', 'decoder.layers.4.self_attn.o_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.scaling', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.5.input_layernorm.weight', 'decoder.layers.5.mlp.down_proj.bias', 'decoder.layers.5.mlp.down_proj.weight', 'decoder.layers.5.mlp.gate_proj.bias', 'decoder.layers.5.mlp.gate_proj.weight', 'decoder.layers.5.mlp.layer_norm.bias', 'decoder.layers.5.mlp.layer_norm.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.o_proj.bias', 'decoder.layers.5.self_attn.o_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.scaling', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.6.input_layernorm.weight', 'decoder.layers.6.mlp.down_proj.bias', 'decoder.layers.6.mlp.down_proj.weight', 'decoder.layers.6.mlp.gate_proj.bias', 'decoder.layers.6.mlp.gate_proj.weight', 'decoder.layers.6.mlp.layer_norm.bias', 'decoder.layers.6.mlp.layer_norm.weight', 'decoder.layers.6.self_attn.k_proj.bias', 'decoder.layers.6.self_attn.k_proj.weight', 'decoder.layers.6.self_attn.o_proj.bias', 'decoder.layers.6.self_attn.o_proj.weight', 'decoder.layers.6.self_attn.q_proj.bias', 'decoder.layers.6.self_attn.q_proj.weight', 'decoder.layers.6.self_attn.scaling', 'decoder.layers.6.self_attn.v_proj.bias', 'decoder.layers.6.self_attn.v_proj.weight', 'decoder.layers.7.input_layernorm.weight', 'decoder.layers.7.mlp.down_proj.bias', 'decoder.layers.7.mlp.down_proj.weight', 'decoder.layers.7.mlp.gate_proj.bias', 'decoder.layers.7.mlp.gate_proj.weight', 'decoder.layers.7.mlp.layer_norm.bias', 'decoder.layers.7.mlp.layer_norm.weight', 'decoder.layers.7.self_attn.k_proj.bias', 'decoder.layers.7.self_attn.k_proj.weight', 'decoder.layers.7.self_attn.o_proj.bias', 'decoder.layers.7.self_attn.o_proj.weight', 'decoder.layers.7.self_attn.q_proj.bias', 'decoder.layers.7.self_attn.q_proj.weight', 'decoder.layers.7.self_attn.scaling', 'decoder.layers.7.self_attn.v_proj.bias', 'decoder.layers.7.self_attn.v_proj.weight', 'decoder.layers.8.input_layernorm.weight', 'decoder.layers.8.mlp.down_proj.bias', 'decoder.layers.8.mlp.down_proj.weight', 'decoder.layers.8.mlp.gate_proj.bias', 'decoder.layers.8.mlp.gate_proj.weight', 'decoder.layers.8.mlp.layer_norm.bias', 'decoder.layers.8.mlp.layer_norm.weight', 'decoder.layers.8.self_attn.k_proj.bias', 'decoder.layers.8.self_attn.k_proj.weight', 'decoder.layers.8.self_attn.o_proj.bias', 'decoder.layers.8.self_attn.o_proj.weight', 'decoder.layers.8.self_attn.q_proj.bias', 'decoder.layers.8.self_attn.q_proj.weight', 'decoder.layers.8.self_attn.scaling', 'decoder.layers.8.self_attn.v_proj.bias', 'decoder.layers.8.self_attn.v_proj.weight', 'decoder.layers.9.input_layernorm.weight', 'decoder.layers.9.mlp.down_proj.bias', 'decoder.layers.9.mlp.down_proj.weight', 'decoder.layers.9.mlp.gate_proj.bias', 'decoder.layers.9.mlp.gate_proj.weight', 'decoder.layers.9.mlp.layer_norm.bias', 'decoder.layers.9.mlp.layer_norm.weight', 'decoder.layers.9.self_attn.k_proj.bias', 'decoder.layers.9.self_attn.k_proj.weight', 'decoder.layers.9.self_attn.o_proj.bias', 'decoder.layers.9.self_attn.o_proj.weight', 'decoder.layers.9.self_attn.q_proj.bias', 'decoder.layers.9.self_attn.q_proj.weight', 'decoder.layers.9.self_attn.scaling', 'decoder.layers.9.self_attn.v_proj.bias', 'decoder.layers.9.self_attn.v_proj.weight', 'horizon_ff_layer.input_layer.bias', 'horizon_ff_layer.input_layer.weight', 'horizon_ff_layer.output_layer.bias', 'horizon_ff_layer.output_layer.weight', 'horizon_ff_layer.residual_layer.bias', 'horizon_ff_layer.residual_layer.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n",
            "  Epoch 1/100 train_loss=1.2423 train_acc=0.5657 eval_loss=0.2859 eval_acc=0.9086 (best)\n",
            "  Epoch 2/100 train_loss=0.1152 train_acc=0.9771 eval_loss=0.1037 eval_acc=0.9543 (best)\n",
            "  Epoch 3/100 train_loss=0.0239 train_acc=0.9943 eval_loss=0.0722 eval_acc=0.9829 (best)\n",
            "  Epoch 4/100 train_loss=0.0093 train_acc=1.0000 eval_loss=0.0186 eval_acc=1.0000 (best)\n",
            "  Epoch 5/100 train_loss=0.0361 train_acc=0.9943 eval_loss=0.1741 eval_acc=0.9371 \n",
            "  Epoch 6/100 train_loss=0.0072 train_acc=0.9943 eval_loss=0.0823 eval_acc=0.9657 \n",
            "  Epoch 7/100 train_loss=0.0030 train_acc=1.0000 eval_loss=0.2317 eval_acc=0.9543 \n",
            "  Epoch 8/100 train_loss=0.0024 train_acc=1.0000 eval_loss=0.2995 eval_acc=0.9543 \n",
            "  Epoch 9/100 train_loss=0.0005 train_acc=1.0000 eval_loss=0.2789 eval_acc=0.9429 \n",
            "  Epoch 10/100 train_loss=0.0005 train_acc=1.0000 eval_loss=0.2193 eval_acc=0.9371 \n",
            "  Epoch 11/100 train_loss=0.0002 train_acc=1.0000 eval_loss=0.1417 eval_acc=0.9486 \n",
            "  Epoch 12/100 train_loss=0.0001 train_acc=1.0000 eval_loss=0.0887 eval_acc=0.9657 \n",
            "  Epoch 13/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0732 eval_acc=0.9829 \n",
            "  Epoch 14/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0677 eval_acc=0.9829 \n",
            "  Early stopping on google/timesfm-2.5-200m-pytorch: no improvement for 10 epochs (best epoch = 4)\n",
            "    tfm[google/timesfm-2.5-200m-pytorch] train_acc=1.0000 eval_acc=0.98285714285714287363759922300232574343681335\n",
            "    mrh_acc=0.9943 mr+h+kg_acc=1.0000 kg_acc=1.0000 ensemble=1.0000 (w=0.60)\n",
            "  Split 1/1 - accuracy=1.0000 time=153.6s\n",
            "Completed Fish: Mean Acc=1.0000\n",
            "\n",
            "=== 36/109 FordA ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  Decision: Heuristic says no filter (clean signal (no filtering))\n",
            "Error processing FordA: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n",
            "\n",
            "=== 37/109 FordB ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 556, in main\n",
            "    results = evaluate_dataset_per_split(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 429, in evaluate_dataset_per_split\n",
            "    X_train_extra = np.concatenate([X_train_all, all_dec_train], axis=1)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "ValueError: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Split 1/1 ---\n",
            "  Decision: Heuristic says no filter (clean signal (no filtering))\n",
            "Error processing FordB: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n",
            "\n",
            "=== 38/109 FreezerRegularTrain ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 556, in main\n",
            "    results = evaluate_dataset_per_split(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 429, in evaluate_dataset_per_split\n",
            "    X_train_extra = np.concatenate([X_train_all, all_dec_train], axis=1)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "ValueError: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n",
            "    Gate split 1/5: baseline_loss=0.1329 adaptive_loss=0.1883\n",
            "    Gate split 2/5: baseline_loss=0.1275 adaptive_loss=0.0903\n",
            "    Gate split 3/5: baseline_loss=0.1817 adaptive_loss=0.1512\n",
            "    Gate split 4/5: baseline_loss=0.1639 adaptive_loss=0.1341\n",
            "    Gate split 5/5: baseline_loss=0.1641 adaptive_loss=0.1353\n",
            "  Decision: Adaptive kept (loss 0.1398 vs baseline 0.1540, delta=-0.0142 <= +0.0200); savgol(window=11, poly=2) - high noise (std_diff)\n",
            "Error processing FreezerRegularTrain: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n",
            "\n",
            "=== 39/109 FreezerSmallTrain ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 556, in main\n",
            "    results = evaluate_dataset_per_split(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 429, in evaluate_dataset_per_split\n",
            "    X_train_extra = np.concatenate([X_train_all, all_dec_train], axis=1)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "ValueError: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n",
            "    Gate split 1/5: baseline_loss=0.1958 adaptive_loss=0.2214\n",
            "    Gate split 2/5: baseline_loss=0.2261 adaptive_loss=0.2039\n",
            "    Gate split 3/5: baseline_loss=0.2672 adaptive_loss=0.2151\n",
            "    Gate split 4/5: baseline_loss=0.2863 adaptive_loss=0.3135\n",
            "    Gate split 5/5: baseline_loss=0.2190 adaptive_loss=0.1529\n",
            "  Decision: Adaptive kept (loss 0.2214 vs baseline 0.2389, delta=-0.0175 <= +0.0200); savgol(window=11, poly=2) - high noise (std_diff)\n",
            "Error processing FreezerSmallTrain: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n",
            "\n",
            "=== 40/109 GunPoint ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 556, in main\n",
            "    results = evaluate_dataset_per_split(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 429, in evaluate_dataset_per_split\n",
            "    X_train_extra = np.concatenate([X_train_all, all_dec_train], axis=1)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "ValueError: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Gate split 1/5: baseline_loss=0.2006 adaptive_loss=0.2130\n",
            "    Gate split 2/5: baseline_loss=0.2555 adaptive_loss=0.2259\n",
            "    Gate split 3/5: baseline_loss=0.1676 adaptive_loss=0.1558\n",
            "    Gate split 4/5: baseline_loss=0.1119 adaptive_loss=0.1116\n",
            "    Gate split 5/5: baseline_loss=0.1483 adaptive_loss=0.1429\n",
            "  Decision: Adaptive kept (loss 0.1698 vs baseline 0.1768, delta=-0.0070 <= +0.0200); savgol(window=7, poly=2) - high noise (std_diff)\n",
            "Error processing GunPoint: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n",
            "\n",
            "=== 41/109 GunPointAgeSpan ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 556, in main\n",
            "    results = evaluate_dataset_per_split(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 429, in evaluate_dataset_per_split\n",
            "    X_train_extra = np.concatenate([X_train_all, all_dec_train], axis=1)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "ValueError: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Gate split 1/5: baseline_loss=0.3300 adaptive_loss=0.3336\n",
            "    Gate split 2/5: baseline_loss=0.3172 adaptive_loss=0.2989\n",
            "    Gate split 3/5: baseline_loss=0.1868 adaptive_loss=0.1861\n",
            "    Gate split 4/5: baseline_loss=0.2366 adaptive_loss=0.2378\n",
            "    Gate split 5/5: baseline_loss=0.1829 adaptive_loss=0.2151\n",
            "  Decision: Adaptive kept (loss 0.2543 vs baseline 0.2507, delta=+0.0036 <= +0.0200); savgol(window=7, poly=2) - high noise (std_diff)\n",
            "Error processing GunPointAgeSpan: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n",
            "\n",
            "=== 42/109 GunPointMaleVersusFemale ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 556, in main\n",
            "    results = evaluate_dataset_per_split(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 429, in evaluate_dataset_per_split\n",
            "    X_train_extra = np.concatenate([X_train_all, all_dec_train], axis=1)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "ValueError: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Gate split 1/5: baseline_loss=0.1739 adaptive_loss=0.1795\n",
            "    Gate split 2/5: baseline_loss=0.1548 adaptive_loss=0.1564\n",
            "    Gate split 3/5: baseline_loss=0.1083 adaptive_loss=0.1081\n",
            "    Gate split 4/5: baseline_loss=0.2141 adaptive_loss=0.2064\n",
            "    Gate split 5/5: baseline_loss=0.1420 adaptive_loss=0.1301\n",
            "  Decision: Adaptive kept (loss 0.1561 vs baseline 0.1586, delta=-0.0025 <= +0.0200); savgol(window=7, poly=2) - high noise (std_diff)\n",
            "Error processing GunPointMaleVersusFemale: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n",
            "\n",
            "=== 43/109 GunPointOldVersusYoung ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 556, in main\n",
            "    results = evaluate_dataset_per_split(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 429, in evaluate_dataset_per_split\n",
            "    X_train_extra = np.concatenate([X_train_all, all_dec_train], axis=1)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "ValueError: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Gate split 1/5: baseline_loss=0.0355 adaptive_loss=0.0337\n",
            "    Gate split 2/5: baseline_loss=0.0391 adaptive_loss=0.0456\n",
            "    Gate split 3/5: baseline_loss=0.0422 adaptive_loss=0.0392\n",
            "    Gate split 4/5: baseline_loss=0.0563 adaptive_loss=0.0564\n",
            "    Gate split 5/5: baseline_loss=0.0173 adaptive_loss=0.0218\n",
            "  Decision: Adaptive kept (loss 0.0393 vs baseline 0.0381, delta=+0.0012 <= +0.0200); savgol(window=7, poly=2) - high noise (std_diff)\n",
            "Error processing GunPointOldVersusYoung: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n",
            "\n",
            "=== 44/109 Ham ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 556, in main\n",
            "    results = evaluate_dataset_per_split(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 429, in evaluate_dataset_per_split\n",
            "    X_train_extra = np.concatenate([X_train_all, all_dec_train], axis=1)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "ValueError: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Gate split 1/5: baseline_loss=0.9237 adaptive_loss=0.8771\n",
            "    Gate split 2/5: baseline_loss=0.9379 adaptive_loss=0.9314\n",
            "    Gate split 3/5: baseline_loss=0.6687 adaptive_loss=0.6461\n",
            "    Gate split 4/5: baseline_loss=0.7584 adaptive_loss=0.7706\n",
            "    Gate split 5/5: baseline_loss=0.7188 adaptive_loss=0.7259\n",
            "  Decision: Adaptive kept (loss 0.7902 vs baseline 0.8015, delta=-0.0113 <= +0.0200); savgol(window=11, poly=2) - high noise (std_diff)\n",
            "Error processing Ham: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n",
            "\n",
            "=== 45/109 Haptics ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 556, in main\n",
            "    results = evaluate_dataset_per_split(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 429, in evaluate_dataset_per_split\n",
            "    X_train_extra = np.concatenate([X_train_all, all_dec_train], axis=1)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "ValueError: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n",
            "    Gate split 1/5: baseline_loss=0.9177 adaptive_loss=0.7880\n",
            "    Gate split 2/5: baseline_loss=0.8702 adaptive_loss=0.7983\n",
            "    Gate split 3/5: baseline_loss=1.0483 adaptive_loss=0.9723\n",
            "    Gate split 4/5: baseline_loss=1.0214 adaptive_loss=0.9134\n",
            "    Gate split 5/5: baseline_loss=0.8981 adaptive_loss=0.8436\n",
            "  Decision: Adaptive kept (loss 0.8631 vs baseline 0.9511, delta=-0.0880 <= +0.0200); savgol(window=21, poly=3) - high noise (std_diff)\n",
            "\n",
            "=== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at google/timesfm-2.5-200m-pytorch were not used when initializing TimesFmModelForPrediction: ['output_projection_point.hidden_layer.weight', 'output_projection_point.output_layer.weight', 'output_projection_point.residual_layer.weight', 'output_projection_quantiles.hidden_layer.weight', 'output_projection_quantiles.output_layer.weight', 'output_projection_quantiles.residual_layer.weight', 'stacked_xf.0.attn.key_ln.scale', 'stacked_xf.0.attn.out.weight', 'stacked_xf.0.attn.per_dim_scale.per_dim_scale', 'stacked_xf.0.attn.qkv_proj.weight', 'stacked_xf.0.attn.query_ln.scale', 'stacked_xf.0.ff0.weight', 'stacked_xf.0.ff1.weight', 'stacked_xf.0.post_attn_ln.scale', 'stacked_xf.0.post_ff_ln.scale', 'stacked_xf.0.pre_attn_ln.scale', 'stacked_xf.0.pre_ff_ln.scale', 'stacked_xf.1.attn.key_ln.scale', 'stacked_xf.1.attn.out.weight', 'stacked_xf.1.attn.per_dim_scale.per_dim_scale', 'stacked_xf.1.attn.qkv_proj.weight', 'stacked_xf.1.attn.query_ln.scale', 'stacked_xf.1.ff0.weight', 'stacked_xf.1.ff1.weight', 'stacked_xf.1.post_attn_ln.scale', 'stacked_xf.1.post_ff_ln.scale', 'stacked_xf.1.pre_attn_ln.scale', 'stacked_xf.1.pre_ff_ln.scale', 'stacked_xf.10.attn.key_ln.scale', 'stacked_xf.10.attn.out.weight', 'stacked_xf.10.attn.per_dim_scale.per_dim_scale', 'stacked_xf.10.attn.qkv_proj.weight', 'stacked_xf.10.attn.query_ln.scale', 'stacked_xf.10.ff0.weight', 'stacked_xf.10.ff1.weight', 'stacked_xf.10.post_attn_ln.scale', 'stacked_xf.10.post_ff_ln.scale', 'stacked_xf.10.pre_attn_ln.scale', 'stacked_xf.10.pre_ff_ln.scale', 'stacked_xf.11.attn.key_ln.scale', 'stacked_xf.11.attn.out.weight', 'stacked_xf.11.attn.per_dim_scale.per_dim_scale', 'stacked_xf.11.attn.qkv_proj.weight', 'stacked_xf.11.attn.query_ln.scale', 'stacked_xf.11.ff0.weight', 'stacked_xf.11.ff1.weight', 'stacked_xf.11.post_attn_ln.scale', 'stacked_xf.11.post_ff_ln.scale', 'stacked_xf.11.pre_attn_ln.scale', 'stacked_xf.11.pre_ff_ln.scale', 'stacked_xf.12.attn.key_ln.scale', 'stacked_xf.12.attn.out.weight', 'stacked_xf.12.attn.per_dim_scale.per_dim_scale', 'stacked_xf.12.attn.qkv_proj.weight', 'stacked_xf.12.attn.query_ln.scale', 'stacked_xf.12.ff0.weight', 'stacked_xf.12.ff1.weight', 'stacked_xf.12.post_attn_ln.scale', 'stacked_xf.12.post_ff_ln.scale', 'stacked_xf.12.pre_attn_ln.scale', 'stacked_xf.12.pre_ff_ln.scale', 'stacked_xf.13.attn.key_ln.scale', 'stacked_xf.13.attn.out.weight', 'stacked_xf.13.attn.per_dim_scale.per_dim_scale', 'stacked_xf.13.attn.qkv_proj.weight', 'stacked_xf.13.attn.query_ln.scale', 'stacked_xf.13.ff0.weight', 'stacked_xf.13.ff1.weight', 'stacked_xf.13.post_attn_ln.scale', 'stacked_xf.13.post_ff_ln.scale', 'stacked_xf.13.pre_attn_ln.scale', 'stacked_xf.13.pre_ff_ln.scale', 'stacked_xf.14.attn.key_ln.scale', 'stacked_xf.14.attn.out.weight', 'stacked_xf.14.attn.per_dim_scale.per_dim_scale', 'stacked_xf.14.attn.qkv_proj.weight', 'stacked_xf.14.attn.query_ln.scale', 'stacked_xf.14.ff0.weight', 'stacked_xf.14.ff1.weight', 'stacked_xf.14.post_attn_ln.scale', 'stacked_xf.14.post_ff_ln.scale', 'stacked_xf.14.pre_attn_ln.scale', 'stacked_xf.14.pre_ff_ln.scale', 'stacked_xf.15.attn.key_ln.scale', 'stacked_xf.15.attn.out.weight', 'stacked_xf.15.attn.per_dim_scale.per_dim_scale', 'stacked_xf.15.attn.qkv_proj.weight', 'stacked_xf.15.attn.query_ln.scale', 'stacked_xf.15.ff0.weight', 'stacked_xf.15.ff1.weight', 'stacked_xf.15.post_attn_ln.scale', 'stacked_xf.15.post_ff_ln.scale', 'stacked_xf.15.pre_attn_ln.scale', 'stacked_xf.15.pre_ff_ln.scale', 'stacked_xf.16.attn.key_ln.scale', 'stacked_xf.16.attn.out.weight', 'stacked_xf.16.attn.per_dim_scale.per_dim_scale', 'stacked_xf.16.attn.qkv_proj.weight', 'stacked_xf.16.attn.query_ln.scale', 'stacked_xf.16.ff0.weight', 'stacked_xf.16.ff1.weight', 'stacked_xf.16.post_attn_ln.scale', 'stacked_xf.16.post_ff_ln.scale', 'stacked_xf.16.pre_attn_ln.scale', 'stacked_xf.16.pre_ff_ln.scale', 'stacked_xf.17.attn.key_ln.scale', 'stacked_xf.17.attn.out.weight', 'stacked_xf.17.attn.per_dim_scale.per_dim_scale', 'stacked_xf.17.attn.qkv_proj.weight', 'stacked_xf.17.attn.query_ln.scale', 'stacked_xf.17.ff0.weight', 'stacked_xf.17.ff1.weight', 'stacked_xf.17.post_attn_ln.scale', 'stacked_xf.17.post_ff_ln.scale', 'stacked_xf.17.pre_attn_ln.scale', 'stacked_xf.17.pre_ff_ln.scale', 'stacked_xf.18.attn.key_ln.scale', 'stacked_xf.18.attn.out.weight', 'stacked_xf.18.attn.per_dim_scale.per_dim_scale', 'stacked_xf.18.attn.qkv_proj.weight', 'stacked_xf.18.attn.query_ln.scale', 'stacked_xf.18.ff0.weight', 'stacked_xf.18.ff1.weight', 'stacked_xf.18.post_attn_ln.scale', 'stacked_xf.18.post_ff_ln.scale', 'stacked_xf.18.pre_attn_ln.scale', 'stacked_xf.18.pre_ff_ln.scale', 'stacked_xf.19.attn.key_ln.scale', 'stacked_xf.19.attn.out.weight', 'stacked_xf.19.attn.per_dim_scale.per_dim_scale', 'stacked_xf.19.attn.qkv_proj.weight', 'stacked_xf.19.attn.query_ln.scale', 'stacked_xf.19.ff0.weight', 'stacked_xf.19.ff1.weight', 'stacked_xf.19.post_attn_ln.scale', 'stacked_xf.19.post_ff_ln.scale', 'stacked_xf.19.pre_attn_ln.scale', 'stacked_xf.19.pre_ff_ln.scale', 'stacked_xf.2.attn.key_ln.scale', 'stacked_xf.2.attn.out.weight', 'stacked_xf.2.attn.per_dim_scale.per_dim_scale', 'stacked_xf.2.attn.qkv_proj.weight', 'stacked_xf.2.attn.query_ln.scale', 'stacked_xf.2.ff0.weight', 'stacked_xf.2.ff1.weight', 'stacked_xf.2.post_attn_ln.scale', 'stacked_xf.2.post_ff_ln.scale', 'stacked_xf.2.pre_attn_ln.scale', 'stacked_xf.2.pre_ff_ln.scale', 'stacked_xf.3.attn.key_ln.scale', 'stacked_xf.3.attn.out.weight', 'stacked_xf.3.attn.per_dim_scale.per_dim_scale', 'stacked_xf.3.attn.qkv_proj.weight', 'stacked_xf.3.attn.query_ln.scale', 'stacked_xf.3.ff0.weight', 'stacked_xf.3.ff1.weight', 'stacked_xf.3.post_attn_ln.scale', 'stacked_xf.3.post_ff_ln.scale', 'stacked_xf.3.pre_attn_ln.scale', 'stacked_xf.3.pre_ff_ln.scale', 'stacked_xf.4.attn.key_ln.scale', 'stacked_xf.4.attn.out.weight', 'stacked_xf.4.attn.per_dim_scale.per_dim_scale', 'stacked_xf.4.attn.qkv_proj.weight', 'stacked_xf.4.attn.query_ln.scale', 'stacked_xf.4.ff0.weight', 'stacked_xf.4.ff1.weight', 'stacked_xf.4.post_attn_ln.scale', 'stacked_xf.4.post_ff_ln.scale', 'stacked_xf.4.pre_attn_ln.scale', 'stacked_xf.4.pre_ff_ln.scale', 'stacked_xf.5.attn.key_ln.scale', 'stacked_xf.5.attn.out.weight', 'stacked_xf.5.attn.per_dim_scale.per_dim_scale', 'stacked_xf.5.attn.qkv_proj.weight', 'stacked_xf.5.attn.query_ln.scale', 'stacked_xf.5.ff0.weight', 'stacked_xf.5.ff1.weight', 'stacked_xf.5.post_attn_ln.scale', 'stacked_xf.5.post_ff_ln.scale', 'stacked_xf.5.pre_attn_ln.scale', 'stacked_xf.5.pre_ff_ln.scale', 'stacked_xf.6.attn.key_ln.scale', 'stacked_xf.6.attn.out.weight', 'stacked_xf.6.attn.per_dim_scale.per_dim_scale', 'stacked_xf.6.attn.qkv_proj.weight', 'stacked_xf.6.attn.query_ln.scale', 'stacked_xf.6.ff0.weight', 'stacked_xf.6.ff1.weight', 'stacked_xf.6.post_attn_ln.scale', 'stacked_xf.6.post_ff_ln.scale', 'stacked_xf.6.pre_attn_ln.scale', 'stacked_xf.6.pre_ff_ln.scale', 'stacked_xf.7.attn.key_ln.scale', 'stacked_xf.7.attn.out.weight', 'stacked_xf.7.attn.per_dim_scale.per_dim_scale', 'stacked_xf.7.attn.qkv_proj.weight', 'stacked_xf.7.attn.query_ln.scale', 'stacked_xf.7.ff0.weight', 'stacked_xf.7.ff1.weight', 'stacked_xf.7.post_attn_ln.scale', 'stacked_xf.7.post_ff_ln.scale', 'stacked_xf.7.pre_attn_ln.scale', 'stacked_xf.7.pre_ff_ln.scale', 'stacked_xf.8.attn.key_ln.scale', 'stacked_xf.8.attn.out.weight', 'stacked_xf.8.attn.per_dim_scale.per_dim_scale', 'stacked_xf.8.attn.qkv_proj.weight', 'stacked_xf.8.attn.query_ln.scale', 'stacked_xf.8.ff0.weight', 'stacked_xf.8.ff1.weight', 'stacked_xf.8.post_attn_ln.scale', 'stacked_xf.8.post_ff_ln.scale', 'stacked_xf.8.pre_attn_ln.scale', 'stacked_xf.8.pre_ff_ln.scale', 'stacked_xf.9.attn.key_ln.scale', 'stacked_xf.9.attn.out.weight', 'stacked_xf.9.attn.per_dim_scale.per_dim_scale', 'stacked_xf.9.attn.qkv_proj.weight', 'stacked_xf.9.attn.query_ln.scale', 'stacked_xf.9.ff0.weight', 'stacked_xf.9.ff1.weight', 'stacked_xf.9.post_attn_ln.scale', 'stacked_xf.9.post_ff_ln.scale', 'stacked_xf.9.pre_attn_ln.scale', 'stacked_xf.9.pre_ff_ln.scale', 'tokenizer.hidden_layer.bias', 'tokenizer.hidden_layer.weight', 'tokenizer.output_layer.bias', 'tokenizer.output_layer.weight', 'tokenizer.residual_layer.bias', 'tokenizer.residual_layer.weight']\n",
            "- This IS expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of TimesFmModelForPrediction were not initialized from the model checkpoint at google/timesfm-2.5-200m-pytorch and are newly initialized: ['decoder.freq_emb.weight', 'decoder.input_ff_layer.input_layer.bias', 'decoder.input_ff_layer.input_layer.weight', 'decoder.input_ff_layer.output_layer.bias', 'decoder.input_ff_layer.output_layer.weight', 'decoder.input_ff_layer.residual_layer.bias', 'decoder.input_ff_layer.residual_layer.weight', 'decoder.layers.0.input_layernorm.weight', 'decoder.layers.0.mlp.down_proj.bias', 'decoder.layers.0.mlp.down_proj.weight', 'decoder.layers.0.mlp.gate_proj.bias', 'decoder.layers.0.mlp.gate_proj.weight', 'decoder.layers.0.mlp.layer_norm.bias', 'decoder.layers.0.mlp.layer_norm.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.o_proj.bias', 'decoder.layers.0.self_attn.o_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.scaling', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.1.input_layernorm.weight', 'decoder.layers.1.mlp.down_proj.bias', 'decoder.layers.1.mlp.down_proj.weight', 'decoder.layers.1.mlp.gate_proj.bias', 'decoder.layers.1.mlp.gate_proj.weight', 'decoder.layers.1.mlp.layer_norm.bias', 'decoder.layers.1.mlp.layer_norm.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.o_proj.bias', 'decoder.layers.1.self_attn.o_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.scaling', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.10.input_layernorm.weight', 'decoder.layers.10.mlp.down_proj.bias', 'decoder.layers.10.mlp.down_proj.weight', 'decoder.layers.10.mlp.gate_proj.bias', 'decoder.layers.10.mlp.gate_proj.weight', 'decoder.layers.10.mlp.layer_norm.bias', 'decoder.layers.10.mlp.layer_norm.weight', 'decoder.layers.10.self_attn.k_proj.bias', 'decoder.layers.10.self_attn.k_proj.weight', 'decoder.layers.10.self_attn.o_proj.bias', 'decoder.layers.10.self_attn.o_proj.weight', 'decoder.layers.10.self_attn.q_proj.bias', 'decoder.layers.10.self_attn.q_proj.weight', 'decoder.layers.10.self_attn.scaling', 'decoder.layers.10.self_attn.v_proj.bias', 'decoder.layers.10.self_attn.v_proj.weight', 'decoder.layers.11.input_layernorm.weight', 'decoder.layers.11.mlp.down_proj.bias', 'decoder.layers.11.mlp.down_proj.weight', 'decoder.layers.11.mlp.gate_proj.bias', 'decoder.layers.11.mlp.gate_proj.weight', 'decoder.layers.11.mlp.layer_norm.bias', 'decoder.layers.11.mlp.layer_norm.weight', 'decoder.layers.11.self_attn.k_proj.bias', 'decoder.layers.11.self_attn.k_proj.weight', 'decoder.layers.11.self_attn.o_proj.bias', 'decoder.layers.11.self_attn.o_proj.weight', 'decoder.layers.11.self_attn.q_proj.bias', 'decoder.layers.11.self_attn.q_proj.weight', 'decoder.layers.11.self_attn.scaling', 'decoder.layers.11.self_attn.v_proj.bias', 'decoder.layers.11.self_attn.v_proj.weight', 'decoder.layers.12.input_layernorm.weight', 'decoder.layers.12.mlp.down_proj.bias', 'decoder.layers.12.mlp.down_proj.weight', 'decoder.layers.12.mlp.gate_proj.bias', 'decoder.layers.12.mlp.gate_proj.weight', 'decoder.layers.12.mlp.layer_norm.bias', 'decoder.layers.12.mlp.layer_norm.weight', 'decoder.layers.12.self_attn.k_proj.bias', 'decoder.layers.12.self_attn.k_proj.weight', 'decoder.layers.12.self_attn.o_proj.bias', 'decoder.layers.12.self_attn.o_proj.weight', 'decoder.layers.12.self_attn.q_proj.bias', 'decoder.layers.12.self_attn.q_proj.weight', 'decoder.layers.12.self_attn.scaling', 'decoder.layers.12.self_attn.v_proj.bias', 'decoder.layers.12.self_attn.v_proj.weight', 'decoder.layers.13.input_layernorm.weight', 'decoder.layers.13.mlp.down_proj.bias', 'decoder.layers.13.mlp.down_proj.weight', 'decoder.layers.13.mlp.gate_proj.bias', 'decoder.layers.13.mlp.gate_proj.weight', 'decoder.layers.13.mlp.layer_norm.bias', 'decoder.layers.13.mlp.layer_norm.weight', 'decoder.layers.13.self_attn.k_proj.bias', 'decoder.layers.13.self_attn.k_proj.weight', 'decoder.layers.13.self_attn.o_proj.bias', 'decoder.layers.13.self_attn.o_proj.weight', 'decoder.layers.13.self_attn.q_proj.bias', 'decoder.layers.13.self_attn.q_proj.weight', 'decoder.layers.13.self_attn.scaling', 'decoder.layers.13.self_attn.v_proj.bias', 'decoder.layers.13.self_attn.v_proj.weight', 'decoder.layers.14.input_layernorm.weight', 'decoder.layers.14.mlp.down_proj.bias', 'decoder.layers.14.mlp.down_proj.weight', 'decoder.layers.14.mlp.gate_proj.bias', 'decoder.layers.14.mlp.gate_proj.weight', 'decoder.layers.14.mlp.layer_norm.bias', 'decoder.layers.14.mlp.layer_norm.weight', 'decoder.layers.14.self_attn.k_proj.bias', 'decoder.layers.14.self_attn.k_proj.weight', 'decoder.layers.14.self_attn.o_proj.bias', 'decoder.layers.14.self_attn.o_proj.weight', 'decoder.layers.14.self_attn.q_proj.bias', 'decoder.layers.14.self_attn.q_proj.weight', 'decoder.layers.14.self_attn.scaling', 'decoder.layers.14.self_attn.v_proj.bias', 'decoder.layers.14.self_attn.v_proj.weight', 'decoder.layers.15.input_layernorm.weight', 'decoder.layers.15.mlp.down_proj.bias', 'decoder.layers.15.mlp.down_proj.weight', 'decoder.layers.15.mlp.gate_proj.bias', 'decoder.layers.15.mlp.gate_proj.weight', 'decoder.layers.15.mlp.layer_norm.bias', 'decoder.layers.15.mlp.layer_norm.weight', 'decoder.layers.15.self_attn.k_proj.bias', 'decoder.layers.15.self_attn.k_proj.weight', 'decoder.layers.15.self_attn.o_proj.bias', 'decoder.layers.15.self_attn.o_proj.weight', 'decoder.layers.15.self_attn.q_proj.bias', 'decoder.layers.15.self_attn.q_proj.weight', 'decoder.layers.15.self_attn.scaling', 'decoder.layers.15.self_attn.v_proj.bias', 'decoder.layers.15.self_attn.v_proj.weight', 'decoder.layers.16.input_layernorm.weight', 'decoder.layers.16.mlp.down_proj.bias', 'decoder.layers.16.mlp.down_proj.weight', 'decoder.layers.16.mlp.gate_proj.bias', 'decoder.layers.16.mlp.gate_proj.weight', 'decoder.layers.16.mlp.layer_norm.bias', 'decoder.layers.16.mlp.layer_norm.weight', 'decoder.layers.16.self_attn.k_proj.bias', 'decoder.layers.16.self_attn.k_proj.weight', 'decoder.layers.16.self_attn.o_proj.bias', 'decoder.layers.16.self_attn.o_proj.weight', 'decoder.layers.16.self_attn.q_proj.bias', 'decoder.layers.16.self_attn.q_proj.weight', 'decoder.layers.16.self_attn.scaling', 'decoder.layers.16.self_attn.v_proj.bias', 'decoder.layers.16.self_attn.v_proj.weight', 'decoder.layers.17.input_layernorm.weight', 'decoder.layers.17.mlp.down_proj.bias', 'decoder.layers.17.mlp.down_proj.weight', 'decoder.layers.17.mlp.gate_proj.bias', 'decoder.layers.17.mlp.gate_proj.weight', 'decoder.layers.17.mlp.layer_norm.bias', 'decoder.layers.17.mlp.layer_norm.weight', 'decoder.layers.17.self_attn.k_proj.bias', 'decoder.layers.17.self_attn.k_proj.weight', 'decoder.layers.17.self_attn.o_proj.bias', 'decoder.layers.17.self_attn.o_proj.weight', 'decoder.layers.17.self_attn.q_proj.bias', 'decoder.layers.17.self_attn.q_proj.weight', 'decoder.layers.17.self_attn.scaling', 'decoder.layers.17.self_attn.v_proj.bias', 'decoder.layers.17.self_attn.v_proj.weight', 'decoder.layers.18.input_layernorm.weight', 'decoder.layers.18.mlp.down_proj.bias', 'decoder.layers.18.mlp.down_proj.weight', 'decoder.layers.18.mlp.gate_proj.bias', 'decoder.layers.18.mlp.gate_proj.weight', 'decoder.layers.18.mlp.layer_norm.bias', 'decoder.layers.18.mlp.layer_norm.weight', 'decoder.layers.18.self_attn.k_proj.bias', 'decoder.layers.18.self_attn.k_proj.weight', 'decoder.layers.18.self_attn.o_proj.bias', 'decoder.layers.18.self_attn.o_proj.weight', 'decoder.layers.18.self_attn.q_proj.bias', 'decoder.layers.18.self_attn.q_proj.weight', 'decoder.layers.18.self_attn.scaling', 'decoder.layers.18.self_attn.v_proj.bias', 'decoder.layers.18.self_attn.v_proj.weight', 'decoder.layers.19.input_layernorm.weight', 'decoder.layers.19.mlp.down_proj.bias', 'decoder.layers.19.mlp.down_proj.weight', 'decoder.layers.19.mlp.gate_proj.bias', 'decoder.layers.19.mlp.gate_proj.weight', 'decoder.layers.19.mlp.layer_norm.bias', 'decoder.layers.19.mlp.layer_norm.weight', 'decoder.layers.19.self_attn.k_proj.bias', 'decoder.layers.19.self_attn.k_proj.weight', 'decoder.layers.19.self_attn.o_proj.bias', 'decoder.layers.19.self_attn.o_proj.weight', 'decoder.layers.19.self_attn.q_proj.bias', 'decoder.layers.19.self_attn.q_proj.weight', 'decoder.layers.19.self_attn.scaling', 'decoder.layers.19.self_attn.v_proj.bias', 'decoder.layers.19.self_attn.v_proj.weight', 'decoder.layers.2.input_layernorm.weight', 'decoder.layers.2.mlp.down_proj.bias', 'decoder.layers.2.mlp.down_proj.weight', 'decoder.layers.2.mlp.gate_proj.bias', 'decoder.layers.2.mlp.gate_proj.weight', 'decoder.layers.2.mlp.layer_norm.bias', 'decoder.layers.2.mlp.layer_norm.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.o_proj.bias', 'decoder.layers.2.self_attn.o_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.scaling', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.3.input_layernorm.weight', 'decoder.layers.3.mlp.down_proj.bias', 'decoder.layers.3.mlp.down_proj.weight', 'decoder.layers.3.mlp.gate_proj.bias', 'decoder.layers.3.mlp.gate_proj.weight', 'decoder.layers.3.mlp.layer_norm.bias', 'decoder.layers.3.mlp.layer_norm.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.o_proj.bias', 'decoder.layers.3.self_attn.o_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.scaling', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.4.input_layernorm.weight', 'decoder.layers.4.mlp.down_proj.bias', 'decoder.layers.4.mlp.down_proj.weight', 'decoder.layers.4.mlp.gate_proj.bias', 'decoder.layers.4.mlp.gate_proj.weight', 'decoder.layers.4.mlp.layer_norm.bias', 'decoder.layers.4.mlp.layer_norm.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.o_proj.bias', 'decoder.layers.4.self_attn.o_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.scaling', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.5.input_layernorm.weight', 'decoder.layers.5.mlp.down_proj.bias', 'decoder.layers.5.mlp.down_proj.weight', 'decoder.layers.5.mlp.gate_proj.bias', 'decoder.layers.5.mlp.gate_proj.weight', 'decoder.layers.5.mlp.layer_norm.bias', 'decoder.layers.5.mlp.layer_norm.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.o_proj.bias', 'decoder.layers.5.self_attn.o_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.scaling', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.6.input_layernorm.weight', 'decoder.layers.6.mlp.down_proj.bias', 'decoder.layers.6.mlp.down_proj.weight', 'decoder.layers.6.mlp.gate_proj.bias', 'decoder.layers.6.mlp.gate_proj.weight', 'decoder.layers.6.mlp.layer_norm.bias', 'decoder.layers.6.mlp.layer_norm.weight', 'decoder.layers.6.self_attn.k_proj.bias', 'decoder.layers.6.self_attn.k_proj.weight', 'decoder.layers.6.self_attn.o_proj.bias', 'decoder.layers.6.self_attn.o_proj.weight', 'decoder.layers.6.self_attn.q_proj.bias', 'decoder.layers.6.self_attn.q_proj.weight', 'decoder.layers.6.self_attn.scaling', 'decoder.layers.6.self_attn.v_proj.bias', 'decoder.layers.6.self_attn.v_proj.weight', 'decoder.layers.7.input_layernorm.weight', 'decoder.layers.7.mlp.down_proj.bias', 'decoder.layers.7.mlp.down_proj.weight', 'decoder.layers.7.mlp.gate_proj.bias', 'decoder.layers.7.mlp.gate_proj.weight', 'decoder.layers.7.mlp.layer_norm.bias', 'decoder.layers.7.mlp.layer_norm.weight', 'decoder.layers.7.self_attn.k_proj.bias', 'decoder.layers.7.self_attn.k_proj.weight', 'decoder.layers.7.self_attn.o_proj.bias', 'decoder.layers.7.self_attn.o_proj.weight', 'decoder.layers.7.self_attn.q_proj.bias', 'decoder.layers.7.self_attn.q_proj.weight', 'decoder.layers.7.self_attn.scaling', 'decoder.layers.7.self_attn.v_proj.bias', 'decoder.layers.7.self_attn.v_proj.weight', 'decoder.layers.8.input_layernorm.weight', 'decoder.layers.8.mlp.down_proj.bias', 'decoder.layers.8.mlp.down_proj.weight', 'decoder.layers.8.mlp.gate_proj.bias', 'decoder.layers.8.mlp.gate_proj.weight', 'decoder.layers.8.mlp.layer_norm.bias', 'decoder.layers.8.mlp.layer_norm.weight', 'decoder.layers.8.self_attn.k_proj.bias', 'decoder.layers.8.self_attn.k_proj.weight', 'decoder.layers.8.self_attn.o_proj.bias', 'decoder.layers.8.self_attn.o_proj.weight', 'decoder.layers.8.self_attn.q_proj.bias', 'decoder.layers.8.self_attn.q_proj.weight', 'decoder.layers.8.self_attn.scaling', 'decoder.layers.8.self_attn.v_proj.bias', 'decoder.layers.8.self_attn.v_proj.weight', 'decoder.layers.9.input_layernorm.weight', 'decoder.layers.9.mlp.down_proj.bias', 'decoder.layers.9.mlp.down_proj.weight', 'decoder.layers.9.mlp.gate_proj.bias', 'decoder.layers.9.mlp.gate_proj.weight', 'decoder.layers.9.mlp.layer_norm.bias', 'decoder.layers.9.mlp.layer_norm.weight', 'decoder.layers.9.self_attn.k_proj.bias', 'decoder.layers.9.self_attn.k_proj.weight', 'decoder.layers.9.self_attn.o_proj.bias', 'decoder.layers.9.self_attn.o_proj.weight', 'decoder.layers.9.self_attn.q_proj.bias', 'decoder.layers.9.self_attn.q_proj.weight', 'decoder.layers.9.self_attn.scaling', 'decoder.layers.9.self_attn.v_proj.bias', 'decoder.layers.9.self_attn.v_proj.weight', 'horizon_ff_layer.input_layer.bias', 'horizon_ff_layer.input_layer.weight', 'horizon_ff_layer.output_layer.bias', 'horizon_ff_layer.output_layer.weight', 'horizon_ff_layer.residual_layer.bias', 'horizon_ff_layer.residual_layer.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n",
            "  Epoch 1/100 train_loss=1.4807 train_acc=0.3419 eval_loss=1.4284 eval_acc=0.5130 (best)\n",
            "  Epoch 2/100 train_loss=0.6836 train_acc=0.7548 eval_loss=1.3832 eval_acc=0.4805 (best)\n",
            "  Epoch 3/100 train_loss=0.3218 train_acc=0.9097 eval_loss=1.4248 eval_acc=0.5779 \n",
            "  Epoch 4/100 train_loss=0.1624 train_acc=0.9548 eval_loss=1.6166 eval_acc=0.6006 \n",
            "  Epoch 5/100 train_loss=0.0554 train_acc=0.9871 eval_loss=1.8817 eval_acc=0.5649 \n",
            "  Epoch 6/100 train_loss=0.0298 train_acc=0.9871 eval_loss=2.2431 eval_acc=0.5779 \n",
            "  Epoch 7/100 train_loss=0.0344 train_acc=0.9806 eval_loss=2.5728 eval_acc=0.5682 \n",
            "  Epoch 8/100 train_loss=0.0249 train_acc=0.9871 eval_loss=2.6196 eval_acc=0.5779 \n",
            "  Epoch 9/100 train_loss=0.0255 train_acc=0.9935 eval_loss=2.9672 eval_acc=0.5552 \n",
            "  Epoch 10/100 train_loss=0.0567 train_acc=0.9871 eval_loss=2.9228 eval_acc=0.5584 \n",
            "  Epoch 11/100 train_loss=0.0467 train_acc=0.9806 eval_loss=3.3059 eval_acc=0.5714 \n",
            "  Epoch 12/100 train_loss=0.0503 train_acc=0.9806 eval_loss=3.5866 eval_acc=0.5422 \n",
            "  Early stopping on google/timesfm-2.5-200m-pytorch: no improvement for 10 epochs (best epoch = 2)\n",
            "    tfm[google/timesfm-2.5-200m-pytorch] train_acc=0.7548 eval_acc=0.54220779220779224960580222614225931465625763\n",
            "    mrh_acc=0.6006 mr+h+kg_acc=0.6201 kg_acc=0.5974 ensemble=0.6136 (w=0.60)\n",
            "  Split 1/1 - accuracy=0.6136 time=171.1s\n",
            "Completed Haptics: Mean Acc=0.6136\n",
            "\n",
            "=== 46/109 Herring ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  Decision: Heuristic says no filter (clean signal (no filtering))\n",
            "Error processing Herring: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n",
            "\n",
            "=== 47/109 HouseTwenty ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 556, in main\n",
            "    results = evaluate_dataset_per_split(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 429, in evaluate_dataset_per_split\n",
            "    X_train_extra = np.concatenate([X_train_all, all_dec_train], axis=1)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "ValueError: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n",
            "    Gate split 1/5: baseline_loss=0.4150 adaptive_loss=0.4016\n",
            "    Gate split 2/5: baseline_loss=0.1897 adaptive_loss=0.1949\n",
            "    Gate split 3/5: baseline_loss=0.3199 adaptive_loss=0.3584\n",
            "    Gate split 4/5: baseline_loss=0.3334 adaptive_loss=0.3882\n",
            "    Gate split 5/5: baseline_loss=0.1802 adaptive_loss=0.1735\n",
            "  Decision: Adaptive kept (loss 0.3033 vs baseline 0.2876, delta=+0.0157 <= +0.0200); savgol(window=21, poly=3) - high noise (std_diff)\n",
            "Error processing HouseTwenty: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n",
            "\n",
            "=== 48/109 InlineSkate ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 556, in main\n",
            "    results = evaluate_dataset_per_split(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 429, in evaluate_dataset_per_split\n",
            "    X_train_extra = np.concatenate([X_train_all, all_dec_train], axis=1)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "ValueError: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n",
            "    Gate split 1/5: baseline_loss=1.2379 adaptive_loss=1.3740\n",
            "    Gate split 2/5: baseline_loss=0.9942 adaptive_loss=1.0697\n",
            "    Gate split 3/5: baseline_loss=0.9997 adaptive_loss=1.0569\n",
            "    Gate split 4/5: baseline_loss=1.0974 adaptive_loss=1.1410\n",
            "    Gate split 5/5: baseline_loss=0.9803 adaptive_loss=1.0531\n",
            "  Decision: Adaptive rejected (loss 1.1389 vs baseline 1.0619, delta=+0.0770 > +0.0200); savgol(window=21, poly=3) - high noise (std_diff)\n",
            "\n",
            "=== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at google/timesfm-2.5-200m-pytorch were not used when initializing TimesFmModelForPrediction: ['output_projection_point.hidden_layer.weight', 'output_projection_point.output_layer.weight', 'output_projection_point.residual_layer.weight', 'output_projection_quantiles.hidden_layer.weight', 'output_projection_quantiles.output_layer.weight', 'output_projection_quantiles.residual_layer.weight', 'stacked_xf.0.attn.key_ln.scale', 'stacked_xf.0.attn.out.weight', 'stacked_xf.0.attn.per_dim_scale.per_dim_scale', 'stacked_xf.0.attn.qkv_proj.weight', 'stacked_xf.0.attn.query_ln.scale', 'stacked_xf.0.ff0.weight', 'stacked_xf.0.ff1.weight', 'stacked_xf.0.post_attn_ln.scale', 'stacked_xf.0.post_ff_ln.scale', 'stacked_xf.0.pre_attn_ln.scale', 'stacked_xf.0.pre_ff_ln.scale', 'stacked_xf.1.attn.key_ln.scale', 'stacked_xf.1.attn.out.weight', 'stacked_xf.1.attn.per_dim_scale.per_dim_scale', 'stacked_xf.1.attn.qkv_proj.weight', 'stacked_xf.1.attn.query_ln.scale', 'stacked_xf.1.ff0.weight', 'stacked_xf.1.ff1.weight', 'stacked_xf.1.post_attn_ln.scale', 'stacked_xf.1.post_ff_ln.scale', 'stacked_xf.1.pre_attn_ln.scale', 'stacked_xf.1.pre_ff_ln.scale', 'stacked_xf.10.attn.key_ln.scale', 'stacked_xf.10.attn.out.weight', 'stacked_xf.10.attn.per_dim_scale.per_dim_scale', 'stacked_xf.10.attn.qkv_proj.weight', 'stacked_xf.10.attn.query_ln.scale', 'stacked_xf.10.ff0.weight', 'stacked_xf.10.ff1.weight', 'stacked_xf.10.post_attn_ln.scale', 'stacked_xf.10.post_ff_ln.scale', 'stacked_xf.10.pre_attn_ln.scale', 'stacked_xf.10.pre_ff_ln.scale', 'stacked_xf.11.attn.key_ln.scale', 'stacked_xf.11.attn.out.weight', 'stacked_xf.11.attn.per_dim_scale.per_dim_scale', 'stacked_xf.11.attn.qkv_proj.weight', 'stacked_xf.11.attn.query_ln.scale', 'stacked_xf.11.ff0.weight', 'stacked_xf.11.ff1.weight', 'stacked_xf.11.post_attn_ln.scale', 'stacked_xf.11.post_ff_ln.scale', 'stacked_xf.11.pre_attn_ln.scale', 'stacked_xf.11.pre_ff_ln.scale', 'stacked_xf.12.attn.key_ln.scale', 'stacked_xf.12.attn.out.weight', 'stacked_xf.12.attn.per_dim_scale.per_dim_scale', 'stacked_xf.12.attn.qkv_proj.weight', 'stacked_xf.12.attn.query_ln.scale', 'stacked_xf.12.ff0.weight', 'stacked_xf.12.ff1.weight', 'stacked_xf.12.post_attn_ln.scale', 'stacked_xf.12.post_ff_ln.scale', 'stacked_xf.12.pre_attn_ln.scale', 'stacked_xf.12.pre_ff_ln.scale', 'stacked_xf.13.attn.key_ln.scale', 'stacked_xf.13.attn.out.weight', 'stacked_xf.13.attn.per_dim_scale.per_dim_scale', 'stacked_xf.13.attn.qkv_proj.weight', 'stacked_xf.13.attn.query_ln.scale', 'stacked_xf.13.ff0.weight', 'stacked_xf.13.ff1.weight', 'stacked_xf.13.post_attn_ln.scale', 'stacked_xf.13.post_ff_ln.scale', 'stacked_xf.13.pre_attn_ln.scale', 'stacked_xf.13.pre_ff_ln.scale', 'stacked_xf.14.attn.key_ln.scale', 'stacked_xf.14.attn.out.weight', 'stacked_xf.14.attn.per_dim_scale.per_dim_scale', 'stacked_xf.14.attn.qkv_proj.weight', 'stacked_xf.14.attn.query_ln.scale', 'stacked_xf.14.ff0.weight', 'stacked_xf.14.ff1.weight', 'stacked_xf.14.post_attn_ln.scale', 'stacked_xf.14.post_ff_ln.scale', 'stacked_xf.14.pre_attn_ln.scale', 'stacked_xf.14.pre_ff_ln.scale', 'stacked_xf.15.attn.key_ln.scale', 'stacked_xf.15.attn.out.weight', 'stacked_xf.15.attn.per_dim_scale.per_dim_scale', 'stacked_xf.15.attn.qkv_proj.weight', 'stacked_xf.15.attn.query_ln.scale', 'stacked_xf.15.ff0.weight', 'stacked_xf.15.ff1.weight', 'stacked_xf.15.post_attn_ln.scale', 'stacked_xf.15.post_ff_ln.scale', 'stacked_xf.15.pre_attn_ln.scale', 'stacked_xf.15.pre_ff_ln.scale', 'stacked_xf.16.attn.key_ln.scale', 'stacked_xf.16.attn.out.weight', 'stacked_xf.16.attn.per_dim_scale.per_dim_scale', 'stacked_xf.16.attn.qkv_proj.weight', 'stacked_xf.16.attn.query_ln.scale', 'stacked_xf.16.ff0.weight', 'stacked_xf.16.ff1.weight', 'stacked_xf.16.post_attn_ln.scale', 'stacked_xf.16.post_ff_ln.scale', 'stacked_xf.16.pre_attn_ln.scale', 'stacked_xf.16.pre_ff_ln.scale', 'stacked_xf.17.attn.key_ln.scale', 'stacked_xf.17.attn.out.weight', 'stacked_xf.17.attn.per_dim_scale.per_dim_scale', 'stacked_xf.17.attn.qkv_proj.weight', 'stacked_xf.17.attn.query_ln.scale', 'stacked_xf.17.ff0.weight', 'stacked_xf.17.ff1.weight', 'stacked_xf.17.post_attn_ln.scale', 'stacked_xf.17.post_ff_ln.scale', 'stacked_xf.17.pre_attn_ln.scale', 'stacked_xf.17.pre_ff_ln.scale', 'stacked_xf.18.attn.key_ln.scale', 'stacked_xf.18.attn.out.weight', 'stacked_xf.18.attn.per_dim_scale.per_dim_scale', 'stacked_xf.18.attn.qkv_proj.weight', 'stacked_xf.18.attn.query_ln.scale', 'stacked_xf.18.ff0.weight', 'stacked_xf.18.ff1.weight', 'stacked_xf.18.post_attn_ln.scale', 'stacked_xf.18.post_ff_ln.scale', 'stacked_xf.18.pre_attn_ln.scale', 'stacked_xf.18.pre_ff_ln.scale', 'stacked_xf.19.attn.key_ln.scale', 'stacked_xf.19.attn.out.weight', 'stacked_xf.19.attn.per_dim_scale.per_dim_scale', 'stacked_xf.19.attn.qkv_proj.weight', 'stacked_xf.19.attn.query_ln.scale', 'stacked_xf.19.ff0.weight', 'stacked_xf.19.ff1.weight', 'stacked_xf.19.post_attn_ln.scale', 'stacked_xf.19.post_ff_ln.scale', 'stacked_xf.19.pre_attn_ln.scale', 'stacked_xf.19.pre_ff_ln.scale', 'stacked_xf.2.attn.key_ln.scale', 'stacked_xf.2.attn.out.weight', 'stacked_xf.2.attn.per_dim_scale.per_dim_scale', 'stacked_xf.2.attn.qkv_proj.weight', 'stacked_xf.2.attn.query_ln.scale', 'stacked_xf.2.ff0.weight', 'stacked_xf.2.ff1.weight', 'stacked_xf.2.post_attn_ln.scale', 'stacked_xf.2.post_ff_ln.scale', 'stacked_xf.2.pre_attn_ln.scale', 'stacked_xf.2.pre_ff_ln.scale', 'stacked_xf.3.attn.key_ln.scale', 'stacked_xf.3.attn.out.weight', 'stacked_xf.3.attn.per_dim_scale.per_dim_scale', 'stacked_xf.3.attn.qkv_proj.weight', 'stacked_xf.3.attn.query_ln.scale', 'stacked_xf.3.ff0.weight', 'stacked_xf.3.ff1.weight', 'stacked_xf.3.post_attn_ln.scale', 'stacked_xf.3.post_ff_ln.scale', 'stacked_xf.3.pre_attn_ln.scale', 'stacked_xf.3.pre_ff_ln.scale', 'stacked_xf.4.attn.key_ln.scale', 'stacked_xf.4.attn.out.weight', 'stacked_xf.4.attn.per_dim_scale.per_dim_scale', 'stacked_xf.4.attn.qkv_proj.weight', 'stacked_xf.4.attn.query_ln.scale', 'stacked_xf.4.ff0.weight', 'stacked_xf.4.ff1.weight', 'stacked_xf.4.post_attn_ln.scale', 'stacked_xf.4.post_ff_ln.scale', 'stacked_xf.4.pre_attn_ln.scale', 'stacked_xf.4.pre_ff_ln.scale', 'stacked_xf.5.attn.key_ln.scale', 'stacked_xf.5.attn.out.weight', 'stacked_xf.5.attn.per_dim_scale.per_dim_scale', 'stacked_xf.5.attn.qkv_proj.weight', 'stacked_xf.5.attn.query_ln.scale', 'stacked_xf.5.ff0.weight', 'stacked_xf.5.ff1.weight', 'stacked_xf.5.post_attn_ln.scale', 'stacked_xf.5.post_ff_ln.scale', 'stacked_xf.5.pre_attn_ln.scale', 'stacked_xf.5.pre_ff_ln.scale', 'stacked_xf.6.attn.key_ln.scale', 'stacked_xf.6.attn.out.weight', 'stacked_xf.6.attn.per_dim_scale.per_dim_scale', 'stacked_xf.6.attn.qkv_proj.weight', 'stacked_xf.6.attn.query_ln.scale', 'stacked_xf.6.ff0.weight', 'stacked_xf.6.ff1.weight', 'stacked_xf.6.post_attn_ln.scale', 'stacked_xf.6.post_ff_ln.scale', 'stacked_xf.6.pre_attn_ln.scale', 'stacked_xf.6.pre_ff_ln.scale', 'stacked_xf.7.attn.key_ln.scale', 'stacked_xf.7.attn.out.weight', 'stacked_xf.7.attn.per_dim_scale.per_dim_scale', 'stacked_xf.7.attn.qkv_proj.weight', 'stacked_xf.7.attn.query_ln.scale', 'stacked_xf.7.ff0.weight', 'stacked_xf.7.ff1.weight', 'stacked_xf.7.post_attn_ln.scale', 'stacked_xf.7.post_ff_ln.scale', 'stacked_xf.7.pre_attn_ln.scale', 'stacked_xf.7.pre_ff_ln.scale', 'stacked_xf.8.attn.key_ln.scale', 'stacked_xf.8.attn.out.weight', 'stacked_xf.8.attn.per_dim_scale.per_dim_scale', 'stacked_xf.8.attn.qkv_proj.weight', 'stacked_xf.8.attn.query_ln.scale', 'stacked_xf.8.ff0.weight', 'stacked_xf.8.ff1.weight', 'stacked_xf.8.post_attn_ln.scale', 'stacked_xf.8.post_ff_ln.scale', 'stacked_xf.8.pre_attn_ln.scale', 'stacked_xf.8.pre_ff_ln.scale', 'stacked_xf.9.attn.key_ln.scale', 'stacked_xf.9.attn.out.weight', 'stacked_xf.9.attn.per_dim_scale.per_dim_scale', 'stacked_xf.9.attn.qkv_proj.weight', 'stacked_xf.9.attn.query_ln.scale', 'stacked_xf.9.ff0.weight', 'stacked_xf.9.ff1.weight', 'stacked_xf.9.post_attn_ln.scale', 'stacked_xf.9.post_ff_ln.scale', 'stacked_xf.9.pre_attn_ln.scale', 'stacked_xf.9.pre_ff_ln.scale', 'tokenizer.hidden_layer.bias', 'tokenizer.hidden_layer.weight', 'tokenizer.output_layer.bias', 'tokenizer.output_layer.weight', 'tokenizer.residual_layer.bias', 'tokenizer.residual_layer.weight']\n",
            "- This IS expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of TimesFmModelForPrediction were not initialized from the model checkpoint at google/timesfm-2.5-200m-pytorch and are newly initialized: ['decoder.freq_emb.weight', 'decoder.input_ff_layer.input_layer.bias', 'decoder.input_ff_layer.input_layer.weight', 'decoder.input_ff_layer.output_layer.bias', 'decoder.input_ff_layer.output_layer.weight', 'decoder.input_ff_layer.residual_layer.bias', 'decoder.input_ff_layer.residual_layer.weight', 'decoder.layers.0.input_layernorm.weight', 'decoder.layers.0.mlp.down_proj.bias', 'decoder.layers.0.mlp.down_proj.weight', 'decoder.layers.0.mlp.gate_proj.bias', 'decoder.layers.0.mlp.gate_proj.weight', 'decoder.layers.0.mlp.layer_norm.bias', 'decoder.layers.0.mlp.layer_norm.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.o_proj.bias', 'decoder.layers.0.self_attn.o_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.scaling', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.1.input_layernorm.weight', 'decoder.layers.1.mlp.down_proj.bias', 'decoder.layers.1.mlp.down_proj.weight', 'decoder.layers.1.mlp.gate_proj.bias', 'decoder.layers.1.mlp.gate_proj.weight', 'decoder.layers.1.mlp.layer_norm.bias', 'decoder.layers.1.mlp.layer_norm.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.o_proj.bias', 'decoder.layers.1.self_attn.o_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.scaling', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.10.input_layernorm.weight', 'decoder.layers.10.mlp.down_proj.bias', 'decoder.layers.10.mlp.down_proj.weight', 'decoder.layers.10.mlp.gate_proj.bias', 'decoder.layers.10.mlp.gate_proj.weight', 'decoder.layers.10.mlp.layer_norm.bias', 'decoder.layers.10.mlp.layer_norm.weight', 'decoder.layers.10.self_attn.k_proj.bias', 'decoder.layers.10.self_attn.k_proj.weight', 'decoder.layers.10.self_attn.o_proj.bias', 'decoder.layers.10.self_attn.o_proj.weight', 'decoder.layers.10.self_attn.q_proj.bias', 'decoder.layers.10.self_attn.q_proj.weight', 'decoder.layers.10.self_attn.scaling', 'decoder.layers.10.self_attn.v_proj.bias', 'decoder.layers.10.self_attn.v_proj.weight', 'decoder.layers.11.input_layernorm.weight', 'decoder.layers.11.mlp.down_proj.bias', 'decoder.layers.11.mlp.down_proj.weight', 'decoder.layers.11.mlp.gate_proj.bias', 'decoder.layers.11.mlp.gate_proj.weight', 'decoder.layers.11.mlp.layer_norm.bias', 'decoder.layers.11.mlp.layer_norm.weight', 'decoder.layers.11.self_attn.k_proj.bias', 'decoder.layers.11.self_attn.k_proj.weight', 'decoder.layers.11.self_attn.o_proj.bias', 'decoder.layers.11.self_attn.o_proj.weight', 'decoder.layers.11.self_attn.q_proj.bias', 'decoder.layers.11.self_attn.q_proj.weight', 'decoder.layers.11.self_attn.scaling', 'decoder.layers.11.self_attn.v_proj.bias', 'decoder.layers.11.self_attn.v_proj.weight', 'decoder.layers.12.input_layernorm.weight', 'decoder.layers.12.mlp.down_proj.bias', 'decoder.layers.12.mlp.down_proj.weight', 'decoder.layers.12.mlp.gate_proj.bias', 'decoder.layers.12.mlp.gate_proj.weight', 'decoder.layers.12.mlp.layer_norm.bias', 'decoder.layers.12.mlp.layer_norm.weight', 'decoder.layers.12.self_attn.k_proj.bias', 'decoder.layers.12.self_attn.k_proj.weight', 'decoder.layers.12.self_attn.o_proj.bias', 'decoder.layers.12.self_attn.o_proj.weight', 'decoder.layers.12.self_attn.q_proj.bias', 'decoder.layers.12.self_attn.q_proj.weight', 'decoder.layers.12.self_attn.scaling', 'decoder.layers.12.self_attn.v_proj.bias', 'decoder.layers.12.self_attn.v_proj.weight', 'decoder.layers.13.input_layernorm.weight', 'decoder.layers.13.mlp.down_proj.bias', 'decoder.layers.13.mlp.down_proj.weight', 'decoder.layers.13.mlp.gate_proj.bias', 'decoder.layers.13.mlp.gate_proj.weight', 'decoder.layers.13.mlp.layer_norm.bias', 'decoder.layers.13.mlp.layer_norm.weight', 'decoder.layers.13.self_attn.k_proj.bias', 'decoder.layers.13.self_attn.k_proj.weight', 'decoder.layers.13.self_attn.o_proj.bias', 'decoder.layers.13.self_attn.o_proj.weight', 'decoder.layers.13.self_attn.q_proj.bias', 'decoder.layers.13.self_attn.q_proj.weight', 'decoder.layers.13.self_attn.scaling', 'decoder.layers.13.self_attn.v_proj.bias', 'decoder.layers.13.self_attn.v_proj.weight', 'decoder.layers.14.input_layernorm.weight', 'decoder.layers.14.mlp.down_proj.bias', 'decoder.layers.14.mlp.down_proj.weight', 'decoder.layers.14.mlp.gate_proj.bias', 'decoder.layers.14.mlp.gate_proj.weight', 'decoder.layers.14.mlp.layer_norm.bias', 'decoder.layers.14.mlp.layer_norm.weight', 'decoder.layers.14.self_attn.k_proj.bias', 'decoder.layers.14.self_attn.k_proj.weight', 'decoder.layers.14.self_attn.o_proj.bias', 'decoder.layers.14.self_attn.o_proj.weight', 'decoder.layers.14.self_attn.q_proj.bias', 'decoder.layers.14.self_attn.q_proj.weight', 'decoder.layers.14.self_attn.scaling', 'decoder.layers.14.self_attn.v_proj.bias', 'decoder.layers.14.self_attn.v_proj.weight', 'decoder.layers.15.input_layernorm.weight', 'decoder.layers.15.mlp.down_proj.bias', 'decoder.layers.15.mlp.down_proj.weight', 'decoder.layers.15.mlp.gate_proj.bias', 'decoder.layers.15.mlp.gate_proj.weight', 'decoder.layers.15.mlp.layer_norm.bias', 'decoder.layers.15.mlp.layer_norm.weight', 'decoder.layers.15.self_attn.k_proj.bias', 'decoder.layers.15.self_attn.k_proj.weight', 'decoder.layers.15.self_attn.o_proj.bias', 'decoder.layers.15.self_attn.o_proj.weight', 'decoder.layers.15.self_attn.q_proj.bias', 'decoder.layers.15.self_attn.q_proj.weight', 'decoder.layers.15.self_attn.scaling', 'decoder.layers.15.self_attn.v_proj.bias', 'decoder.layers.15.self_attn.v_proj.weight', 'decoder.layers.16.input_layernorm.weight', 'decoder.layers.16.mlp.down_proj.bias', 'decoder.layers.16.mlp.down_proj.weight', 'decoder.layers.16.mlp.gate_proj.bias', 'decoder.layers.16.mlp.gate_proj.weight', 'decoder.layers.16.mlp.layer_norm.bias', 'decoder.layers.16.mlp.layer_norm.weight', 'decoder.layers.16.self_attn.k_proj.bias', 'decoder.layers.16.self_attn.k_proj.weight', 'decoder.layers.16.self_attn.o_proj.bias', 'decoder.layers.16.self_attn.o_proj.weight', 'decoder.layers.16.self_attn.q_proj.bias', 'decoder.layers.16.self_attn.q_proj.weight', 'decoder.layers.16.self_attn.scaling', 'decoder.layers.16.self_attn.v_proj.bias', 'decoder.layers.16.self_attn.v_proj.weight', 'decoder.layers.17.input_layernorm.weight', 'decoder.layers.17.mlp.down_proj.bias', 'decoder.layers.17.mlp.down_proj.weight', 'decoder.layers.17.mlp.gate_proj.bias', 'decoder.layers.17.mlp.gate_proj.weight', 'decoder.layers.17.mlp.layer_norm.bias', 'decoder.layers.17.mlp.layer_norm.weight', 'decoder.layers.17.self_attn.k_proj.bias', 'decoder.layers.17.self_attn.k_proj.weight', 'decoder.layers.17.self_attn.o_proj.bias', 'decoder.layers.17.self_attn.o_proj.weight', 'decoder.layers.17.self_attn.q_proj.bias', 'decoder.layers.17.self_attn.q_proj.weight', 'decoder.layers.17.self_attn.scaling', 'decoder.layers.17.self_attn.v_proj.bias', 'decoder.layers.17.self_attn.v_proj.weight', 'decoder.layers.18.input_layernorm.weight', 'decoder.layers.18.mlp.down_proj.bias', 'decoder.layers.18.mlp.down_proj.weight', 'decoder.layers.18.mlp.gate_proj.bias', 'decoder.layers.18.mlp.gate_proj.weight', 'decoder.layers.18.mlp.layer_norm.bias', 'decoder.layers.18.mlp.layer_norm.weight', 'decoder.layers.18.self_attn.k_proj.bias', 'decoder.layers.18.self_attn.k_proj.weight', 'decoder.layers.18.self_attn.o_proj.bias', 'decoder.layers.18.self_attn.o_proj.weight', 'decoder.layers.18.self_attn.q_proj.bias', 'decoder.layers.18.self_attn.q_proj.weight', 'decoder.layers.18.self_attn.scaling', 'decoder.layers.18.self_attn.v_proj.bias', 'decoder.layers.18.self_attn.v_proj.weight', 'decoder.layers.19.input_layernorm.weight', 'decoder.layers.19.mlp.down_proj.bias', 'decoder.layers.19.mlp.down_proj.weight', 'decoder.layers.19.mlp.gate_proj.bias', 'decoder.layers.19.mlp.gate_proj.weight', 'decoder.layers.19.mlp.layer_norm.bias', 'decoder.layers.19.mlp.layer_norm.weight', 'decoder.layers.19.self_attn.k_proj.bias', 'decoder.layers.19.self_attn.k_proj.weight', 'decoder.layers.19.self_attn.o_proj.bias', 'decoder.layers.19.self_attn.o_proj.weight', 'decoder.layers.19.self_attn.q_proj.bias', 'decoder.layers.19.self_attn.q_proj.weight', 'decoder.layers.19.self_attn.scaling', 'decoder.layers.19.self_attn.v_proj.bias', 'decoder.layers.19.self_attn.v_proj.weight', 'decoder.layers.2.input_layernorm.weight', 'decoder.layers.2.mlp.down_proj.bias', 'decoder.layers.2.mlp.down_proj.weight', 'decoder.layers.2.mlp.gate_proj.bias', 'decoder.layers.2.mlp.gate_proj.weight', 'decoder.layers.2.mlp.layer_norm.bias', 'decoder.layers.2.mlp.layer_norm.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.o_proj.bias', 'decoder.layers.2.self_attn.o_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.scaling', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.3.input_layernorm.weight', 'decoder.layers.3.mlp.down_proj.bias', 'decoder.layers.3.mlp.down_proj.weight', 'decoder.layers.3.mlp.gate_proj.bias', 'decoder.layers.3.mlp.gate_proj.weight', 'decoder.layers.3.mlp.layer_norm.bias', 'decoder.layers.3.mlp.layer_norm.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.o_proj.bias', 'decoder.layers.3.self_attn.o_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.scaling', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.4.input_layernorm.weight', 'decoder.layers.4.mlp.down_proj.bias', 'decoder.layers.4.mlp.down_proj.weight', 'decoder.layers.4.mlp.gate_proj.bias', 'decoder.layers.4.mlp.gate_proj.weight', 'decoder.layers.4.mlp.layer_norm.bias', 'decoder.layers.4.mlp.layer_norm.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.o_proj.bias', 'decoder.layers.4.self_attn.o_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.scaling', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.5.input_layernorm.weight', 'decoder.layers.5.mlp.down_proj.bias', 'decoder.layers.5.mlp.down_proj.weight', 'decoder.layers.5.mlp.gate_proj.bias', 'decoder.layers.5.mlp.gate_proj.weight', 'decoder.layers.5.mlp.layer_norm.bias', 'decoder.layers.5.mlp.layer_norm.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.o_proj.bias', 'decoder.layers.5.self_attn.o_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.scaling', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.6.input_layernorm.weight', 'decoder.layers.6.mlp.down_proj.bias', 'decoder.layers.6.mlp.down_proj.weight', 'decoder.layers.6.mlp.gate_proj.bias', 'decoder.layers.6.mlp.gate_proj.weight', 'decoder.layers.6.mlp.layer_norm.bias', 'decoder.layers.6.mlp.layer_norm.weight', 'decoder.layers.6.self_attn.k_proj.bias', 'decoder.layers.6.self_attn.k_proj.weight', 'decoder.layers.6.self_attn.o_proj.bias', 'decoder.layers.6.self_attn.o_proj.weight', 'decoder.layers.6.self_attn.q_proj.bias', 'decoder.layers.6.self_attn.q_proj.weight', 'decoder.layers.6.self_attn.scaling', 'decoder.layers.6.self_attn.v_proj.bias', 'decoder.layers.6.self_attn.v_proj.weight', 'decoder.layers.7.input_layernorm.weight', 'decoder.layers.7.mlp.down_proj.bias', 'decoder.layers.7.mlp.down_proj.weight', 'decoder.layers.7.mlp.gate_proj.bias', 'decoder.layers.7.mlp.gate_proj.weight', 'decoder.layers.7.mlp.layer_norm.bias', 'decoder.layers.7.mlp.layer_norm.weight', 'decoder.layers.7.self_attn.k_proj.bias', 'decoder.layers.7.self_attn.k_proj.weight', 'decoder.layers.7.self_attn.o_proj.bias', 'decoder.layers.7.self_attn.o_proj.weight', 'decoder.layers.7.self_attn.q_proj.bias', 'decoder.layers.7.self_attn.q_proj.weight', 'decoder.layers.7.self_attn.scaling', 'decoder.layers.7.self_attn.v_proj.bias', 'decoder.layers.7.self_attn.v_proj.weight', 'decoder.layers.8.input_layernorm.weight', 'decoder.layers.8.mlp.down_proj.bias', 'decoder.layers.8.mlp.down_proj.weight', 'decoder.layers.8.mlp.gate_proj.bias', 'decoder.layers.8.mlp.gate_proj.weight', 'decoder.layers.8.mlp.layer_norm.bias', 'decoder.layers.8.mlp.layer_norm.weight', 'decoder.layers.8.self_attn.k_proj.bias', 'decoder.layers.8.self_attn.k_proj.weight', 'decoder.layers.8.self_attn.o_proj.bias', 'decoder.layers.8.self_attn.o_proj.weight', 'decoder.layers.8.self_attn.q_proj.bias', 'decoder.layers.8.self_attn.q_proj.weight', 'decoder.layers.8.self_attn.scaling', 'decoder.layers.8.self_attn.v_proj.bias', 'decoder.layers.8.self_attn.v_proj.weight', 'decoder.layers.9.input_layernorm.weight', 'decoder.layers.9.mlp.down_proj.bias', 'decoder.layers.9.mlp.down_proj.weight', 'decoder.layers.9.mlp.gate_proj.bias', 'decoder.layers.9.mlp.gate_proj.weight', 'decoder.layers.9.mlp.layer_norm.bias', 'decoder.layers.9.mlp.layer_norm.weight', 'decoder.layers.9.self_attn.k_proj.bias', 'decoder.layers.9.self_attn.k_proj.weight', 'decoder.layers.9.self_attn.o_proj.bias', 'decoder.layers.9.self_attn.o_proj.weight', 'decoder.layers.9.self_attn.q_proj.bias', 'decoder.layers.9.self_attn.q_proj.weight', 'decoder.layers.9.self_attn.scaling', 'decoder.layers.9.self_attn.v_proj.bias', 'decoder.layers.9.self_attn.v_proj.weight', 'horizon_ff_layer.input_layer.bias', 'horizon_ff_layer.input_layer.weight', 'horizon_ff_layer.output_layer.bias', 'horizon_ff_layer.output_layer.weight', 'horizon_ff_layer.residual_layer.bias', 'horizon_ff_layer.residual_layer.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n",
            "  Epoch 1/100 train_loss=1.8545 train_acc=0.2100 eval_loss=1.7895 eval_acc=0.3255 (best)\n",
            "  Epoch 2/100 train_loss=0.9909 train_acc=0.6100 eval_loss=1.5036 eval_acc=0.4364 (best)\n",
            "  Epoch 3/100 train_loss=0.4935 train_acc=0.9100 eval_loss=1.4754 eval_acc=0.4236 (best)\n",
            "  Epoch 4/100 train_loss=0.2778 train_acc=0.9400 eval_loss=1.4120 eval_acc=0.4782 (best)\n",
            "  Epoch 5/100 train_loss=0.1020 train_acc=0.9800 eval_loss=1.8488 eval_acc=0.4418 \n",
            "  Epoch 6/100 train_loss=0.1630 train_acc=0.9400 eval_loss=2.0866 eval_acc=0.4473 \n",
            "  Epoch 7/100 train_loss=0.1091 train_acc=0.9700 eval_loss=2.1695 eval_acc=0.4655 \n",
            "  Epoch 8/100 train_loss=0.0477 train_acc=0.9900 eval_loss=3.0930 eval_acc=0.4327 \n",
            "  Epoch 9/100 train_loss=0.0582 train_acc=0.9800 eval_loss=2.6580 eval_acc=0.4909 \n",
            "  Epoch 10/100 train_loss=0.2163 train_acc=0.9500 eval_loss=2.6354 eval_acc=0.4727 \n",
            "  Epoch 11/100 train_loss=0.0165 train_acc=1.0000 eval_loss=3.4636 eval_acc=0.4182 \n",
            "  Epoch 12/100 train_loss=0.0148 train_acc=1.0000 eval_loss=2.7389 eval_acc=0.5164 \n",
            "  Epoch 13/100 train_loss=0.0220 train_acc=0.9900 eval_loss=2.5924 eval_acc=0.4927 \n",
            "  Epoch 14/100 train_loss=0.0044 train_acc=1.0000 eval_loss=2.6921 eval_acc=0.4945 \n",
            "  Early stopping on google/timesfm-2.5-200m-pytorch: no improvement for 10 epochs (best epoch = 4)\n",
            "    tfm[google/timesfm-2.5-200m-pytorch] train_acc=0.9400 eval_acc=0.49454545454545456584227736129832919687032700\n",
            "    mrh_acc=0.5109 mr+h+kg_acc=0.5200 kg_acc=0.5091 ensemble=0.5182 (w=0.60)\n",
            "  Split 1/1 - accuracy=0.5182 time=232.8s\n",
            "Completed InlineSkate: Mean Acc=0.5182\n",
            "\n",
            "=== 49/109 InsectEPGRegularTrain ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n",
            "    Gate split 1/5: baseline_loss=0.0000 adaptive_loss=0.0000\n",
            "    Gate split 2/5: baseline_loss=0.0000 adaptive_loss=0.0000\n",
            "    Gate split 3/5: baseline_loss=0.0054 adaptive_loss=0.0679\n",
            "    Gate split 4/5: baseline_loss=0.0000 adaptive_loss=0.0126\n",
            "    Gate split 5/5: baseline_loss=0.0000 adaptive_loss=0.0000\n",
            "  Decision: Adaptive kept (loss 0.0161 vs baseline 0.0011, delta=+0.0150 <= +0.0200); savgol(window=15, poly=3) - high noise (std_diff)\n",
            "\n",
            "=== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at google/timesfm-2.5-200m-pytorch were not used when initializing TimesFmModelForPrediction: ['output_projection_point.hidden_layer.weight', 'output_projection_point.output_layer.weight', 'output_projection_point.residual_layer.weight', 'output_projection_quantiles.hidden_layer.weight', 'output_projection_quantiles.output_layer.weight', 'output_projection_quantiles.residual_layer.weight', 'stacked_xf.0.attn.key_ln.scale', 'stacked_xf.0.attn.out.weight', 'stacked_xf.0.attn.per_dim_scale.per_dim_scale', 'stacked_xf.0.attn.qkv_proj.weight', 'stacked_xf.0.attn.query_ln.scale', 'stacked_xf.0.ff0.weight', 'stacked_xf.0.ff1.weight', 'stacked_xf.0.post_attn_ln.scale', 'stacked_xf.0.post_ff_ln.scale', 'stacked_xf.0.pre_attn_ln.scale', 'stacked_xf.0.pre_ff_ln.scale', 'stacked_xf.1.attn.key_ln.scale', 'stacked_xf.1.attn.out.weight', 'stacked_xf.1.attn.per_dim_scale.per_dim_scale', 'stacked_xf.1.attn.qkv_proj.weight', 'stacked_xf.1.attn.query_ln.scale', 'stacked_xf.1.ff0.weight', 'stacked_xf.1.ff1.weight', 'stacked_xf.1.post_attn_ln.scale', 'stacked_xf.1.post_ff_ln.scale', 'stacked_xf.1.pre_attn_ln.scale', 'stacked_xf.1.pre_ff_ln.scale', 'stacked_xf.10.attn.key_ln.scale', 'stacked_xf.10.attn.out.weight', 'stacked_xf.10.attn.per_dim_scale.per_dim_scale', 'stacked_xf.10.attn.qkv_proj.weight', 'stacked_xf.10.attn.query_ln.scale', 'stacked_xf.10.ff0.weight', 'stacked_xf.10.ff1.weight', 'stacked_xf.10.post_attn_ln.scale', 'stacked_xf.10.post_ff_ln.scale', 'stacked_xf.10.pre_attn_ln.scale', 'stacked_xf.10.pre_ff_ln.scale', 'stacked_xf.11.attn.key_ln.scale', 'stacked_xf.11.attn.out.weight', 'stacked_xf.11.attn.per_dim_scale.per_dim_scale', 'stacked_xf.11.attn.qkv_proj.weight', 'stacked_xf.11.attn.query_ln.scale', 'stacked_xf.11.ff0.weight', 'stacked_xf.11.ff1.weight', 'stacked_xf.11.post_attn_ln.scale', 'stacked_xf.11.post_ff_ln.scale', 'stacked_xf.11.pre_attn_ln.scale', 'stacked_xf.11.pre_ff_ln.scale', 'stacked_xf.12.attn.key_ln.scale', 'stacked_xf.12.attn.out.weight', 'stacked_xf.12.attn.per_dim_scale.per_dim_scale', 'stacked_xf.12.attn.qkv_proj.weight', 'stacked_xf.12.attn.query_ln.scale', 'stacked_xf.12.ff0.weight', 'stacked_xf.12.ff1.weight', 'stacked_xf.12.post_attn_ln.scale', 'stacked_xf.12.post_ff_ln.scale', 'stacked_xf.12.pre_attn_ln.scale', 'stacked_xf.12.pre_ff_ln.scale', 'stacked_xf.13.attn.key_ln.scale', 'stacked_xf.13.attn.out.weight', 'stacked_xf.13.attn.per_dim_scale.per_dim_scale', 'stacked_xf.13.attn.qkv_proj.weight', 'stacked_xf.13.attn.query_ln.scale', 'stacked_xf.13.ff0.weight', 'stacked_xf.13.ff1.weight', 'stacked_xf.13.post_attn_ln.scale', 'stacked_xf.13.post_ff_ln.scale', 'stacked_xf.13.pre_attn_ln.scale', 'stacked_xf.13.pre_ff_ln.scale', 'stacked_xf.14.attn.key_ln.scale', 'stacked_xf.14.attn.out.weight', 'stacked_xf.14.attn.per_dim_scale.per_dim_scale', 'stacked_xf.14.attn.qkv_proj.weight', 'stacked_xf.14.attn.query_ln.scale', 'stacked_xf.14.ff0.weight', 'stacked_xf.14.ff1.weight', 'stacked_xf.14.post_attn_ln.scale', 'stacked_xf.14.post_ff_ln.scale', 'stacked_xf.14.pre_attn_ln.scale', 'stacked_xf.14.pre_ff_ln.scale', 'stacked_xf.15.attn.key_ln.scale', 'stacked_xf.15.attn.out.weight', 'stacked_xf.15.attn.per_dim_scale.per_dim_scale', 'stacked_xf.15.attn.qkv_proj.weight', 'stacked_xf.15.attn.query_ln.scale', 'stacked_xf.15.ff0.weight', 'stacked_xf.15.ff1.weight', 'stacked_xf.15.post_attn_ln.scale', 'stacked_xf.15.post_ff_ln.scale', 'stacked_xf.15.pre_attn_ln.scale', 'stacked_xf.15.pre_ff_ln.scale', 'stacked_xf.16.attn.key_ln.scale', 'stacked_xf.16.attn.out.weight', 'stacked_xf.16.attn.per_dim_scale.per_dim_scale', 'stacked_xf.16.attn.qkv_proj.weight', 'stacked_xf.16.attn.query_ln.scale', 'stacked_xf.16.ff0.weight', 'stacked_xf.16.ff1.weight', 'stacked_xf.16.post_attn_ln.scale', 'stacked_xf.16.post_ff_ln.scale', 'stacked_xf.16.pre_attn_ln.scale', 'stacked_xf.16.pre_ff_ln.scale', 'stacked_xf.17.attn.key_ln.scale', 'stacked_xf.17.attn.out.weight', 'stacked_xf.17.attn.per_dim_scale.per_dim_scale', 'stacked_xf.17.attn.qkv_proj.weight', 'stacked_xf.17.attn.query_ln.scale', 'stacked_xf.17.ff0.weight', 'stacked_xf.17.ff1.weight', 'stacked_xf.17.post_attn_ln.scale', 'stacked_xf.17.post_ff_ln.scale', 'stacked_xf.17.pre_attn_ln.scale', 'stacked_xf.17.pre_ff_ln.scale', 'stacked_xf.18.attn.key_ln.scale', 'stacked_xf.18.attn.out.weight', 'stacked_xf.18.attn.per_dim_scale.per_dim_scale', 'stacked_xf.18.attn.qkv_proj.weight', 'stacked_xf.18.attn.query_ln.scale', 'stacked_xf.18.ff0.weight', 'stacked_xf.18.ff1.weight', 'stacked_xf.18.post_attn_ln.scale', 'stacked_xf.18.post_ff_ln.scale', 'stacked_xf.18.pre_attn_ln.scale', 'stacked_xf.18.pre_ff_ln.scale', 'stacked_xf.19.attn.key_ln.scale', 'stacked_xf.19.attn.out.weight', 'stacked_xf.19.attn.per_dim_scale.per_dim_scale', 'stacked_xf.19.attn.qkv_proj.weight', 'stacked_xf.19.attn.query_ln.scale', 'stacked_xf.19.ff0.weight', 'stacked_xf.19.ff1.weight', 'stacked_xf.19.post_attn_ln.scale', 'stacked_xf.19.post_ff_ln.scale', 'stacked_xf.19.pre_attn_ln.scale', 'stacked_xf.19.pre_ff_ln.scale', 'stacked_xf.2.attn.key_ln.scale', 'stacked_xf.2.attn.out.weight', 'stacked_xf.2.attn.per_dim_scale.per_dim_scale', 'stacked_xf.2.attn.qkv_proj.weight', 'stacked_xf.2.attn.query_ln.scale', 'stacked_xf.2.ff0.weight', 'stacked_xf.2.ff1.weight', 'stacked_xf.2.post_attn_ln.scale', 'stacked_xf.2.post_ff_ln.scale', 'stacked_xf.2.pre_attn_ln.scale', 'stacked_xf.2.pre_ff_ln.scale', 'stacked_xf.3.attn.key_ln.scale', 'stacked_xf.3.attn.out.weight', 'stacked_xf.3.attn.per_dim_scale.per_dim_scale', 'stacked_xf.3.attn.qkv_proj.weight', 'stacked_xf.3.attn.query_ln.scale', 'stacked_xf.3.ff0.weight', 'stacked_xf.3.ff1.weight', 'stacked_xf.3.post_attn_ln.scale', 'stacked_xf.3.post_ff_ln.scale', 'stacked_xf.3.pre_attn_ln.scale', 'stacked_xf.3.pre_ff_ln.scale', 'stacked_xf.4.attn.key_ln.scale', 'stacked_xf.4.attn.out.weight', 'stacked_xf.4.attn.per_dim_scale.per_dim_scale', 'stacked_xf.4.attn.qkv_proj.weight', 'stacked_xf.4.attn.query_ln.scale', 'stacked_xf.4.ff0.weight', 'stacked_xf.4.ff1.weight', 'stacked_xf.4.post_attn_ln.scale', 'stacked_xf.4.post_ff_ln.scale', 'stacked_xf.4.pre_attn_ln.scale', 'stacked_xf.4.pre_ff_ln.scale', 'stacked_xf.5.attn.key_ln.scale', 'stacked_xf.5.attn.out.weight', 'stacked_xf.5.attn.per_dim_scale.per_dim_scale', 'stacked_xf.5.attn.qkv_proj.weight', 'stacked_xf.5.attn.query_ln.scale', 'stacked_xf.5.ff0.weight', 'stacked_xf.5.ff1.weight', 'stacked_xf.5.post_attn_ln.scale', 'stacked_xf.5.post_ff_ln.scale', 'stacked_xf.5.pre_attn_ln.scale', 'stacked_xf.5.pre_ff_ln.scale', 'stacked_xf.6.attn.key_ln.scale', 'stacked_xf.6.attn.out.weight', 'stacked_xf.6.attn.per_dim_scale.per_dim_scale', 'stacked_xf.6.attn.qkv_proj.weight', 'stacked_xf.6.attn.query_ln.scale', 'stacked_xf.6.ff0.weight', 'stacked_xf.6.ff1.weight', 'stacked_xf.6.post_attn_ln.scale', 'stacked_xf.6.post_ff_ln.scale', 'stacked_xf.6.pre_attn_ln.scale', 'stacked_xf.6.pre_ff_ln.scale', 'stacked_xf.7.attn.key_ln.scale', 'stacked_xf.7.attn.out.weight', 'stacked_xf.7.attn.per_dim_scale.per_dim_scale', 'stacked_xf.7.attn.qkv_proj.weight', 'stacked_xf.7.attn.query_ln.scale', 'stacked_xf.7.ff0.weight', 'stacked_xf.7.ff1.weight', 'stacked_xf.7.post_attn_ln.scale', 'stacked_xf.7.post_ff_ln.scale', 'stacked_xf.7.pre_attn_ln.scale', 'stacked_xf.7.pre_ff_ln.scale', 'stacked_xf.8.attn.key_ln.scale', 'stacked_xf.8.attn.out.weight', 'stacked_xf.8.attn.per_dim_scale.per_dim_scale', 'stacked_xf.8.attn.qkv_proj.weight', 'stacked_xf.8.attn.query_ln.scale', 'stacked_xf.8.ff0.weight', 'stacked_xf.8.ff1.weight', 'stacked_xf.8.post_attn_ln.scale', 'stacked_xf.8.post_ff_ln.scale', 'stacked_xf.8.pre_attn_ln.scale', 'stacked_xf.8.pre_ff_ln.scale', 'stacked_xf.9.attn.key_ln.scale', 'stacked_xf.9.attn.out.weight', 'stacked_xf.9.attn.per_dim_scale.per_dim_scale', 'stacked_xf.9.attn.qkv_proj.weight', 'stacked_xf.9.attn.query_ln.scale', 'stacked_xf.9.ff0.weight', 'stacked_xf.9.ff1.weight', 'stacked_xf.9.post_attn_ln.scale', 'stacked_xf.9.post_ff_ln.scale', 'stacked_xf.9.pre_attn_ln.scale', 'stacked_xf.9.pre_ff_ln.scale', 'tokenizer.hidden_layer.bias', 'tokenizer.hidden_layer.weight', 'tokenizer.output_layer.bias', 'tokenizer.output_layer.weight', 'tokenizer.residual_layer.bias', 'tokenizer.residual_layer.weight']\n",
            "- This IS expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of TimesFmModelForPrediction were not initialized from the model checkpoint at google/timesfm-2.5-200m-pytorch and are newly initialized: ['decoder.freq_emb.weight', 'decoder.input_ff_layer.input_layer.bias', 'decoder.input_ff_layer.input_layer.weight', 'decoder.input_ff_layer.output_layer.bias', 'decoder.input_ff_layer.output_layer.weight', 'decoder.input_ff_layer.residual_layer.bias', 'decoder.input_ff_layer.residual_layer.weight', 'decoder.layers.0.input_layernorm.weight', 'decoder.layers.0.mlp.down_proj.bias', 'decoder.layers.0.mlp.down_proj.weight', 'decoder.layers.0.mlp.gate_proj.bias', 'decoder.layers.0.mlp.gate_proj.weight', 'decoder.layers.0.mlp.layer_norm.bias', 'decoder.layers.0.mlp.layer_norm.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.o_proj.bias', 'decoder.layers.0.self_attn.o_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.scaling', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.1.input_layernorm.weight', 'decoder.layers.1.mlp.down_proj.bias', 'decoder.layers.1.mlp.down_proj.weight', 'decoder.layers.1.mlp.gate_proj.bias', 'decoder.layers.1.mlp.gate_proj.weight', 'decoder.layers.1.mlp.layer_norm.bias', 'decoder.layers.1.mlp.layer_norm.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.o_proj.bias', 'decoder.layers.1.self_attn.o_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.scaling', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.10.input_layernorm.weight', 'decoder.layers.10.mlp.down_proj.bias', 'decoder.layers.10.mlp.down_proj.weight', 'decoder.layers.10.mlp.gate_proj.bias', 'decoder.layers.10.mlp.gate_proj.weight', 'decoder.layers.10.mlp.layer_norm.bias', 'decoder.layers.10.mlp.layer_norm.weight', 'decoder.layers.10.self_attn.k_proj.bias', 'decoder.layers.10.self_attn.k_proj.weight', 'decoder.layers.10.self_attn.o_proj.bias', 'decoder.layers.10.self_attn.o_proj.weight', 'decoder.layers.10.self_attn.q_proj.bias', 'decoder.layers.10.self_attn.q_proj.weight', 'decoder.layers.10.self_attn.scaling', 'decoder.layers.10.self_attn.v_proj.bias', 'decoder.layers.10.self_attn.v_proj.weight', 'decoder.layers.11.input_layernorm.weight', 'decoder.layers.11.mlp.down_proj.bias', 'decoder.layers.11.mlp.down_proj.weight', 'decoder.layers.11.mlp.gate_proj.bias', 'decoder.layers.11.mlp.gate_proj.weight', 'decoder.layers.11.mlp.layer_norm.bias', 'decoder.layers.11.mlp.layer_norm.weight', 'decoder.layers.11.self_attn.k_proj.bias', 'decoder.layers.11.self_attn.k_proj.weight', 'decoder.layers.11.self_attn.o_proj.bias', 'decoder.layers.11.self_attn.o_proj.weight', 'decoder.layers.11.self_attn.q_proj.bias', 'decoder.layers.11.self_attn.q_proj.weight', 'decoder.layers.11.self_attn.scaling', 'decoder.layers.11.self_attn.v_proj.bias', 'decoder.layers.11.self_attn.v_proj.weight', 'decoder.layers.12.input_layernorm.weight', 'decoder.layers.12.mlp.down_proj.bias', 'decoder.layers.12.mlp.down_proj.weight', 'decoder.layers.12.mlp.gate_proj.bias', 'decoder.layers.12.mlp.gate_proj.weight', 'decoder.layers.12.mlp.layer_norm.bias', 'decoder.layers.12.mlp.layer_norm.weight', 'decoder.layers.12.self_attn.k_proj.bias', 'decoder.layers.12.self_attn.k_proj.weight', 'decoder.layers.12.self_attn.o_proj.bias', 'decoder.layers.12.self_attn.o_proj.weight', 'decoder.layers.12.self_attn.q_proj.bias', 'decoder.layers.12.self_attn.q_proj.weight', 'decoder.layers.12.self_attn.scaling', 'decoder.layers.12.self_attn.v_proj.bias', 'decoder.layers.12.self_attn.v_proj.weight', 'decoder.layers.13.input_layernorm.weight', 'decoder.layers.13.mlp.down_proj.bias', 'decoder.layers.13.mlp.down_proj.weight', 'decoder.layers.13.mlp.gate_proj.bias', 'decoder.layers.13.mlp.gate_proj.weight', 'decoder.layers.13.mlp.layer_norm.bias', 'decoder.layers.13.mlp.layer_norm.weight', 'decoder.layers.13.self_attn.k_proj.bias', 'decoder.layers.13.self_attn.k_proj.weight', 'decoder.layers.13.self_attn.o_proj.bias', 'decoder.layers.13.self_attn.o_proj.weight', 'decoder.layers.13.self_attn.q_proj.bias', 'decoder.layers.13.self_attn.q_proj.weight', 'decoder.layers.13.self_attn.scaling', 'decoder.layers.13.self_attn.v_proj.bias', 'decoder.layers.13.self_attn.v_proj.weight', 'decoder.layers.14.input_layernorm.weight', 'decoder.layers.14.mlp.down_proj.bias', 'decoder.layers.14.mlp.down_proj.weight', 'decoder.layers.14.mlp.gate_proj.bias', 'decoder.layers.14.mlp.gate_proj.weight', 'decoder.layers.14.mlp.layer_norm.bias', 'decoder.layers.14.mlp.layer_norm.weight', 'decoder.layers.14.self_attn.k_proj.bias', 'decoder.layers.14.self_attn.k_proj.weight', 'decoder.layers.14.self_attn.o_proj.bias', 'decoder.layers.14.self_attn.o_proj.weight', 'decoder.layers.14.self_attn.q_proj.bias', 'decoder.layers.14.self_attn.q_proj.weight', 'decoder.layers.14.self_attn.scaling', 'decoder.layers.14.self_attn.v_proj.bias', 'decoder.layers.14.self_attn.v_proj.weight', 'decoder.layers.15.input_layernorm.weight', 'decoder.layers.15.mlp.down_proj.bias', 'decoder.layers.15.mlp.down_proj.weight', 'decoder.layers.15.mlp.gate_proj.bias', 'decoder.layers.15.mlp.gate_proj.weight', 'decoder.layers.15.mlp.layer_norm.bias', 'decoder.layers.15.mlp.layer_norm.weight', 'decoder.layers.15.self_attn.k_proj.bias', 'decoder.layers.15.self_attn.k_proj.weight', 'decoder.layers.15.self_attn.o_proj.bias', 'decoder.layers.15.self_attn.o_proj.weight', 'decoder.layers.15.self_attn.q_proj.bias', 'decoder.layers.15.self_attn.q_proj.weight', 'decoder.layers.15.self_attn.scaling', 'decoder.layers.15.self_attn.v_proj.bias', 'decoder.layers.15.self_attn.v_proj.weight', 'decoder.layers.16.input_layernorm.weight', 'decoder.layers.16.mlp.down_proj.bias', 'decoder.layers.16.mlp.down_proj.weight', 'decoder.layers.16.mlp.gate_proj.bias', 'decoder.layers.16.mlp.gate_proj.weight', 'decoder.layers.16.mlp.layer_norm.bias', 'decoder.layers.16.mlp.layer_norm.weight', 'decoder.layers.16.self_attn.k_proj.bias', 'decoder.layers.16.self_attn.k_proj.weight', 'decoder.layers.16.self_attn.o_proj.bias', 'decoder.layers.16.self_attn.o_proj.weight', 'decoder.layers.16.self_attn.q_proj.bias', 'decoder.layers.16.self_attn.q_proj.weight', 'decoder.layers.16.self_attn.scaling', 'decoder.layers.16.self_attn.v_proj.bias', 'decoder.layers.16.self_attn.v_proj.weight', 'decoder.layers.17.input_layernorm.weight', 'decoder.layers.17.mlp.down_proj.bias', 'decoder.layers.17.mlp.down_proj.weight', 'decoder.layers.17.mlp.gate_proj.bias', 'decoder.layers.17.mlp.gate_proj.weight', 'decoder.layers.17.mlp.layer_norm.bias', 'decoder.layers.17.mlp.layer_norm.weight', 'decoder.layers.17.self_attn.k_proj.bias', 'decoder.layers.17.self_attn.k_proj.weight', 'decoder.layers.17.self_attn.o_proj.bias', 'decoder.layers.17.self_attn.o_proj.weight', 'decoder.layers.17.self_attn.q_proj.bias', 'decoder.layers.17.self_attn.q_proj.weight', 'decoder.layers.17.self_attn.scaling', 'decoder.layers.17.self_attn.v_proj.bias', 'decoder.layers.17.self_attn.v_proj.weight', 'decoder.layers.18.input_layernorm.weight', 'decoder.layers.18.mlp.down_proj.bias', 'decoder.layers.18.mlp.down_proj.weight', 'decoder.layers.18.mlp.gate_proj.bias', 'decoder.layers.18.mlp.gate_proj.weight', 'decoder.layers.18.mlp.layer_norm.bias', 'decoder.layers.18.mlp.layer_norm.weight', 'decoder.layers.18.self_attn.k_proj.bias', 'decoder.layers.18.self_attn.k_proj.weight', 'decoder.layers.18.self_attn.o_proj.bias', 'decoder.layers.18.self_attn.o_proj.weight', 'decoder.layers.18.self_attn.q_proj.bias', 'decoder.layers.18.self_attn.q_proj.weight', 'decoder.layers.18.self_attn.scaling', 'decoder.layers.18.self_attn.v_proj.bias', 'decoder.layers.18.self_attn.v_proj.weight', 'decoder.layers.19.input_layernorm.weight', 'decoder.layers.19.mlp.down_proj.bias', 'decoder.layers.19.mlp.down_proj.weight', 'decoder.layers.19.mlp.gate_proj.bias', 'decoder.layers.19.mlp.gate_proj.weight', 'decoder.layers.19.mlp.layer_norm.bias', 'decoder.layers.19.mlp.layer_norm.weight', 'decoder.layers.19.self_attn.k_proj.bias', 'decoder.layers.19.self_attn.k_proj.weight', 'decoder.layers.19.self_attn.o_proj.bias', 'decoder.layers.19.self_attn.o_proj.weight', 'decoder.layers.19.self_attn.q_proj.bias', 'decoder.layers.19.self_attn.q_proj.weight', 'decoder.layers.19.self_attn.scaling', 'decoder.layers.19.self_attn.v_proj.bias', 'decoder.layers.19.self_attn.v_proj.weight', 'decoder.layers.2.input_layernorm.weight', 'decoder.layers.2.mlp.down_proj.bias', 'decoder.layers.2.mlp.down_proj.weight', 'decoder.layers.2.mlp.gate_proj.bias', 'decoder.layers.2.mlp.gate_proj.weight', 'decoder.layers.2.mlp.layer_norm.bias', 'decoder.layers.2.mlp.layer_norm.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.o_proj.bias', 'decoder.layers.2.self_attn.o_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.scaling', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.3.input_layernorm.weight', 'decoder.layers.3.mlp.down_proj.bias', 'decoder.layers.3.mlp.down_proj.weight', 'decoder.layers.3.mlp.gate_proj.bias', 'decoder.layers.3.mlp.gate_proj.weight', 'decoder.layers.3.mlp.layer_norm.bias', 'decoder.layers.3.mlp.layer_norm.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.o_proj.bias', 'decoder.layers.3.self_attn.o_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.scaling', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.4.input_layernorm.weight', 'decoder.layers.4.mlp.down_proj.bias', 'decoder.layers.4.mlp.down_proj.weight', 'decoder.layers.4.mlp.gate_proj.bias', 'decoder.layers.4.mlp.gate_proj.weight', 'decoder.layers.4.mlp.layer_norm.bias', 'decoder.layers.4.mlp.layer_norm.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.o_proj.bias', 'decoder.layers.4.self_attn.o_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.scaling', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.5.input_layernorm.weight', 'decoder.layers.5.mlp.down_proj.bias', 'decoder.layers.5.mlp.down_proj.weight', 'decoder.layers.5.mlp.gate_proj.bias', 'decoder.layers.5.mlp.gate_proj.weight', 'decoder.layers.5.mlp.layer_norm.bias', 'decoder.layers.5.mlp.layer_norm.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.o_proj.bias', 'decoder.layers.5.self_attn.o_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.scaling', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.6.input_layernorm.weight', 'decoder.layers.6.mlp.down_proj.bias', 'decoder.layers.6.mlp.down_proj.weight', 'decoder.layers.6.mlp.gate_proj.bias', 'decoder.layers.6.mlp.gate_proj.weight', 'decoder.layers.6.mlp.layer_norm.bias', 'decoder.layers.6.mlp.layer_norm.weight', 'decoder.layers.6.self_attn.k_proj.bias', 'decoder.layers.6.self_attn.k_proj.weight', 'decoder.layers.6.self_attn.o_proj.bias', 'decoder.layers.6.self_attn.o_proj.weight', 'decoder.layers.6.self_attn.q_proj.bias', 'decoder.layers.6.self_attn.q_proj.weight', 'decoder.layers.6.self_attn.scaling', 'decoder.layers.6.self_attn.v_proj.bias', 'decoder.layers.6.self_attn.v_proj.weight', 'decoder.layers.7.input_layernorm.weight', 'decoder.layers.7.mlp.down_proj.bias', 'decoder.layers.7.mlp.down_proj.weight', 'decoder.layers.7.mlp.gate_proj.bias', 'decoder.layers.7.mlp.gate_proj.weight', 'decoder.layers.7.mlp.layer_norm.bias', 'decoder.layers.7.mlp.layer_norm.weight', 'decoder.layers.7.self_attn.k_proj.bias', 'decoder.layers.7.self_attn.k_proj.weight', 'decoder.layers.7.self_attn.o_proj.bias', 'decoder.layers.7.self_attn.o_proj.weight', 'decoder.layers.7.self_attn.q_proj.bias', 'decoder.layers.7.self_attn.q_proj.weight', 'decoder.layers.7.self_attn.scaling', 'decoder.layers.7.self_attn.v_proj.bias', 'decoder.layers.7.self_attn.v_proj.weight', 'decoder.layers.8.input_layernorm.weight', 'decoder.layers.8.mlp.down_proj.bias', 'decoder.layers.8.mlp.down_proj.weight', 'decoder.layers.8.mlp.gate_proj.bias', 'decoder.layers.8.mlp.gate_proj.weight', 'decoder.layers.8.mlp.layer_norm.bias', 'decoder.layers.8.mlp.layer_norm.weight', 'decoder.layers.8.self_attn.k_proj.bias', 'decoder.layers.8.self_attn.k_proj.weight', 'decoder.layers.8.self_attn.o_proj.bias', 'decoder.layers.8.self_attn.o_proj.weight', 'decoder.layers.8.self_attn.q_proj.bias', 'decoder.layers.8.self_attn.q_proj.weight', 'decoder.layers.8.self_attn.scaling', 'decoder.layers.8.self_attn.v_proj.bias', 'decoder.layers.8.self_attn.v_proj.weight', 'decoder.layers.9.input_layernorm.weight', 'decoder.layers.9.mlp.down_proj.bias', 'decoder.layers.9.mlp.down_proj.weight', 'decoder.layers.9.mlp.gate_proj.bias', 'decoder.layers.9.mlp.gate_proj.weight', 'decoder.layers.9.mlp.layer_norm.bias', 'decoder.layers.9.mlp.layer_norm.weight', 'decoder.layers.9.self_attn.k_proj.bias', 'decoder.layers.9.self_attn.k_proj.weight', 'decoder.layers.9.self_attn.o_proj.bias', 'decoder.layers.9.self_attn.o_proj.weight', 'decoder.layers.9.self_attn.q_proj.bias', 'decoder.layers.9.self_attn.q_proj.weight', 'decoder.layers.9.self_attn.scaling', 'decoder.layers.9.self_attn.v_proj.bias', 'decoder.layers.9.self_attn.v_proj.weight', 'horizon_ff_layer.input_layer.bias', 'horizon_ff_layer.input_layer.weight', 'horizon_ff_layer.output_layer.bias', 'horizon_ff_layer.output_layer.weight', 'horizon_ff_layer.residual_layer.bias', 'horizon_ff_layer.residual_layer.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n",
            "  Epoch 1/100 train_loss=1.1774 train_acc=0.2419 eval_loss=0.1334 eval_acc=0.9679 (best)\n",
            "  Epoch 2/100 train_loss=0.0647 train_acc=1.0000 eval_loss=0.0102 eval_acc=1.0000 (best)\n",
            "  Epoch 3/100 train_loss=0.0042 train_acc=1.0000 eval_loss=0.0089 eval_acc=0.9960 (best)\n",
            "  Epoch 4/100 train_loss=0.0012 train_acc=1.0000 eval_loss=0.0056 eval_acc=0.9960 (best)\n",
            "  Epoch 5/100 train_loss=0.0002 train_acc=1.0000 eval_loss=0.0036 eval_acc=0.9960 (best)\n",
            "  Epoch 6/100 train_loss=0.0001 train_acc=1.0000 eval_loss=0.0023 eval_acc=1.0000 (best)\n",
            "  Epoch 7/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0014 eval_acc=1.0000 (best)\n",
            "  Epoch 8/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0009 eval_acc=1.0000 (best)\n",
            "  Epoch 9/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0005 eval_acc=1.0000 (best)\n",
            "  Epoch 10/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0003 eval_acc=1.0000 (best)\n",
            "  Epoch 11/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0002 eval_acc=1.0000 (best)\n",
            "  Epoch 12/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0002 eval_acc=1.0000 (best)\n",
            "  Epoch 13/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0001 eval_acc=1.0000 (best)\n",
            "  Epoch 14/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0001 eval_acc=1.0000 (best)\n",
            "  Epoch 15/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0001 eval_acc=1.0000 (best)\n",
            "  Epoch 16/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0001 eval_acc=1.0000 (best)\n",
            "  Epoch 17/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0001 eval_acc=1.0000 (best)\n",
            "  Epoch 18/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 (best)\n",
            "  Epoch 19/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 (best)\n",
            "  Epoch 20/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 (best)\n",
            "  Epoch 21/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 (best)\n",
            "  Epoch 22/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 (best)\n",
            "  Epoch 23/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 (best)\n",
            "  Epoch 24/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 (best)\n",
            "  Epoch 25/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 (best)\n",
            "  Epoch 26/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 (best)\n",
            "  Epoch 27/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 (best)\n",
            "  Epoch 28/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 (best)\n",
            "  Epoch 29/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 (best)\n",
            "  Epoch 30/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 (best)\n",
            "  Epoch 31/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 (best)\n",
            "  Epoch 32/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 (best)\n",
            "  Epoch 33/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 (best)\n",
            "  Epoch 34/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 (best)\n",
            "  Epoch 35/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 (best)\n",
            "  Epoch 36/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 (best)\n",
            "  Epoch 37/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 (best)\n",
            "  Epoch 38/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 (best)\n",
            "  Epoch 39/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 (best)\n",
            "  Epoch 40/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 (best)\n",
            "  Epoch 41/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 \n",
            "  Epoch 42/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 \n",
            "  Epoch 43/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 \n",
            "  Epoch 44/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 \n",
            "  Epoch 45/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 \n",
            "  Epoch 46/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 \n",
            "  Epoch 47/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 \n",
            "  Epoch 48/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 \n",
            "  Epoch 49/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 \n",
            "  Epoch 50/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0000 eval_acc=1.0000 \n",
            "  Early stopping on google/timesfm-2.5-200m-pytorch: no improvement for 10 epochs (best epoch = 40)\n",
            "    tfm[google/timesfm-2.5-200m-pytorch] train_acc=1.0000 eval_acc=1.00000000000000000000000000000000000000000000\n",
            "    mrh_acc=1.0000 mr+h+kg_acc=1.0000 kg_acc=1.0000 ensemble=1.0000 (w=0.60)\n",
            "  Split 1/1 - accuracy=1.0000 time=331.9s\n",
            "Completed InsectEPGRegularTrain: Mean Acc=1.0000\n",
            "\n",
            "=== 50/109 InsectEPGSmallTrain ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n",
            "    Gate split 1/5: baseline_loss=0.0000 adaptive_loss=0.0000\n",
            "    Gate split 2/5: baseline_loss=0.0583 adaptive_loss=0.0000\n",
            "    Gate split 3/5: baseline_loss=0.0264 adaptive_loss=0.0050\n",
            "    Gate split 4/5: baseline_loss=0.0000 adaptive_loss=0.0180\n",
            "    Gate split 5/5: baseline_loss=0.2827 adaptive_loss=0.0948\n",
            "  Decision: Adaptive kept (loss 0.0236 vs baseline 0.0735, delta=-0.0499 <= +0.0200); savgol(window=15, poly=3) - high noise (std_diff)\n",
            "\n",
            "=== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at google/timesfm-2.5-200m-pytorch were not used when initializing TimesFmModelForPrediction: ['output_projection_point.hidden_layer.weight', 'output_projection_point.output_layer.weight', 'output_projection_point.residual_layer.weight', 'output_projection_quantiles.hidden_layer.weight', 'output_projection_quantiles.output_layer.weight', 'output_projection_quantiles.residual_layer.weight', 'stacked_xf.0.attn.key_ln.scale', 'stacked_xf.0.attn.out.weight', 'stacked_xf.0.attn.per_dim_scale.per_dim_scale', 'stacked_xf.0.attn.qkv_proj.weight', 'stacked_xf.0.attn.query_ln.scale', 'stacked_xf.0.ff0.weight', 'stacked_xf.0.ff1.weight', 'stacked_xf.0.post_attn_ln.scale', 'stacked_xf.0.post_ff_ln.scale', 'stacked_xf.0.pre_attn_ln.scale', 'stacked_xf.0.pre_ff_ln.scale', 'stacked_xf.1.attn.key_ln.scale', 'stacked_xf.1.attn.out.weight', 'stacked_xf.1.attn.per_dim_scale.per_dim_scale', 'stacked_xf.1.attn.qkv_proj.weight', 'stacked_xf.1.attn.query_ln.scale', 'stacked_xf.1.ff0.weight', 'stacked_xf.1.ff1.weight', 'stacked_xf.1.post_attn_ln.scale', 'stacked_xf.1.post_ff_ln.scale', 'stacked_xf.1.pre_attn_ln.scale', 'stacked_xf.1.pre_ff_ln.scale', 'stacked_xf.10.attn.key_ln.scale', 'stacked_xf.10.attn.out.weight', 'stacked_xf.10.attn.per_dim_scale.per_dim_scale', 'stacked_xf.10.attn.qkv_proj.weight', 'stacked_xf.10.attn.query_ln.scale', 'stacked_xf.10.ff0.weight', 'stacked_xf.10.ff1.weight', 'stacked_xf.10.post_attn_ln.scale', 'stacked_xf.10.post_ff_ln.scale', 'stacked_xf.10.pre_attn_ln.scale', 'stacked_xf.10.pre_ff_ln.scale', 'stacked_xf.11.attn.key_ln.scale', 'stacked_xf.11.attn.out.weight', 'stacked_xf.11.attn.per_dim_scale.per_dim_scale', 'stacked_xf.11.attn.qkv_proj.weight', 'stacked_xf.11.attn.query_ln.scale', 'stacked_xf.11.ff0.weight', 'stacked_xf.11.ff1.weight', 'stacked_xf.11.post_attn_ln.scale', 'stacked_xf.11.post_ff_ln.scale', 'stacked_xf.11.pre_attn_ln.scale', 'stacked_xf.11.pre_ff_ln.scale', 'stacked_xf.12.attn.key_ln.scale', 'stacked_xf.12.attn.out.weight', 'stacked_xf.12.attn.per_dim_scale.per_dim_scale', 'stacked_xf.12.attn.qkv_proj.weight', 'stacked_xf.12.attn.query_ln.scale', 'stacked_xf.12.ff0.weight', 'stacked_xf.12.ff1.weight', 'stacked_xf.12.post_attn_ln.scale', 'stacked_xf.12.post_ff_ln.scale', 'stacked_xf.12.pre_attn_ln.scale', 'stacked_xf.12.pre_ff_ln.scale', 'stacked_xf.13.attn.key_ln.scale', 'stacked_xf.13.attn.out.weight', 'stacked_xf.13.attn.per_dim_scale.per_dim_scale', 'stacked_xf.13.attn.qkv_proj.weight', 'stacked_xf.13.attn.query_ln.scale', 'stacked_xf.13.ff0.weight', 'stacked_xf.13.ff1.weight', 'stacked_xf.13.post_attn_ln.scale', 'stacked_xf.13.post_ff_ln.scale', 'stacked_xf.13.pre_attn_ln.scale', 'stacked_xf.13.pre_ff_ln.scale', 'stacked_xf.14.attn.key_ln.scale', 'stacked_xf.14.attn.out.weight', 'stacked_xf.14.attn.per_dim_scale.per_dim_scale', 'stacked_xf.14.attn.qkv_proj.weight', 'stacked_xf.14.attn.query_ln.scale', 'stacked_xf.14.ff0.weight', 'stacked_xf.14.ff1.weight', 'stacked_xf.14.post_attn_ln.scale', 'stacked_xf.14.post_ff_ln.scale', 'stacked_xf.14.pre_attn_ln.scale', 'stacked_xf.14.pre_ff_ln.scale', 'stacked_xf.15.attn.key_ln.scale', 'stacked_xf.15.attn.out.weight', 'stacked_xf.15.attn.per_dim_scale.per_dim_scale', 'stacked_xf.15.attn.qkv_proj.weight', 'stacked_xf.15.attn.query_ln.scale', 'stacked_xf.15.ff0.weight', 'stacked_xf.15.ff1.weight', 'stacked_xf.15.post_attn_ln.scale', 'stacked_xf.15.post_ff_ln.scale', 'stacked_xf.15.pre_attn_ln.scale', 'stacked_xf.15.pre_ff_ln.scale', 'stacked_xf.16.attn.key_ln.scale', 'stacked_xf.16.attn.out.weight', 'stacked_xf.16.attn.per_dim_scale.per_dim_scale', 'stacked_xf.16.attn.qkv_proj.weight', 'stacked_xf.16.attn.query_ln.scale', 'stacked_xf.16.ff0.weight', 'stacked_xf.16.ff1.weight', 'stacked_xf.16.post_attn_ln.scale', 'stacked_xf.16.post_ff_ln.scale', 'stacked_xf.16.pre_attn_ln.scale', 'stacked_xf.16.pre_ff_ln.scale', 'stacked_xf.17.attn.key_ln.scale', 'stacked_xf.17.attn.out.weight', 'stacked_xf.17.attn.per_dim_scale.per_dim_scale', 'stacked_xf.17.attn.qkv_proj.weight', 'stacked_xf.17.attn.query_ln.scale', 'stacked_xf.17.ff0.weight', 'stacked_xf.17.ff1.weight', 'stacked_xf.17.post_attn_ln.scale', 'stacked_xf.17.post_ff_ln.scale', 'stacked_xf.17.pre_attn_ln.scale', 'stacked_xf.17.pre_ff_ln.scale', 'stacked_xf.18.attn.key_ln.scale', 'stacked_xf.18.attn.out.weight', 'stacked_xf.18.attn.per_dim_scale.per_dim_scale', 'stacked_xf.18.attn.qkv_proj.weight', 'stacked_xf.18.attn.query_ln.scale', 'stacked_xf.18.ff0.weight', 'stacked_xf.18.ff1.weight', 'stacked_xf.18.post_attn_ln.scale', 'stacked_xf.18.post_ff_ln.scale', 'stacked_xf.18.pre_attn_ln.scale', 'stacked_xf.18.pre_ff_ln.scale', 'stacked_xf.19.attn.key_ln.scale', 'stacked_xf.19.attn.out.weight', 'stacked_xf.19.attn.per_dim_scale.per_dim_scale', 'stacked_xf.19.attn.qkv_proj.weight', 'stacked_xf.19.attn.query_ln.scale', 'stacked_xf.19.ff0.weight', 'stacked_xf.19.ff1.weight', 'stacked_xf.19.post_attn_ln.scale', 'stacked_xf.19.post_ff_ln.scale', 'stacked_xf.19.pre_attn_ln.scale', 'stacked_xf.19.pre_ff_ln.scale', 'stacked_xf.2.attn.key_ln.scale', 'stacked_xf.2.attn.out.weight', 'stacked_xf.2.attn.per_dim_scale.per_dim_scale', 'stacked_xf.2.attn.qkv_proj.weight', 'stacked_xf.2.attn.query_ln.scale', 'stacked_xf.2.ff0.weight', 'stacked_xf.2.ff1.weight', 'stacked_xf.2.post_attn_ln.scale', 'stacked_xf.2.post_ff_ln.scale', 'stacked_xf.2.pre_attn_ln.scale', 'stacked_xf.2.pre_ff_ln.scale', 'stacked_xf.3.attn.key_ln.scale', 'stacked_xf.3.attn.out.weight', 'stacked_xf.3.attn.per_dim_scale.per_dim_scale', 'stacked_xf.3.attn.qkv_proj.weight', 'stacked_xf.3.attn.query_ln.scale', 'stacked_xf.3.ff0.weight', 'stacked_xf.3.ff1.weight', 'stacked_xf.3.post_attn_ln.scale', 'stacked_xf.3.post_ff_ln.scale', 'stacked_xf.3.pre_attn_ln.scale', 'stacked_xf.3.pre_ff_ln.scale', 'stacked_xf.4.attn.key_ln.scale', 'stacked_xf.4.attn.out.weight', 'stacked_xf.4.attn.per_dim_scale.per_dim_scale', 'stacked_xf.4.attn.qkv_proj.weight', 'stacked_xf.4.attn.query_ln.scale', 'stacked_xf.4.ff0.weight', 'stacked_xf.4.ff1.weight', 'stacked_xf.4.post_attn_ln.scale', 'stacked_xf.4.post_ff_ln.scale', 'stacked_xf.4.pre_attn_ln.scale', 'stacked_xf.4.pre_ff_ln.scale', 'stacked_xf.5.attn.key_ln.scale', 'stacked_xf.5.attn.out.weight', 'stacked_xf.5.attn.per_dim_scale.per_dim_scale', 'stacked_xf.5.attn.qkv_proj.weight', 'stacked_xf.5.attn.query_ln.scale', 'stacked_xf.5.ff0.weight', 'stacked_xf.5.ff1.weight', 'stacked_xf.5.post_attn_ln.scale', 'stacked_xf.5.post_ff_ln.scale', 'stacked_xf.5.pre_attn_ln.scale', 'stacked_xf.5.pre_ff_ln.scale', 'stacked_xf.6.attn.key_ln.scale', 'stacked_xf.6.attn.out.weight', 'stacked_xf.6.attn.per_dim_scale.per_dim_scale', 'stacked_xf.6.attn.qkv_proj.weight', 'stacked_xf.6.attn.query_ln.scale', 'stacked_xf.6.ff0.weight', 'stacked_xf.6.ff1.weight', 'stacked_xf.6.post_attn_ln.scale', 'stacked_xf.6.post_ff_ln.scale', 'stacked_xf.6.pre_attn_ln.scale', 'stacked_xf.6.pre_ff_ln.scale', 'stacked_xf.7.attn.key_ln.scale', 'stacked_xf.7.attn.out.weight', 'stacked_xf.7.attn.per_dim_scale.per_dim_scale', 'stacked_xf.7.attn.qkv_proj.weight', 'stacked_xf.7.attn.query_ln.scale', 'stacked_xf.7.ff0.weight', 'stacked_xf.7.ff1.weight', 'stacked_xf.7.post_attn_ln.scale', 'stacked_xf.7.post_ff_ln.scale', 'stacked_xf.7.pre_attn_ln.scale', 'stacked_xf.7.pre_ff_ln.scale', 'stacked_xf.8.attn.key_ln.scale', 'stacked_xf.8.attn.out.weight', 'stacked_xf.8.attn.per_dim_scale.per_dim_scale', 'stacked_xf.8.attn.qkv_proj.weight', 'stacked_xf.8.attn.query_ln.scale', 'stacked_xf.8.ff0.weight', 'stacked_xf.8.ff1.weight', 'stacked_xf.8.post_attn_ln.scale', 'stacked_xf.8.post_ff_ln.scale', 'stacked_xf.8.pre_attn_ln.scale', 'stacked_xf.8.pre_ff_ln.scale', 'stacked_xf.9.attn.key_ln.scale', 'stacked_xf.9.attn.out.weight', 'stacked_xf.9.attn.per_dim_scale.per_dim_scale', 'stacked_xf.9.attn.qkv_proj.weight', 'stacked_xf.9.attn.query_ln.scale', 'stacked_xf.9.ff0.weight', 'stacked_xf.9.ff1.weight', 'stacked_xf.9.post_attn_ln.scale', 'stacked_xf.9.post_ff_ln.scale', 'stacked_xf.9.pre_attn_ln.scale', 'stacked_xf.9.pre_ff_ln.scale', 'tokenizer.hidden_layer.bias', 'tokenizer.hidden_layer.weight', 'tokenizer.output_layer.bias', 'tokenizer.output_layer.weight', 'tokenizer.residual_layer.bias', 'tokenizer.residual_layer.weight']\n",
            "- This IS expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of TimesFmModelForPrediction were not initialized from the model checkpoint at google/timesfm-2.5-200m-pytorch and are newly initialized: ['decoder.freq_emb.weight', 'decoder.input_ff_layer.input_layer.bias', 'decoder.input_ff_layer.input_layer.weight', 'decoder.input_ff_layer.output_layer.bias', 'decoder.input_ff_layer.output_layer.weight', 'decoder.input_ff_layer.residual_layer.bias', 'decoder.input_ff_layer.residual_layer.weight', 'decoder.layers.0.input_layernorm.weight', 'decoder.layers.0.mlp.down_proj.bias', 'decoder.layers.0.mlp.down_proj.weight', 'decoder.layers.0.mlp.gate_proj.bias', 'decoder.layers.0.mlp.gate_proj.weight', 'decoder.layers.0.mlp.layer_norm.bias', 'decoder.layers.0.mlp.layer_norm.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.o_proj.bias', 'decoder.layers.0.self_attn.o_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.scaling', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.1.input_layernorm.weight', 'decoder.layers.1.mlp.down_proj.bias', 'decoder.layers.1.mlp.down_proj.weight', 'decoder.layers.1.mlp.gate_proj.bias', 'decoder.layers.1.mlp.gate_proj.weight', 'decoder.layers.1.mlp.layer_norm.bias', 'decoder.layers.1.mlp.layer_norm.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.o_proj.bias', 'decoder.layers.1.self_attn.o_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.scaling', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.10.input_layernorm.weight', 'decoder.layers.10.mlp.down_proj.bias', 'decoder.layers.10.mlp.down_proj.weight', 'decoder.layers.10.mlp.gate_proj.bias', 'decoder.layers.10.mlp.gate_proj.weight', 'decoder.layers.10.mlp.layer_norm.bias', 'decoder.layers.10.mlp.layer_norm.weight', 'decoder.layers.10.self_attn.k_proj.bias', 'decoder.layers.10.self_attn.k_proj.weight', 'decoder.layers.10.self_attn.o_proj.bias', 'decoder.layers.10.self_attn.o_proj.weight', 'decoder.layers.10.self_attn.q_proj.bias', 'decoder.layers.10.self_attn.q_proj.weight', 'decoder.layers.10.self_attn.scaling', 'decoder.layers.10.self_attn.v_proj.bias', 'decoder.layers.10.self_attn.v_proj.weight', 'decoder.layers.11.input_layernorm.weight', 'decoder.layers.11.mlp.down_proj.bias', 'decoder.layers.11.mlp.down_proj.weight', 'decoder.layers.11.mlp.gate_proj.bias', 'decoder.layers.11.mlp.gate_proj.weight', 'decoder.layers.11.mlp.layer_norm.bias', 'decoder.layers.11.mlp.layer_norm.weight', 'decoder.layers.11.self_attn.k_proj.bias', 'decoder.layers.11.self_attn.k_proj.weight', 'decoder.layers.11.self_attn.o_proj.bias', 'decoder.layers.11.self_attn.o_proj.weight', 'decoder.layers.11.self_attn.q_proj.bias', 'decoder.layers.11.self_attn.q_proj.weight', 'decoder.layers.11.self_attn.scaling', 'decoder.layers.11.self_attn.v_proj.bias', 'decoder.layers.11.self_attn.v_proj.weight', 'decoder.layers.12.input_layernorm.weight', 'decoder.layers.12.mlp.down_proj.bias', 'decoder.layers.12.mlp.down_proj.weight', 'decoder.layers.12.mlp.gate_proj.bias', 'decoder.layers.12.mlp.gate_proj.weight', 'decoder.layers.12.mlp.layer_norm.bias', 'decoder.layers.12.mlp.layer_norm.weight', 'decoder.layers.12.self_attn.k_proj.bias', 'decoder.layers.12.self_attn.k_proj.weight', 'decoder.layers.12.self_attn.o_proj.bias', 'decoder.layers.12.self_attn.o_proj.weight', 'decoder.layers.12.self_attn.q_proj.bias', 'decoder.layers.12.self_attn.q_proj.weight', 'decoder.layers.12.self_attn.scaling', 'decoder.layers.12.self_attn.v_proj.bias', 'decoder.layers.12.self_attn.v_proj.weight', 'decoder.layers.13.input_layernorm.weight', 'decoder.layers.13.mlp.down_proj.bias', 'decoder.layers.13.mlp.down_proj.weight', 'decoder.layers.13.mlp.gate_proj.bias', 'decoder.layers.13.mlp.gate_proj.weight', 'decoder.layers.13.mlp.layer_norm.bias', 'decoder.layers.13.mlp.layer_norm.weight', 'decoder.layers.13.self_attn.k_proj.bias', 'decoder.layers.13.self_attn.k_proj.weight', 'decoder.layers.13.self_attn.o_proj.bias', 'decoder.layers.13.self_attn.o_proj.weight', 'decoder.layers.13.self_attn.q_proj.bias', 'decoder.layers.13.self_attn.q_proj.weight', 'decoder.layers.13.self_attn.scaling', 'decoder.layers.13.self_attn.v_proj.bias', 'decoder.layers.13.self_attn.v_proj.weight', 'decoder.layers.14.input_layernorm.weight', 'decoder.layers.14.mlp.down_proj.bias', 'decoder.layers.14.mlp.down_proj.weight', 'decoder.layers.14.mlp.gate_proj.bias', 'decoder.layers.14.mlp.gate_proj.weight', 'decoder.layers.14.mlp.layer_norm.bias', 'decoder.layers.14.mlp.layer_norm.weight', 'decoder.layers.14.self_attn.k_proj.bias', 'decoder.layers.14.self_attn.k_proj.weight', 'decoder.layers.14.self_attn.o_proj.bias', 'decoder.layers.14.self_attn.o_proj.weight', 'decoder.layers.14.self_attn.q_proj.bias', 'decoder.layers.14.self_attn.q_proj.weight', 'decoder.layers.14.self_attn.scaling', 'decoder.layers.14.self_attn.v_proj.bias', 'decoder.layers.14.self_attn.v_proj.weight', 'decoder.layers.15.input_layernorm.weight', 'decoder.layers.15.mlp.down_proj.bias', 'decoder.layers.15.mlp.down_proj.weight', 'decoder.layers.15.mlp.gate_proj.bias', 'decoder.layers.15.mlp.gate_proj.weight', 'decoder.layers.15.mlp.layer_norm.bias', 'decoder.layers.15.mlp.layer_norm.weight', 'decoder.layers.15.self_attn.k_proj.bias', 'decoder.layers.15.self_attn.k_proj.weight', 'decoder.layers.15.self_attn.o_proj.bias', 'decoder.layers.15.self_attn.o_proj.weight', 'decoder.layers.15.self_attn.q_proj.bias', 'decoder.layers.15.self_attn.q_proj.weight', 'decoder.layers.15.self_attn.scaling', 'decoder.layers.15.self_attn.v_proj.bias', 'decoder.layers.15.self_attn.v_proj.weight', 'decoder.layers.16.input_layernorm.weight', 'decoder.layers.16.mlp.down_proj.bias', 'decoder.layers.16.mlp.down_proj.weight', 'decoder.layers.16.mlp.gate_proj.bias', 'decoder.layers.16.mlp.gate_proj.weight', 'decoder.layers.16.mlp.layer_norm.bias', 'decoder.layers.16.mlp.layer_norm.weight', 'decoder.layers.16.self_attn.k_proj.bias', 'decoder.layers.16.self_attn.k_proj.weight', 'decoder.layers.16.self_attn.o_proj.bias', 'decoder.layers.16.self_attn.o_proj.weight', 'decoder.layers.16.self_attn.q_proj.bias', 'decoder.layers.16.self_attn.q_proj.weight', 'decoder.layers.16.self_attn.scaling', 'decoder.layers.16.self_attn.v_proj.bias', 'decoder.layers.16.self_attn.v_proj.weight', 'decoder.layers.17.input_layernorm.weight', 'decoder.layers.17.mlp.down_proj.bias', 'decoder.layers.17.mlp.down_proj.weight', 'decoder.layers.17.mlp.gate_proj.bias', 'decoder.layers.17.mlp.gate_proj.weight', 'decoder.layers.17.mlp.layer_norm.bias', 'decoder.layers.17.mlp.layer_norm.weight', 'decoder.layers.17.self_attn.k_proj.bias', 'decoder.layers.17.self_attn.k_proj.weight', 'decoder.layers.17.self_attn.o_proj.bias', 'decoder.layers.17.self_attn.o_proj.weight', 'decoder.layers.17.self_attn.q_proj.bias', 'decoder.layers.17.self_attn.q_proj.weight', 'decoder.layers.17.self_attn.scaling', 'decoder.layers.17.self_attn.v_proj.bias', 'decoder.layers.17.self_attn.v_proj.weight', 'decoder.layers.18.input_layernorm.weight', 'decoder.layers.18.mlp.down_proj.bias', 'decoder.layers.18.mlp.down_proj.weight', 'decoder.layers.18.mlp.gate_proj.bias', 'decoder.layers.18.mlp.gate_proj.weight', 'decoder.layers.18.mlp.layer_norm.bias', 'decoder.layers.18.mlp.layer_norm.weight', 'decoder.layers.18.self_attn.k_proj.bias', 'decoder.layers.18.self_attn.k_proj.weight', 'decoder.layers.18.self_attn.o_proj.bias', 'decoder.layers.18.self_attn.o_proj.weight', 'decoder.layers.18.self_attn.q_proj.bias', 'decoder.layers.18.self_attn.q_proj.weight', 'decoder.layers.18.self_attn.scaling', 'decoder.layers.18.self_attn.v_proj.bias', 'decoder.layers.18.self_attn.v_proj.weight', 'decoder.layers.19.input_layernorm.weight', 'decoder.layers.19.mlp.down_proj.bias', 'decoder.layers.19.mlp.down_proj.weight', 'decoder.layers.19.mlp.gate_proj.bias', 'decoder.layers.19.mlp.gate_proj.weight', 'decoder.layers.19.mlp.layer_norm.bias', 'decoder.layers.19.mlp.layer_norm.weight', 'decoder.layers.19.self_attn.k_proj.bias', 'decoder.layers.19.self_attn.k_proj.weight', 'decoder.layers.19.self_attn.o_proj.bias', 'decoder.layers.19.self_attn.o_proj.weight', 'decoder.layers.19.self_attn.q_proj.bias', 'decoder.layers.19.self_attn.q_proj.weight', 'decoder.layers.19.self_attn.scaling', 'decoder.layers.19.self_attn.v_proj.bias', 'decoder.layers.19.self_attn.v_proj.weight', 'decoder.layers.2.input_layernorm.weight', 'decoder.layers.2.mlp.down_proj.bias', 'decoder.layers.2.mlp.down_proj.weight', 'decoder.layers.2.mlp.gate_proj.bias', 'decoder.layers.2.mlp.gate_proj.weight', 'decoder.layers.2.mlp.layer_norm.bias', 'decoder.layers.2.mlp.layer_norm.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.o_proj.bias', 'decoder.layers.2.self_attn.o_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.scaling', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.3.input_layernorm.weight', 'decoder.layers.3.mlp.down_proj.bias', 'decoder.layers.3.mlp.down_proj.weight', 'decoder.layers.3.mlp.gate_proj.bias', 'decoder.layers.3.mlp.gate_proj.weight', 'decoder.layers.3.mlp.layer_norm.bias', 'decoder.layers.3.mlp.layer_norm.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.o_proj.bias', 'decoder.layers.3.self_attn.o_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.scaling', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.4.input_layernorm.weight', 'decoder.layers.4.mlp.down_proj.bias', 'decoder.layers.4.mlp.down_proj.weight', 'decoder.layers.4.mlp.gate_proj.bias', 'decoder.layers.4.mlp.gate_proj.weight', 'decoder.layers.4.mlp.layer_norm.bias', 'decoder.layers.4.mlp.layer_norm.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.o_proj.bias', 'decoder.layers.4.self_attn.o_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.scaling', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.5.input_layernorm.weight', 'decoder.layers.5.mlp.down_proj.bias', 'decoder.layers.5.mlp.down_proj.weight', 'decoder.layers.5.mlp.gate_proj.bias', 'decoder.layers.5.mlp.gate_proj.weight', 'decoder.layers.5.mlp.layer_norm.bias', 'decoder.layers.5.mlp.layer_norm.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.o_proj.bias', 'decoder.layers.5.self_attn.o_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.scaling', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.6.input_layernorm.weight', 'decoder.layers.6.mlp.down_proj.bias', 'decoder.layers.6.mlp.down_proj.weight', 'decoder.layers.6.mlp.gate_proj.bias', 'decoder.layers.6.mlp.gate_proj.weight', 'decoder.layers.6.mlp.layer_norm.bias', 'decoder.layers.6.mlp.layer_norm.weight', 'decoder.layers.6.self_attn.k_proj.bias', 'decoder.layers.6.self_attn.k_proj.weight', 'decoder.layers.6.self_attn.o_proj.bias', 'decoder.layers.6.self_attn.o_proj.weight', 'decoder.layers.6.self_attn.q_proj.bias', 'decoder.layers.6.self_attn.q_proj.weight', 'decoder.layers.6.self_attn.scaling', 'decoder.layers.6.self_attn.v_proj.bias', 'decoder.layers.6.self_attn.v_proj.weight', 'decoder.layers.7.input_layernorm.weight', 'decoder.layers.7.mlp.down_proj.bias', 'decoder.layers.7.mlp.down_proj.weight', 'decoder.layers.7.mlp.gate_proj.bias', 'decoder.layers.7.mlp.gate_proj.weight', 'decoder.layers.7.mlp.layer_norm.bias', 'decoder.layers.7.mlp.layer_norm.weight', 'decoder.layers.7.self_attn.k_proj.bias', 'decoder.layers.7.self_attn.k_proj.weight', 'decoder.layers.7.self_attn.o_proj.bias', 'decoder.layers.7.self_attn.o_proj.weight', 'decoder.layers.7.self_attn.q_proj.bias', 'decoder.layers.7.self_attn.q_proj.weight', 'decoder.layers.7.self_attn.scaling', 'decoder.layers.7.self_attn.v_proj.bias', 'decoder.layers.7.self_attn.v_proj.weight', 'decoder.layers.8.input_layernorm.weight', 'decoder.layers.8.mlp.down_proj.bias', 'decoder.layers.8.mlp.down_proj.weight', 'decoder.layers.8.mlp.gate_proj.bias', 'decoder.layers.8.mlp.gate_proj.weight', 'decoder.layers.8.mlp.layer_norm.bias', 'decoder.layers.8.mlp.layer_norm.weight', 'decoder.layers.8.self_attn.k_proj.bias', 'decoder.layers.8.self_attn.k_proj.weight', 'decoder.layers.8.self_attn.o_proj.bias', 'decoder.layers.8.self_attn.o_proj.weight', 'decoder.layers.8.self_attn.q_proj.bias', 'decoder.layers.8.self_attn.q_proj.weight', 'decoder.layers.8.self_attn.scaling', 'decoder.layers.8.self_attn.v_proj.bias', 'decoder.layers.8.self_attn.v_proj.weight', 'decoder.layers.9.input_layernorm.weight', 'decoder.layers.9.mlp.down_proj.bias', 'decoder.layers.9.mlp.down_proj.weight', 'decoder.layers.9.mlp.gate_proj.bias', 'decoder.layers.9.mlp.gate_proj.weight', 'decoder.layers.9.mlp.layer_norm.bias', 'decoder.layers.9.mlp.layer_norm.weight', 'decoder.layers.9.self_attn.k_proj.bias', 'decoder.layers.9.self_attn.k_proj.weight', 'decoder.layers.9.self_attn.o_proj.bias', 'decoder.layers.9.self_attn.o_proj.weight', 'decoder.layers.9.self_attn.q_proj.bias', 'decoder.layers.9.self_attn.q_proj.weight', 'decoder.layers.9.self_attn.scaling', 'decoder.layers.9.self_attn.v_proj.bias', 'decoder.layers.9.self_attn.v_proj.weight', 'horizon_ff_layer.input_layer.bias', 'horizon_ff_layer.input_layer.weight', 'horizon_ff_layer.output_layer.bias', 'horizon_ff_layer.output_layer.weight', 'horizon_ff_layer.residual_layer.bias', 'horizon_ff_layer.residual_layer.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n",
            "  Epoch 1/100 train_loss=1.1214 train_acc=0.3529 eval_loss=1.1159 eval_acc=0.3253 (best)\n",
            "  Epoch 2/100 train_loss=1.1610 train_acc=0.2941 eval_loss=0.2422 eval_acc=0.8956 (best)\n",
            "  Epoch 3/100 train_loss=0.0310 train_acc=1.0000 eval_loss=0.0410 eval_acc=0.9839 (best)\n",
            "  Epoch 4/100 train_loss=0.0062 train_acc=1.0000 eval_loss=0.0179 eval_acc=0.9960 (best)\n",
            "  Epoch 5/100 train_loss=0.0029 train_acc=1.0000 eval_loss=0.0113 eval_acc=0.9960 (best)\n",
            "  Epoch 6/100 train_loss=0.0011 train_acc=1.0000 eval_loss=0.0089 eval_acc=0.9960 (best)\n",
            "  Epoch 7/100 train_loss=0.0004 train_acc=1.0000 eval_loss=0.0083 eval_acc=0.9960 (best)\n",
            "  Epoch 8/100 train_loss=0.0002 train_acc=1.0000 eval_loss=0.0084 eval_acc=0.9960 \n",
            "  Epoch 9/100 train_loss=0.0001 train_acc=1.0000 eval_loss=0.0090 eval_acc=0.9960 \n",
            "  Epoch 10/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0098 eval_acc=0.9960 \n",
            "  Epoch 11/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0110 eval_acc=0.9960 \n",
            "  Epoch 12/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0121 eval_acc=0.9960 \n",
            "  Epoch 13/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0132 eval_acc=0.9960 \n",
            "  Epoch 14/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0143 eval_acc=0.9960 \n",
            "  Epoch 15/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0154 eval_acc=0.9960 \n",
            "  Epoch 16/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0163 eval_acc=0.9960 \n",
            "  Epoch 17/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0172 eval_acc=0.9960 \n",
            "  Early stopping on google/timesfm-2.5-200m-pytorch: no improvement for 10 epochs (best epoch = 7)\n",
            "    tfm[google/timesfm-2.5-200m-pytorch] train_acc=1.0000 eval_acc=0.99598393574297183761245833011344075202941895\n",
            "    mrh_acc=0.9960 mr+h+kg_acc=0.9960 kg_acc=0.9880 ensemble=0.9960 (w=0.60)\n",
            "  Split 1/1 - accuracy=0.9960 time=87.3s\n",
            "Completed InsectEPGSmallTrain: Mean Acc=0.9960\n",
            "\n",
            "=== 51/109 InsectWingbeatSound ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n",
            "    Gate split 1/5: baseline_loss=0.8579 adaptive_loss=0.8526\n",
            "    Gate split 2/5: baseline_loss=0.7761 adaptive_loss=0.7763\n",
            "    Gate split 3/5: baseline_loss=0.8075 adaptive_loss=0.7971\n",
            "    Gate split 4/5: baseline_loss=0.7452 adaptive_loss=0.7470\n",
            "    Gate split 5/5: baseline_loss=0.7783 adaptive_loss=0.7955\n",
            "  Decision: Adaptive kept (loss 0.7937 vs baseline 0.7930, delta=+0.0007 <= +0.0200); savgol(window=11, poly=2) - high noise (std_diff)\n",
            "\n",
            "=== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at google/timesfm-2.5-200m-pytorch were not used when initializing TimesFmModelForPrediction: ['output_projection_point.hidden_layer.weight', 'output_projection_point.output_layer.weight', 'output_projection_point.residual_layer.weight', 'output_projection_quantiles.hidden_layer.weight', 'output_projection_quantiles.output_layer.weight', 'output_projection_quantiles.residual_layer.weight', 'stacked_xf.0.attn.key_ln.scale', 'stacked_xf.0.attn.out.weight', 'stacked_xf.0.attn.per_dim_scale.per_dim_scale', 'stacked_xf.0.attn.qkv_proj.weight', 'stacked_xf.0.attn.query_ln.scale', 'stacked_xf.0.ff0.weight', 'stacked_xf.0.ff1.weight', 'stacked_xf.0.post_attn_ln.scale', 'stacked_xf.0.post_ff_ln.scale', 'stacked_xf.0.pre_attn_ln.scale', 'stacked_xf.0.pre_ff_ln.scale', 'stacked_xf.1.attn.key_ln.scale', 'stacked_xf.1.attn.out.weight', 'stacked_xf.1.attn.per_dim_scale.per_dim_scale', 'stacked_xf.1.attn.qkv_proj.weight', 'stacked_xf.1.attn.query_ln.scale', 'stacked_xf.1.ff0.weight', 'stacked_xf.1.ff1.weight', 'stacked_xf.1.post_attn_ln.scale', 'stacked_xf.1.post_ff_ln.scale', 'stacked_xf.1.pre_attn_ln.scale', 'stacked_xf.1.pre_ff_ln.scale', 'stacked_xf.10.attn.key_ln.scale', 'stacked_xf.10.attn.out.weight', 'stacked_xf.10.attn.per_dim_scale.per_dim_scale', 'stacked_xf.10.attn.qkv_proj.weight', 'stacked_xf.10.attn.query_ln.scale', 'stacked_xf.10.ff0.weight', 'stacked_xf.10.ff1.weight', 'stacked_xf.10.post_attn_ln.scale', 'stacked_xf.10.post_ff_ln.scale', 'stacked_xf.10.pre_attn_ln.scale', 'stacked_xf.10.pre_ff_ln.scale', 'stacked_xf.11.attn.key_ln.scale', 'stacked_xf.11.attn.out.weight', 'stacked_xf.11.attn.per_dim_scale.per_dim_scale', 'stacked_xf.11.attn.qkv_proj.weight', 'stacked_xf.11.attn.query_ln.scale', 'stacked_xf.11.ff0.weight', 'stacked_xf.11.ff1.weight', 'stacked_xf.11.post_attn_ln.scale', 'stacked_xf.11.post_ff_ln.scale', 'stacked_xf.11.pre_attn_ln.scale', 'stacked_xf.11.pre_ff_ln.scale', 'stacked_xf.12.attn.key_ln.scale', 'stacked_xf.12.attn.out.weight', 'stacked_xf.12.attn.per_dim_scale.per_dim_scale', 'stacked_xf.12.attn.qkv_proj.weight', 'stacked_xf.12.attn.query_ln.scale', 'stacked_xf.12.ff0.weight', 'stacked_xf.12.ff1.weight', 'stacked_xf.12.post_attn_ln.scale', 'stacked_xf.12.post_ff_ln.scale', 'stacked_xf.12.pre_attn_ln.scale', 'stacked_xf.12.pre_ff_ln.scale', 'stacked_xf.13.attn.key_ln.scale', 'stacked_xf.13.attn.out.weight', 'stacked_xf.13.attn.per_dim_scale.per_dim_scale', 'stacked_xf.13.attn.qkv_proj.weight', 'stacked_xf.13.attn.query_ln.scale', 'stacked_xf.13.ff0.weight', 'stacked_xf.13.ff1.weight', 'stacked_xf.13.post_attn_ln.scale', 'stacked_xf.13.post_ff_ln.scale', 'stacked_xf.13.pre_attn_ln.scale', 'stacked_xf.13.pre_ff_ln.scale', 'stacked_xf.14.attn.key_ln.scale', 'stacked_xf.14.attn.out.weight', 'stacked_xf.14.attn.per_dim_scale.per_dim_scale', 'stacked_xf.14.attn.qkv_proj.weight', 'stacked_xf.14.attn.query_ln.scale', 'stacked_xf.14.ff0.weight', 'stacked_xf.14.ff1.weight', 'stacked_xf.14.post_attn_ln.scale', 'stacked_xf.14.post_ff_ln.scale', 'stacked_xf.14.pre_attn_ln.scale', 'stacked_xf.14.pre_ff_ln.scale', 'stacked_xf.15.attn.key_ln.scale', 'stacked_xf.15.attn.out.weight', 'stacked_xf.15.attn.per_dim_scale.per_dim_scale', 'stacked_xf.15.attn.qkv_proj.weight', 'stacked_xf.15.attn.query_ln.scale', 'stacked_xf.15.ff0.weight', 'stacked_xf.15.ff1.weight', 'stacked_xf.15.post_attn_ln.scale', 'stacked_xf.15.post_ff_ln.scale', 'stacked_xf.15.pre_attn_ln.scale', 'stacked_xf.15.pre_ff_ln.scale', 'stacked_xf.16.attn.key_ln.scale', 'stacked_xf.16.attn.out.weight', 'stacked_xf.16.attn.per_dim_scale.per_dim_scale', 'stacked_xf.16.attn.qkv_proj.weight', 'stacked_xf.16.attn.query_ln.scale', 'stacked_xf.16.ff0.weight', 'stacked_xf.16.ff1.weight', 'stacked_xf.16.post_attn_ln.scale', 'stacked_xf.16.post_ff_ln.scale', 'stacked_xf.16.pre_attn_ln.scale', 'stacked_xf.16.pre_ff_ln.scale', 'stacked_xf.17.attn.key_ln.scale', 'stacked_xf.17.attn.out.weight', 'stacked_xf.17.attn.per_dim_scale.per_dim_scale', 'stacked_xf.17.attn.qkv_proj.weight', 'stacked_xf.17.attn.query_ln.scale', 'stacked_xf.17.ff0.weight', 'stacked_xf.17.ff1.weight', 'stacked_xf.17.post_attn_ln.scale', 'stacked_xf.17.post_ff_ln.scale', 'stacked_xf.17.pre_attn_ln.scale', 'stacked_xf.17.pre_ff_ln.scale', 'stacked_xf.18.attn.key_ln.scale', 'stacked_xf.18.attn.out.weight', 'stacked_xf.18.attn.per_dim_scale.per_dim_scale', 'stacked_xf.18.attn.qkv_proj.weight', 'stacked_xf.18.attn.query_ln.scale', 'stacked_xf.18.ff0.weight', 'stacked_xf.18.ff1.weight', 'stacked_xf.18.post_attn_ln.scale', 'stacked_xf.18.post_ff_ln.scale', 'stacked_xf.18.pre_attn_ln.scale', 'stacked_xf.18.pre_ff_ln.scale', 'stacked_xf.19.attn.key_ln.scale', 'stacked_xf.19.attn.out.weight', 'stacked_xf.19.attn.per_dim_scale.per_dim_scale', 'stacked_xf.19.attn.qkv_proj.weight', 'stacked_xf.19.attn.query_ln.scale', 'stacked_xf.19.ff0.weight', 'stacked_xf.19.ff1.weight', 'stacked_xf.19.post_attn_ln.scale', 'stacked_xf.19.post_ff_ln.scale', 'stacked_xf.19.pre_attn_ln.scale', 'stacked_xf.19.pre_ff_ln.scale', 'stacked_xf.2.attn.key_ln.scale', 'stacked_xf.2.attn.out.weight', 'stacked_xf.2.attn.per_dim_scale.per_dim_scale', 'stacked_xf.2.attn.qkv_proj.weight', 'stacked_xf.2.attn.query_ln.scale', 'stacked_xf.2.ff0.weight', 'stacked_xf.2.ff1.weight', 'stacked_xf.2.post_attn_ln.scale', 'stacked_xf.2.post_ff_ln.scale', 'stacked_xf.2.pre_attn_ln.scale', 'stacked_xf.2.pre_ff_ln.scale', 'stacked_xf.3.attn.key_ln.scale', 'stacked_xf.3.attn.out.weight', 'stacked_xf.3.attn.per_dim_scale.per_dim_scale', 'stacked_xf.3.attn.qkv_proj.weight', 'stacked_xf.3.attn.query_ln.scale', 'stacked_xf.3.ff0.weight', 'stacked_xf.3.ff1.weight', 'stacked_xf.3.post_attn_ln.scale', 'stacked_xf.3.post_ff_ln.scale', 'stacked_xf.3.pre_attn_ln.scale', 'stacked_xf.3.pre_ff_ln.scale', 'stacked_xf.4.attn.key_ln.scale', 'stacked_xf.4.attn.out.weight', 'stacked_xf.4.attn.per_dim_scale.per_dim_scale', 'stacked_xf.4.attn.qkv_proj.weight', 'stacked_xf.4.attn.query_ln.scale', 'stacked_xf.4.ff0.weight', 'stacked_xf.4.ff1.weight', 'stacked_xf.4.post_attn_ln.scale', 'stacked_xf.4.post_ff_ln.scale', 'stacked_xf.4.pre_attn_ln.scale', 'stacked_xf.4.pre_ff_ln.scale', 'stacked_xf.5.attn.key_ln.scale', 'stacked_xf.5.attn.out.weight', 'stacked_xf.5.attn.per_dim_scale.per_dim_scale', 'stacked_xf.5.attn.qkv_proj.weight', 'stacked_xf.5.attn.query_ln.scale', 'stacked_xf.5.ff0.weight', 'stacked_xf.5.ff1.weight', 'stacked_xf.5.post_attn_ln.scale', 'stacked_xf.5.post_ff_ln.scale', 'stacked_xf.5.pre_attn_ln.scale', 'stacked_xf.5.pre_ff_ln.scale', 'stacked_xf.6.attn.key_ln.scale', 'stacked_xf.6.attn.out.weight', 'stacked_xf.6.attn.per_dim_scale.per_dim_scale', 'stacked_xf.6.attn.qkv_proj.weight', 'stacked_xf.6.attn.query_ln.scale', 'stacked_xf.6.ff0.weight', 'stacked_xf.6.ff1.weight', 'stacked_xf.6.post_attn_ln.scale', 'stacked_xf.6.post_ff_ln.scale', 'stacked_xf.6.pre_attn_ln.scale', 'stacked_xf.6.pre_ff_ln.scale', 'stacked_xf.7.attn.key_ln.scale', 'stacked_xf.7.attn.out.weight', 'stacked_xf.7.attn.per_dim_scale.per_dim_scale', 'stacked_xf.7.attn.qkv_proj.weight', 'stacked_xf.7.attn.query_ln.scale', 'stacked_xf.7.ff0.weight', 'stacked_xf.7.ff1.weight', 'stacked_xf.7.post_attn_ln.scale', 'stacked_xf.7.post_ff_ln.scale', 'stacked_xf.7.pre_attn_ln.scale', 'stacked_xf.7.pre_ff_ln.scale', 'stacked_xf.8.attn.key_ln.scale', 'stacked_xf.8.attn.out.weight', 'stacked_xf.8.attn.per_dim_scale.per_dim_scale', 'stacked_xf.8.attn.qkv_proj.weight', 'stacked_xf.8.attn.query_ln.scale', 'stacked_xf.8.ff0.weight', 'stacked_xf.8.ff1.weight', 'stacked_xf.8.post_attn_ln.scale', 'stacked_xf.8.post_ff_ln.scale', 'stacked_xf.8.pre_attn_ln.scale', 'stacked_xf.8.pre_ff_ln.scale', 'stacked_xf.9.attn.key_ln.scale', 'stacked_xf.9.attn.out.weight', 'stacked_xf.9.attn.per_dim_scale.per_dim_scale', 'stacked_xf.9.attn.qkv_proj.weight', 'stacked_xf.9.attn.query_ln.scale', 'stacked_xf.9.ff0.weight', 'stacked_xf.9.ff1.weight', 'stacked_xf.9.post_attn_ln.scale', 'stacked_xf.9.post_ff_ln.scale', 'stacked_xf.9.pre_attn_ln.scale', 'stacked_xf.9.pre_ff_ln.scale', 'tokenizer.hidden_layer.bias', 'tokenizer.hidden_layer.weight', 'tokenizer.output_layer.bias', 'tokenizer.output_layer.weight', 'tokenizer.residual_layer.bias', 'tokenizer.residual_layer.weight']\n",
            "- This IS expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of TimesFmModelForPrediction were not initialized from the model checkpoint at google/timesfm-2.5-200m-pytorch and are newly initialized: ['decoder.freq_emb.weight', 'decoder.input_ff_layer.input_layer.bias', 'decoder.input_ff_layer.input_layer.weight', 'decoder.input_ff_layer.output_layer.bias', 'decoder.input_ff_layer.output_layer.weight', 'decoder.input_ff_layer.residual_layer.bias', 'decoder.input_ff_layer.residual_layer.weight', 'decoder.layers.0.input_layernorm.weight', 'decoder.layers.0.mlp.down_proj.bias', 'decoder.layers.0.mlp.down_proj.weight', 'decoder.layers.0.mlp.gate_proj.bias', 'decoder.layers.0.mlp.gate_proj.weight', 'decoder.layers.0.mlp.layer_norm.bias', 'decoder.layers.0.mlp.layer_norm.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.o_proj.bias', 'decoder.layers.0.self_attn.o_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.scaling', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.1.input_layernorm.weight', 'decoder.layers.1.mlp.down_proj.bias', 'decoder.layers.1.mlp.down_proj.weight', 'decoder.layers.1.mlp.gate_proj.bias', 'decoder.layers.1.mlp.gate_proj.weight', 'decoder.layers.1.mlp.layer_norm.bias', 'decoder.layers.1.mlp.layer_norm.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.o_proj.bias', 'decoder.layers.1.self_attn.o_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.scaling', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.10.input_layernorm.weight', 'decoder.layers.10.mlp.down_proj.bias', 'decoder.layers.10.mlp.down_proj.weight', 'decoder.layers.10.mlp.gate_proj.bias', 'decoder.layers.10.mlp.gate_proj.weight', 'decoder.layers.10.mlp.layer_norm.bias', 'decoder.layers.10.mlp.layer_norm.weight', 'decoder.layers.10.self_attn.k_proj.bias', 'decoder.layers.10.self_attn.k_proj.weight', 'decoder.layers.10.self_attn.o_proj.bias', 'decoder.layers.10.self_attn.o_proj.weight', 'decoder.layers.10.self_attn.q_proj.bias', 'decoder.layers.10.self_attn.q_proj.weight', 'decoder.layers.10.self_attn.scaling', 'decoder.layers.10.self_attn.v_proj.bias', 'decoder.layers.10.self_attn.v_proj.weight', 'decoder.layers.11.input_layernorm.weight', 'decoder.layers.11.mlp.down_proj.bias', 'decoder.layers.11.mlp.down_proj.weight', 'decoder.layers.11.mlp.gate_proj.bias', 'decoder.layers.11.mlp.gate_proj.weight', 'decoder.layers.11.mlp.layer_norm.bias', 'decoder.layers.11.mlp.layer_norm.weight', 'decoder.layers.11.self_attn.k_proj.bias', 'decoder.layers.11.self_attn.k_proj.weight', 'decoder.layers.11.self_attn.o_proj.bias', 'decoder.layers.11.self_attn.o_proj.weight', 'decoder.layers.11.self_attn.q_proj.bias', 'decoder.layers.11.self_attn.q_proj.weight', 'decoder.layers.11.self_attn.scaling', 'decoder.layers.11.self_attn.v_proj.bias', 'decoder.layers.11.self_attn.v_proj.weight', 'decoder.layers.12.input_layernorm.weight', 'decoder.layers.12.mlp.down_proj.bias', 'decoder.layers.12.mlp.down_proj.weight', 'decoder.layers.12.mlp.gate_proj.bias', 'decoder.layers.12.mlp.gate_proj.weight', 'decoder.layers.12.mlp.layer_norm.bias', 'decoder.layers.12.mlp.layer_norm.weight', 'decoder.layers.12.self_attn.k_proj.bias', 'decoder.layers.12.self_attn.k_proj.weight', 'decoder.layers.12.self_attn.o_proj.bias', 'decoder.layers.12.self_attn.o_proj.weight', 'decoder.layers.12.self_attn.q_proj.bias', 'decoder.layers.12.self_attn.q_proj.weight', 'decoder.layers.12.self_attn.scaling', 'decoder.layers.12.self_attn.v_proj.bias', 'decoder.layers.12.self_attn.v_proj.weight', 'decoder.layers.13.input_layernorm.weight', 'decoder.layers.13.mlp.down_proj.bias', 'decoder.layers.13.mlp.down_proj.weight', 'decoder.layers.13.mlp.gate_proj.bias', 'decoder.layers.13.mlp.gate_proj.weight', 'decoder.layers.13.mlp.layer_norm.bias', 'decoder.layers.13.mlp.layer_norm.weight', 'decoder.layers.13.self_attn.k_proj.bias', 'decoder.layers.13.self_attn.k_proj.weight', 'decoder.layers.13.self_attn.o_proj.bias', 'decoder.layers.13.self_attn.o_proj.weight', 'decoder.layers.13.self_attn.q_proj.bias', 'decoder.layers.13.self_attn.q_proj.weight', 'decoder.layers.13.self_attn.scaling', 'decoder.layers.13.self_attn.v_proj.bias', 'decoder.layers.13.self_attn.v_proj.weight', 'decoder.layers.14.input_layernorm.weight', 'decoder.layers.14.mlp.down_proj.bias', 'decoder.layers.14.mlp.down_proj.weight', 'decoder.layers.14.mlp.gate_proj.bias', 'decoder.layers.14.mlp.gate_proj.weight', 'decoder.layers.14.mlp.layer_norm.bias', 'decoder.layers.14.mlp.layer_norm.weight', 'decoder.layers.14.self_attn.k_proj.bias', 'decoder.layers.14.self_attn.k_proj.weight', 'decoder.layers.14.self_attn.o_proj.bias', 'decoder.layers.14.self_attn.o_proj.weight', 'decoder.layers.14.self_attn.q_proj.bias', 'decoder.layers.14.self_attn.q_proj.weight', 'decoder.layers.14.self_attn.scaling', 'decoder.layers.14.self_attn.v_proj.bias', 'decoder.layers.14.self_attn.v_proj.weight', 'decoder.layers.15.input_layernorm.weight', 'decoder.layers.15.mlp.down_proj.bias', 'decoder.layers.15.mlp.down_proj.weight', 'decoder.layers.15.mlp.gate_proj.bias', 'decoder.layers.15.mlp.gate_proj.weight', 'decoder.layers.15.mlp.layer_norm.bias', 'decoder.layers.15.mlp.layer_norm.weight', 'decoder.layers.15.self_attn.k_proj.bias', 'decoder.layers.15.self_attn.k_proj.weight', 'decoder.layers.15.self_attn.o_proj.bias', 'decoder.layers.15.self_attn.o_proj.weight', 'decoder.layers.15.self_attn.q_proj.bias', 'decoder.layers.15.self_attn.q_proj.weight', 'decoder.layers.15.self_attn.scaling', 'decoder.layers.15.self_attn.v_proj.bias', 'decoder.layers.15.self_attn.v_proj.weight', 'decoder.layers.16.input_layernorm.weight', 'decoder.layers.16.mlp.down_proj.bias', 'decoder.layers.16.mlp.down_proj.weight', 'decoder.layers.16.mlp.gate_proj.bias', 'decoder.layers.16.mlp.gate_proj.weight', 'decoder.layers.16.mlp.layer_norm.bias', 'decoder.layers.16.mlp.layer_norm.weight', 'decoder.layers.16.self_attn.k_proj.bias', 'decoder.layers.16.self_attn.k_proj.weight', 'decoder.layers.16.self_attn.o_proj.bias', 'decoder.layers.16.self_attn.o_proj.weight', 'decoder.layers.16.self_attn.q_proj.bias', 'decoder.layers.16.self_attn.q_proj.weight', 'decoder.layers.16.self_attn.scaling', 'decoder.layers.16.self_attn.v_proj.bias', 'decoder.layers.16.self_attn.v_proj.weight', 'decoder.layers.17.input_layernorm.weight', 'decoder.layers.17.mlp.down_proj.bias', 'decoder.layers.17.mlp.down_proj.weight', 'decoder.layers.17.mlp.gate_proj.bias', 'decoder.layers.17.mlp.gate_proj.weight', 'decoder.layers.17.mlp.layer_norm.bias', 'decoder.layers.17.mlp.layer_norm.weight', 'decoder.layers.17.self_attn.k_proj.bias', 'decoder.layers.17.self_attn.k_proj.weight', 'decoder.layers.17.self_attn.o_proj.bias', 'decoder.layers.17.self_attn.o_proj.weight', 'decoder.layers.17.self_attn.q_proj.bias', 'decoder.layers.17.self_attn.q_proj.weight', 'decoder.layers.17.self_attn.scaling', 'decoder.layers.17.self_attn.v_proj.bias', 'decoder.layers.17.self_attn.v_proj.weight', 'decoder.layers.18.input_layernorm.weight', 'decoder.layers.18.mlp.down_proj.bias', 'decoder.layers.18.mlp.down_proj.weight', 'decoder.layers.18.mlp.gate_proj.bias', 'decoder.layers.18.mlp.gate_proj.weight', 'decoder.layers.18.mlp.layer_norm.bias', 'decoder.layers.18.mlp.layer_norm.weight', 'decoder.layers.18.self_attn.k_proj.bias', 'decoder.layers.18.self_attn.k_proj.weight', 'decoder.layers.18.self_attn.o_proj.bias', 'decoder.layers.18.self_attn.o_proj.weight', 'decoder.layers.18.self_attn.q_proj.bias', 'decoder.layers.18.self_attn.q_proj.weight', 'decoder.layers.18.self_attn.scaling', 'decoder.layers.18.self_attn.v_proj.bias', 'decoder.layers.18.self_attn.v_proj.weight', 'decoder.layers.19.input_layernorm.weight', 'decoder.layers.19.mlp.down_proj.bias', 'decoder.layers.19.mlp.down_proj.weight', 'decoder.layers.19.mlp.gate_proj.bias', 'decoder.layers.19.mlp.gate_proj.weight', 'decoder.layers.19.mlp.layer_norm.bias', 'decoder.layers.19.mlp.layer_norm.weight', 'decoder.layers.19.self_attn.k_proj.bias', 'decoder.layers.19.self_attn.k_proj.weight', 'decoder.layers.19.self_attn.o_proj.bias', 'decoder.layers.19.self_attn.o_proj.weight', 'decoder.layers.19.self_attn.q_proj.bias', 'decoder.layers.19.self_attn.q_proj.weight', 'decoder.layers.19.self_attn.scaling', 'decoder.layers.19.self_attn.v_proj.bias', 'decoder.layers.19.self_attn.v_proj.weight', 'decoder.layers.2.input_layernorm.weight', 'decoder.layers.2.mlp.down_proj.bias', 'decoder.layers.2.mlp.down_proj.weight', 'decoder.layers.2.mlp.gate_proj.bias', 'decoder.layers.2.mlp.gate_proj.weight', 'decoder.layers.2.mlp.layer_norm.bias', 'decoder.layers.2.mlp.layer_norm.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.o_proj.bias', 'decoder.layers.2.self_attn.o_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.scaling', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.3.input_layernorm.weight', 'decoder.layers.3.mlp.down_proj.bias', 'decoder.layers.3.mlp.down_proj.weight', 'decoder.layers.3.mlp.gate_proj.bias', 'decoder.layers.3.mlp.gate_proj.weight', 'decoder.layers.3.mlp.layer_norm.bias', 'decoder.layers.3.mlp.layer_norm.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.o_proj.bias', 'decoder.layers.3.self_attn.o_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.scaling', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.4.input_layernorm.weight', 'decoder.layers.4.mlp.down_proj.bias', 'decoder.layers.4.mlp.down_proj.weight', 'decoder.layers.4.mlp.gate_proj.bias', 'decoder.layers.4.mlp.gate_proj.weight', 'decoder.layers.4.mlp.layer_norm.bias', 'decoder.layers.4.mlp.layer_norm.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.o_proj.bias', 'decoder.layers.4.self_attn.o_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.scaling', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.5.input_layernorm.weight', 'decoder.layers.5.mlp.down_proj.bias', 'decoder.layers.5.mlp.down_proj.weight', 'decoder.layers.5.mlp.gate_proj.bias', 'decoder.layers.5.mlp.gate_proj.weight', 'decoder.layers.5.mlp.layer_norm.bias', 'decoder.layers.5.mlp.layer_norm.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.o_proj.bias', 'decoder.layers.5.self_attn.o_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.scaling', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.6.input_layernorm.weight', 'decoder.layers.6.mlp.down_proj.bias', 'decoder.layers.6.mlp.down_proj.weight', 'decoder.layers.6.mlp.gate_proj.bias', 'decoder.layers.6.mlp.gate_proj.weight', 'decoder.layers.6.mlp.layer_norm.bias', 'decoder.layers.6.mlp.layer_norm.weight', 'decoder.layers.6.self_attn.k_proj.bias', 'decoder.layers.6.self_attn.k_proj.weight', 'decoder.layers.6.self_attn.o_proj.bias', 'decoder.layers.6.self_attn.o_proj.weight', 'decoder.layers.6.self_attn.q_proj.bias', 'decoder.layers.6.self_attn.q_proj.weight', 'decoder.layers.6.self_attn.scaling', 'decoder.layers.6.self_attn.v_proj.bias', 'decoder.layers.6.self_attn.v_proj.weight', 'decoder.layers.7.input_layernorm.weight', 'decoder.layers.7.mlp.down_proj.bias', 'decoder.layers.7.mlp.down_proj.weight', 'decoder.layers.7.mlp.gate_proj.bias', 'decoder.layers.7.mlp.gate_proj.weight', 'decoder.layers.7.mlp.layer_norm.bias', 'decoder.layers.7.mlp.layer_norm.weight', 'decoder.layers.7.self_attn.k_proj.bias', 'decoder.layers.7.self_attn.k_proj.weight', 'decoder.layers.7.self_attn.o_proj.bias', 'decoder.layers.7.self_attn.o_proj.weight', 'decoder.layers.7.self_attn.q_proj.bias', 'decoder.layers.7.self_attn.q_proj.weight', 'decoder.layers.7.self_attn.scaling', 'decoder.layers.7.self_attn.v_proj.bias', 'decoder.layers.7.self_attn.v_proj.weight', 'decoder.layers.8.input_layernorm.weight', 'decoder.layers.8.mlp.down_proj.bias', 'decoder.layers.8.mlp.down_proj.weight', 'decoder.layers.8.mlp.gate_proj.bias', 'decoder.layers.8.mlp.gate_proj.weight', 'decoder.layers.8.mlp.layer_norm.bias', 'decoder.layers.8.mlp.layer_norm.weight', 'decoder.layers.8.self_attn.k_proj.bias', 'decoder.layers.8.self_attn.k_proj.weight', 'decoder.layers.8.self_attn.o_proj.bias', 'decoder.layers.8.self_attn.o_proj.weight', 'decoder.layers.8.self_attn.q_proj.bias', 'decoder.layers.8.self_attn.q_proj.weight', 'decoder.layers.8.self_attn.scaling', 'decoder.layers.8.self_attn.v_proj.bias', 'decoder.layers.8.self_attn.v_proj.weight', 'decoder.layers.9.input_layernorm.weight', 'decoder.layers.9.mlp.down_proj.bias', 'decoder.layers.9.mlp.down_proj.weight', 'decoder.layers.9.mlp.gate_proj.bias', 'decoder.layers.9.mlp.gate_proj.weight', 'decoder.layers.9.mlp.layer_norm.bias', 'decoder.layers.9.mlp.layer_norm.weight', 'decoder.layers.9.self_attn.k_proj.bias', 'decoder.layers.9.self_attn.k_proj.weight', 'decoder.layers.9.self_attn.o_proj.bias', 'decoder.layers.9.self_attn.o_proj.weight', 'decoder.layers.9.self_attn.q_proj.bias', 'decoder.layers.9.self_attn.q_proj.weight', 'decoder.layers.9.self_attn.scaling', 'decoder.layers.9.self_attn.v_proj.bias', 'decoder.layers.9.self_attn.v_proj.weight', 'horizon_ff_layer.input_layer.bias', 'horizon_ff_layer.input_layer.weight', 'horizon_ff_layer.output_layer.bias', 'horizon_ff_layer.output_layer.weight', 'horizon_ff_layer.residual_layer.bias', 'horizon_ff_layer.residual_layer.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n",
            "  Epoch 1/100 train_loss=1.8790 train_acc=0.3227 eval_loss=1.1959 eval_acc=0.5682 (best)\n",
            "  Epoch 2/100 train_loss=0.8172 train_acc=0.7136 eval_loss=1.0397 eval_acc=0.6247 (best)\n",
            "  Epoch 3/100 train_loss=0.4906 train_acc=0.8682 eval_loss=1.0921 eval_acc=0.6101 \n",
            "  Epoch 4/100 train_loss=0.2847 train_acc=0.9045 eval_loss=1.1861 eval_acc=0.6045 \n",
            "  Epoch 5/100 train_loss=0.1716 train_acc=0.9545 eval_loss=1.3358 eval_acc=0.6136 \n",
            "  Epoch 6/100 train_loss=0.0847 train_acc=0.9864 eval_loss=1.5886 eval_acc=0.5909 \n",
            "  Epoch 7/100 train_loss=0.1142 train_acc=0.9682 eval_loss=1.7398 eval_acc=0.5859 \n",
            "  Epoch 8/100 train_loss=0.0943 train_acc=0.9727 eval_loss=1.7196 eval_acc=0.6035 \n",
            "  Epoch 9/100 train_loss=0.0587 train_acc=0.9909 eval_loss=2.0098 eval_acc=0.5707 \n",
            "  Epoch 10/100 train_loss=0.0832 train_acc=0.9818 eval_loss=2.1436 eval_acc=0.5768 \n",
            "  Epoch 11/100 train_loss=0.0364 train_acc=0.9864 eval_loss=2.0799 eval_acc=0.5808 \n",
            "  Epoch 12/100 train_loss=0.0429 train_acc=0.9864 eval_loss=2.4133 eval_acc=0.5626 \n",
            "  Early stopping on google/timesfm-2.5-200m-pytorch: no improvement for 10 epochs (best epoch = 2)\n",
            "    tfm[google/timesfm-2.5-200m-pytorch] train_acc=0.7136 eval_acc=0.56262626262626258544230495317606255412101746\n",
            "    mrh_acc=0.6444 mr+h+kg_acc=0.6343 kg_acc=0.6283 ensemble=0.6389 (w=0.60)\n",
            "  Split 1/1 - accuracy=0.6389 time=510.4s\n",
            "Completed InsectWingbeatSound: Mean Acc=0.6389\n",
            "\n",
            "=== 52/109 ItalyPowerDemand ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  Decision: Heuristic says no filter (too short to filter)\n",
            "Error processing ItalyPowerDemand: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n",
            "\n",
            "=== 53/109 LargeKitchenAppliances ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 556, in main\n",
            "    results = evaluate_dataset_per_split(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 429, in evaluate_dataset_per_split\n",
            "    X_train_extra = np.concatenate([X_train_all, all_dec_train], axis=1)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "ValueError: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n",
            "    Gate split 1/5: baseline_loss=0.3888 adaptive_loss=0.4334\n",
            "    Gate split 2/5: baseline_loss=0.4642 adaptive_loss=0.4114\n",
            "    Gate split 3/5: baseline_loss=0.2614 adaptive_loss=0.1958\n",
            "    Gate split 4/5: baseline_loss=0.1674 adaptive_loss=0.2905\n",
            "    Gate split 5/5: baseline_loss=0.3572 adaptive_loss=0.5292\n",
            "  Decision: Adaptive rejected (loss 0.3720 vs baseline 0.3278, delta=+0.0442 > +0.0200); savgol(window=15, poly=3) - high noise (std_diff)\n",
            "\n",
            "=== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at google/timesfm-2.5-200m-pytorch were not used when initializing TimesFmModelForPrediction: ['output_projection_point.hidden_layer.weight', 'output_projection_point.output_layer.weight', 'output_projection_point.residual_layer.weight', 'output_projection_quantiles.hidden_layer.weight', 'output_projection_quantiles.output_layer.weight', 'output_projection_quantiles.residual_layer.weight', 'stacked_xf.0.attn.key_ln.scale', 'stacked_xf.0.attn.out.weight', 'stacked_xf.0.attn.per_dim_scale.per_dim_scale', 'stacked_xf.0.attn.qkv_proj.weight', 'stacked_xf.0.attn.query_ln.scale', 'stacked_xf.0.ff0.weight', 'stacked_xf.0.ff1.weight', 'stacked_xf.0.post_attn_ln.scale', 'stacked_xf.0.post_ff_ln.scale', 'stacked_xf.0.pre_attn_ln.scale', 'stacked_xf.0.pre_ff_ln.scale', 'stacked_xf.1.attn.key_ln.scale', 'stacked_xf.1.attn.out.weight', 'stacked_xf.1.attn.per_dim_scale.per_dim_scale', 'stacked_xf.1.attn.qkv_proj.weight', 'stacked_xf.1.attn.query_ln.scale', 'stacked_xf.1.ff0.weight', 'stacked_xf.1.ff1.weight', 'stacked_xf.1.post_attn_ln.scale', 'stacked_xf.1.post_ff_ln.scale', 'stacked_xf.1.pre_attn_ln.scale', 'stacked_xf.1.pre_ff_ln.scale', 'stacked_xf.10.attn.key_ln.scale', 'stacked_xf.10.attn.out.weight', 'stacked_xf.10.attn.per_dim_scale.per_dim_scale', 'stacked_xf.10.attn.qkv_proj.weight', 'stacked_xf.10.attn.query_ln.scale', 'stacked_xf.10.ff0.weight', 'stacked_xf.10.ff1.weight', 'stacked_xf.10.post_attn_ln.scale', 'stacked_xf.10.post_ff_ln.scale', 'stacked_xf.10.pre_attn_ln.scale', 'stacked_xf.10.pre_ff_ln.scale', 'stacked_xf.11.attn.key_ln.scale', 'stacked_xf.11.attn.out.weight', 'stacked_xf.11.attn.per_dim_scale.per_dim_scale', 'stacked_xf.11.attn.qkv_proj.weight', 'stacked_xf.11.attn.query_ln.scale', 'stacked_xf.11.ff0.weight', 'stacked_xf.11.ff1.weight', 'stacked_xf.11.post_attn_ln.scale', 'stacked_xf.11.post_ff_ln.scale', 'stacked_xf.11.pre_attn_ln.scale', 'stacked_xf.11.pre_ff_ln.scale', 'stacked_xf.12.attn.key_ln.scale', 'stacked_xf.12.attn.out.weight', 'stacked_xf.12.attn.per_dim_scale.per_dim_scale', 'stacked_xf.12.attn.qkv_proj.weight', 'stacked_xf.12.attn.query_ln.scale', 'stacked_xf.12.ff0.weight', 'stacked_xf.12.ff1.weight', 'stacked_xf.12.post_attn_ln.scale', 'stacked_xf.12.post_ff_ln.scale', 'stacked_xf.12.pre_attn_ln.scale', 'stacked_xf.12.pre_ff_ln.scale', 'stacked_xf.13.attn.key_ln.scale', 'stacked_xf.13.attn.out.weight', 'stacked_xf.13.attn.per_dim_scale.per_dim_scale', 'stacked_xf.13.attn.qkv_proj.weight', 'stacked_xf.13.attn.query_ln.scale', 'stacked_xf.13.ff0.weight', 'stacked_xf.13.ff1.weight', 'stacked_xf.13.post_attn_ln.scale', 'stacked_xf.13.post_ff_ln.scale', 'stacked_xf.13.pre_attn_ln.scale', 'stacked_xf.13.pre_ff_ln.scale', 'stacked_xf.14.attn.key_ln.scale', 'stacked_xf.14.attn.out.weight', 'stacked_xf.14.attn.per_dim_scale.per_dim_scale', 'stacked_xf.14.attn.qkv_proj.weight', 'stacked_xf.14.attn.query_ln.scale', 'stacked_xf.14.ff0.weight', 'stacked_xf.14.ff1.weight', 'stacked_xf.14.post_attn_ln.scale', 'stacked_xf.14.post_ff_ln.scale', 'stacked_xf.14.pre_attn_ln.scale', 'stacked_xf.14.pre_ff_ln.scale', 'stacked_xf.15.attn.key_ln.scale', 'stacked_xf.15.attn.out.weight', 'stacked_xf.15.attn.per_dim_scale.per_dim_scale', 'stacked_xf.15.attn.qkv_proj.weight', 'stacked_xf.15.attn.query_ln.scale', 'stacked_xf.15.ff0.weight', 'stacked_xf.15.ff1.weight', 'stacked_xf.15.post_attn_ln.scale', 'stacked_xf.15.post_ff_ln.scale', 'stacked_xf.15.pre_attn_ln.scale', 'stacked_xf.15.pre_ff_ln.scale', 'stacked_xf.16.attn.key_ln.scale', 'stacked_xf.16.attn.out.weight', 'stacked_xf.16.attn.per_dim_scale.per_dim_scale', 'stacked_xf.16.attn.qkv_proj.weight', 'stacked_xf.16.attn.query_ln.scale', 'stacked_xf.16.ff0.weight', 'stacked_xf.16.ff1.weight', 'stacked_xf.16.post_attn_ln.scale', 'stacked_xf.16.post_ff_ln.scale', 'stacked_xf.16.pre_attn_ln.scale', 'stacked_xf.16.pre_ff_ln.scale', 'stacked_xf.17.attn.key_ln.scale', 'stacked_xf.17.attn.out.weight', 'stacked_xf.17.attn.per_dim_scale.per_dim_scale', 'stacked_xf.17.attn.qkv_proj.weight', 'stacked_xf.17.attn.query_ln.scale', 'stacked_xf.17.ff0.weight', 'stacked_xf.17.ff1.weight', 'stacked_xf.17.post_attn_ln.scale', 'stacked_xf.17.post_ff_ln.scale', 'stacked_xf.17.pre_attn_ln.scale', 'stacked_xf.17.pre_ff_ln.scale', 'stacked_xf.18.attn.key_ln.scale', 'stacked_xf.18.attn.out.weight', 'stacked_xf.18.attn.per_dim_scale.per_dim_scale', 'stacked_xf.18.attn.qkv_proj.weight', 'stacked_xf.18.attn.query_ln.scale', 'stacked_xf.18.ff0.weight', 'stacked_xf.18.ff1.weight', 'stacked_xf.18.post_attn_ln.scale', 'stacked_xf.18.post_ff_ln.scale', 'stacked_xf.18.pre_attn_ln.scale', 'stacked_xf.18.pre_ff_ln.scale', 'stacked_xf.19.attn.key_ln.scale', 'stacked_xf.19.attn.out.weight', 'stacked_xf.19.attn.per_dim_scale.per_dim_scale', 'stacked_xf.19.attn.qkv_proj.weight', 'stacked_xf.19.attn.query_ln.scale', 'stacked_xf.19.ff0.weight', 'stacked_xf.19.ff1.weight', 'stacked_xf.19.post_attn_ln.scale', 'stacked_xf.19.post_ff_ln.scale', 'stacked_xf.19.pre_attn_ln.scale', 'stacked_xf.19.pre_ff_ln.scale', 'stacked_xf.2.attn.key_ln.scale', 'stacked_xf.2.attn.out.weight', 'stacked_xf.2.attn.per_dim_scale.per_dim_scale', 'stacked_xf.2.attn.qkv_proj.weight', 'stacked_xf.2.attn.query_ln.scale', 'stacked_xf.2.ff0.weight', 'stacked_xf.2.ff1.weight', 'stacked_xf.2.post_attn_ln.scale', 'stacked_xf.2.post_ff_ln.scale', 'stacked_xf.2.pre_attn_ln.scale', 'stacked_xf.2.pre_ff_ln.scale', 'stacked_xf.3.attn.key_ln.scale', 'stacked_xf.3.attn.out.weight', 'stacked_xf.3.attn.per_dim_scale.per_dim_scale', 'stacked_xf.3.attn.qkv_proj.weight', 'stacked_xf.3.attn.query_ln.scale', 'stacked_xf.3.ff0.weight', 'stacked_xf.3.ff1.weight', 'stacked_xf.3.post_attn_ln.scale', 'stacked_xf.3.post_ff_ln.scale', 'stacked_xf.3.pre_attn_ln.scale', 'stacked_xf.3.pre_ff_ln.scale', 'stacked_xf.4.attn.key_ln.scale', 'stacked_xf.4.attn.out.weight', 'stacked_xf.4.attn.per_dim_scale.per_dim_scale', 'stacked_xf.4.attn.qkv_proj.weight', 'stacked_xf.4.attn.query_ln.scale', 'stacked_xf.4.ff0.weight', 'stacked_xf.4.ff1.weight', 'stacked_xf.4.post_attn_ln.scale', 'stacked_xf.4.post_ff_ln.scale', 'stacked_xf.4.pre_attn_ln.scale', 'stacked_xf.4.pre_ff_ln.scale', 'stacked_xf.5.attn.key_ln.scale', 'stacked_xf.5.attn.out.weight', 'stacked_xf.5.attn.per_dim_scale.per_dim_scale', 'stacked_xf.5.attn.qkv_proj.weight', 'stacked_xf.5.attn.query_ln.scale', 'stacked_xf.5.ff0.weight', 'stacked_xf.5.ff1.weight', 'stacked_xf.5.post_attn_ln.scale', 'stacked_xf.5.post_ff_ln.scale', 'stacked_xf.5.pre_attn_ln.scale', 'stacked_xf.5.pre_ff_ln.scale', 'stacked_xf.6.attn.key_ln.scale', 'stacked_xf.6.attn.out.weight', 'stacked_xf.6.attn.per_dim_scale.per_dim_scale', 'stacked_xf.6.attn.qkv_proj.weight', 'stacked_xf.6.attn.query_ln.scale', 'stacked_xf.6.ff0.weight', 'stacked_xf.6.ff1.weight', 'stacked_xf.6.post_attn_ln.scale', 'stacked_xf.6.post_ff_ln.scale', 'stacked_xf.6.pre_attn_ln.scale', 'stacked_xf.6.pre_ff_ln.scale', 'stacked_xf.7.attn.key_ln.scale', 'stacked_xf.7.attn.out.weight', 'stacked_xf.7.attn.per_dim_scale.per_dim_scale', 'stacked_xf.7.attn.qkv_proj.weight', 'stacked_xf.7.attn.query_ln.scale', 'stacked_xf.7.ff0.weight', 'stacked_xf.7.ff1.weight', 'stacked_xf.7.post_attn_ln.scale', 'stacked_xf.7.post_ff_ln.scale', 'stacked_xf.7.pre_attn_ln.scale', 'stacked_xf.7.pre_ff_ln.scale', 'stacked_xf.8.attn.key_ln.scale', 'stacked_xf.8.attn.out.weight', 'stacked_xf.8.attn.per_dim_scale.per_dim_scale', 'stacked_xf.8.attn.qkv_proj.weight', 'stacked_xf.8.attn.query_ln.scale', 'stacked_xf.8.ff0.weight', 'stacked_xf.8.ff1.weight', 'stacked_xf.8.post_attn_ln.scale', 'stacked_xf.8.post_ff_ln.scale', 'stacked_xf.8.pre_attn_ln.scale', 'stacked_xf.8.pre_ff_ln.scale', 'stacked_xf.9.attn.key_ln.scale', 'stacked_xf.9.attn.out.weight', 'stacked_xf.9.attn.per_dim_scale.per_dim_scale', 'stacked_xf.9.attn.qkv_proj.weight', 'stacked_xf.9.attn.query_ln.scale', 'stacked_xf.9.ff0.weight', 'stacked_xf.9.ff1.weight', 'stacked_xf.9.post_attn_ln.scale', 'stacked_xf.9.post_ff_ln.scale', 'stacked_xf.9.pre_attn_ln.scale', 'stacked_xf.9.pre_ff_ln.scale', 'tokenizer.hidden_layer.bias', 'tokenizer.hidden_layer.weight', 'tokenizer.output_layer.bias', 'tokenizer.output_layer.weight', 'tokenizer.residual_layer.bias', 'tokenizer.residual_layer.weight']\n",
            "- This IS expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of TimesFmModelForPrediction were not initialized from the model checkpoint at google/timesfm-2.5-200m-pytorch and are newly initialized: ['decoder.freq_emb.weight', 'decoder.input_ff_layer.input_layer.bias', 'decoder.input_ff_layer.input_layer.weight', 'decoder.input_ff_layer.output_layer.bias', 'decoder.input_ff_layer.output_layer.weight', 'decoder.input_ff_layer.residual_layer.bias', 'decoder.input_ff_layer.residual_layer.weight', 'decoder.layers.0.input_layernorm.weight', 'decoder.layers.0.mlp.down_proj.bias', 'decoder.layers.0.mlp.down_proj.weight', 'decoder.layers.0.mlp.gate_proj.bias', 'decoder.layers.0.mlp.gate_proj.weight', 'decoder.layers.0.mlp.layer_norm.bias', 'decoder.layers.0.mlp.layer_norm.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.o_proj.bias', 'decoder.layers.0.self_attn.o_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.scaling', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.1.input_layernorm.weight', 'decoder.layers.1.mlp.down_proj.bias', 'decoder.layers.1.mlp.down_proj.weight', 'decoder.layers.1.mlp.gate_proj.bias', 'decoder.layers.1.mlp.gate_proj.weight', 'decoder.layers.1.mlp.layer_norm.bias', 'decoder.layers.1.mlp.layer_norm.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.o_proj.bias', 'decoder.layers.1.self_attn.o_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.scaling', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.10.input_layernorm.weight', 'decoder.layers.10.mlp.down_proj.bias', 'decoder.layers.10.mlp.down_proj.weight', 'decoder.layers.10.mlp.gate_proj.bias', 'decoder.layers.10.mlp.gate_proj.weight', 'decoder.layers.10.mlp.layer_norm.bias', 'decoder.layers.10.mlp.layer_norm.weight', 'decoder.layers.10.self_attn.k_proj.bias', 'decoder.layers.10.self_attn.k_proj.weight', 'decoder.layers.10.self_attn.o_proj.bias', 'decoder.layers.10.self_attn.o_proj.weight', 'decoder.layers.10.self_attn.q_proj.bias', 'decoder.layers.10.self_attn.q_proj.weight', 'decoder.layers.10.self_attn.scaling', 'decoder.layers.10.self_attn.v_proj.bias', 'decoder.layers.10.self_attn.v_proj.weight', 'decoder.layers.11.input_layernorm.weight', 'decoder.layers.11.mlp.down_proj.bias', 'decoder.layers.11.mlp.down_proj.weight', 'decoder.layers.11.mlp.gate_proj.bias', 'decoder.layers.11.mlp.gate_proj.weight', 'decoder.layers.11.mlp.layer_norm.bias', 'decoder.layers.11.mlp.layer_norm.weight', 'decoder.layers.11.self_attn.k_proj.bias', 'decoder.layers.11.self_attn.k_proj.weight', 'decoder.layers.11.self_attn.o_proj.bias', 'decoder.layers.11.self_attn.o_proj.weight', 'decoder.layers.11.self_attn.q_proj.bias', 'decoder.layers.11.self_attn.q_proj.weight', 'decoder.layers.11.self_attn.scaling', 'decoder.layers.11.self_attn.v_proj.bias', 'decoder.layers.11.self_attn.v_proj.weight', 'decoder.layers.12.input_layernorm.weight', 'decoder.layers.12.mlp.down_proj.bias', 'decoder.layers.12.mlp.down_proj.weight', 'decoder.layers.12.mlp.gate_proj.bias', 'decoder.layers.12.mlp.gate_proj.weight', 'decoder.layers.12.mlp.layer_norm.bias', 'decoder.layers.12.mlp.layer_norm.weight', 'decoder.layers.12.self_attn.k_proj.bias', 'decoder.layers.12.self_attn.k_proj.weight', 'decoder.layers.12.self_attn.o_proj.bias', 'decoder.layers.12.self_attn.o_proj.weight', 'decoder.layers.12.self_attn.q_proj.bias', 'decoder.layers.12.self_attn.q_proj.weight', 'decoder.layers.12.self_attn.scaling', 'decoder.layers.12.self_attn.v_proj.bias', 'decoder.layers.12.self_attn.v_proj.weight', 'decoder.layers.13.input_layernorm.weight', 'decoder.layers.13.mlp.down_proj.bias', 'decoder.layers.13.mlp.down_proj.weight', 'decoder.layers.13.mlp.gate_proj.bias', 'decoder.layers.13.mlp.gate_proj.weight', 'decoder.layers.13.mlp.layer_norm.bias', 'decoder.layers.13.mlp.layer_norm.weight', 'decoder.layers.13.self_attn.k_proj.bias', 'decoder.layers.13.self_attn.k_proj.weight', 'decoder.layers.13.self_attn.o_proj.bias', 'decoder.layers.13.self_attn.o_proj.weight', 'decoder.layers.13.self_attn.q_proj.bias', 'decoder.layers.13.self_attn.q_proj.weight', 'decoder.layers.13.self_attn.scaling', 'decoder.layers.13.self_attn.v_proj.bias', 'decoder.layers.13.self_attn.v_proj.weight', 'decoder.layers.14.input_layernorm.weight', 'decoder.layers.14.mlp.down_proj.bias', 'decoder.layers.14.mlp.down_proj.weight', 'decoder.layers.14.mlp.gate_proj.bias', 'decoder.layers.14.mlp.gate_proj.weight', 'decoder.layers.14.mlp.layer_norm.bias', 'decoder.layers.14.mlp.layer_norm.weight', 'decoder.layers.14.self_attn.k_proj.bias', 'decoder.layers.14.self_attn.k_proj.weight', 'decoder.layers.14.self_attn.o_proj.bias', 'decoder.layers.14.self_attn.o_proj.weight', 'decoder.layers.14.self_attn.q_proj.bias', 'decoder.layers.14.self_attn.q_proj.weight', 'decoder.layers.14.self_attn.scaling', 'decoder.layers.14.self_attn.v_proj.bias', 'decoder.layers.14.self_attn.v_proj.weight', 'decoder.layers.15.input_layernorm.weight', 'decoder.layers.15.mlp.down_proj.bias', 'decoder.layers.15.mlp.down_proj.weight', 'decoder.layers.15.mlp.gate_proj.bias', 'decoder.layers.15.mlp.gate_proj.weight', 'decoder.layers.15.mlp.layer_norm.bias', 'decoder.layers.15.mlp.layer_norm.weight', 'decoder.layers.15.self_attn.k_proj.bias', 'decoder.layers.15.self_attn.k_proj.weight', 'decoder.layers.15.self_attn.o_proj.bias', 'decoder.layers.15.self_attn.o_proj.weight', 'decoder.layers.15.self_attn.q_proj.bias', 'decoder.layers.15.self_attn.q_proj.weight', 'decoder.layers.15.self_attn.scaling', 'decoder.layers.15.self_attn.v_proj.bias', 'decoder.layers.15.self_attn.v_proj.weight', 'decoder.layers.16.input_layernorm.weight', 'decoder.layers.16.mlp.down_proj.bias', 'decoder.layers.16.mlp.down_proj.weight', 'decoder.layers.16.mlp.gate_proj.bias', 'decoder.layers.16.mlp.gate_proj.weight', 'decoder.layers.16.mlp.layer_norm.bias', 'decoder.layers.16.mlp.layer_norm.weight', 'decoder.layers.16.self_attn.k_proj.bias', 'decoder.layers.16.self_attn.k_proj.weight', 'decoder.layers.16.self_attn.o_proj.bias', 'decoder.layers.16.self_attn.o_proj.weight', 'decoder.layers.16.self_attn.q_proj.bias', 'decoder.layers.16.self_attn.q_proj.weight', 'decoder.layers.16.self_attn.scaling', 'decoder.layers.16.self_attn.v_proj.bias', 'decoder.layers.16.self_attn.v_proj.weight', 'decoder.layers.17.input_layernorm.weight', 'decoder.layers.17.mlp.down_proj.bias', 'decoder.layers.17.mlp.down_proj.weight', 'decoder.layers.17.mlp.gate_proj.bias', 'decoder.layers.17.mlp.gate_proj.weight', 'decoder.layers.17.mlp.layer_norm.bias', 'decoder.layers.17.mlp.layer_norm.weight', 'decoder.layers.17.self_attn.k_proj.bias', 'decoder.layers.17.self_attn.k_proj.weight', 'decoder.layers.17.self_attn.o_proj.bias', 'decoder.layers.17.self_attn.o_proj.weight', 'decoder.layers.17.self_attn.q_proj.bias', 'decoder.layers.17.self_attn.q_proj.weight', 'decoder.layers.17.self_attn.scaling', 'decoder.layers.17.self_attn.v_proj.bias', 'decoder.layers.17.self_attn.v_proj.weight', 'decoder.layers.18.input_layernorm.weight', 'decoder.layers.18.mlp.down_proj.bias', 'decoder.layers.18.mlp.down_proj.weight', 'decoder.layers.18.mlp.gate_proj.bias', 'decoder.layers.18.mlp.gate_proj.weight', 'decoder.layers.18.mlp.layer_norm.bias', 'decoder.layers.18.mlp.layer_norm.weight', 'decoder.layers.18.self_attn.k_proj.bias', 'decoder.layers.18.self_attn.k_proj.weight', 'decoder.layers.18.self_attn.o_proj.bias', 'decoder.layers.18.self_attn.o_proj.weight', 'decoder.layers.18.self_attn.q_proj.bias', 'decoder.layers.18.self_attn.q_proj.weight', 'decoder.layers.18.self_attn.scaling', 'decoder.layers.18.self_attn.v_proj.bias', 'decoder.layers.18.self_attn.v_proj.weight', 'decoder.layers.19.input_layernorm.weight', 'decoder.layers.19.mlp.down_proj.bias', 'decoder.layers.19.mlp.down_proj.weight', 'decoder.layers.19.mlp.gate_proj.bias', 'decoder.layers.19.mlp.gate_proj.weight', 'decoder.layers.19.mlp.layer_norm.bias', 'decoder.layers.19.mlp.layer_norm.weight', 'decoder.layers.19.self_attn.k_proj.bias', 'decoder.layers.19.self_attn.k_proj.weight', 'decoder.layers.19.self_attn.o_proj.bias', 'decoder.layers.19.self_attn.o_proj.weight', 'decoder.layers.19.self_attn.q_proj.bias', 'decoder.layers.19.self_attn.q_proj.weight', 'decoder.layers.19.self_attn.scaling', 'decoder.layers.19.self_attn.v_proj.bias', 'decoder.layers.19.self_attn.v_proj.weight', 'decoder.layers.2.input_layernorm.weight', 'decoder.layers.2.mlp.down_proj.bias', 'decoder.layers.2.mlp.down_proj.weight', 'decoder.layers.2.mlp.gate_proj.bias', 'decoder.layers.2.mlp.gate_proj.weight', 'decoder.layers.2.mlp.layer_norm.bias', 'decoder.layers.2.mlp.layer_norm.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.o_proj.bias', 'decoder.layers.2.self_attn.o_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.scaling', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.3.input_layernorm.weight', 'decoder.layers.3.mlp.down_proj.bias', 'decoder.layers.3.mlp.down_proj.weight', 'decoder.layers.3.mlp.gate_proj.bias', 'decoder.layers.3.mlp.gate_proj.weight', 'decoder.layers.3.mlp.layer_norm.bias', 'decoder.layers.3.mlp.layer_norm.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.o_proj.bias', 'decoder.layers.3.self_attn.o_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.scaling', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.4.input_layernorm.weight', 'decoder.layers.4.mlp.down_proj.bias', 'decoder.layers.4.mlp.down_proj.weight', 'decoder.layers.4.mlp.gate_proj.bias', 'decoder.layers.4.mlp.gate_proj.weight', 'decoder.layers.4.mlp.layer_norm.bias', 'decoder.layers.4.mlp.layer_norm.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.o_proj.bias', 'decoder.layers.4.self_attn.o_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.scaling', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.5.input_layernorm.weight', 'decoder.layers.5.mlp.down_proj.bias', 'decoder.layers.5.mlp.down_proj.weight', 'decoder.layers.5.mlp.gate_proj.bias', 'decoder.layers.5.mlp.gate_proj.weight', 'decoder.layers.5.mlp.layer_norm.bias', 'decoder.layers.5.mlp.layer_norm.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.o_proj.bias', 'decoder.layers.5.self_attn.o_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.scaling', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.6.input_layernorm.weight', 'decoder.layers.6.mlp.down_proj.bias', 'decoder.layers.6.mlp.down_proj.weight', 'decoder.layers.6.mlp.gate_proj.bias', 'decoder.layers.6.mlp.gate_proj.weight', 'decoder.layers.6.mlp.layer_norm.bias', 'decoder.layers.6.mlp.layer_norm.weight', 'decoder.layers.6.self_attn.k_proj.bias', 'decoder.layers.6.self_attn.k_proj.weight', 'decoder.layers.6.self_attn.o_proj.bias', 'decoder.layers.6.self_attn.o_proj.weight', 'decoder.layers.6.self_attn.q_proj.bias', 'decoder.layers.6.self_attn.q_proj.weight', 'decoder.layers.6.self_attn.scaling', 'decoder.layers.6.self_attn.v_proj.bias', 'decoder.layers.6.self_attn.v_proj.weight', 'decoder.layers.7.input_layernorm.weight', 'decoder.layers.7.mlp.down_proj.bias', 'decoder.layers.7.mlp.down_proj.weight', 'decoder.layers.7.mlp.gate_proj.bias', 'decoder.layers.7.mlp.gate_proj.weight', 'decoder.layers.7.mlp.layer_norm.bias', 'decoder.layers.7.mlp.layer_norm.weight', 'decoder.layers.7.self_attn.k_proj.bias', 'decoder.layers.7.self_attn.k_proj.weight', 'decoder.layers.7.self_attn.o_proj.bias', 'decoder.layers.7.self_attn.o_proj.weight', 'decoder.layers.7.self_attn.q_proj.bias', 'decoder.layers.7.self_attn.q_proj.weight', 'decoder.layers.7.self_attn.scaling', 'decoder.layers.7.self_attn.v_proj.bias', 'decoder.layers.7.self_attn.v_proj.weight', 'decoder.layers.8.input_layernorm.weight', 'decoder.layers.8.mlp.down_proj.bias', 'decoder.layers.8.mlp.down_proj.weight', 'decoder.layers.8.mlp.gate_proj.bias', 'decoder.layers.8.mlp.gate_proj.weight', 'decoder.layers.8.mlp.layer_norm.bias', 'decoder.layers.8.mlp.layer_norm.weight', 'decoder.layers.8.self_attn.k_proj.bias', 'decoder.layers.8.self_attn.k_proj.weight', 'decoder.layers.8.self_attn.o_proj.bias', 'decoder.layers.8.self_attn.o_proj.weight', 'decoder.layers.8.self_attn.q_proj.bias', 'decoder.layers.8.self_attn.q_proj.weight', 'decoder.layers.8.self_attn.scaling', 'decoder.layers.8.self_attn.v_proj.bias', 'decoder.layers.8.self_attn.v_proj.weight', 'decoder.layers.9.input_layernorm.weight', 'decoder.layers.9.mlp.down_proj.bias', 'decoder.layers.9.mlp.down_proj.weight', 'decoder.layers.9.mlp.gate_proj.bias', 'decoder.layers.9.mlp.gate_proj.weight', 'decoder.layers.9.mlp.layer_norm.bias', 'decoder.layers.9.mlp.layer_norm.weight', 'decoder.layers.9.self_attn.k_proj.bias', 'decoder.layers.9.self_attn.k_proj.weight', 'decoder.layers.9.self_attn.o_proj.bias', 'decoder.layers.9.self_attn.o_proj.weight', 'decoder.layers.9.self_attn.q_proj.bias', 'decoder.layers.9.self_attn.q_proj.weight', 'decoder.layers.9.self_attn.scaling', 'decoder.layers.9.self_attn.v_proj.bias', 'decoder.layers.9.self_attn.v_proj.weight', 'horizon_ff_layer.input_layer.bias', 'horizon_ff_layer.input_layer.weight', 'horizon_ff_layer.output_layer.bias', 'horizon_ff_layer.output_layer.weight', 'horizon_ff_layer.residual_layer.bias', 'horizon_ff_layer.residual_layer.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n",
            "  Epoch 1/100 train_loss=0.7733 train_acc=0.6453 eval_loss=0.4660 eval_acc=0.8213 (best)\n",
            "  Epoch 2/100 train_loss=0.2840 train_acc=0.9093 eval_loss=0.4381 eval_acc=0.8613 (best)\n",
            "  Epoch 3/100 train_loss=0.1742 train_acc=0.9547 eval_loss=0.3579 eval_acc=0.8693 (best)\n",
            "  Epoch 4/100 train_loss=0.1187 train_acc=0.9680 eval_loss=0.3230 eval_acc=0.9067 (best)\n",
            "  Epoch 5/100 train_loss=0.0544 train_acc=0.9867 eval_loss=0.3855 eval_acc=0.8907 \n",
            "  Epoch 6/100 train_loss=0.1096 train_acc=0.9600 eval_loss=0.4970 eval_acc=0.8560 \n",
            "  Epoch 7/100 train_loss=0.2016 train_acc=0.9333 eval_loss=0.7726 eval_acc=0.8347 \n",
            "  Epoch 8/100 train_loss=0.1063 train_acc=0.9627 eval_loss=0.5923 eval_acc=0.8720 \n",
            "  Epoch 9/100 train_loss=0.1805 train_acc=0.9440 eval_loss=1.1608 eval_acc=0.8080 \n",
            "  Epoch 10/100 train_loss=0.2047 train_acc=0.9520 eval_loss=0.8027 eval_acc=0.8853 \n",
            "  Epoch 11/100 train_loss=0.1871 train_acc=0.9387 eval_loss=0.9877 eval_acc=0.8533 \n",
            "  Epoch 12/100 train_loss=0.0788 train_acc=0.9707 eval_loss=0.6747 eval_acc=0.8507 \n",
            "  Epoch 13/100 train_loss=0.0495 train_acc=0.9920 eval_loss=0.9335 eval_acc=0.8853 \n",
            "  Epoch 14/100 train_loss=0.0446 train_acc=0.9840 eval_loss=0.7684 eval_acc=0.9013 \n",
            "  Early stopping on google/timesfm-2.5-200m-pytorch: no improvement for 10 epochs (best epoch = 4)\n",
            "    tfm[google/timesfm-2.5-200m-pytorch] train_acc=0.9680 eval_acc=0.90133333333333331971459756459807977080345154\n",
            "    mrh_acc=0.9520 mr+h+kg_acc=0.9467 kg_acc=0.9520 ensemble=0.9547 (w=0.60)\n",
            "  Split 1/1 - accuracy=0.9547 time=336.3s\n",
            "Completed LargeKitchenAppliances: Mean Acc=0.9547\n",
            "\n",
            "=== 54/109 Lightning2 ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n",
            "    Gate split 1/5: baseline_loss=0.7162 adaptive_loss=0.6920\n",
            "    Gate split 2/5: baseline_loss=0.6825 adaptive_loss=0.5979\n",
            "    Gate split 3/5: baseline_loss=0.7891 adaptive_loss=0.7058\n",
            "    Gate split 4/5: baseline_loss=0.5076 adaptive_loss=0.5725\n",
            "    Gate split 5/5: baseline_loss=0.8481 adaptive_loss=0.7883\n",
            "  Decision: Adaptive kept (loss 0.6713 vs baseline 0.7087, delta=-0.0374 <= +0.0200); savgol(window=15, poly=3) - high noise (std_diff)\n",
            "Error processing Lightning2: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n",
            "\n",
            "=== 55/109 Lightning7 ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 556, in main\n",
            "    results = evaluate_dataset_per_split(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 429, in evaluate_dataset_per_split\n",
            "    X_train_extra = np.concatenate([X_train_all, all_dec_train], axis=1)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "ValueError: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Gate split 1/5: baseline_loss=0.5797 adaptive_loss=0.5479\n",
            "    Gate split 2/5: baseline_loss=0.4829 adaptive_loss=0.3686\n",
            "    Gate split 3/5: baseline_loss=0.3968 adaptive_loss=0.3918\n",
            "    Gate split 4/5: baseline_loss=0.4902 adaptive_loss=0.4655\n",
            "    Gate split 5/5: baseline_loss=0.5266 adaptive_loss=0.4760\n",
            "  Decision: Adaptive kept (loss 0.4500 vs baseline 0.4952, delta=-0.0452 <= +0.0200); savgol(window=11, poly=2) - high noise (std_diff)\n",
            "\n",
            "=== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at google/timesfm-2.5-200m-pytorch were not used when initializing TimesFmModelForPrediction: ['output_projection_point.hidden_layer.weight', 'output_projection_point.output_layer.weight', 'output_projection_point.residual_layer.weight', 'output_projection_quantiles.hidden_layer.weight', 'output_projection_quantiles.output_layer.weight', 'output_projection_quantiles.residual_layer.weight', 'stacked_xf.0.attn.key_ln.scale', 'stacked_xf.0.attn.out.weight', 'stacked_xf.0.attn.per_dim_scale.per_dim_scale', 'stacked_xf.0.attn.qkv_proj.weight', 'stacked_xf.0.attn.query_ln.scale', 'stacked_xf.0.ff0.weight', 'stacked_xf.0.ff1.weight', 'stacked_xf.0.post_attn_ln.scale', 'stacked_xf.0.post_ff_ln.scale', 'stacked_xf.0.pre_attn_ln.scale', 'stacked_xf.0.pre_ff_ln.scale', 'stacked_xf.1.attn.key_ln.scale', 'stacked_xf.1.attn.out.weight', 'stacked_xf.1.attn.per_dim_scale.per_dim_scale', 'stacked_xf.1.attn.qkv_proj.weight', 'stacked_xf.1.attn.query_ln.scale', 'stacked_xf.1.ff0.weight', 'stacked_xf.1.ff1.weight', 'stacked_xf.1.post_attn_ln.scale', 'stacked_xf.1.post_ff_ln.scale', 'stacked_xf.1.pre_attn_ln.scale', 'stacked_xf.1.pre_ff_ln.scale', 'stacked_xf.10.attn.key_ln.scale', 'stacked_xf.10.attn.out.weight', 'stacked_xf.10.attn.per_dim_scale.per_dim_scale', 'stacked_xf.10.attn.qkv_proj.weight', 'stacked_xf.10.attn.query_ln.scale', 'stacked_xf.10.ff0.weight', 'stacked_xf.10.ff1.weight', 'stacked_xf.10.post_attn_ln.scale', 'stacked_xf.10.post_ff_ln.scale', 'stacked_xf.10.pre_attn_ln.scale', 'stacked_xf.10.pre_ff_ln.scale', 'stacked_xf.11.attn.key_ln.scale', 'stacked_xf.11.attn.out.weight', 'stacked_xf.11.attn.per_dim_scale.per_dim_scale', 'stacked_xf.11.attn.qkv_proj.weight', 'stacked_xf.11.attn.query_ln.scale', 'stacked_xf.11.ff0.weight', 'stacked_xf.11.ff1.weight', 'stacked_xf.11.post_attn_ln.scale', 'stacked_xf.11.post_ff_ln.scale', 'stacked_xf.11.pre_attn_ln.scale', 'stacked_xf.11.pre_ff_ln.scale', 'stacked_xf.12.attn.key_ln.scale', 'stacked_xf.12.attn.out.weight', 'stacked_xf.12.attn.per_dim_scale.per_dim_scale', 'stacked_xf.12.attn.qkv_proj.weight', 'stacked_xf.12.attn.query_ln.scale', 'stacked_xf.12.ff0.weight', 'stacked_xf.12.ff1.weight', 'stacked_xf.12.post_attn_ln.scale', 'stacked_xf.12.post_ff_ln.scale', 'stacked_xf.12.pre_attn_ln.scale', 'stacked_xf.12.pre_ff_ln.scale', 'stacked_xf.13.attn.key_ln.scale', 'stacked_xf.13.attn.out.weight', 'stacked_xf.13.attn.per_dim_scale.per_dim_scale', 'stacked_xf.13.attn.qkv_proj.weight', 'stacked_xf.13.attn.query_ln.scale', 'stacked_xf.13.ff0.weight', 'stacked_xf.13.ff1.weight', 'stacked_xf.13.post_attn_ln.scale', 'stacked_xf.13.post_ff_ln.scale', 'stacked_xf.13.pre_attn_ln.scale', 'stacked_xf.13.pre_ff_ln.scale', 'stacked_xf.14.attn.key_ln.scale', 'stacked_xf.14.attn.out.weight', 'stacked_xf.14.attn.per_dim_scale.per_dim_scale', 'stacked_xf.14.attn.qkv_proj.weight', 'stacked_xf.14.attn.query_ln.scale', 'stacked_xf.14.ff0.weight', 'stacked_xf.14.ff1.weight', 'stacked_xf.14.post_attn_ln.scale', 'stacked_xf.14.post_ff_ln.scale', 'stacked_xf.14.pre_attn_ln.scale', 'stacked_xf.14.pre_ff_ln.scale', 'stacked_xf.15.attn.key_ln.scale', 'stacked_xf.15.attn.out.weight', 'stacked_xf.15.attn.per_dim_scale.per_dim_scale', 'stacked_xf.15.attn.qkv_proj.weight', 'stacked_xf.15.attn.query_ln.scale', 'stacked_xf.15.ff0.weight', 'stacked_xf.15.ff1.weight', 'stacked_xf.15.post_attn_ln.scale', 'stacked_xf.15.post_ff_ln.scale', 'stacked_xf.15.pre_attn_ln.scale', 'stacked_xf.15.pre_ff_ln.scale', 'stacked_xf.16.attn.key_ln.scale', 'stacked_xf.16.attn.out.weight', 'stacked_xf.16.attn.per_dim_scale.per_dim_scale', 'stacked_xf.16.attn.qkv_proj.weight', 'stacked_xf.16.attn.query_ln.scale', 'stacked_xf.16.ff0.weight', 'stacked_xf.16.ff1.weight', 'stacked_xf.16.post_attn_ln.scale', 'stacked_xf.16.post_ff_ln.scale', 'stacked_xf.16.pre_attn_ln.scale', 'stacked_xf.16.pre_ff_ln.scale', 'stacked_xf.17.attn.key_ln.scale', 'stacked_xf.17.attn.out.weight', 'stacked_xf.17.attn.per_dim_scale.per_dim_scale', 'stacked_xf.17.attn.qkv_proj.weight', 'stacked_xf.17.attn.query_ln.scale', 'stacked_xf.17.ff0.weight', 'stacked_xf.17.ff1.weight', 'stacked_xf.17.post_attn_ln.scale', 'stacked_xf.17.post_ff_ln.scale', 'stacked_xf.17.pre_attn_ln.scale', 'stacked_xf.17.pre_ff_ln.scale', 'stacked_xf.18.attn.key_ln.scale', 'stacked_xf.18.attn.out.weight', 'stacked_xf.18.attn.per_dim_scale.per_dim_scale', 'stacked_xf.18.attn.qkv_proj.weight', 'stacked_xf.18.attn.query_ln.scale', 'stacked_xf.18.ff0.weight', 'stacked_xf.18.ff1.weight', 'stacked_xf.18.post_attn_ln.scale', 'stacked_xf.18.post_ff_ln.scale', 'stacked_xf.18.pre_attn_ln.scale', 'stacked_xf.18.pre_ff_ln.scale', 'stacked_xf.19.attn.key_ln.scale', 'stacked_xf.19.attn.out.weight', 'stacked_xf.19.attn.per_dim_scale.per_dim_scale', 'stacked_xf.19.attn.qkv_proj.weight', 'stacked_xf.19.attn.query_ln.scale', 'stacked_xf.19.ff0.weight', 'stacked_xf.19.ff1.weight', 'stacked_xf.19.post_attn_ln.scale', 'stacked_xf.19.post_ff_ln.scale', 'stacked_xf.19.pre_attn_ln.scale', 'stacked_xf.19.pre_ff_ln.scale', 'stacked_xf.2.attn.key_ln.scale', 'stacked_xf.2.attn.out.weight', 'stacked_xf.2.attn.per_dim_scale.per_dim_scale', 'stacked_xf.2.attn.qkv_proj.weight', 'stacked_xf.2.attn.query_ln.scale', 'stacked_xf.2.ff0.weight', 'stacked_xf.2.ff1.weight', 'stacked_xf.2.post_attn_ln.scale', 'stacked_xf.2.post_ff_ln.scale', 'stacked_xf.2.pre_attn_ln.scale', 'stacked_xf.2.pre_ff_ln.scale', 'stacked_xf.3.attn.key_ln.scale', 'stacked_xf.3.attn.out.weight', 'stacked_xf.3.attn.per_dim_scale.per_dim_scale', 'stacked_xf.3.attn.qkv_proj.weight', 'stacked_xf.3.attn.query_ln.scale', 'stacked_xf.3.ff0.weight', 'stacked_xf.3.ff1.weight', 'stacked_xf.3.post_attn_ln.scale', 'stacked_xf.3.post_ff_ln.scale', 'stacked_xf.3.pre_attn_ln.scale', 'stacked_xf.3.pre_ff_ln.scale', 'stacked_xf.4.attn.key_ln.scale', 'stacked_xf.4.attn.out.weight', 'stacked_xf.4.attn.per_dim_scale.per_dim_scale', 'stacked_xf.4.attn.qkv_proj.weight', 'stacked_xf.4.attn.query_ln.scale', 'stacked_xf.4.ff0.weight', 'stacked_xf.4.ff1.weight', 'stacked_xf.4.post_attn_ln.scale', 'stacked_xf.4.post_ff_ln.scale', 'stacked_xf.4.pre_attn_ln.scale', 'stacked_xf.4.pre_ff_ln.scale', 'stacked_xf.5.attn.key_ln.scale', 'stacked_xf.5.attn.out.weight', 'stacked_xf.5.attn.per_dim_scale.per_dim_scale', 'stacked_xf.5.attn.qkv_proj.weight', 'stacked_xf.5.attn.query_ln.scale', 'stacked_xf.5.ff0.weight', 'stacked_xf.5.ff1.weight', 'stacked_xf.5.post_attn_ln.scale', 'stacked_xf.5.post_ff_ln.scale', 'stacked_xf.5.pre_attn_ln.scale', 'stacked_xf.5.pre_ff_ln.scale', 'stacked_xf.6.attn.key_ln.scale', 'stacked_xf.6.attn.out.weight', 'stacked_xf.6.attn.per_dim_scale.per_dim_scale', 'stacked_xf.6.attn.qkv_proj.weight', 'stacked_xf.6.attn.query_ln.scale', 'stacked_xf.6.ff0.weight', 'stacked_xf.6.ff1.weight', 'stacked_xf.6.post_attn_ln.scale', 'stacked_xf.6.post_ff_ln.scale', 'stacked_xf.6.pre_attn_ln.scale', 'stacked_xf.6.pre_ff_ln.scale', 'stacked_xf.7.attn.key_ln.scale', 'stacked_xf.7.attn.out.weight', 'stacked_xf.7.attn.per_dim_scale.per_dim_scale', 'stacked_xf.7.attn.qkv_proj.weight', 'stacked_xf.7.attn.query_ln.scale', 'stacked_xf.7.ff0.weight', 'stacked_xf.7.ff1.weight', 'stacked_xf.7.post_attn_ln.scale', 'stacked_xf.7.post_ff_ln.scale', 'stacked_xf.7.pre_attn_ln.scale', 'stacked_xf.7.pre_ff_ln.scale', 'stacked_xf.8.attn.key_ln.scale', 'stacked_xf.8.attn.out.weight', 'stacked_xf.8.attn.per_dim_scale.per_dim_scale', 'stacked_xf.8.attn.qkv_proj.weight', 'stacked_xf.8.attn.query_ln.scale', 'stacked_xf.8.ff0.weight', 'stacked_xf.8.ff1.weight', 'stacked_xf.8.post_attn_ln.scale', 'stacked_xf.8.post_ff_ln.scale', 'stacked_xf.8.pre_attn_ln.scale', 'stacked_xf.8.pre_ff_ln.scale', 'stacked_xf.9.attn.key_ln.scale', 'stacked_xf.9.attn.out.weight', 'stacked_xf.9.attn.per_dim_scale.per_dim_scale', 'stacked_xf.9.attn.qkv_proj.weight', 'stacked_xf.9.attn.query_ln.scale', 'stacked_xf.9.ff0.weight', 'stacked_xf.9.ff1.weight', 'stacked_xf.9.post_attn_ln.scale', 'stacked_xf.9.post_ff_ln.scale', 'stacked_xf.9.pre_attn_ln.scale', 'stacked_xf.9.pre_ff_ln.scale', 'tokenizer.hidden_layer.bias', 'tokenizer.hidden_layer.weight', 'tokenizer.output_layer.bias', 'tokenizer.output_layer.weight', 'tokenizer.residual_layer.bias', 'tokenizer.residual_layer.weight']\n",
            "- This IS expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of TimesFmModelForPrediction were not initialized from the model checkpoint at google/timesfm-2.5-200m-pytorch and are newly initialized: ['decoder.freq_emb.weight', 'decoder.input_ff_layer.input_layer.bias', 'decoder.input_ff_layer.input_layer.weight', 'decoder.input_ff_layer.output_layer.bias', 'decoder.input_ff_layer.output_layer.weight', 'decoder.input_ff_layer.residual_layer.bias', 'decoder.input_ff_layer.residual_layer.weight', 'decoder.layers.0.input_layernorm.weight', 'decoder.layers.0.mlp.down_proj.bias', 'decoder.layers.0.mlp.down_proj.weight', 'decoder.layers.0.mlp.gate_proj.bias', 'decoder.layers.0.mlp.gate_proj.weight', 'decoder.layers.0.mlp.layer_norm.bias', 'decoder.layers.0.mlp.layer_norm.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.o_proj.bias', 'decoder.layers.0.self_attn.o_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.scaling', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.1.input_layernorm.weight', 'decoder.layers.1.mlp.down_proj.bias', 'decoder.layers.1.mlp.down_proj.weight', 'decoder.layers.1.mlp.gate_proj.bias', 'decoder.layers.1.mlp.gate_proj.weight', 'decoder.layers.1.mlp.layer_norm.bias', 'decoder.layers.1.mlp.layer_norm.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.o_proj.bias', 'decoder.layers.1.self_attn.o_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.scaling', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.10.input_layernorm.weight', 'decoder.layers.10.mlp.down_proj.bias', 'decoder.layers.10.mlp.down_proj.weight', 'decoder.layers.10.mlp.gate_proj.bias', 'decoder.layers.10.mlp.gate_proj.weight', 'decoder.layers.10.mlp.layer_norm.bias', 'decoder.layers.10.mlp.layer_norm.weight', 'decoder.layers.10.self_attn.k_proj.bias', 'decoder.layers.10.self_attn.k_proj.weight', 'decoder.layers.10.self_attn.o_proj.bias', 'decoder.layers.10.self_attn.o_proj.weight', 'decoder.layers.10.self_attn.q_proj.bias', 'decoder.layers.10.self_attn.q_proj.weight', 'decoder.layers.10.self_attn.scaling', 'decoder.layers.10.self_attn.v_proj.bias', 'decoder.layers.10.self_attn.v_proj.weight', 'decoder.layers.11.input_layernorm.weight', 'decoder.layers.11.mlp.down_proj.bias', 'decoder.layers.11.mlp.down_proj.weight', 'decoder.layers.11.mlp.gate_proj.bias', 'decoder.layers.11.mlp.gate_proj.weight', 'decoder.layers.11.mlp.layer_norm.bias', 'decoder.layers.11.mlp.layer_norm.weight', 'decoder.layers.11.self_attn.k_proj.bias', 'decoder.layers.11.self_attn.k_proj.weight', 'decoder.layers.11.self_attn.o_proj.bias', 'decoder.layers.11.self_attn.o_proj.weight', 'decoder.layers.11.self_attn.q_proj.bias', 'decoder.layers.11.self_attn.q_proj.weight', 'decoder.layers.11.self_attn.scaling', 'decoder.layers.11.self_attn.v_proj.bias', 'decoder.layers.11.self_attn.v_proj.weight', 'decoder.layers.12.input_layernorm.weight', 'decoder.layers.12.mlp.down_proj.bias', 'decoder.layers.12.mlp.down_proj.weight', 'decoder.layers.12.mlp.gate_proj.bias', 'decoder.layers.12.mlp.gate_proj.weight', 'decoder.layers.12.mlp.layer_norm.bias', 'decoder.layers.12.mlp.layer_norm.weight', 'decoder.layers.12.self_attn.k_proj.bias', 'decoder.layers.12.self_attn.k_proj.weight', 'decoder.layers.12.self_attn.o_proj.bias', 'decoder.layers.12.self_attn.o_proj.weight', 'decoder.layers.12.self_attn.q_proj.bias', 'decoder.layers.12.self_attn.q_proj.weight', 'decoder.layers.12.self_attn.scaling', 'decoder.layers.12.self_attn.v_proj.bias', 'decoder.layers.12.self_attn.v_proj.weight', 'decoder.layers.13.input_layernorm.weight', 'decoder.layers.13.mlp.down_proj.bias', 'decoder.layers.13.mlp.down_proj.weight', 'decoder.layers.13.mlp.gate_proj.bias', 'decoder.layers.13.mlp.gate_proj.weight', 'decoder.layers.13.mlp.layer_norm.bias', 'decoder.layers.13.mlp.layer_norm.weight', 'decoder.layers.13.self_attn.k_proj.bias', 'decoder.layers.13.self_attn.k_proj.weight', 'decoder.layers.13.self_attn.o_proj.bias', 'decoder.layers.13.self_attn.o_proj.weight', 'decoder.layers.13.self_attn.q_proj.bias', 'decoder.layers.13.self_attn.q_proj.weight', 'decoder.layers.13.self_attn.scaling', 'decoder.layers.13.self_attn.v_proj.bias', 'decoder.layers.13.self_attn.v_proj.weight', 'decoder.layers.14.input_layernorm.weight', 'decoder.layers.14.mlp.down_proj.bias', 'decoder.layers.14.mlp.down_proj.weight', 'decoder.layers.14.mlp.gate_proj.bias', 'decoder.layers.14.mlp.gate_proj.weight', 'decoder.layers.14.mlp.layer_norm.bias', 'decoder.layers.14.mlp.layer_norm.weight', 'decoder.layers.14.self_attn.k_proj.bias', 'decoder.layers.14.self_attn.k_proj.weight', 'decoder.layers.14.self_attn.o_proj.bias', 'decoder.layers.14.self_attn.o_proj.weight', 'decoder.layers.14.self_attn.q_proj.bias', 'decoder.layers.14.self_attn.q_proj.weight', 'decoder.layers.14.self_attn.scaling', 'decoder.layers.14.self_attn.v_proj.bias', 'decoder.layers.14.self_attn.v_proj.weight', 'decoder.layers.15.input_layernorm.weight', 'decoder.layers.15.mlp.down_proj.bias', 'decoder.layers.15.mlp.down_proj.weight', 'decoder.layers.15.mlp.gate_proj.bias', 'decoder.layers.15.mlp.gate_proj.weight', 'decoder.layers.15.mlp.layer_norm.bias', 'decoder.layers.15.mlp.layer_norm.weight', 'decoder.layers.15.self_attn.k_proj.bias', 'decoder.layers.15.self_attn.k_proj.weight', 'decoder.layers.15.self_attn.o_proj.bias', 'decoder.layers.15.self_attn.o_proj.weight', 'decoder.layers.15.self_attn.q_proj.bias', 'decoder.layers.15.self_attn.q_proj.weight', 'decoder.layers.15.self_attn.scaling', 'decoder.layers.15.self_attn.v_proj.bias', 'decoder.layers.15.self_attn.v_proj.weight', 'decoder.layers.16.input_layernorm.weight', 'decoder.layers.16.mlp.down_proj.bias', 'decoder.layers.16.mlp.down_proj.weight', 'decoder.layers.16.mlp.gate_proj.bias', 'decoder.layers.16.mlp.gate_proj.weight', 'decoder.layers.16.mlp.layer_norm.bias', 'decoder.layers.16.mlp.layer_norm.weight', 'decoder.layers.16.self_attn.k_proj.bias', 'decoder.layers.16.self_attn.k_proj.weight', 'decoder.layers.16.self_attn.o_proj.bias', 'decoder.layers.16.self_attn.o_proj.weight', 'decoder.layers.16.self_attn.q_proj.bias', 'decoder.layers.16.self_attn.q_proj.weight', 'decoder.layers.16.self_attn.scaling', 'decoder.layers.16.self_attn.v_proj.bias', 'decoder.layers.16.self_attn.v_proj.weight', 'decoder.layers.17.input_layernorm.weight', 'decoder.layers.17.mlp.down_proj.bias', 'decoder.layers.17.mlp.down_proj.weight', 'decoder.layers.17.mlp.gate_proj.bias', 'decoder.layers.17.mlp.gate_proj.weight', 'decoder.layers.17.mlp.layer_norm.bias', 'decoder.layers.17.mlp.layer_norm.weight', 'decoder.layers.17.self_attn.k_proj.bias', 'decoder.layers.17.self_attn.k_proj.weight', 'decoder.layers.17.self_attn.o_proj.bias', 'decoder.layers.17.self_attn.o_proj.weight', 'decoder.layers.17.self_attn.q_proj.bias', 'decoder.layers.17.self_attn.q_proj.weight', 'decoder.layers.17.self_attn.scaling', 'decoder.layers.17.self_attn.v_proj.bias', 'decoder.layers.17.self_attn.v_proj.weight', 'decoder.layers.18.input_layernorm.weight', 'decoder.layers.18.mlp.down_proj.bias', 'decoder.layers.18.mlp.down_proj.weight', 'decoder.layers.18.mlp.gate_proj.bias', 'decoder.layers.18.mlp.gate_proj.weight', 'decoder.layers.18.mlp.layer_norm.bias', 'decoder.layers.18.mlp.layer_norm.weight', 'decoder.layers.18.self_attn.k_proj.bias', 'decoder.layers.18.self_attn.k_proj.weight', 'decoder.layers.18.self_attn.o_proj.bias', 'decoder.layers.18.self_attn.o_proj.weight', 'decoder.layers.18.self_attn.q_proj.bias', 'decoder.layers.18.self_attn.q_proj.weight', 'decoder.layers.18.self_attn.scaling', 'decoder.layers.18.self_attn.v_proj.bias', 'decoder.layers.18.self_attn.v_proj.weight', 'decoder.layers.19.input_layernorm.weight', 'decoder.layers.19.mlp.down_proj.bias', 'decoder.layers.19.mlp.down_proj.weight', 'decoder.layers.19.mlp.gate_proj.bias', 'decoder.layers.19.mlp.gate_proj.weight', 'decoder.layers.19.mlp.layer_norm.bias', 'decoder.layers.19.mlp.layer_norm.weight', 'decoder.layers.19.self_attn.k_proj.bias', 'decoder.layers.19.self_attn.k_proj.weight', 'decoder.layers.19.self_attn.o_proj.bias', 'decoder.layers.19.self_attn.o_proj.weight', 'decoder.layers.19.self_attn.q_proj.bias', 'decoder.layers.19.self_attn.q_proj.weight', 'decoder.layers.19.self_attn.scaling', 'decoder.layers.19.self_attn.v_proj.bias', 'decoder.layers.19.self_attn.v_proj.weight', 'decoder.layers.2.input_layernorm.weight', 'decoder.layers.2.mlp.down_proj.bias', 'decoder.layers.2.mlp.down_proj.weight', 'decoder.layers.2.mlp.gate_proj.bias', 'decoder.layers.2.mlp.gate_proj.weight', 'decoder.layers.2.mlp.layer_norm.bias', 'decoder.layers.2.mlp.layer_norm.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.o_proj.bias', 'decoder.layers.2.self_attn.o_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.scaling', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.3.input_layernorm.weight', 'decoder.layers.3.mlp.down_proj.bias', 'decoder.layers.3.mlp.down_proj.weight', 'decoder.layers.3.mlp.gate_proj.bias', 'decoder.layers.3.mlp.gate_proj.weight', 'decoder.layers.3.mlp.layer_norm.bias', 'decoder.layers.3.mlp.layer_norm.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.o_proj.bias', 'decoder.layers.3.self_attn.o_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.scaling', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.4.input_layernorm.weight', 'decoder.layers.4.mlp.down_proj.bias', 'decoder.layers.4.mlp.down_proj.weight', 'decoder.layers.4.mlp.gate_proj.bias', 'decoder.layers.4.mlp.gate_proj.weight', 'decoder.layers.4.mlp.layer_norm.bias', 'decoder.layers.4.mlp.layer_norm.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.o_proj.bias', 'decoder.layers.4.self_attn.o_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.scaling', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.5.input_layernorm.weight', 'decoder.layers.5.mlp.down_proj.bias', 'decoder.layers.5.mlp.down_proj.weight', 'decoder.layers.5.mlp.gate_proj.bias', 'decoder.layers.5.mlp.gate_proj.weight', 'decoder.layers.5.mlp.layer_norm.bias', 'decoder.layers.5.mlp.layer_norm.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.o_proj.bias', 'decoder.layers.5.self_attn.o_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.scaling', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.6.input_layernorm.weight', 'decoder.layers.6.mlp.down_proj.bias', 'decoder.layers.6.mlp.down_proj.weight', 'decoder.layers.6.mlp.gate_proj.bias', 'decoder.layers.6.mlp.gate_proj.weight', 'decoder.layers.6.mlp.layer_norm.bias', 'decoder.layers.6.mlp.layer_norm.weight', 'decoder.layers.6.self_attn.k_proj.bias', 'decoder.layers.6.self_attn.k_proj.weight', 'decoder.layers.6.self_attn.o_proj.bias', 'decoder.layers.6.self_attn.o_proj.weight', 'decoder.layers.6.self_attn.q_proj.bias', 'decoder.layers.6.self_attn.q_proj.weight', 'decoder.layers.6.self_attn.scaling', 'decoder.layers.6.self_attn.v_proj.bias', 'decoder.layers.6.self_attn.v_proj.weight', 'decoder.layers.7.input_layernorm.weight', 'decoder.layers.7.mlp.down_proj.bias', 'decoder.layers.7.mlp.down_proj.weight', 'decoder.layers.7.mlp.gate_proj.bias', 'decoder.layers.7.mlp.gate_proj.weight', 'decoder.layers.7.mlp.layer_norm.bias', 'decoder.layers.7.mlp.layer_norm.weight', 'decoder.layers.7.self_attn.k_proj.bias', 'decoder.layers.7.self_attn.k_proj.weight', 'decoder.layers.7.self_attn.o_proj.bias', 'decoder.layers.7.self_attn.o_proj.weight', 'decoder.layers.7.self_attn.q_proj.bias', 'decoder.layers.7.self_attn.q_proj.weight', 'decoder.layers.7.self_attn.scaling', 'decoder.layers.7.self_attn.v_proj.bias', 'decoder.layers.7.self_attn.v_proj.weight', 'decoder.layers.8.input_layernorm.weight', 'decoder.layers.8.mlp.down_proj.bias', 'decoder.layers.8.mlp.down_proj.weight', 'decoder.layers.8.mlp.gate_proj.bias', 'decoder.layers.8.mlp.gate_proj.weight', 'decoder.layers.8.mlp.layer_norm.bias', 'decoder.layers.8.mlp.layer_norm.weight', 'decoder.layers.8.self_attn.k_proj.bias', 'decoder.layers.8.self_attn.k_proj.weight', 'decoder.layers.8.self_attn.o_proj.bias', 'decoder.layers.8.self_attn.o_proj.weight', 'decoder.layers.8.self_attn.q_proj.bias', 'decoder.layers.8.self_attn.q_proj.weight', 'decoder.layers.8.self_attn.scaling', 'decoder.layers.8.self_attn.v_proj.bias', 'decoder.layers.8.self_attn.v_proj.weight', 'decoder.layers.9.input_layernorm.weight', 'decoder.layers.9.mlp.down_proj.bias', 'decoder.layers.9.mlp.down_proj.weight', 'decoder.layers.9.mlp.gate_proj.bias', 'decoder.layers.9.mlp.gate_proj.weight', 'decoder.layers.9.mlp.layer_norm.bias', 'decoder.layers.9.mlp.layer_norm.weight', 'decoder.layers.9.self_attn.k_proj.bias', 'decoder.layers.9.self_attn.k_proj.weight', 'decoder.layers.9.self_attn.o_proj.bias', 'decoder.layers.9.self_attn.o_proj.weight', 'decoder.layers.9.self_attn.q_proj.bias', 'decoder.layers.9.self_attn.q_proj.weight', 'decoder.layers.9.self_attn.scaling', 'decoder.layers.9.self_attn.v_proj.bias', 'decoder.layers.9.self_attn.v_proj.weight', 'horizon_ff_layer.input_layer.bias', 'horizon_ff_layer.input_layer.weight', 'horizon_ff_layer.output_layer.bias', 'horizon_ff_layer.output_layer.weight', 'horizon_ff_layer.residual_layer.bias', 'horizon_ff_layer.residual_layer.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n",
            "  Epoch 1/100 train_loss=1.8523 train_acc=0.2429 eval_loss=1.1910 eval_acc=0.5890 (best)\n",
            "  Epoch 2/100 train_loss=0.7431 train_acc=0.7286 eval_loss=0.8301 eval_acc=0.7260 (best)\n",
            "  Epoch 3/100 train_loss=0.4038 train_acc=0.9143 eval_loss=0.7674 eval_acc=0.6986 (best)\n",
            "  Epoch 4/100 train_loss=0.1703 train_acc=0.9429 eval_loss=0.6499 eval_acc=0.8082 (best)\n",
            "  Epoch 5/100 train_loss=0.0620 train_acc=0.9857 eval_loss=0.7088 eval_acc=0.7671 \n",
            "  Epoch 6/100 train_loss=0.0292 train_acc=1.0000 eval_loss=0.8880 eval_acc=0.7671 \n",
            "  Epoch 7/100 train_loss=0.0054 train_acc=1.0000 eval_loss=1.0797 eval_acc=0.7945 \n",
            "  Epoch 8/100 train_loss=0.0022 train_acc=1.0000 eval_loss=1.3044 eval_acc=0.7808 \n",
            "  Epoch 9/100 train_loss=0.0010 train_acc=1.0000 eval_loss=1.6244 eval_acc=0.7260 \n",
            "  Epoch 10/100 train_loss=0.0034 train_acc=1.0000 eval_loss=1.8039 eval_acc=0.7260 \n",
            "  Epoch 11/100 train_loss=0.0007 train_acc=1.0000 eval_loss=1.8489 eval_acc=0.7397 \n",
            "  Epoch 12/100 train_loss=0.0002 train_acc=1.0000 eval_loss=1.8734 eval_acc=0.7397 \n",
            "  Epoch 13/100 train_loss=0.0001 train_acc=1.0000 eval_loss=1.8852 eval_acc=0.7397 \n",
            "  Epoch 14/100 train_loss=0.0001 train_acc=1.0000 eval_loss=1.8933 eval_acc=0.7534 \n",
            "  Early stopping on google/timesfm-2.5-200m-pytorch: no improvement for 10 epochs (best epoch = 4)\n",
            "    tfm[google/timesfm-2.5-200m-pytorch] train_acc=0.9429 eval_acc=0.75342465753424658903014687894028611481189728\n",
            "    mrh_acc=0.8082 mr+h+kg_acc=0.8082 kg_acc=0.8219 ensemble=0.8219 (w=0.60)\n",
            "  Split 1/1 - accuracy=0.8219 time=70.2s\n",
            "Completed Lightning7: Mean Acc=0.8219\n",
            "\n",
            "=== 56/109 Mallat ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n",
            "    Gate split 1/5: baseline_loss=0.2643 adaptive_loss=0.3383\n",
            "    Gate split 2/5: baseline_loss=0.1755 adaptive_loss=0.2353\n",
            "    Gate split 3/5: baseline_loss=0.3607 adaptive_loss=0.3771\n",
            "    Gate split 4/5: baseline_loss=0.3207 adaptive_loss=0.3122\n",
            "    Gate split 5/5: baseline_loss=0.3050 adaptive_loss=0.3310\n",
            "  Decision: Adaptive rejected (loss 0.3188 vs baseline 0.2852, delta=+0.0335 > +0.0200); savgol(window=21, poly=3) - high noise (std_diff)\n",
            "\n",
            "=== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at google/timesfm-2.5-200m-pytorch were not used when initializing TimesFmModelForPrediction: ['output_projection_point.hidden_layer.weight', 'output_projection_point.output_layer.weight', 'output_projection_point.residual_layer.weight', 'output_projection_quantiles.hidden_layer.weight', 'output_projection_quantiles.output_layer.weight', 'output_projection_quantiles.residual_layer.weight', 'stacked_xf.0.attn.key_ln.scale', 'stacked_xf.0.attn.out.weight', 'stacked_xf.0.attn.per_dim_scale.per_dim_scale', 'stacked_xf.0.attn.qkv_proj.weight', 'stacked_xf.0.attn.query_ln.scale', 'stacked_xf.0.ff0.weight', 'stacked_xf.0.ff1.weight', 'stacked_xf.0.post_attn_ln.scale', 'stacked_xf.0.post_ff_ln.scale', 'stacked_xf.0.pre_attn_ln.scale', 'stacked_xf.0.pre_ff_ln.scale', 'stacked_xf.1.attn.key_ln.scale', 'stacked_xf.1.attn.out.weight', 'stacked_xf.1.attn.per_dim_scale.per_dim_scale', 'stacked_xf.1.attn.qkv_proj.weight', 'stacked_xf.1.attn.query_ln.scale', 'stacked_xf.1.ff0.weight', 'stacked_xf.1.ff1.weight', 'stacked_xf.1.post_attn_ln.scale', 'stacked_xf.1.post_ff_ln.scale', 'stacked_xf.1.pre_attn_ln.scale', 'stacked_xf.1.pre_ff_ln.scale', 'stacked_xf.10.attn.key_ln.scale', 'stacked_xf.10.attn.out.weight', 'stacked_xf.10.attn.per_dim_scale.per_dim_scale', 'stacked_xf.10.attn.qkv_proj.weight', 'stacked_xf.10.attn.query_ln.scale', 'stacked_xf.10.ff0.weight', 'stacked_xf.10.ff1.weight', 'stacked_xf.10.post_attn_ln.scale', 'stacked_xf.10.post_ff_ln.scale', 'stacked_xf.10.pre_attn_ln.scale', 'stacked_xf.10.pre_ff_ln.scale', 'stacked_xf.11.attn.key_ln.scale', 'stacked_xf.11.attn.out.weight', 'stacked_xf.11.attn.per_dim_scale.per_dim_scale', 'stacked_xf.11.attn.qkv_proj.weight', 'stacked_xf.11.attn.query_ln.scale', 'stacked_xf.11.ff0.weight', 'stacked_xf.11.ff1.weight', 'stacked_xf.11.post_attn_ln.scale', 'stacked_xf.11.post_ff_ln.scale', 'stacked_xf.11.pre_attn_ln.scale', 'stacked_xf.11.pre_ff_ln.scale', 'stacked_xf.12.attn.key_ln.scale', 'stacked_xf.12.attn.out.weight', 'stacked_xf.12.attn.per_dim_scale.per_dim_scale', 'stacked_xf.12.attn.qkv_proj.weight', 'stacked_xf.12.attn.query_ln.scale', 'stacked_xf.12.ff0.weight', 'stacked_xf.12.ff1.weight', 'stacked_xf.12.post_attn_ln.scale', 'stacked_xf.12.post_ff_ln.scale', 'stacked_xf.12.pre_attn_ln.scale', 'stacked_xf.12.pre_ff_ln.scale', 'stacked_xf.13.attn.key_ln.scale', 'stacked_xf.13.attn.out.weight', 'stacked_xf.13.attn.per_dim_scale.per_dim_scale', 'stacked_xf.13.attn.qkv_proj.weight', 'stacked_xf.13.attn.query_ln.scale', 'stacked_xf.13.ff0.weight', 'stacked_xf.13.ff1.weight', 'stacked_xf.13.post_attn_ln.scale', 'stacked_xf.13.post_ff_ln.scale', 'stacked_xf.13.pre_attn_ln.scale', 'stacked_xf.13.pre_ff_ln.scale', 'stacked_xf.14.attn.key_ln.scale', 'stacked_xf.14.attn.out.weight', 'stacked_xf.14.attn.per_dim_scale.per_dim_scale', 'stacked_xf.14.attn.qkv_proj.weight', 'stacked_xf.14.attn.query_ln.scale', 'stacked_xf.14.ff0.weight', 'stacked_xf.14.ff1.weight', 'stacked_xf.14.post_attn_ln.scale', 'stacked_xf.14.post_ff_ln.scale', 'stacked_xf.14.pre_attn_ln.scale', 'stacked_xf.14.pre_ff_ln.scale', 'stacked_xf.15.attn.key_ln.scale', 'stacked_xf.15.attn.out.weight', 'stacked_xf.15.attn.per_dim_scale.per_dim_scale', 'stacked_xf.15.attn.qkv_proj.weight', 'stacked_xf.15.attn.query_ln.scale', 'stacked_xf.15.ff0.weight', 'stacked_xf.15.ff1.weight', 'stacked_xf.15.post_attn_ln.scale', 'stacked_xf.15.post_ff_ln.scale', 'stacked_xf.15.pre_attn_ln.scale', 'stacked_xf.15.pre_ff_ln.scale', 'stacked_xf.16.attn.key_ln.scale', 'stacked_xf.16.attn.out.weight', 'stacked_xf.16.attn.per_dim_scale.per_dim_scale', 'stacked_xf.16.attn.qkv_proj.weight', 'stacked_xf.16.attn.query_ln.scale', 'stacked_xf.16.ff0.weight', 'stacked_xf.16.ff1.weight', 'stacked_xf.16.post_attn_ln.scale', 'stacked_xf.16.post_ff_ln.scale', 'stacked_xf.16.pre_attn_ln.scale', 'stacked_xf.16.pre_ff_ln.scale', 'stacked_xf.17.attn.key_ln.scale', 'stacked_xf.17.attn.out.weight', 'stacked_xf.17.attn.per_dim_scale.per_dim_scale', 'stacked_xf.17.attn.qkv_proj.weight', 'stacked_xf.17.attn.query_ln.scale', 'stacked_xf.17.ff0.weight', 'stacked_xf.17.ff1.weight', 'stacked_xf.17.post_attn_ln.scale', 'stacked_xf.17.post_ff_ln.scale', 'stacked_xf.17.pre_attn_ln.scale', 'stacked_xf.17.pre_ff_ln.scale', 'stacked_xf.18.attn.key_ln.scale', 'stacked_xf.18.attn.out.weight', 'stacked_xf.18.attn.per_dim_scale.per_dim_scale', 'stacked_xf.18.attn.qkv_proj.weight', 'stacked_xf.18.attn.query_ln.scale', 'stacked_xf.18.ff0.weight', 'stacked_xf.18.ff1.weight', 'stacked_xf.18.post_attn_ln.scale', 'stacked_xf.18.post_ff_ln.scale', 'stacked_xf.18.pre_attn_ln.scale', 'stacked_xf.18.pre_ff_ln.scale', 'stacked_xf.19.attn.key_ln.scale', 'stacked_xf.19.attn.out.weight', 'stacked_xf.19.attn.per_dim_scale.per_dim_scale', 'stacked_xf.19.attn.qkv_proj.weight', 'stacked_xf.19.attn.query_ln.scale', 'stacked_xf.19.ff0.weight', 'stacked_xf.19.ff1.weight', 'stacked_xf.19.post_attn_ln.scale', 'stacked_xf.19.post_ff_ln.scale', 'stacked_xf.19.pre_attn_ln.scale', 'stacked_xf.19.pre_ff_ln.scale', 'stacked_xf.2.attn.key_ln.scale', 'stacked_xf.2.attn.out.weight', 'stacked_xf.2.attn.per_dim_scale.per_dim_scale', 'stacked_xf.2.attn.qkv_proj.weight', 'stacked_xf.2.attn.query_ln.scale', 'stacked_xf.2.ff0.weight', 'stacked_xf.2.ff1.weight', 'stacked_xf.2.post_attn_ln.scale', 'stacked_xf.2.post_ff_ln.scale', 'stacked_xf.2.pre_attn_ln.scale', 'stacked_xf.2.pre_ff_ln.scale', 'stacked_xf.3.attn.key_ln.scale', 'stacked_xf.3.attn.out.weight', 'stacked_xf.3.attn.per_dim_scale.per_dim_scale', 'stacked_xf.3.attn.qkv_proj.weight', 'stacked_xf.3.attn.query_ln.scale', 'stacked_xf.3.ff0.weight', 'stacked_xf.3.ff1.weight', 'stacked_xf.3.post_attn_ln.scale', 'stacked_xf.3.post_ff_ln.scale', 'stacked_xf.3.pre_attn_ln.scale', 'stacked_xf.3.pre_ff_ln.scale', 'stacked_xf.4.attn.key_ln.scale', 'stacked_xf.4.attn.out.weight', 'stacked_xf.4.attn.per_dim_scale.per_dim_scale', 'stacked_xf.4.attn.qkv_proj.weight', 'stacked_xf.4.attn.query_ln.scale', 'stacked_xf.4.ff0.weight', 'stacked_xf.4.ff1.weight', 'stacked_xf.4.post_attn_ln.scale', 'stacked_xf.4.post_ff_ln.scale', 'stacked_xf.4.pre_attn_ln.scale', 'stacked_xf.4.pre_ff_ln.scale', 'stacked_xf.5.attn.key_ln.scale', 'stacked_xf.5.attn.out.weight', 'stacked_xf.5.attn.per_dim_scale.per_dim_scale', 'stacked_xf.5.attn.qkv_proj.weight', 'stacked_xf.5.attn.query_ln.scale', 'stacked_xf.5.ff0.weight', 'stacked_xf.5.ff1.weight', 'stacked_xf.5.post_attn_ln.scale', 'stacked_xf.5.post_ff_ln.scale', 'stacked_xf.5.pre_attn_ln.scale', 'stacked_xf.5.pre_ff_ln.scale', 'stacked_xf.6.attn.key_ln.scale', 'stacked_xf.6.attn.out.weight', 'stacked_xf.6.attn.per_dim_scale.per_dim_scale', 'stacked_xf.6.attn.qkv_proj.weight', 'stacked_xf.6.attn.query_ln.scale', 'stacked_xf.6.ff0.weight', 'stacked_xf.6.ff1.weight', 'stacked_xf.6.post_attn_ln.scale', 'stacked_xf.6.post_ff_ln.scale', 'stacked_xf.6.pre_attn_ln.scale', 'stacked_xf.6.pre_ff_ln.scale', 'stacked_xf.7.attn.key_ln.scale', 'stacked_xf.7.attn.out.weight', 'stacked_xf.7.attn.per_dim_scale.per_dim_scale', 'stacked_xf.7.attn.qkv_proj.weight', 'stacked_xf.7.attn.query_ln.scale', 'stacked_xf.7.ff0.weight', 'stacked_xf.7.ff1.weight', 'stacked_xf.7.post_attn_ln.scale', 'stacked_xf.7.post_ff_ln.scale', 'stacked_xf.7.pre_attn_ln.scale', 'stacked_xf.7.pre_ff_ln.scale', 'stacked_xf.8.attn.key_ln.scale', 'stacked_xf.8.attn.out.weight', 'stacked_xf.8.attn.per_dim_scale.per_dim_scale', 'stacked_xf.8.attn.qkv_proj.weight', 'stacked_xf.8.attn.query_ln.scale', 'stacked_xf.8.ff0.weight', 'stacked_xf.8.ff1.weight', 'stacked_xf.8.post_attn_ln.scale', 'stacked_xf.8.post_ff_ln.scale', 'stacked_xf.8.pre_attn_ln.scale', 'stacked_xf.8.pre_ff_ln.scale', 'stacked_xf.9.attn.key_ln.scale', 'stacked_xf.9.attn.out.weight', 'stacked_xf.9.attn.per_dim_scale.per_dim_scale', 'stacked_xf.9.attn.qkv_proj.weight', 'stacked_xf.9.attn.query_ln.scale', 'stacked_xf.9.ff0.weight', 'stacked_xf.9.ff1.weight', 'stacked_xf.9.post_attn_ln.scale', 'stacked_xf.9.post_ff_ln.scale', 'stacked_xf.9.pre_attn_ln.scale', 'stacked_xf.9.pre_ff_ln.scale', 'tokenizer.hidden_layer.bias', 'tokenizer.hidden_layer.weight', 'tokenizer.output_layer.bias', 'tokenizer.output_layer.weight', 'tokenizer.residual_layer.bias', 'tokenizer.residual_layer.weight']\n",
            "- This IS expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of TimesFmModelForPrediction were not initialized from the model checkpoint at google/timesfm-2.5-200m-pytorch and are newly initialized: ['decoder.freq_emb.weight', 'decoder.input_ff_layer.input_layer.bias', 'decoder.input_ff_layer.input_layer.weight', 'decoder.input_ff_layer.output_layer.bias', 'decoder.input_ff_layer.output_layer.weight', 'decoder.input_ff_layer.residual_layer.bias', 'decoder.input_ff_layer.residual_layer.weight', 'decoder.layers.0.input_layernorm.weight', 'decoder.layers.0.mlp.down_proj.bias', 'decoder.layers.0.mlp.down_proj.weight', 'decoder.layers.0.mlp.gate_proj.bias', 'decoder.layers.0.mlp.gate_proj.weight', 'decoder.layers.0.mlp.layer_norm.bias', 'decoder.layers.0.mlp.layer_norm.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.o_proj.bias', 'decoder.layers.0.self_attn.o_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.scaling', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.1.input_layernorm.weight', 'decoder.layers.1.mlp.down_proj.bias', 'decoder.layers.1.mlp.down_proj.weight', 'decoder.layers.1.mlp.gate_proj.bias', 'decoder.layers.1.mlp.gate_proj.weight', 'decoder.layers.1.mlp.layer_norm.bias', 'decoder.layers.1.mlp.layer_norm.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.o_proj.bias', 'decoder.layers.1.self_attn.o_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.scaling', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.10.input_layernorm.weight', 'decoder.layers.10.mlp.down_proj.bias', 'decoder.layers.10.mlp.down_proj.weight', 'decoder.layers.10.mlp.gate_proj.bias', 'decoder.layers.10.mlp.gate_proj.weight', 'decoder.layers.10.mlp.layer_norm.bias', 'decoder.layers.10.mlp.layer_norm.weight', 'decoder.layers.10.self_attn.k_proj.bias', 'decoder.layers.10.self_attn.k_proj.weight', 'decoder.layers.10.self_attn.o_proj.bias', 'decoder.layers.10.self_attn.o_proj.weight', 'decoder.layers.10.self_attn.q_proj.bias', 'decoder.layers.10.self_attn.q_proj.weight', 'decoder.layers.10.self_attn.scaling', 'decoder.layers.10.self_attn.v_proj.bias', 'decoder.layers.10.self_attn.v_proj.weight', 'decoder.layers.11.input_layernorm.weight', 'decoder.layers.11.mlp.down_proj.bias', 'decoder.layers.11.mlp.down_proj.weight', 'decoder.layers.11.mlp.gate_proj.bias', 'decoder.layers.11.mlp.gate_proj.weight', 'decoder.layers.11.mlp.layer_norm.bias', 'decoder.layers.11.mlp.layer_norm.weight', 'decoder.layers.11.self_attn.k_proj.bias', 'decoder.layers.11.self_attn.k_proj.weight', 'decoder.layers.11.self_attn.o_proj.bias', 'decoder.layers.11.self_attn.o_proj.weight', 'decoder.layers.11.self_attn.q_proj.bias', 'decoder.layers.11.self_attn.q_proj.weight', 'decoder.layers.11.self_attn.scaling', 'decoder.layers.11.self_attn.v_proj.bias', 'decoder.layers.11.self_attn.v_proj.weight', 'decoder.layers.12.input_layernorm.weight', 'decoder.layers.12.mlp.down_proj.bias', 'decoder.layers.12.mlp.down_proj.weight', 'decoder.layers.12.mlp.gate_proj.bias', 'decoder.layers.12.mlp.gate_proj.weight', 'decoder.layers.12.mlp.layer_norm.bias', 'decoder.layers.12.mlp.layer_norm.weight', 'decoder.layers.12.self_attn.k_proj.bias', 'decoder.layers.12.self_attn.k_proj.weight', 'decoder.layers.12.self_attn.o_proj.bias', 'decoder.layers.12.self_attn.o_proj.weight', 'decoder.layers.12.self_attn.q_proj.bias', 'decoder.layers.12.self_attn.q_proj.weight', 'decoder.layers.12.self_attn.scaling', 'decoder.layers.12.self_attn.v_proj.bias', 'decoder.layers.12.self_attn.v_proj.weight', 'decoder.layers.13.input_layernorm.weight', 'decoder.layers.13.mlp.down_proj.bias', 'decoder.layers.13.mlp.down_proj.weight', 'decoder.layers.13.mlp.gate_proj.bias', 'decoder.layers.13.mlp.gate_proj.weight', 'decoder.layers.13.mlp.layer_norm.bias', 'decoder.layers.13.mlp.layer_norm.weight', 'decoder.layers.13.self_attn.k_proj.bias', 'decoder.layers.13.self_attn.k_proj.weight', 'decoder.layers.13.self_attn.o_proj.bias', 'decoder.layers.13.self_attn.o_proj.weight', 'decoder.layers.13.self_attn.q_proj.bias', 'decoder.layers.13.self_attn.q_proj.weight', 'decoder.layers.13.self_attn.scaling', 'decoder.layers.13.self_attn.v_proj.bias', 'decoder.layers.13.self_attn.v_proj.weight', 'decoder.layers.14.input_layernorm.weight', 'decoder.layers.14.mlp.down_proj.bias', 'decoder.layers.14.mlp.down_proj.weight', 'decoder.layers.14.mlp.gate_proj.bias', 'decoder.layers.14.mlp.gate_proj.weight', 'decoder.layers.14.mlp.layer_norm.bias', 'decoder.layers.14.mlp.layer_norm.weight', 'decoder.layers.14.self_attn.k_proj.bias', 'decoder.layers.14.self_attn.k_proj.weight', 'decoder.layers.14.self_attn.o_proj.bias', 'decoder.layers.14.self_attn.o_proj.weight', 'decoder.layers.14.self_attn.q_proj.bias', 'decoder.layers.14.self_attn.q_proj.weight', 'decoder.layers.14.self_attn.scaling', 'decoder.layers.14.self_attn.v_proj.bias', 'decoder.layers.14.self_attn.v_proj.weight', 'decoder.layers.15.input_layernorm.weight', 'decoder.layers.15.mlp.down_proj.bias', 'decoder.layers.15.mlp.down_proj.weight', 'decoder.layers.15.mlp.gate_proj.bias', 'decoder.layers.15.mlp.gate_proj.weight', 'decoder.layers.15.mlp.layer_norm.bias', 'decoder.layers.15.mlp.layer_norm.weight', 'decoder.layers.15.self_attn.k_proj.bias', 'decoder.layers.15.self_attn.k_proj.weight', 'decoder.layers.15.self_attn.o_proj.bias', 'decoder.layers.15.self_attn.o_proj.weight', 'decoder.layers.15.self_attn.q_proj.bias', 'decoder.layers.15.self_attn.q_proj.weight', 'decoder.layers.15.self_attn.scaling', 'decoder.layers.15.self_attn.v_proj.bias', 'decoder.layers.15.self_attn.v_proj.weight', 'decoder.layers.16.input_layernorm.weight', 'decoder.layers.16.mlp.down_proj.bias', 'decoder.layers.16.mlp.down_proj.weight', 'decoder.layers.16.mlp.gate_proj.bias', 'decoder.layers.16.mlp.gate_proj.weight', 'decoder.layers.16.mlp.layer_norm.bias', 'decoder.layers.16.mlp.layer_norm.weight', 'decoder.layers.16.self_attn.k_proj.bias', 'decoder.layers.16.self_attn.k_proj.weight', 'decoder.layers.16.self_attn.o_proj.bias', 'decoder.layers.16.self_attn.o_proj.weight', 'decoder.layers.16.self_attn.q_proj.bias', 'decoder.layers.16.self_attn.q_proj.weight', 'decoder.layers.16.self_attn.scaling', 'decoder.layers.16.self_attn.v_proj.bias', 'decoder.layers.16.self_attn.v_proj.weight', 'decoder.layers.17.input_layernorm.weight', 'decoder.layers.17.mlp.down_proj.bias', 'decoder.layers.17.mlp.down_proj.weight', 'decoder.layers.17.mlp.gate_proj.bias', 'decoder.layers.17.mlp.gate_proj.weight', 'decoder.layers.17.mlp.layer_norm.bias', 'decoder.layers.17.mlp.layer_norm.weight', 'decoder.layers.17.self_attn.k_proj.bias', 'decoder.layers.17.self_attn.k_proj.weight', 'decoder.layers.17.self_attn.o_proj.bias', 'decoder.layers.17.self_attn.o_proj.weight', 'decoder.layers.17.self_attn.q_proj.bias', 'decoder.layers.17.self_attn.q_proj.weight', 'decoder.layers.17.self_attn.scaling', 'decoder.layers.17.self_attn.v_proj.bias', 'decoder.layers.17.self_attn.v_proj.weight', 'decoder.layers.18.input_layernorm.weight', 'decoder.layers.18.mlp.down_proj.bias', 'decoder.layers.18.mlp.down_proj.weight', 'decoder.layers.18.mlp.gate_proj.bias', 'decoder.layers.18.mlp.gate_proj.weight', 'decoder.layers.18.mlp.layer_norm.bias', 'decoder.layers.18.mlp.layer_norm.weight', 'decoder.layers.18.self_attn.k_proj.bias', 'decoder.layers.18.self_attn.k_proj.weight', 'decoder.layers.18.self_attn.o_proj.bias', 'decoder.layers.18.self_attn.o_proj.weight', 'decoder.layers.18.self_attn.q_proj.bias', 'decoder.layers.18.self_attn.q_proj.weight', 'decoder.layers.18.self_attn.scaling', 'decoder.layers.18.self_attn.v_proj.bias', 'decoder.layers.18.self_attn.v_proj.weight', 'decoder.layers.19.input_layernorm.weight', 'decoder.layers.19.mlp.down_proj.bias', 'decoder.layers.19.mlp.down_proj.weight', 'decoder.layers.19.mlp.gate_proj.bias', 'decoder.layers.19.mlp.gate_proj.weight', 'decoder.layers.19.mlp.layer_norm.bias', 'decoder.layers.19.mlp.layer_norm.weight', 'decoder.layers.19.self_attn.k_proj.bias', 'decoder.layers.19.self_attn.k_proj.weight', 'decoder.layers.19.self_attn.o_proj.bias', 'decoder.layers.19.self_attn.o_proj.weight', 'decoder.layers.19.self_attn.q_proj.bias', 'decoder.layers.19.self_attn.q_proj.weight', 'decoder.layers.19.self_attn.scaling', 'decoder.layers.19.self_attn.v_proj.bias', 'decoder.layers.19.self_attn.v_proj.weight', 'decoder.layers.2.input_layernorm.weight', 'decoder.layers.2.mlp.down_proj.bias', 'decoder.layers.2.mlp.down_proj.weight', 'decoder.layers.2.mlp.gate_proj.bias', 'decoder.layers.2.mlp.gate_proj.weight', 'decoder.layers.2.mlp.layer_norm.bias', 'decoder.layers.2.mlp.layer_norm.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.o_proj.bias', 'decoder.layers.2.self_attn.o_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.scaling', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.3.input_layernorm.weight', 'decoder.layers.3.mlp.down_proj.bias', 'decoder.layers.3.mlp.down_proj.weight', 'decoder.layers.3.mlp.gate_proj.bias', 'decoder.layers.3.mlp.gate_proj.weight', 'decoder.layers.3.mlp.layer_norm.bias', 'decoder.layers.3.mlp.layer_norm.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.o_proj.bias', 'decoder.layers.3.self_attn.o_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.scaling', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.4.input_layernorm.weight', 'decoder.layers.4.mlp.down_proj.bias', 'decoder.layers.4.mlp.down_proj.weight', 'decoder.layers.4.mlp.gate_proj.bias', 'decoder.layers.4.mlp.gate_proj.weight', 'decoder.layers.4.mlp.layer_norm.bias', 'decoder.layers.4.mlp.layer_norm.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.o_proj.bias', 'decoder.layers.4.self_attn.o_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.scaling', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.5.input_layernorm.weight', 'decoder.layers.5.mlp.down_proj.bias', 'decoder.layers.5.mlp.down_proj.weight', 'decoder.layers.5.mlp.gate_proj.bias', 'decoder.layers.5.mlp.gate_proj.weight', 'decoder.layers.5.mlp.layer_norm.bias', 'decoder.layers.5.mlp.layer_norm.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.o_proj.bias', 'decoder.layers.5.self_attn.o_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.scaling', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.6.input_layernorm.weight', 'decoder.layers.6.mlp.down_proj.bias', 'decoder.layers.6.mlp.down_proj.weight', 'decoder.layers.6.mlp.gate_proj.bias', 'decoder.layers.6.mlp.gate_proj.weight', 'decoder.layers.6.mlp.layer_norm.bias', 'decoder.layers.6.mlp.layer_norm.weight', 'decoder.layers.6.self_attn.k_proj.bias', 'decoder.layers.6.self_attn.k_proj.weight', 'decoder.layers.6.self_attn.o_proj.bias', 'decoder.layers.6.self_attn.o_proj.weight', 'decoder.layers.6.self_attn.q_proj.bias', 'decoder.layers.6.self_attn.q_proj.weight', 'decoder.layers.6.self_attn.scaling', 'decoder.layers.6.self_attn.v_proj.bias', 'decoder.layers.6.self_attn.v_proj.weight', 'decoder.layers.7.input_layernorm.weight', 'decoder.layers.7.mlp.down_proj.bias', 'decoder.layers.7.mlp.down_proj.weight', 'decoder.layers.7.mlp.gate_proj.bias', 'decoder.layers.7.mlp.gate_proj.weight', 'decoder.layers.7.mlp.layer_norm.bias', 'decoder.layers.7.mlp.layer_norm.weight', 'decoder.layers.7.self_attn.k_proj.bias', 'decoder.layers.7.self_attn.k_proj.weight', 'decoder.layers.7.self_attn.o_proj.bias', 'decoder.layers.7.self_attn.o_proj.weight', 'decoder.layers.7.self_attn.q_proj.bias', 'decoder.layers.7.self_attn.q_proj.weight', 'decoder.layers.7.self_attn.scaling', 'decoder.layers.7.self_attn.v_proj.bias', 'decoder.layers.7.self_attn.v_proj.weight', 'decoder.layers.8.input_layernorm.weight', 'decoder.layers.8.mlp.down_proj.bias', 'decoder.layers.8.mlp.down_proj.weight', 'decoder.layers.8.mlp.gate_proj.bias', 'decoder.layers.8.mlp.gate_proj.weight', 'decoder.layers.8.mlp.layer_norm.bias', 'decoder.layers.8.mlp.layer_norm.weight', 'decoder.layers.8.self_attn.k_proj.bias', 'decoder.layers.8.self_attn.k_proj.weight', 'decoder.layers.8.self_attn.o_proj.bias', 'decoder.layers.8.self_attn.o_proj.weight', 'decoder.layers.8.self_attn.q_proj.bias', 'decoder.layers.8.self_attn.q_proj.weight', 'decoder.layers.8.self_attn.scaling', 'decoder.layers.8.self_attn.v_proj.bias', 'decoder.layers.8.self_attn.v_proj.weight', 'decoder.layers.9.input_layernorm.weight', 'decoder.layers.9.mlp.down_proj.bias', 'decoder.layers.9.mlp.down_proj.weight', 'decoder.layers.9.mlp.gate_proj.bias', 'decoder.layers.9.mlp.gate_proj.weight', 'decoder.layers.9.mlp.layer_norm.bias', 'decoder.layers.9.mlp.layer_norm.weight', 'decoder.layers.9.self_attn.k_proj.bias', 'decoder.layers.9.self_attn.k_proj.weight', 'decoder.layers.9.self_attn.o_proj.bias', 'decoder.layers.9.self_attn.o_proj.weight', 'decoder.layers.9.self_attn.q_proj.bias', 'decoder.layers.9.self_attn.q_proj.weight', 'decoder.layers.9.self_attn.scaling', 'decoder.layers.9.self_attn.v_proj.bias', 'decoder.layers.9.self_attn.v_proj.weight', 'horizon_ff_layer.input_layer.bias', 'horizon_ff_layer.input_layer.weight', 'horizon_ff_layer.output_layer.bias', 'horizon_ff_layer.output_layer.weight', 'horizon_ff_layer.residual_layer.bias', 'horizon_ff_layer.residual_layer.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n",
            "  Epoch 1/100 train_loss=2.0830 train_acc=0.1455 eval_loss=0.6545 eval_acc=0.9608 (best)\n",
            "  Epoch 2/100 train_loss=0.4894 train_acc=0.9455 eval_loss=0.1984 eval_acc=0.9655 (best)\n",
            "  Epoch 3/100 train_loss=0.1028 train_acc=1.0000 eval_loss=0.1025 eval_acc=0.9684 (best)\n",
            "  Epoch 4/100 train_loss=0.0335 train_acc=1.0000 eval_loss=0.1454 eval_acc=0.9582 \n",
            "  Epoch 5/100 train_loss=0.0219 train_acc=1.0000 eval_loss=0.0831 eval_acc=0.9757 (best)\n",
            "  Epoch 6/100 train_loss=0.0032 train_acc=1.0000 eval_loss=0.1014 eval_acc=0.9706 \n",
            "  Epoch 7/100 train_loss=0.0033 train_acc=1.0000 eval_loss=0.1069 eval_acc=0.9723 \n",
            "  Epoch 8/100 train_loss=0.0007 train_acc=1.0000 eval_loss=0.1141 eval_acc=0.9748 \n",
            "  Epoch 9/100 train_loss=0.0002 train_acc=1.0000 eval_loss=0.1244 eval_acc=0.9748 \n",
            "  Epoch 10/100 train_loss=0.0001 train_acc=1.0000 eval_loss=0.1376 eval_acc=0.9753 \n",
            "  Epoch 11/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.1518 eval_acc=0.9761 \n",
            "  Epoch 12/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.1649 eval_acc=0.9748 \n",
            "  Epoch 13/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.1764 eval_acc=0.9748 \n",
            "  Epoch 14/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.1863 eval_acc=0.9753 \n",
            "  Epoch 15/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.1948 eval_acc=0.9753 \n",
            "  Early stopping on google/timesfm-2.5-200m-pytorch: no improvement for 10 epochs (best epoch = 5)\n",
            "    tfm[google/timesfm-2.5-200m-pytorch] train_acc=1.0000 eval_acc=0.97526652452025586192974060395499691367149353\n",
            "    mrh_acc=0.9757 mr+h+kg_acc=0.9774 kg_acc=0.9783 ensemble=0.9783 (w=0.60)\n",
            "  Split 1/1 - accuracy=0.9783 time=619.1s\n",
            "Completed Mallat: Mean Acc=0.9783\n",
            "\n",
            "=== 57/109 Meat ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n",
            "    Gate split 1/5: baseline_loss=0.1931 adaptive_loss=0.0498\n",
            "    Gate split 2/5: baseline_loss=0.1669 adaptive_loss=0.0107\n",
            "    Gate split 3/5: baseline_loss=0.0750 adaptive_loss=0.0419\n",
            "    Gate split 4/5: baseline_loss=0.0411 adaptive_loss=0.0179\n",
            "    Gate split 5/5: baseline_loss=0.0041 adaptive_loss=0.0025\n",
            "  Decision: Adaptive kept (loss 0.0245 vs baseline 0.0961, delta=-0.0715 <= +0.0200); savgol(window=11, poly=2) - high noise (std_diff)\n",
            "\n",
            "=== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at google/timesfm-2.5-200m-pytorch were not used when initializing TimesFmModelForPrediction: ['output_projection_point.hidden_layer.weight', 'output_projection_point.output_layer.weight', 'output_projection_point.residual_layer.weight', 'output_projection_quantiles.hidden_layer.weight', 'output_projection_quantiles.output_layer.weight', 'output_projection_quantiles.residual_layer.weight', 'stacked_xf.0.attn.key_ln.scale', 'stacked_xf.0.attn.out.weight', 'stacked_xf.0.attn.per_dim_scale.per_dim_scale', 'stacked_xf.0.attn.qkv_proj.weight', 'stacked_xf.0.attn.query_ln.scale', 'stacked_xf.0.ff0.weight', 'stacked_xf.0.ff1.weight', 'stacked_xf.0.post_attn_ln.scale', 'stacked_xf.0.post_ff_ln.scale', 'stacked_xf.0.pre_attn_ln.scale', 'stacked_xf.0.pre_ff_ln.scale', 'stacked_xf.1.attn.key_ln.scale', 'stacked_xf.1.attn.out.weight', 'stacked_xf.1.attn.per_dim_scale.per_dim_scale', 'stacked_xf.1.attn.qkv_proj.weight', 'stacked_xf.1.attn.query_ln.scale', 'stacked_xf.1.ff0.weight', 'stacked_xf.1.ff1.weight', 'stacked_xf.1.post_attn_ln.scale', 'stacked_xf.1.post_ff_ln.scale', 'stacked_xf.1.pre_attn_ln.scale', 'stacked_xf.1.pre_ff_ln.scale', 'stacked_xf.10.attn.key_ln.scale', 'stacked_xf.10.attn.out.weight', 'stacked_xf.10.attn.per_dim_scale.per_dim_scale', 'stacked_xf.10.attn.qkv_proj.weight', 'stacked_xf.10.attn.query_ln.scale', 'stacked_xf.10.ff0.weight', 'stacked_xf.10.ff1.weight', 'stacked_xf.10.post_attn_ln.scale', 'stacked_xf.10.post_ff_ln.scale', 'stacked_xf.10.pre_attn_ln.scale', 'stacked_xf.10.pre_ff_ln.scale', 'stacked_xf.11.attn.key_ln.scale', 'stacked_xf.11.attn.out.weight', 'stacked_xf.11.attn.per_dim_scale.per_dim_scale', 'stacked_xf.11.attn.qkv_proj.weight', 'stacked_xf.11.attn.query_ln.scale', 'stacked_xf.11.ff0.weight', 'stacked_xf.11.ff1.weight', 'stacked_xf.11.post_attn_ln.scale', 'stacked_xf.11.post_ff_ln.scale', 'stacked_xf.11.pre_attn_ln.scale', 'stacked_xf.11.pre_ff_ln.scale', 'stacked_xf.12.attn.key_ln.scale', 'stacked_xf.12.attn.out.weight', 'stacked_xf.12.attn.per_dim_scale.per_dim_scale', 'stacked_xf.12.attn.qkv_proj.weight', 'stacked_xf.12.attn.query_ln.scale', 'stacked_xf.12.ff0.weight', 'stacked_xf.12.ff1.weight', 'stacked_xf.12.post_attn_ln.scale', 'stacked_xf.12.post_ff_ln.scale', 'stacked_xf.12.pre_attn_ln.scale', 'stacked_xf.12.pre_ff_ln.scale', 'stacked_xf.13.attn.key_ln.scale', 'stacked_xf.13.attn.out.weight', 'stacked_xf.13.attn.per_dim_scale.per_dim_scale', 'stacked_xf.13.attn.qkv_proj.weight', 'stacked_xf.13.attn.query_ln.scale', 'stacked_xf.13.ff0.weight', 'stacked_xf.13.ff1.weight', 'stacked_xf.13.post_attn_ln.scale', 'stacked_xf.13.post_ff_ln.scale', 'stacked_xf.13.pre_attn_ln.scale', 'stacked_xf.13.pre_ff_ln.scale', 'stacked_xf.14.attn.key_ln.scale', 'stacked_xf.14.attn.out.weight', 'stacked_xf.14.attn.per_dim_scale.per_dim_scale', 'stacked_xf.14.attn.qkv_proj.weight', 'stacked_xf.14.attn.query_ln.scale', 'stacked_xf.14.ff0.weight', 'stacked_xf.14.ff1.weight', 'stacked_xf.14.post_attn_ln.scale', 'stacked_xf.14.post_ff_ln.scale', 'stacked_xf.14.pre_attn_ln.scale', 'stacked_xf.14.pre_ff_ln.scale', 'stacked_xf.15.attn.key_ln.scale', 'stacked_xf.15.attn.out.weight', 'stacked_xf.15.attn.per_dim_scale.per_dim_scale', 'stacked_xf.15.attn.qkv_proj.weight', 'stacked_xf.15.attn.query_ln.scale', 'stacked_xf.15.ff0.weight', 'stacked_xf.15.ff1.weight', 'stacked_xf.15.post_attn_ln.scale', 'stacked_xf.15.post_ff_ln.scale', 'stacked_xf.15.pre_attn_ln.scale', 'stacked_xf.15.pre_ff_ln.scale', 'stacked_xf.16.attn.key_ln.scale', 'stacked_xf.16.attn.out.weight', 'stacked_xf.16.attn.per_dim_scale.per_dim_scale', 'stacked_xf.16.attn.qkv_proj.weight', 'stacked_xf.16.attn.query_ln.scale', 'stacked_xf.16.ff0.weight', 'stacked_xf.16.ff1.weight', 'stacked_xf.16.post_attn_ln.scale', 'stacked_xf.16.post_ff_ln.scale', 'stacked_xf.16.pre_attn_ln.scale', 'stacked_xf.16.pre_ff_ln.scale', 'stacked_xf.17.attn.key_ln.scale', 'stacked_xf.17.attn.out.weight', 'stacked_xf.17.attn.per_dim_scale.per_dim_scale', 'stacked_xf.17.attn.qkv_proj.weight', 'stacked_xf.17.attn.query_ln.scale', 'stacked_xf.17.ff0.weight', 'stacked_xf.17.ff1.weight', 'stacked_xf.17.post_attn_ln.scale', 'stacked_xf.17.post_ff_ln.scale', 'stacked_xf.17.pre_attn_ln.scale', 'stacked_xf.17.pre_ff_ln.scale', 'stacked_xf.18.attn.key_ln.scale', 'stacked_xf.18.attn.out.weight', 'stacked_xf.18.attn.per_dim_scale.per_dim_scale', 'stacked_xf.18.attn.qkv_proj.weight', 'stacked_xf.18.attn.query_ln.scale', 'stacked_xf.18.ff0.weight', 'stacked_xf.18.ff1.weight', 'stacked_xf.18.post_attn_ln.scale', 'stacked_xf.18.post_ff_ln.scale', 'stacked_xf.18.pre_attn_ln.scale', 'stacked_xf.18.pre_ff_ln.scale', 'stacked_xf.19.attn.key_ln.scale', 'stacked_xf.19.attn.out.weight', 'stacked_xf.19.attn.per_dim_scale.per_dim_scale', 'stacked_xf.19.attn.qkv_proj.weight', 'stacked_xf.19.attn.query_ln.scale', 'stacked_xf.19.ff0.weight', 'stacked_xf.19.ff1.weight', 'stacked_xf.19.post_attn_ln.scale', 'stacked_xf.19.post_ff_ln.scale', 'stacked_xf.19.pre_attn_ln.scale', 'stacked_xf.19.pre_ff_ln.scale', 'stacked_xf.2.attn.key_ln.scale', 'stacked_xf.2.attn.out.weight', 'stacked_xf.2.attn.per_dim_scale.per_dim_scale', 'stacked_xf.2.attn.qkv_proj.weight', 'stacked_xf.2.attn.query_ln.scale', 'stacked_xf.2.ff0.weight', 'stacked_xf.2.ff1.weight', 'stacked_xf.2.post_attn_ln.scale', 'stacked_xf.2.post_ff_ln.scale', 'stacked_xf.2.pre_attn_ln.scale', 'stacked_xf.2.pre_ff_ln.scale', 'stacked_xf.3.attn.key_ln.scale', 'stacked_xf.3.attn.out.weight', 'stacked_xf.3.attn.per_dim_scale.per_dim_scale', 'stacked_xf.3.attn.qkv_proj.weight', 'stacked_xf.3.attn.query_ln.scale', 'stacked_xf.3.ff0.weight', 'stacked_xf.3.ff1.weight', 'stacked_xf.3.post_attn_ln.scale', 'stacked_xf.3.post_ff_ln.scale', 'stacked_xf.3.pre_attn_ln.scale', 'stacked_xf.3.pre_ff_ln.scale', 'stacked_xf.4.attn.key_ln.scale', 'stacked_xf.4.attn.out.weight', 'stacked_xf.4.attn.per_dim_scale.per_dim_scale', 'stacked_xf.4.attn.qkv_proj.weight', 'stacked_xf.4.attn.query_ln.scale', 'stacked_xf.4.ff0.weight', 'stacked_xf.4.ff1.weight', 'stacked_xf.4.post_attn_ln.scale', 'stacked_xf.4.post_ff_ln.scale', 'stacked_xf.4.pre_attn_ln.scale', 'stacked_xf.4.pre_ff_ln.scale', 'stacked_xf.5.attn.key_ln.scale', 'stacked_xf.5.attn.out.weight', 'stacked_xf.5.attn.per_dim_scale.per_dim_scale', 'stacked_xf.5.attn.qkv_proj.weight', 'stacked_xf.5.attn.query_ln.scale', 'stacked_xf.5.ff0.weight', 'stacked_xf.5.ff1.weight', 'stacked_xf.5.post_attn_ln.scale', 'stacked_xf.5.post_ff_ln.scale', 'stacked_xf.5.pre_attn_ln.scale', 'stacked_xf.5.pre_ff_ln.scale', 'stacked_xf.6.attn.key_ln.scale', 'stacked_xf.6.attn.out.weight', 'stacked_xf.6.attn.per_dim_scale.per_dim_scale', 'stacked_xf.6.attn.qkv_proj.weight', 'stacked_xf.6.attn.query_ln.scale', 'stacked_xf.6.ff0.weight', 'stacked_xf.6.ff1.weight', 'stacked_xf.6.post_attn_ln.scale', 'stacked_xf.6.post_ff_ln.scale', 'stacked_xf.6.pre_attn_ln.scale', 'stacked_xf.6.pre_ff_ln.scale', 'stacked_xf.7.attn.key_ln.scale', 'stacked_xf.7.attn.out.weight', 'stacked_xf.7.attn.per_dim_scale.per_dim_scale', 'stacked_xf.7.attn.qkv_proj.weight', 'stacked_xf.7.attn.query_ln.scale', 'stacked_xf.7.ff0.weight', 'stacked_xf.7.ff1.weight', 'stacked_xf.7.post_attn_ln.scale', 'stacked_xf.7.post_ff_ln.scale', 'stacked_xf.7.pre_attn_ln.scale', 'stacked_xf.7.pre_ff_ln.scale', 'stacked_xf.8.attn.key_ln.scale', 'stacked_xf.8.attn.out.weight', 'stacked_xf.8.attn.per_dim_scale.per_dim_scale', 'stacked_xf.8.attn.qkv_proj.weight', 'stacked_xf.8.attn.query_ln.scale', 'stacked_xf.8.ff0.weight', 'stacked_xf.8.ff1.weight', 'stacked_xf.8.post_attn_ln.scale', 'stacked_xf.8.post_ff_ln.scale', 'stacked_xf.8.pre_attn_ln.scale', 'stacked_xf.8.pre_ff_ln.scale', 'stacked_xf.9.attn.key_ln.scale', 'stacked_xf.9.attn.out.weight', 'stacked_xf.9.attn.per_dim_scale.per_dim_scale', 'stacked_xf.9.attn.qkv_proj.weight', 'stacked_xf.9.attn.query_ln.scale', 'stacked_xf.9.ff0.weight', 'stacked_xf.9.ff1.weight', 'stacked_xf.9.post_attn_ln.scale', 'stacked_xf.9.post_ff_ln.scale', 'stacked_xf.9.pre_attn_ln.scale', 'stacked_xf.9.pre_ff_ln.scale', 'tokenizer.hidden_layer.bias', 'tokenizer.hidden_layer.weight', 'tokenizer.output_layer.bias', 'tokenizer.output_layer.weight', 'tokenizer.residual_layer.bias', 'tokenizer.residual_layer.weight']\n",
            "- This IS expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of TimesFmModelForPrediction were not initialized from the model checkpoint at google/timesfm-2.5-200m-pytorch and are newly initialized: ['decoder.freq_emb.weight', 'decoder.input_ff_layer.input_layer.bias', 'decoder.input_ff_layer.input_layer.weight', 'decoder.input_ff_layer.output_layer.bias', 'decoder.input_ff_layer.output_layer.weight', 'decoder.input_ff_layer.residual_layer.bias', 'decoder.input_ff_layer.residual_layer.weight', 'decoder.layers.0.input_layernorm.weight', 'decoder.layers.0.mlp.down_proj.bias', 'decoder.layers.0.mlp.down_proj.weight', 'decoder.layers.0.mlp.gate_proj.bias', 'decoder.layers.0.mlp.gate_proj.weight', 'decoder.layers.0.mlp.layer_norm.bias', 'decoder.layers.0.mlp.layer_norm.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.o_proj.bias', 'decoder.layers.0.self_attn.o_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.scaling', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.1.input_layernorm.weight', 'decoder.layers.1.mlp.down_proj.bias', 'decoder.layers.1.mlp.down_proj.weight', 'decoder.layers.1.mlp.gate_proj.bias', 'decoder.layers.1.mlp.gate_proj.weight', 'decoder.layers.1.mlp.layer_norm.bias', 'decoder.layers.1.mlp.layer_norm.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.o_proj.bias', 'decoder.layers.1.self_attn.o_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.scaling', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.10.input_layernorm.weight', 'decoder.layers.10.mlp.down_proj.bias', 'decoder.layers.10.mlp.down_proj.weight', 'decoder.layers.10.mlp.gate_proj.bias', 'decoder.layers.10.mlp.gate_proj.weight', 'decoder.layers.10.mlp.layer_norm.bias', 'decoder.layers.10.mlp.layer_norm.weight', 'decoder.layers.10.self_attn.k_proj.bias', 'decoder.layers.10.self_attn.k_proj.weight', 'decoder.layers.10.self_attn.o_proj.bias', 'decoder.layers.10.self_attn.o_proj.weight', 'decoder.layers.10.self_attn.q_proj.bias', 'decoder.layers.10.self_attn.q_proj.weight', 'decoder.layers.10.self_attn.scaling', 'decoder.layers.10.self_attn.v_proj.bias', 'decoder.layers.10.self_attn.v_proj.weight', 'decoder.layers.11.input_layernorm.weight', 'decoder.layers.11.mlp.down_proj.bias', 'decoder.layers.11.mlp.down_proj.weight', 'decoder.layers.11.mlp.gate_proj.bias', 'decoder.layers.11.mlp.gate_proj.weight', 'decoder.layers.11.mlp.layer_norm.bias', 'decoder.layers.11.mlp.layer_norm.weight', 'decoder.layers.11.self_attn.k_proj.bias', 'decoder.layers.11.self_attn.k_proj.weight', 'decoder.layers.11.self_attn.o_proj.bias', 'decoder.layers.11.self_attn.o_proj.weight', 'decoder.layers.11.self_attn.q_proj.bias', 'decoder.layers.11.self_attn.q_proj.weight', 'decoder.layers.11.self_attn.scaling', 'decoder.layers.11.self_attn.v_proj.bias', 'decoder.layers.11.self_attn.v_proj.weight', 'decoder.layers.12.input_layernorm.weight', 'decoder.layers.12.mlp.down_proj.bias', 'decoder.layers.12.mlp.down_proj.weight', 'decoder.layers.12.mlp.gate_proj.bias', 'decoder.layers.12.mlp.gate_proj.weight', 'decoder.layers.12.mlp.layer_norm.bias', 'decoder.layers.12.mlp.layer_norm.weight', 'decoder.layers.12.self_attn.k_proj.bias', 'decoder.layers.12.self_attn.k_proj.weight', 'decoder.layers.12.self_attn.o_proj.bias', 'decoder.layers.12.self_attn.o_proj.weight', 'decoder.layers.12.self_attn.q_proj.bias', 'decoder.layers.12.self_attn.q_proj.weight', 'decoder.layers.12.self_attn.scaling', 'decoder.layers.12.self_attn.v_proj.bias', 'decoder.layers.12.self_attn.v_proj.weight', 'decoder.layers.13.input_layernorm.weight', 'decoder.layers.13.mlp.down_proj.bias', 'decoder.layers.13.mlp.down_proj.weight', 'decoder.layers.13.mlp.gate_proj.bias', 'decoder.layers.13.mlp.gate_proj.weight', 'decoder.layers.13.mlp.layer_norm.bias', 'decoder.layers.13.mlp.layer_norm.weight', 'decoder.layers.13.self_attn.k_proj.bias', 'decoder.layers.13.self_attn.k_proj.weight', 'decoder.layers.13.self_attn.o_proj.bias', 'decoder.layers.13.self_attn.o_proj.weight', 'decoder.layers.13.self_attn.q_proj.bias', 'decoder.layers.13.self_attn.q_proj.weight', 'decoder.layers.13.self_attn.scaling', 'decoder.layers.13.self_attn.v_proj.bias', 'decoder.layers.13.self_attn.v_proj.weight', 'decoder.layers.14.input_layernorm.weight', 'decoder.layers.14.mlp.down_proj.bias', 'decoder.layers.14.mlp.down_proj.weight', 'decoder.layers.14.mlp.gate_proj.bias', 'decoder.layers.14.mlp.gate_proj.weight', 'decoder.layers.14.mlp.layer_norm.bias', 'decoder.layers.14.mlp.layer_norm.weight', 'decoder.layers.14.self_attn.k_proj.bias', 'decoder.layers.14.self_attn.k_proj.weight', 'decoder.layers.14.self_attn.o_proj.bias', 'decoder.layers.14.self_attn.o_proj.weight', 'decoder.layers.14.self_attn.q_proj.bias', 'decoder.layers.14.self_attn.q_proj.weight', 'decoder.layers.14.self_attn.scaling', 'decoder.layers.14.self_attn.v_proj.bias', 'decoder.layers.14.self_attn.v_proj.weight', 'decoder.layers.15.input_layernorm.weight', 'decoder.layers.15.mlp.down_proj.bias', 'decoder.layers.15.mlp.down_proj.weight', 'decoder.layers.15.mlp.gate_proj.bias', 'decoder.layers.15.mlp.gate_proj.weight', 'decoder.layers.15.mlp.layer_norm.bias', 'decoder.layers.15.mlp.layer_norm.weight', 'decoder.layers.15.self_attn.k_proj.bias', 'decoder.layers.15.self_attn.k_proj.weight', 'decoder.layers.15.self_attn.o_proj.bias', 'decoder.layers.15.self_attn.o_proj.weight', 'decoder.layers.15.self_attn.q_proj.bias', 'decoder.layers.15.self_attn.q_proj.weight', 'decoder.layers.15.self_attn.scaling', 'decoder.layers.15.self_attn.v_proj.bias', 'decoder.layers.15.self_attn.v_proj.weight', 'decoder.layers.16.input_layernorm.weight', 'decoder.layers.16.mlp.down_proj.bias', 'decoder.layers.16.mlp.down_proj.weight', 'decoder.layers.16.mlp.gate_proj.bias', 'decoder.layers.16.mlp.gate_proj.weight', 'decoder.layers.16.mlp.layer_norm.bias', 'decoder.layers.16.mlp.layer_norm.weight', 'decoder.layers.16.self_attn.k_proj.bias', 'decoder.layers.16.self_attn.k_proj.weight', 'decoder.layers.16.self_attn.o_proj.bias', 'decoder.layers.16.self_attn.o_proj.weight', 'decoder.layers.16.self_attn.q_proj.bias', 'decoder.layers.16.self_attn.q_proj.weight', 'decoder.layers.16.self_attn.scaling', 'decoder.layers.16.self_attn.v_proj.bias', 'decoder.layers.16.self_attn.v_proj.weight', 'decoder.layers.17.input_layernorm.weight', 'decoder.layers.17.mlp.down_proj.bias', 'decoder.layers.17.mlp.down_proj.weight', 'decoder.layers.17.mlp.gate_proj.bias', 'decoder.layers.17.mlp.gate_proj.weight', 'decoder.layers.17.mlp.layer_norm.bias', 'decoder.layers.17.mlp.layer_norm.weight', 'decoder.layers.17.self_attn.k_proj.bias', 'decoder.layers.17.self_attn.k_proj.weight', 'decoder.layers.17.self_attn.o_proj.bias', 'decoder.layers.17.self_attn.o_proj.weight', 'decoder.layers.17.self_attn.q_proj.bias', 'decoder.layers.17.self_attn.q_proj.weight', 'decoder.layers.17.self_attn.scaling', 'decoder.layers.17.self_attn.v_proj.bias', 'decoder.layers.17.self_attn.v_proj.weight', 'decoder.layers.18.input_layernorm.weight', 'decoder.layers.18.mlp.down_proj.bias', 'decoder.layers.18.mlp.down_proj.weight', 'decoder.layers.18.mlp.gate_proj.bias', 'decoder.layers.18.mlp.gate_proj.weight', 'decoder.layers.18.mlp.layer_norm.bias', 'decoder.layers.18.mlp.layer_norm.weight', 'decoder.layers.18.self_attn.k_proj.bias', 'decoder.layers.18.self_attn.k_proj.weight', 'decoder.layers.18.self_attn.o_proj.bias', 'decoder.layers.18.self_attn.o_proj.weight', 'decoder.layers.18.self_attn.q_proj.bias', 'decoder.layers.18.self_attn.q_proj.weight', 'decoder.layers.18.self_attn.scaling', 'decoder.layers.18.self_attn.v_proj.bias', 'decoder.layers.18.self_attn.v_proj.weight', 'decoder.layers.19.input_layernorm.weight', 'decoder.layers.19.mlp.down_proj.bias', 'decoder.layers.19.mlp.down_proj.weight', 'decoder.layers.19.mlp.gate_proj.bias', 'decoder.layers.19.mlp.gate_proj.weight', 'decoder.layers.19.mlp.layer_norm.bias', 'decoder.layers.19.mlp.layer_norm.weight', 'decoder.layers.19.self_attn.k_proj.bias', 'decoder.layers.19.self_attn.k_proj.weight', 'decoder.layers.19.self_attn.o_proj.bias', 'decoder.layers.19.self_attn.o_proj.weight', 'decoder.layers.19.self_attn.q_proj.bias', 'decoder.layers.19.self_attn.q_proj.weight', 'decoder.layers.19.self_attn.scaling', 'decoder.layers.19.self_attn.v_proj.bias', 'decoder.layers.19.self_attn.v_proj.weight', 'decoder.layers.2.input_layernorm.weight', 'decoder.layers.2.mlp.down_proj.bias', 'decoder.layers.2.mlp.down_proj.weight', 'decoder.layers.2.mlp.gate_proj.bias', 'decoder.layers.2.mlp.gate_proj.weight', 'decoder.layers.2.mlp.layer_norm.bias', 'decoder.layers.2.mlp.layer_norm.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.o_proj.bias', 'decoder.layers.2.self_attn.o_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.scaling', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.3.input_layernorm.weight', 'decoder.layers.3.mlp.down_proj.bias', 'decoder.layers.3.mlp.down_proj.weight', 'decoder.layers.3.mlp.gate_proj.bias', 'decoder.layers.3.mlp.gate_proj.weight', 'decoder.layers.3.mlp.layer_norm.bias', 'decoder.layers.3.mlp.layer_norm.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.o_proj.bias', 'decoder.layers.3.self_attn.o_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.scaling', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.4.input_layernorm.weight', 'decoder.layers.4.mlp.down_proj.bias', 'decoder.layers.4.mlp.down_proj.weight', 'decoder.layers.4.mlp.gate_proj.bias', 'decoder.layers.4.mlp.gate_proj.weight', 'decoder.layers.4.mlp.layer_norm.bias', 'decoder.layers.4.mlp.layer_norm.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.o_proj.bias', 'decoder.layers.4.self_attn.o_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.scaling', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.5.input_layernorm.weight', 'decoder.layers.5.mlp.down_proj.bias', 'decoder.layers.5.mlp.down_proj.weight', 'decoder.layers.5.mlp.gate_proj.bias', 'decoder.layers.5.mlp.gate_proj.weight', 'decoder.layers.5.mlp.layer_norm.bias', 'decoder.layers.5.mlp.layer_norm.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.o_proj.bias', 'decoder.layers.5.self_attn.o_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.scaling', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.6.input_layernorm.weight', 'decoder.layers.6.mlp.down_proj.bias', 'decoder.layers.6.mlp.down_proj.weight', 'decoder.layers.6.mlp.gate_proj.bias', 'decoder.layers.6.mlp.gate_proj.weight', 'decoder.layers.6.mlp.layer_norm.bias', 'decoder.layers.6.mlp.layer_norm.weight', 'decoder.layers.6.self_attn.k_proj.bias', 'decoder.layers.6.self_attn.k_proj.weight', 'decoder.layers.6.self_attn.o_proj.bias', 'decoder.layers.6.self_attn.o_proj.weight', 'decoder.layers.6.self_attn.q_proj.bias', 'decoder.layers.6.self_attn.q_proj.weight', 'decoder.layers.6.self_attn.scaling', 'decoder.layers.6.self_attn.v_proj.bias', 'decoder.layers.6.self_attn.v_proj.weight', 'decoder.layers.7.input_layernorm.weight', 'decoder.layers.7.mlp.down_proj.bias', 'decoder.layers.7.mlp.down_proj.weight', 'decoder.layers.7.mlp.gate_proj.bias', 'decoder.layers.7.mlp.gate_proj.weight', 'decoder.layers.7.mlp.layer_norm.bias', 'decoder.layers.7.mlp.layer_norm.weight', 'decoder.layers.7.self_attn.k_proj.bias', 'decoder.layers.7.self_attn.k_proj.weight', 'decoder.layers.7.self_attn.o_proj.bias', 'decoder.layers.7.self_attn.o_proj.weight', 'decoder.layers.7.self_attn.q_proj.bias', 'decoder.layers.7.self_attn.q_proj.weight', 'decoder.layers.7.self_attn.scaling', 'decoder.layers.7.self_attn.v_proj.bias', 'decoder.layers.7.self_attn.v_proj.weight', 'decoder.layers.8.input_layernorm.weight', 'decoder.layers.8.mlp.down_proj.bias', 'decoder.layers.8.mlp.down_proj.weight', 'decoder.layers.8.mlp.gate_proj.bias', 'decoder.layers.8.mlp.gate_proj.weight', 'decoder.layers.8.mlp.layer_norm.bias', 'decoder.layers.8.mlp.layer_norm.weight', 'decoder.layers.8.self_attn.k_proj.bias', 'decoder.layers.8.self_attn.k_proj.weight', 'decoder.layers.8.self_attn.o_proj.bias', 'decoder.layers.8.self_attn.o_proj.weight', 'decoder.layers.8.self_attn.q_proj.bias', 'decoder.layers.8.self_attn.q_proj.weight', 'decoder.layers.8.self_attn.scaling', 'decoder.layers.8.self_attn.v_proj.bias', 'decoder.layers.8.self_attn.v_proj.weight', 'decoder.layers.9.input_layernorm.weight', 'decoder.layers.9.mlp.down_proj.bias', 'decoder.layers.9.mlp.down_proj.weight', 'decoder.layers.9.mlp.gate_proj.bias', 'decoder.layers.9.mlp.gate_proj.weight', 'decoder.layers.9.mlp.layer_norm.bias', 'decoder.layers.9.mlp.layer_norm.weight', 'decoder.layers.9.self_attn.k_proj.bias', 'decoder.layers.9.self_attn.k_proj.weight', 'decoder.layers.9.self_attn.o_proj.bias', 'decoder.layers.9.self_attn.o_proj.weight', 'decoder.layers.9.self_attn.q_proj.bias', 'decoder.layers.9.self_attn.q_proj.weight', 'decoder.layers.9.self_attn.scaling', 'decoder.layers.9.self_attn.v_proj.bias', 'decoder.layers.9.self_attn.v_proj.weight', 'horizon_ff_layer.input_layer.bias', 'horizon_ff_layer.input_layer.weight', 'horizon_ff_layer.output_layer.bias', 'horizon_ff_layer.output_layer.weight', 'horizon_ff_layer.residual_layer.bias', 'horizon_ff_layer.residual_layer.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n",
            "  Epoch 1/100 train_loss=1.1213 train_acc=0.3333 eval_loss=0.2681 eval_acc=0.9333 (best)\n",
            "  Epoch 2/100 train_loss=0.1231 train_acc=0.9667 eval_loss=0.0803 eval_acc=0.9500 (best)\n",
            "  Epoch 3/100 train_loss=0.0087 train_acc=1.0000 eval_loss=0.0922 eval_acc=0.9667 \n",
            "  Epoch 4/100 train_loss=0.0041 train_acc=1.0000 eval_loss=0.0960 eval_acc=0.9667 \n",
            "  Epoch 5/100 train_loss=0.0007 train_acc=1.0000 eval_loss=0.0925 eval_acc=0.9667 \n",
            "  Epoch 6/100 train_loss=0.0001 train_acc=1.0000 eval_loss=0.0893 eval_acc=0.9667 \n",
            "  Epoch 7/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0865 eval_acc=0.9667 \n",
            "  Epoch 8/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0837 eval_acc=0.9667 \n",
            "  Epoch 9/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0809 eval_acc=0.9667 \n",
            "  Epoch 10/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0781 eval_acc=0.9667 (best)\n",
            "  Epoch 11/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0756 eval_acc=0.9667 (best)\n",
            "  Epoch 12/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0736 eval_acc=0.9667 (best)\n",
            "  Epoch 13/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0720 eval_acc=0.9833 (best)\n",
            "  Epoch 14/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0707 eval_acc=0.9833 (best)\n",
            "  Epoch 15/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0696 eval_acc=0.9833 (best)\n",
            "  Epoch 16/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0688 eval_acc=0.9833 (best)\n",
            "  Epoch 17/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0681 eval_acc=0.9833 (best)\n",
            "  Epoch 18/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0676 eval_acc=0.9833 (best)\n",
            "  Epoch 19/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0672 eval_acc=0.9833 (best)\n",
            "  Epoch 20/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0668 eval_acc=0.9833 (best)\n",
            "  Epoch 21/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0666 eval_acc=0.9833 (best)\n",
            "  Epoch 22/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0663 eval_acc=0.9833 (best)\n",
            "  Epoch 23/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0662 eval_acc=0.9833 (best)\n",
            "  Epoch 24/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0660 eval_acc=0.9833 (best)\n",
            "  Epoch 25/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0659 eval_acc=0.9833 (best)\n",
            "  Epoch 26/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0658 eval_acc=0.9833 (best)\n",
            "  Epoch 27/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0657 eval_acc=0.9833 (best)\n",
            "  Epoch 28/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0657 eval_acc=0.9833 (best)\n",
            "  Epoch 29/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0656 eval_acc=0.9833 (best)\n",
            "  Epoch 30/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0656 eval_acc=0.9833 (best)\n",
            "  Epoch 31/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0655 eval_acc=0.9833 (best)\n",
            "  Epoch 32/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0655 eval_acc=0.9833 (best)\n",
            "  Epoch 33/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0655 eval_acc=0.9833 (best)\n",
            "  Epoch 34/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0655 eval_acc=0.9833 (best)\n",
            "  Epoch 35/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0655 eval_acc=0.9833 (best)\n",
            "  Epoch 36/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0654 eval_acc=0.9833 (best)\n",
            "  Epoch 37/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0654 eval_acc=0.9833 (best)\n",
            "  Epoch 38/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0654 eval_acc=0.9833 (best)\n",
            "  Epoch 39/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0654 eval_acc=0.9833 (best)\n",
            "  Epoch 40/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0654 eval_acc=0.9833 (best)\n",
            "  Epoch 41/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0654 eval_acc=0.9833 (best)\n",
            "  Epoch 42/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0654 eval_acc=0.9833 (best)\n",
            "  Epoch 43/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0654 eval_acc=0.9833 (best)\n",
            "  Epoch 44/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0654 eval_acc=0.9833 (best)\n",
            "  Epoch 45/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0654 eval_acc=0.9833 (best)\n",
            "  Epoch 46/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0654 eval_acc=0.9833 (best)\n",
            "  Epoch 47/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0654 eval_acc=0.9833 (best)\n",
            "  Epoch 48/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0654 eval_acc=0.9833 (best)\n",
            "  Epoch 49/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0654 eval_acc=0.9833 (best)\n",
            "  Epoch 50/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0654 eval_acc=0.9833 (best)\n",
            "  Epoch 51/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0654 eval_acc=0.9833 (best)\n",
            "  Epoch 52/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0654 eval_acc=0.9833 (best)\n",
            "  Epoch 53/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0654 eval_acc=0.9833 (best)\n",
            "  Epoch 54/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0654 eval_acc=0.9833 (best)\n",
            "  Epoch 55/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0654 eval_acc=0.9833 (best)\n",
            "  Epoch 56/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0654 eval_acc=0.9833 (best)\n",
            "  Epoch 57/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0654 eval_acc=0.9833 (best)\n",
            "  Epoch 58/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0654 eval_acc=0.9833 (best)\n",
            "  Epoch 59/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0654 eval_acc=0.9833 (best)\n",
            "  Epoch 60/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0654 eval_acc=0.9833 (best)\n",
            "  Epoch 61/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0654 eval_acc=0.9833 \n",
            "  Epoch 62/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0654 eval_acc=0.9833 (best)\n",
            "  Epoch 63/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0654 eval_acc=0.9833 \n",
            "  Epoch 64/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0654 eval_acc=0.9833 \n",
            "  Epoch 65/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0654 eval_acc=0.9833 \n",
            "  Epoch 66/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0654 eval_acc=0.9833 \n",
            "  Epoch 67/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0654 eval_acc=0.9833 \n",
            "  Epoch 68/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0654 eval_acc=0.9833 \n",
            "  Epoch 69/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0654 eval_acc=0.9833 \n",
            "  Epoch 70/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0654 eval_acc=0.9833 \n",
            "  Epoch 71/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0654 eval_acc=0.9833 \n",
            "  Epoch 72/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.0654 eval_acc=0.9833 \n",
            "  Early stopping on google/timesfm-2.5-200m-pytorch: no improvement for 10 epochs (best epoch = 62)\n",
            "    tfm[google/timesfm-2.5-200m-pytorch] train_acc=1.0000 eval_acc=0.98333333333333328152292551749269478023052216\n",
            "    mrh_acc=0.9667 mr+h+kg_acc=0.9667 kg_acc=0.9833 ensemble=0.9833 (w=0.60)\n",
            "  Split 1/1 - accuracy=0.9833 time=263.9s\n",
            "Completed Meat: Mean Acc=0.9833\n",
            "\n",
            "=== 58/109 MedicalImages ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n",
            "    Gate split 1/5: baseline_loss=0.5839 adaptive_loss=0.5895\n",
            "    Gate split 2/5: baseline_loss=0.4818 adaptive_loss=0.4803\n",
            "    Gate split 3/5: baseline_loss=0.4936 adaptive_loss=0.5004\n",
            "    Gate split 4/5: baseline_loss=0.4829 adaptive_loss=0.4812\n",
            "    Gate split 5/5: baseline_loss=0.6256 adaptive_loss=0.6224\n",
            "  Decision: Adaptive kept (loss 0.5347 vs baseline 0.5336, delta=+0.0012 <= +0.0200); savgol(window=5, poly=2) - high noise (std_diff)\n",
            "\n",
            "=== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at google/timesfm-2.5-200m-pytorch were not used when initializing TimesFmModelForPrediction: ['output_projection_point.hidden_layer.weight', 'output_projection_point.output_layer.weight', 'output_projection_point.residual_layer.weight', 'output_projection_quantiles.hidden_layer.weight', 'output_projection_quantiles.output_layer.weight', 'output_projection_quantiles.residual_layer.weight', 'stacked_xf.0.attn.key_ln.scale', 'stacked_xf.0.attn.out.weight', 'stacked_xf.0.attn.per_dim_scale.per_dim_scale', 'stacked_xf.0.attn.qkv_proj.weight', 'stacked_xf.0.attn.query_ln.scale', 'stacked_xf.0.ff0.weight', 'stacked_xf.0.ff1.weight', 'stacked_xf.0.post_attn_ln.scale', 'stacked_xf.0.post_ff_ln.scale', 'stacked_xf.0.pre_attn_ln.scale', 'stacked_xf.0.pre_ff_ln.scale', 'stacked_xf.1.attn.key_ln.scale', 'stacked_xf.1.attn.out.weight', 'stacked_xf.1.attn.per_dim_scale.per_dim_scale', 'stacked_xf.1.attn.qkv_proj.weight', 'stacked_xf.1.attn.query_ln.scale', 'stacked_xf.1.ff0.weight', 'stacked_xf.1.ff1.weight', 'stacked_xf.1.post_attn_ln.scale', 'stacked_xf.1.post_ff_ln.scale', 'stacked_xf.1.pre_attn_ln.scale', 'stacked_xf.1.pre_ff_ln.scale', 'stacked_xf.10.attn.key_ln.scale', 'stacked_xf.10.attn.out.weight', 'stacked_xf.10.attn.per_dim_scale.per_dim_scale', 'stacked_xf.10.attn.qkv_proj.weight', 'stacked_xf.10.attn.query_ln.scale', 'stacked_xf.10.ff0.weight', 'stacked_xf.10.ff1.weight', 'stacked_xf.10.post_attn_ln.scale', 'stacked_xf.10.post_ff_ln.scale', 'stacked_xf.10.pre_attn_ln.scale', 'stacked_xf.10.pre_ff_ln.scale', 'stacked_xf.11.attn.key_ln.scale', 'stacked_xf.11.attn.out.weight', 'stacked_xf.11.attn.per_dim_scale.per_dim_scale', 'stacked_xf.11.attn.qkv_proj.weight', 'stacked_xf.11.attn.query_ln.scale', 'stacked_xf.11.ff0.weight', 'stacked_xf.11.ff1.weight', 'stacked_xf.11.post_attn_ln.scale', 'stacked_xf.11.post_ff_ln.scale', 'stacked_xf.11.pre_attn_ln.scale', 'stacked_xf.11.pre_ff_ln.scale', 'stacked_xf.12.attn.key_ln.scale', 'stacked_xf.12.attn.out.weight', 'stacked_xf.12.attn.per_dim_scale.per_dim_scale', 'stacked_xf.12.attn.qkv_proj.weight', 'stacked_xf.12.attn.query_ln.scale', 'stacked_xf.12.ff0.weight', 'stacked_xf.12.ff1.weight', 'stacked_xf.12.post_attn_ln.scale', 'stacked_xf.12.post_ff_ln.scale', 'stacked_xf.12.pre_attn_ln.scale', 'stacked_xf.12.pre_ff_ln.scale', 'stacked_xf.13.attn.key_ln.scale', 'stacked_xf.13.attn.out.weight', 'stacked_xf.13.attn.per_dim_scale.per_dim_scale', 'stacked_xf.13.attn.qkv_proj.weight', 'stacked_xf.13.attn.query_ln.scale', 'stacked_xf.13.ff0.weight', 'stacked_xf.13.ff1.weight', 'stacked_xf.13.post_attn_ln.scale', 'stacked_xf.13.post_ff_ln.scale', 'stacked_xf.13.pre_attn_ln.scale', 'stacked_xf.13.pre_ff_ln.scale', 'stacked_xf.14.attn.key_ln.scale', 'stacked_xf.14.attn.out.weight', 'stacked_xf.14.attn.per_dim_scale.per_dim_scale', 'stacked_xf.14.attn.qkv_proj.weight', 'stacked_xf.14.attn.query_ln.scale', 'stacked_xf.14.ff0.weight', 'stacked_xf.14.ff1.weight', 'stacked_xf.14.post_attn_ln.scale', 'stacked_xf.14.post_ff_ln.scale', 'stacked_xf.14.pre_attn_ln.scale', 'stacked_xf.14.pre_ff_ln.scale', 'stacked_xf.15.attn.key_ln.scale', 'stacked_xf.15.attn.out.weight', 'stacked_xf.15.attn.per_dim_scale.per_dim_scale', 'stacked_xf.15.attn.qkv_proj.weight', 'stacked_xf.15.attn.query_ln.scale', 'stacked_xf.15.ff0.weight', 'stacked_xf.15.ff1.weight', 'stacked_xf.15.post_attn_ln.scale', 'stacked_xf.15.post_ff_ln.scale', 'stacked_xf.15.pre_attn_ln.scale', 'stacked_xf.15.pre_ff_ln.scale', 'stacked_xf.16.attn.key_ln.scale', 'stacked_xf.16.attn.out.weight', 'stacked_xf.16.attn.per_dim_scale.per_dim_scale', 'stacked_xf.16.attn.qkv_proj.weight', 'stacked_xf.16.attn.query_ln.scale', 'stacked_xf.16.ff0.weight', 'stacked_xf.16.ff1.weight', 'stacked_xf.16.post_attn_ln.scale', 'stacked_xf.16.post_ff_ln.scale', 'stacked_xf.16.pre_attn_ln.scale', 'stacked_xf.16.pre_ff_ln.scale', 'stacked_xf.17.attn.key_ln.scale', 'stacked_xf.17.attn.out.weight', 'stacked_xf.17.attn.per_dim_scale.per_dim_scale', 'stacked_xf.17.attn.qkv_proj.weight', 'stacked_xf.17.attn.query_ln.scale', 'stacked_xf.17.ff0.weight', 'stacked_xf.17.ff1.weight', 'stacked_xf.17.post_attn_ln.scale', 'stacked_xf.17.post_ff_ln.scale', 'stacked_xf.17.pre_attn_ln.scale', 'stacked_xf.17.pre_ff_ln.scale', 'stacked_xf.18.attn.key_ln.scale', 'stacked_xf.18.attn.out.weight', 'stacked_xf.18.attn.per_dim_scale.per_dim_scale', 'stacked_xf.18.attn.qkv_proj.weight', 'stacked_xf.18.attn.query_ln.scale', 'stacked_xf.18.ff0.weight', 'stacked_xf.18.ff1.weight', 'stacked_xf.18.post_attn_ln.scale', 'stacked_xf.18.post_ff_ln.scale', 'stacked_xf.18.pre_attn_ln.scale', 'stacked_xf.18.pre_ff_ln.scale', 'stacked_xf.19.attn.key_ln.scale', 'stacked_xf.19.attn.out.weight', 'stacked_xf.19.attn.per_dim_scale.per_dim_scale', 'stacked_xf.19.attn.qkv_proj.weight', 'stacked_xf.19.attn.query_ln.scale', 'stacked_xf.19.ff0.weight', 'stacked_xf.19.ff1.weight', 'stacked_xf.19.post_attn_ln.scale', 'stacked_xf.19.post_ff_ln.scale', 'stacked_xf.19.pre_attn_ln.scale', 'stacked_xf.19.pre_ff_ln.scale', 'stacked_xf.2.attn.key_ln.scale', 'stacked_xf.2.attn.out.weight', 'stacked_xf.2.attn.per_dim_scale.per_dim_scale', 'stacked_xf.2.attn.qkv_proj.weight', 'stacked_xf.2.attn.query_ln.scale', 'stacked_xf.2.ff0.weight', 'stacked_xf.2.ff1.weight', 'stacked_xf.2.post_attn_ln.scale', 'stacked_xf.2.post_ff_ln.scale', 'stacked_xf.2.pre_attn_ln.scale', 'stacked_xf.2.pre_ff_ln.scale', 'stacked_xf.3.attn.key_ln.scale', 'stacked_xf.3.attn.out.weight', 'stacked_xf.3.attn.per_dim_scale.per_dim_scale', 'stacked_xf.3.attn.qkv_proj.weight', 'stacked_xf.3.attn.query_ln.scale', 'stacked_xf.3.ff0.weight', 'stacked_xf.3.ff1.weight', 'stacked_xf.3.post_attn_ln.scale', 'stacked_xf.3.post_ff_ln.scale', 'stacked_xf.3.pre_attn_ln.scale', 'stacked_xf.3.pre_ff_ln.scale', 'stacked_xf.4.attn.key_ln.scale', 'stacked_xf.4.attn.out.weight', 'stacked_xf.4.attn.per_dim_scale.per_dim_scale', 'stacked_xf.4.attn.qkv_proj.weight', 'stacked_xf.4.attn.query_ln.scale', 'stacked_xf.4.ff0.weight', 'stacked_xf.4.ff1.weight', 'stacked_xf.4.post_attn_ln.scale', 'stacked_xf.4.post_ff_ln.scale', 'stacked_xf.4.pre_attn_ln.scale', 'stacked_xf.4.pre_ff_ln.scale', 'stacked_xf.5.attn.key_ln.scale', 'stacked_xf.5.attn.out.weight', 'stacked_xf.5.attn.per_dim_scale.per_dim_scale', 'stacked_xf.5.attn.qkv_proj.weight', 'stacked_xf.5.attn.query_ln.scale', 'stacked_xf.5.ff0.weight', 'stacked_xf.5.ff1.weight', 'stacked_xf.5.post_attn_ln.scale', 'stacked_xf.5.post_ff_ln.scale', 'stacked_xf.5.pre_attn_ln.scale', 'stacked_xf.5.pre_ff_ln.scale', 'stacked_xf.6.attn.key_ln.scale', 'stacked_xf.6.attn.out.weight', 'stacked_xf.6.attn.per_dim_scale.per_dim_scale', 'stacked_xf.6.attn.qkv_proj.weight', 'stacked_xf.6.attn.query_ln.scale', 'stacked_xf.6.ff0.weight', 'stacked_xf.6.ff1.weight', 'stacked_xf.6.post_attn_ln.scale', 'stacked_xf.6.post_ff_ln.scale', 'stacked_xf.6.pre_attn_ln.scale', 'stacked_xf.6.pre_ff_ln.scale', 'stacked_xf.7.attn.key_ln.scale', 'stacked_xf.7.attn.out.weight', 'stacked_xf.7.attn.per_dim_scale.per_dim_scale', 'stacked_xf.7.attn.qkv_proj.weight', 'stacked_xf.7.attn.query_ln.scale', 'stacked_xf.7.ff0.weight', 'stacked_xf.7.ff1.weight', 'stacked_xf.7.post_attn_ln.scale', 'stacked_xf.7.post_ff_ln.scale', 'stacked_xf.7.pre_attn_ln.scale', 'stacked_xf.7.pre_ff_ln.scale', 'stacked_xf.8.attn.key_ln.scale', 'stacked_xf.8.attn.out.weight', 'stacked_xf.8.attn.per_dim_scale.per_dim_scale', 'stacked_xf.8.attn.qkv_proj.weight', 'stacked_xf.8.attn.query_ln.scale', 'stacked_xf.8.ff0.weight', 'stacked_xf.8.ff1.weight', 'stacked_xf.8.post_attn_ln.scale', 'stacked_xf.8.post_ff_ln.scale', 'stacked_xf.8.pre_attn_ln.scale', 'stacked_xf.8.pre_ff_ln.scale', 'stacked_xf.9.attn.key_ln.scale', 'stacked_xf.9.attn.out.weight', 'stacked_xf.9.attn.per_dim_scale.per_dim_scale', 'stacked_xf.9.attn.qkv_proj.weight', 'stacked_xf.9.attn.query_ln.scale', 'stacked_xf.9.ff0.weight', 'stacked_xf.9.ff1.weight', 'stacked_xf.9.post_attn_ln.scale', 'stacked_xf.9.post_ff_ln.scale', 'stacked_xf.9.pre_attn_ln.scale', 'stacked_xf.9.pre_ff_ln.scale', 'tokenizer.hidden_layer.bias', 'tokenizer.hidden_layer.weight', 'tokenizer.output_layer.bias', 'tokenizer.output_layer.weight', 'tokenizer.residual_layer.bias', 'tokenizer.residual_layer.weight']\n",
            "- This IS expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of TimesFmModelForPrediction were not initialized from the model checkpoint at google/timesfm-2.5-200m-pytorch and are newly initialized: ['decoder.freq_emb.weight', 'decoder.input_ff_layer.input_layer.bias', 'decoder.input_ff_layer.input_layer.weight', 'decoder.input_ff_layer.output_layer.bias', 'decoder.input_ff_layer.output_layer.weight', 'decoder.input_ff_layer.residual_layer.bias', 'decoder.input_ff_layer.residual_layer.weight', 'decoder.layers.0.input_layernorm.weight', 'decoder.layers.0.mlp.down_proj.bias', 'decoder.layers.0.mlp.down_proj.weight', 'decoder.layers.0.mlp.gate_proj.bias', 'decoder.layers.0.mlp.gate_proj.weight', 'decoder.layers.0.mlp.layer_norm.bias', 'decoder.layers.0.mlp.layer_norm.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.o_proj.bias', 'decoder.layers.0.self_attn.o_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.scaling', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.1.input_layernorm.weight', 'decoder.layers.1.mlp.down_proj.bias', 'decoder.layers.1.mlp.down_proj.weight', 'decoder.layers.1.mlp.gate_proj.bias', 'decoder.layers.1.mlp.gate_proj.weight', 'decoder.layers.1.mlp.layer_norm.bias', 'decoder.layers.1.mlp.layer_norm.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.o_proj.bias', 'decoder.layers.1.self_attn.o_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.scaling', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.10.input_layernorm.weight', 'decoder.layers.10.mlp.down_proj.bias', 'decoder.layers.10.mlp.down_proj.weight', 'decoder.layers.10.mlp.gate_proj.bias', 'decoder.layers.10.mlp.gate_proj.weight', 'decoder.layers.10.mlp.layer_norm.bias', 'decoder.layers.10.mlp.layer_norm.weight', 'decoder.layers.10.self_attn.k_proj.bias', 'decoder.layers.10.self_attn.k_proj.weight', 'decoder.layers.10.self_attn.o_proj.bias', 'decoder.layers.10.self_attn.o_proj.weight', 'decoder.layers.10.self_attn.q_proj.bias', 'decoder.layers.10.self_attn.q_proj.weight', 'decoder.layers.10.self_attn.scaling', 'decoder.layers.10.self_attn.v_proj.bias', 'decoder.layers.10.self_attn.v_proj.weight', 'decoder.layers.11.input_layernorm.weight', 'decoder.layers.11.mlp.down_proj.bias', 'decoder.layers.11.mlp.down_proj.weight', 'decoder.layers.11.mlp.gate_proj.bias', 'decoder.layers.11.mlp.gate_proj.weight', 'decoder.layers.11.mlp.layer_norm.bias', 'decoder.layers.11.mlp.layer_norm.weight', 'decoder.layers.11.self_attn.k_proj.bias', 'decoder.layers.11.self_attn.k_proj.weight', 'decoder.layers.11.self_attn.o_proj.bias', 'decoder.layers.11.self_attn.o_proj.weight', 'decoder.layers.11.self_attn.q_proj.bias', 'decoder.layers.11.self_attn.q_proj.weight', 'decoder.layers.11.self_attn.scaling', 'decoder.layers.11.self_attn.v_proj.bias', 'decoder.layers.11.self_attn.v_proj.weight', 'decoder.layers.12.input_layernorm.weight', 'decoder.layers.12.mlp.down_proj.bias', 'decoder.layers.12.mlp.down_proj.weight', 'decoder.layers.12.mlp.gate_proj.bias', 'decoder.layers.12.mlp.gate_proj.weight', 'decoder.layers.12.mlp.layer_norm.bias', 'decoder.layers.12.mlp.layer_norm.weight', 'decoder.layers.12.self_attn.k_proj.bias', 'decoder.layers.12.self_attn.k_proj.weight', 'decoder.layers.12.self_attn.o_proj.bias', 'decoder.layers.12.self_attn.o_proj.weight', 'decoder.layers.12.self_attn.q_proj.bias', 'decoder.layers.12.self_attn.q_proj.weight', 'decoder.layers.12.self_attn.scaling', 'decoder.layers.12.self_attn.v_proj.bias', 'decoder.layers.12.self_attn.v_proj.weight', 'decoder.layers.13.input_layernorm.weight', 'decoder.layers.13.mlp.down_proj.bias', 'decoder.layers.13.mlp.down_proj.weight', 'decoder.layers.13.mlp.gate_proj.bias', 'decoder.layers.13.mlp.gate_proj.weight', 'decoder.layers.13.mlp.layer_norm.bias', 'decoder.layers.13.mlp.layer_norm.weight', 'decoder.layers.13.self_attn.k_proj.bias', 'decoder.layers.13.self_attn.k_proj.weight', 'decoder.layers.13.self_attn.o_proj.bias', 'decoder.layers.13.self_attn.o_proj.weight', 'decoder.layers.13.self_attn.q_proj.bias', 'decoder.layers.13.self_attn.q_proj.weight', 'decoder.layers.13.self_attn.scaling', 'decoder.layers.13.self_attn.v_proj.bias', 'decoder.layers.13.self_attn.v_proj.weight', 'decoder.layers.14.input_layernorm.weight', 'decoder.layers.14.mlp.down_proj.bias', 'decoder.layers.14.mlp.down_proj.weight', 'decoder.layers.14.mlp.gate_proj.bias', 'decoder.layers.14.mlp.gate_proj.weight', 'decoder.layers.14.mlp.layer_norm.bias', 'decoder.layers.14.mlp.layer_norm.weight', 'decoder.layers.14.self_attn.k_proj.bias', 'decoder.layers.14.self_attn.k_proj.weight', 'decoder.layers.14.self_attn.o_proj.bias', 'decoder.layers.14.self_attn.o_proj.weight', 'decoder.layers.14.self_attn.q_proj.bias', 'decoder.layers.14.self_attn.q_proj.weight', 'decoder.layers.14.self_attn.scaling', 'decoder.layers.14.self_attn.v_proj.bias', 'decoder.layers.14.self_attn.v_proj.weight', 'decoder.layers.15.input_layernorm.weight', 'decoder.layers.15.mlp.down_proj.bias', 'decoder.layers.15.mlp.down_proj.weight', 'decoder.layers.15.mlp.gate_proj.bias', 'decoder.layers.15.mlp.gate_proj.weight', 'decoder.layers.15.mlp.layer_norm.bias', 'decoder.layers.15.mlp.layer_norm.weight', 'decoder.layers.15.self_attn.k_proj.bias', 'decoder.layers.15.self_attn.k_proj.weight', 'decoder.layers.15.self_attn.o_proj.bias', 'decoder.layers.15.self_attn.o_proj.weight', 'decoder.layers.15.self_attn.q_proj.bias', 'decoder.layers.15.self_attn.q_proj.weight', 'decoder.layers.15.self_attn.scaling', 'decoder.layers.15.self_attn.v_proj.bias', 'decoder.layers.15.self_attn.v_proj.weight', 'decoder.layers.16.input_layernorm.weight', 'decoder.layers.16.mlp.down_proj.bias', 'decoder.layers.16.mlp.down_proj.weight', 'decoder.layers.16.mlp.gate_proj.bias', 'decoder.layers.16.mlp.gate_proj.weight', 'decoder.layers.16.mlp.layer_norm.bias', 'decoder.layers.16.mlp.layer_norm.weight', 'decoder.layers.16.self_attn.k_proj.bias', 'decoder.layers.16.self_attn.k_proj.weight', 'decoder.layers.16.self_attn.o_proj.bias', 'decoder.layers.16.self_attn.o_proj.weight', 'decoder.layers.16.self_attn.q_proj.bias', 'decoder.layers.16.self_attn.q_proj.weight', 'decoder.layers.16.self_attn.scaling', 'decoder.layers.16.self_attn.v_proj.bias', 'decoder.layers.16.self_attn.v_proj.weight', 'decoder.layers.17.input_layernorm.weight', 'decoder.layers.17.mlp.down_proj.bias', 'decoder.layers.17.mlp.down_proj.weight', 'decoder.layers.17.mlp.gate_proj.bias', 'decoder.layers.17.mlp.gate_proj.weight', 'decoder.layers.17.mlp.layer_norm.bias', 'decoder.layers.17.mlp.layer_norm.weight', 'decoder.layers.17.self_attn.k_proj.bias', 'decoder.layers.17.self_attn.k_proj.weight', 'decoder.layers.17.self_attn.o_proj.bias', 'decoder.layers.17.self_attn.o_proj.weight', 'decoder.layers.17.self_attn.q_proj.bias', 'decoder.layers.17.self_attn.q_proj.weight', 'decoder.layers.17.self_attn.scaling', 'decoder.layers.17.self_attn.v_proj.bias', 'decoder.layers.17.self_attn.v_proj.weight', 'decoder.layers.18.input_layernorm.weight', 'decoder.layers.18.mlp.down_proj.bias', 'decoder.layers.18.mlp.down_proj.weight', 'decoder.layers.18.mlp.gate_proj.bias', 'decoder.layers.18.mlp.gate_proj.weight', 'decoder.layers.18.mlp.layer_norm.bias', 'decoder.layers.18.mlp.layer_norm.weight', 'decoder.layers.18.self_attn.k_proj.bias', 'decoder.layers.18.self_attn.k_proj.weight', 'decoder.layers.18.self_attn.o_proj.bias', 'decoder.layers.18.self_attn.o_proj.weight', 'decoder.layers.18.self_attn.q_proj.bias', 'decoder.layers.18.self_attn.q_proj.weight', 'decoder.layers.18.self_attn.scaling', 'decoder.layers.18.self_attn.v_proj.bias', 'decoder.layers.18.self_attn.v_proj.weight', 'decoder.layers.19.input_layernorm.weight', 'decoder.layers.19.mlp.down_proj.bias', 'decoder.layers.19.mlp.down_proj.weight', 'decoder.layers.19.mlp.gate_proj.bias', 'decoder.layers.19.mlp.gate_proj.weight', 'decoder.layers.19.mlp.layer_norm.bias', 'decoder.layers.19.mlp.layer_norm.weight', 'decoder.layers.19.self_attn.k_proj.bias', 'decoder.layers.19.self_attn.k_proj.weight', 'decoder.layers.19.self_attn.o_proj.bias', 'decoder.layers.19.self_attn.o_proj.weight', 'decoder.layers.19.self_attn.q_proj.bias', 'decoder.layers.19.self_attn.q_proj.weight', 'decoder.layers.19.self_attn.scaling', 'decoder.layers.19.self_attn.v_proj.bias', 'decoder.layers.19.self_attn.v_proj.weight', 'decoder.layers.2.input_layernorm.weight', 'decoder.layers.2.mlp.down_proj.bias', 'decoder.layers.2.mlp.down_proj.weight', 'decoder.layers.2.mlp.gate_proj.bias', 'decoder.layers.2.mlp.gate_proj.weight', 'decoder.layers.2.mlp.layer_norm.bias', 'decoder.layers.2.mlp.layer_norm.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.o_proj.bias', 'decoder.layers.2.self_attn.o_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.scaling', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.3.input_layernorm.weight', 'decoder.layers.3.mlp.down_proj.bias', 'decoder.layers.3.mlp.down_proj.weight', 'decoder.layers.3.mlp.gate_proj.bias', 'decoder.layers.3.mlp.gate_proj.weight', 'decoder.layers.3.mlp.layer_norm.bias', 'decoder.layers.3.mlp.layer_norm.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.o_proj.bias', 'decoder.layers.3.self_attn.o_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.scaling', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.4.input_layernorm.weight', 'decoder.layers.4.mlp.down_proj.bias', 'decoder.layers.4.mlp.down_proj.weight', 'decoder.layers.4.mlp.gate_proj.bias', 'decoder.layers.4.mlp.gate_proj.weight', 'decoder.layers.4.mlp.layer_norm.bias', 'decoder.layers.4.mlp.layer_norm.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.o_proj.bias', 'decoder.layers.4.self_attn.o_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.scaling', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.5.input_layernorm.weight', 'decoder.layers.5.mlp.down_proj.bias', 'decoder.layers.5.mlp.down_proj.weight', 'decoder.layers.5.mlp.gate_proj.bias', 'decoder.layers.5.mlp.gate_proj.weight', 'decoder.layers.5.mlp.layer_norm.bias', 'decoder.layers.5.mlp.layer_norm.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.o_proj.bias', 'decoder.layers.5.self_attn.o_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.scaling', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.6.input_layernorm.weight', 'decoder.layers.6.mlp.down_proj.bias', 'decoder.layers.6.mlp.down_proj.weight', 'decoder.layers.6.mlp.gate_proj.bias', 'decoder.layers.6.mlp.gate_proj.weight', 'decoder.layers.6.mlp.layer_norm.bias', 'decoder.layers.6.mlp.layer_norm.weight', 'decoder.layers.6.self_attn.k_proj.bias', 'decoder.layers.6.self_attn.k_proj.weight', 'decoder.layers.6.self_attn.o_proj.bias', 'decoder.layers.6.self_attn.o_proj.weight', 'decoder.layers.6.self_attn.q_proj.bias', 'decoder.layers.6.self_attn.q_proj.weight', 'decoder.layers.6.self_attn.scaling', 'decoder.layers.6.self_attn.v_proj.bias', 'decoder.layers.6.self_attn.v_proj.weight', 'decoder.layers.7.input_layernorm.weight', 'decoder.layers.7.mlp.down_proj.bias', 'decoder.layers.7.mlp.down_proj.weight', 'decoder.layers.7.mlp.gate_proj.bias', 'decoder.layers.7.mlp.gate_proj.weight', 'decoder.layers.7.mlp.layer_norm.bias', 'decoder.layers.7.mlp.layer_norm.weight', 'decoder.layers.7.self_attn.k_proj.bias', 'decoder.layers.7.self_attn.k_proj.weight', 'decoder.layers.7.self_attn.o_proj.bias', 'decoder.layers.7.self_attn.o_proj.weight', 'decoder.layers.7.self_attn.q_proj.bias', 'decoder.layers.7.self_attn.q_proj.weight', 'decoder.layers.7.self_attn.scaling', 'decoder.layers.7.self_attn.v_proj.bias', 'decoder.layers.7.self_attn.v_proj.weight', 'decoder.layers.8.input_layernorm.weight', 'decoder.layers.8.mlp.down_proj.bias', 'decoder.layers.8.mlp.down_proj.weight', 'decoder.layers.8.mlp.gate_proj.bias', 'decoder.layers.8.mlp.gate_proj.weight', 'decoder.layers.8.mlp.layer_norm.bias', 'decoder.layers.8.mlp.layer_norm.weight', 'decoder.layers.8.self_attn.k_proj.bias', 'decoder.layers.8.self_attn.k_proj.weight', 'decoder.layers.8.self_attn.o_proj.bias', 'decoder.layers.8.self_attn.o_proj.weight', 'decoder.layers.8.self_attn.q_proj.bias', 'decoder.layers.8.self_attn.q_proj.weight', 'decoder.layers.8.self_attn.scaling', 'decoder.layers.8.self_attn.v_proj.bias', 'decoder.layers.8.self_attn.v_proj.weight', 'decoder.layers.9.input_layernorm.weight', 'decoder.layers.9.mlp.down_proj.bias', 'decoder.layers.9.mlp.down_proj.weight', 'decoder.layers.9.mlp.gate_proj.bias', 'decoder.layers.9.mlp.gate_proj.weight', 'decoder.layers.9.mlp.layer_norm.bias', 'decoder.layers.9.mlp.layer_norm.weight', 'decoder.layers.9.self_attn.k_proj.bias', 'decoder.layers.9.self_attn.k_proj.weight', 'decoder.layers.9.self_attn.o_proj.bias', 'decoder.layers.9.self_attn.o_proj.weight', 'decoder.layers.9.self_attn.q_proj.bias', 'decoder.layers.9.self_attn.q_proj.weight', 'decoder.layers.9.self_attn.scaling', 'decoder.layers.9.self_attn.v_proj.bias', 'decoder.layers.9.self_attn.v_proj.weight', 'horizon_ff_layer.input_layer.bias', 'horizon_ff_layer.input_layer.weight', 'horizon_ff_layer.output_layer.bias', 'horizon_ff_layer.output_layer.weight', 'horizon_ff_layer.residual_layer.bias', 'horizon_ff_layer.residual_layer.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n",
            "  Epoch 1/100 train_loss=1.4353 train_acc=0.5223 eval_loss=0.8726 eval_acc=0.6711 (best)\n",
            "  Epoch 2/100 train_loss=0.5942 train_acc=0.7927 eval_loss=0.7382 eval_acc=0.6934 (best)\n",
            "  Epoch 3/100 train_loss=0.3477 train_acc=0.9003 eval_loss=0.7697 eval_acc=0.7553 \n",
            "  Epoch 4/100 train_loss=0.2521 train_acc=0.9160 eval_loss=0.7702 eval_acc=0.7842 \n",
            "  Epoch 5/100 train_loss=0.2100 train_acc=0.9213 eval_loss=0.7502 eval_acc=0.7658 \n",
            "  Epoch 6/100 train_loss=0.1437 train_acc=0.9423 eval_loss=1.0025 eval_acc=0.7184 \n",
            "  Epoch 7/100 train_loss=0.2234 train_acc=0.9160 eval_loss=0.9226 eval_acc=0.7566 \n",
            "  Epoch 8/100 train_loss=0.1522 train_acc=0.9370 eval_loss=0.8687 eval_acc=0.7592 \n",
            "  Epoch 9/100 train_loss=0.1546 train_acc=0.9344 eval_loss=1.4980 eval_acc=0.6750 \n",
            "  Epoch 10/100 train_loss=0.2044 train_acc=0.9528 eval_loss=1.1523 eval_acc=0.6987 \n",
            "  Epoch 11/100 train_loss=0.2074 train_acc=0.9423 eval_loss=1.1710 eval_acc=0.7329 \n",
            "  Epoch 12/100 train_loss=0.0855 train_acc=0.9606 eval_loss=1.1803 eval_acc=0.7737 \n",
            "  Early stopping on google/timesfm-2.5-200m-pytorch: no improvement for 10 epochs (best epoch = 2)\n",
            "    tfm[google/timesfm-2.5-200m-pytorch] train_acc=0.7927 eval_acc=0.77368421052631575207669811788946390151977539\n",
            "    mrh_acc=0.7895 mr+h+kg_acc=0.7987 kg_acc=0.8013 ensemble=0.7947 (w=0.60)\n",
            "  Split 1/1 - accuracy=0.7947 time=359.1s\n",
            "Completed MedicalImages: Mean Acc=0.7947\n",
            "\n",
            "=== 59/109 MiddlePhalanxOutlineAgeGroup ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n",
            "    Gate split 1/5: baseline_loss=0.9313 adaptive_loss=0.9815\n",
            "    Gate split 2/5: baseline_loss=0.6094 adaptive_loss=0.6574\n",
            "    Gate split 3/5: baseline_loss=0.7354 adaptive_loss=0.7681\n",
            "    Gate split 4/5: baseline_loss=0.6663 adaptive_loss=0.6591\n",
            "    Gate split 5/5: baseline_loss=0.8715 adaptive_loss=0.8543\n",
            "  Decision: Adaptive rejected (loss 0.7841 vs baseline 0.7628, delta=+0.0213 > +0.0200); savgol(window=5, poly=2) - high noise (std_diff)\n",
            "\n",
            "=== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at google/timesfm-2.5-200m-pytorch were not used when initializing TimesFmModelForPrediction: ['output_projection_point.hidden_layer.weight', 'output_projection_point.output_layer.weight', 'output_projection_point.residual_layer.weight', 'output_projection_quantiles.hidden_layer.weight', 'output_projection_quantiles.output_layer.weight', 'output_projection_quantiles.residual_layer.weight', 'stacked_xf.0.attn.key_ln.scale', 'stacked_xf.0.attn.out.weight', 'stacked_xf.0.attn.per_dim_scale.per_dim_scale', 'stacked_xf.0.attn.qkv_proj.weight', 'stacked_xf.0.attn.query_ln.scale', 'stacked_xf.0.ff0.weight', 'stacked_xf.0.ff1.weight', 'stacked_xf.0.post_attn_ln.scale', 'stacked_xf.0.post_ff_ln.scale', 'stacked_xf.0.pre_attn_ln.scale', 'stacked_xf.0.pre_ff_ln.scale', 'stacked_xf.1.attn.key_ln.scale', 'stacked_xf.1.attn.out.weight', 'stacked_xf.1.attn.per_dim_scale.per_dim_scale', 'stacked_xf.1.attn.qkv_proj.weight', 'stacked_xf.1.attn.query_ln.scale', 'stacked_xf.1.ff0.weight', 'stacked_xf.1.ff1.weight', 'stacked_xf.1.post_attn_ln.scale', 'stacked_xf.1.post_ff_ln.scale', 'stacked_xf.1.pre_attn_ln.scale', 'stacked_xf.1.pre_ff_ln.scale', 'stacked_xf.10.attn.key_ln.scale', 'stacked_xf.10.attn.out.weight', 'stacked_xf.10.attn.per_dim_scale.per_dim_scale', 'stacked_xf.10.attn.qkv_proj.weight', 'stacked_xf.10.attn.query_ln.scale', 'stacked_xf.10.ff0.weight', 'stacked_xf.10.ff1.weight', 'stacked_xf.10.post_attn_ln.scale', 'stacked_xf.10.post_ff_ln.scale', 'stacked_xf.10.pre_attn_ln.scale', 'stacked_xf.10.pre_ff_ln.scale', 'stacked_xf.11.attn.key_ln.scale', 'stacked_xf.11.attn.out.weight', 'stacked_xf.11.attn.per_dim_scale.per_dim_scale', 'stacked_xf.11.attn.qkv_proj.weight', 'stacked_xf.11.attn.query_ln.scale', 'stacked_xf.11.ff0.weight', 'stacked_xf.11.ff1.weight', 'stacked_xf.11.post_attn_ln.scale', 'stacked_xf.11.post_ff_ln.scale', 'stacked_xf.11.pre_attn_ln.scale', 'stacked_xf.11.pre_ff_ln.scale', 'stacked_xf.12.attn.key_ln.scale', 'stacked_xf.12.attn.out.weight', 'stacked_xf.12.attn.per_dim_scale.per_dim_scale', 'stacked_xf.12.attn.qkv_proj.weight', 'stacked_xf.12.attn.query_ln.scale', 'stacked_xf.12.ff0.weight', 'stacked_xf.12.ff1.weight', 'stacked_xf.12.post_attn_ln.scale', 'stacked_xf.12.post_ff_ln.scale', 'stacked_xf.12.pre_attn_ln.scale', 'stacked_xf.12.pre_ff_ln.scale', 'stacked_xf.13.attn.key_ln.scale', 'stacked_xf.13.attn.out.weight', 'stacked_xf.13.attn.per_dim_scale.per_dim_scale', 'stacked_xf.13.attn.qkv_proj.weight', 'stacked_xf.13.attn.query_ln.scale', 'stacked_xf.13.ff0.weight', 'stacked_xf.13.ff1.weight', 'stacked_xf.13.post_attn_ln.scale', 'stacked_xf.13.post_ff_ln.scale', 'stacked_xf.13.pre_attn_ln.scale', 'stacked_xf.13.pre_ff_ln.scale', 'stacked_xf.14.attn.key_ln.scale', 'stacked_xf.14.attn.out.weight', 'stacked_xf.14.attn.per_dim_scale.per_dim_scale', 'stacked_xf.14.attn.qkv_proj.weight', 'stacked_xf.14.attn.query_ln.scale', 'stacked_xf.14.ff0.weight', 'stacked_xf.14.ff1.weight', 'stacked_xf.14.post_attn_ln.scale', 'stacked_xf.14.post_ff_ln.scale', 'stacked_xf.14.pre_attn_ln.scale', 'stacked_xf.14.pre_ff_ln.scale', 'stacked_xf.15.attn.key_ln.scale', 'stacked_xf.15.attn.out.weight', 'stacked_xf.15.attn.per_dim_scale.per_dim_scale', 'stacked_xf.15.attn.qkv_proj.weight', 'stacked_xf.15.attn.query_ln.scale', 'stacked_xf.15.ff0.weight', 'stacked_xf.15.ff1.weight', 'stacked_xf.15.post_attn_ln.scale', 'stacked_xf.15.post_ff_ln.scale', 'stacked_xf.15.pre_attn_ln.scale', 'stacked_xf.15.pre_ff_ln.scale', 'stacked_xf.16.attn.key_ln.scale', 'stacked_xf.16.attn.out.weight', 'stacked_xf.16.attn.per_dim_scale.per_dim_scale', 'stacked_xf.16.attn.qkv_proj.weight', 'stacked_xf.16.attn.query_ln.scale', 'stacked_xf.16.ff0.weight', 'stacked_xf.16.ff1.weight', 'stacked_xf.16.post_attn_ln.scale', 'stacked_xf.16.post_ff_ln.scale', 'stacked_xf.16.pre_attn_ln.scale', 'stacked_xf.16.pre_ff_ln.scale', 'stacked_xf.17.attn.key_ln.scale', 'stacked_xf.17.attn.out.weight', 'stacked_xf.17.attn.per_dim_scale.per_dim_scale', 'stacked_xf.17.attn.qkv_proj.weight', 'stacked_xf.17.attn.query_ln.scale', 'stacked_xf.17.ff0.weight', 'stacked_xf.17.ff1.weight', 'stacked_xf.17.post_attn_ln.scale', 'stacked_xf.17.post_ff_ln.scale', 'stacked_xf.17.pre_attn_ln.scale', 'stacked_xf.17.pre_ff_ln.scale', 'stacked_xf.18.attn.key_ln.scale', 'stacked_xf.18.attn.out.weight', 'stacked_xf.18.attn.per_dim_scale.per_dim_scale', 'stacked_xf.18.attn.qkv_proj.weight', 'stacked_xf.18.attn.query_ln.scale', 'stacked_xf.18.ff0.weight', 'stacked_xf.18.ff1.weight', 'stacked_xf.18.post_attn_ln.scale', 'stacked_xf.18.post_ff_ln.scale', 'stacked_xf.18.pre_attn_ln.scale', 'stacked_xf.18.pre_ff_ln.scale', 'stacked_xf.19.attn.key_ln.scale', 'stacked_xf.19.attn.out.weight', 'stacked_xf.19.attn.per_dim_scale.per_dim_scale', 'stacked_xf.19.attn.qkv_proj.weight', 'stacked_xf.19.attn.query_ln.scale', 'stacked_xf.19.ff0.weight', 'stacked_xf.19.ff1.weight', 'stacked_xf.19.post_attn_ln.scale', 'stacked_xf.19.post_ff_ln.scale', 'stacked_xf.19.pre_attn_ln.scale', 'stacked_xf.19.pre_ff_ln.scale', 'stacked_xf.2.attn.key_ln.scale', 'stacked_xf.2.attn.out.weight', 'stacked_xf.2.attn.per_dim_scale.per_dim_scale', 'stacked_xf.2.attn.qkv_proj.weight', 'stacked_xf.2.attn.query_ln.scale', 'stacked_xf.2.ff0.weight', 'stacked_xf.2.ff1.weight', 'stacked_xf.2.post_attn_ln.scale', 'stacked_xf.2.post_ff_ln.scale', 'stacked_xf.2.pre_attn_ln.scale', 'stacked_xf.2.pre_ff_ln.scale', 'stacked_xf.3.attn.key_ln.scale', 'stacked_xf.3.attn.out.weight', 'stacked_xf.3.attn.per_dim_scale.per_dim_scale', 'stacked_xf.3.attn.qkv_proj.weight', 'stacked_xf.3.attn.query_ln.scale', 'stacked_xf.3.ff0.weight', 'stacked_xf.3.ff1.weight', 'stacked_xf.3.post_attn_ln.scale', 'stacked_xf.3.post_ff_ln.scale', 'stacked_xf.3.pre_attn_ln.scale', 'stacked_xf.3.pre_ff_ln.scale', 'stacked_xf.4.attn.key_ln.scale', 'stacked_xf.4.attn.out.weight', 'stacked_xf.4.attn.per_dim_scale.per_dim_scale', 'stacked_xf.4.attn.qkv_proj.weight', 'stacked_xf.4.attn.query_ln.scale', 'stacked_xf.4.ff0.weight', 'stacked_xf.4.ff1.weight', 'stacked_xf.4.post_attn_ln.scale', 'stacked_xf.4.post_ff_ln.scale', 'stacked_xf.4.pre_attn_ln.scale', 'stacked_xf.4.pre_ff_ln.scale', 'stacked_xf.5.attn.key_ln.scale', 'stacked_xf.5.attn.out.weight', 'stacked_xf.5.attn.per_dim_scale.per_dim_scale', 'stacked_xf.5.attn.qkv_proj.weight', 'stacked_xf.5.attn.query_ln.scale', 'stacked_xf.5.ff0.weight', 'stacked_xf.5.ff1.weight', 'stacked_xf.5.post_attn_ln.scale', 'stacked_xf.5.post_ff_ln.scale', 'stacked_xf.5.pre_attn_ln.scale', 'stacked_xf.5.pre_ff_ln.scale', 'stacked_xf.6.attn.key_ln.scale', 'stacked_xf.6.attn.out.weight', 'stacked_xf.6.attn.per_dim_scale.per_dim_scale', 'stacked_xf.6.attn.qkv_proj.weight', 'stacked_xf.6.attn.query_ln.scale', 'stacked_xf.6.ff0.weight', 'stacked_xf.6.ff1.weight', 'stacked_xf.6.post_attn_ln.scale', 'stacked_xf.6.post_ff_ln.scale', 'stacked_xf.6.pre_attn_ln.scale', 'stacked_xf.6.pre_ff_ln.scale', 'stacked_xf.7.attn.key_ln.scale', 'stacked_xf.7.attn.out.weight', 'stacked_xf.7.attn.per_dim_scale.per_dim_scale', 'stacked_xf.7.attn.qkv_proj.weight', 'stacked_xf.7.attn.query_ln.scale', 'stacked_xf.7.ff0.weight', 'stacked_xf.7.ff1.weight', 'stacked_xf.7.post_attn_ln.scale', 'stacked_xf.7.post_ff_ln.scale', 'stacked_xf.7.pre_attn_ln.scale', 'stacked_xf.7.pre_ff_ln.scale', 'stacked_xf.8.attn.key_ln.scale', 'stacked_xf.8.attn.out.weight', 'stacked_xf.8.attn.per_dim_scale.per_dim_scale', 'stacked_xf.8.attn.qkv_proj.weight', 'stacked_xf.8.attn.query_ln.scale', 'stacked_xf.8.ff0.weight', 'stacked_xf.8.ff1.weight', 'stacked_xf.8.post_attn_ln.scale', 'stacked_xf.8.post_ff_ln.scale', 'stacked_xf.8.pre_attn_ln.scale', 'stacked_xf.8.pre_ff_ln.scale', 'stacked_xf.9.attn.key_ln.scale', 'stacked_xf.9.attn.out.weight', 'stacked_xf.9.attn.per_dim_scale.per_dim_scale', 'stacked_xf.9.attn.qkv_proj.weight', 'stacked_xf.9.attn.query_ln.scale', 'stacked_xf.9.ff0.weight', 'stacked_xf.9.ff1.weight', 'stacked_xf.9.post_attn_ln.scale', 'stacked_xf.9.post_ff_ln.scale', 'stacked_xf.9.pre_attn_ln.scale', 'stacked_xf.9.pre_ff_ln.scale', 'tokenizer.hidden_layer.bias', 'tokenizer.hidden_layer.weight', 'tokenizer.output_layer.bias', 'tokenizer.output_layer.weight', 'tokenizer.residual_layer.bias', 'tokenizer.residual_layer.weight']\n",
            "- This IS expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of TimesFmModelForPrediction were not initialized from the model checkpoint at google/timesfm-2.5-200m-pytorch and are newly initialized: ['decoder.freq_emb.weight', 'decoder.input_ff_layer.input_layer.bias', 'decoder.input_ff_layer.input_layer.weight', 'decoder.input_ff_layer.output_layer.bias', 'decoder.input_ff_layer.output_layer.weight', 'decoder.input_ff_layer.residual_layer.bias', 'decoder.input_ff_layer.residual_layer.weight', 'decoder.layers.0.input_layernorm.weight', 'decoder.layers.0.mlp.down_proj.bias', 'decoder.layers.0.mlp.down_proj.weight', 'decoder.layers.0.mlp.gate_proj.bias', 'decoder.layers.0.mlp.gate_proj.weight', 'decoder.layers.0.mlp.layer_norm.bias', 'decoder.layers.0.mlp.layer_norm.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.o_proj.bias', 'decoder.layers.0.self_attn.o_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.scaling', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.1.input_layernorm.weight', 'decoder.layers.1.mlp.down_proj.bias', 'decoder.layers.1.mlp.down_proj.weight', 'decoder.layers.1.mlp.gate_proj.bias', 'decoder.layers.1.mlp.gate_proj.weight', 'decoder.layers.1.mlp.layer_norm.bias', 'decoder.layers.1.mlp.layer_norm.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.o_proj.bias', 'decoder.layers.1.self_attn.o_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.scaling', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.10.input_layernorm.weight', 'decoder.layers.10.mlp.down_proj.bias', 'decoder.layers.10.mlp.down_proj.weight', 'decoder.layers.10.mlp.gate_proj.bias', 'decoder.layers.10.mlp.gate_proj.weight', 'decoder.layers.10.mlp.layer_norm.bias', 'decoder.layers.10.mlp.layer_norm.weight', 'decoder.layers.10.self_attn.k_proj.bias', 'decoder.layers.10.self_attn.k_proj.weight', 'decoder.layers.10.self_attn.o_proj.bias', 'decoder.layers.10.self_attn.o_proj.weight', 'decoder.layers.10.self_attn.q_proj.bias', 'decoder.layers.10.self_attn.q_proj.weight', 'decoder.layers.10.self_attn.scaling', 'decoder.layers.10.self_attn.v_proj.bias', 'decoder.layers.10.self_attn.v_proj.weight', 'decoder.layers.11.input_layernorm.weight', 'decoder.layers.11.mlp.down_proj.bias', 'decoder.layers.11.mlp.down_proj.weight', 'decoder.layers.11.mlp.gate_proj.bias', 'decoder.layers.11.mlp.gate_proj.weight', 'decoder.layers.11.mlp.layer_norm.bias', 'decoder.layers.11.mlp.layer_norm.weight', 'decoder.layers.11.self_attn.k_proj.bias', 'decoder.layers.11.self_attn.k_proj.weight', 'decoder.layers.11.self_attn.o_proj.bias', 'decoder.layers.11.self_attn.o_proj.weight', 'decoder.layers.11.self_attn.q_proj.bias', 'decoder.layers.11.self_attn.q_proj.weight', 'decoder.layers.11.self_attn.scaling', 'decoder.layers.11.self_attn.v_proj.bias', 'decoder.layers.11.self_attn.v_proj.weight', 'decoder.layers.12.input_layernorm.weight', 'decoder.layers.12.mlp.down_proj.bias', 'decoder.layers.12.mlp.down_proj.weight', 'decoder.layers.12.mlp.gate_proj.bias', 'decoder.layers.12.mlp.gate_proj.weight', 'decoder.layers.12.mlp.layer_norm.bias', 'decoder.layers.12.mlp.layer_norm.weight', 'decoder.layers.12.self_attn.k_proj.bias', 'decoder.layers.12.self_attn.k_proj.weight', 'decoder.layers.12.self_attn.o_proj.bias', 'decoder.layers.12.self_attn.o_proj.weight', 'decoder.layers.12.self_attn.q_proj.bias', 'decoder.layers.12.self_attn.q_proj.weight', 'decoder.layers.12.self_attn.scaling', 'decoder.layers.12.self_attn.v_proj.bias', 'decoder.layers.12.self_attn.v_proj.weight', 'decoder.layers.13.input_layernorm.weight', 'decoder.layers.13.mlp.down_proj.bias', 'decoder.layers.13.mlp.down_proj.weight', 'decoder.layers.13.mlp.gate_proj.bias', 'decoder.layers.13.mlp.gate_proj.weight', 'decoder.layers.13.mlp.layer_norm.bias', 'decoder.layers.13.mlp.layer_norm.weight', 'decoder.layers.13.self_attn.k_proj.bias', 'decoder.layers.13.self_attn.k_proj.weight', 'decoder.layers.13.self_attn.o_proj.bias', 'decoder.layers.13.self_attn.o_proj.weight', 'decoder.layers.13.self_attn.q_proj.bias', 'decoder.layers.13.self_attn.q_proj.weight', 'decoder.layers.13.self_attn.scaling', 'decoder.layers.13.self_attn.v_proj.bias', 'decoder.layers.13.self_attn.v_proj.weight', 'decoder.layers.14.input_layernorm.weight', 'decoder.layers.14.mlp.down_proj.bias', 'decoder.layers.14.mlp.down_proj.weight', 'decoder.layers.14.mlp.gate_proj.bias', 'decoder.layers.14.mlp.gate_proj.weight', 'decoder.layers.14.mlp.layer_norm.bias', 'decoder.layers.14.mlp.layer_norm.weight', 'decoder.layers.14.self_attn.k_proj.bias', 'decoder.layers.14.self_attn.k_proj.weight', 'decoder.layers.14.self_attn.o_proj.bias', 'decoder.layers.14.self_attn.o_proj.weight', 'decoder.layers.14.self_attn.q_proj.bias', 'decoder.layers.14.self_attn.q_proj.weight', 'decoder.layers.14.self_attn.scaling', 'decoder.layers.14.self_attn.v_proj.bias', 'decoder.layers.14.self_attn.v_proj.weight', 'decoder.layers.15.input_layernorm.weight', 'decoder.layers.15.mlp.down_proj.bias', 'decoder.layers.15.mlp.down_proj.weight', 'decoder.layers.15.mlp.gate_proj.bias', 'decoder.layers.15.mlp.gate_proj.weight', 'decoder.layers.15.mlp.layer_norm.bias', 'decoder.layers.15.mlp.layer_norm.weight', 'decoder.layers.15.self_attn.k_proj.bias', 'decoder.layers.15.self_attn.k_proj.weight', 'decoder.layers.15.self_attn.o_proj.bias', 'decoder.layers.15.self_attn.o_proj.weight', 'decoder.layers.15.self_attn.q_proj.bias', 'decoder.layers.15.self_attn.q_proj.weight', 'decoder.layers.15.self_attn.scaling', 'decoder.layers.15.self_attn.v_proj.bias', 'decoder.layers.15.self_attn.v_proj.weight', 'decoder.layers.16.input_layernorm.weight', 'decoder.layers.16.mlp.down_proj.bias', 'decoder.layers.16.mlp.down_proj.weight', 'decoder.layers.16.mlp.gate_proj.bias', 'decoder.layers.16.mlp.gate_proj.weight', 'decoder.layers.16.mlp.layer_norm.bias', 'decoder.layers.16.mlp.layer_norm.weight', 'decoder.layers.16.self_attn.k_proj.bias', 'decoder.layers.16.self_attn.k_proj.weight', 'decoder.layers.16.self_attn.o_proj.bias', 'decoder.layers.16.self_attn.o_proj.weight', 'decoder.layers.16.self_attn.q_proj.bias', 'decoder.layers.16.self_attn.q_proj.weight', 'decoder.layers.16.self_attn.scaling', 'decoder.layers.16.self_attn.v_proj.bias', 'decoder.layers.16.self_attn.v_proj.weight', 'decoder.layers.17.input_layernorm.weight', 'decoder.layers.17.mlp.down_proj.bias', 'decoder.layers.17.mlp.down_proj.weight', 'decoder.layers.17.mlp.gate_proj.bias', 'decoder.layers.17.mlp.gate_proj.weight', 'decoder.layers.17.mlp.layer_norm.bias', 'decoder.layers.17.mlp.layer_norm.weight', 'decoder.layers.17.self_attn.k_proj.bias', 'decoder.layers.17.self_attn.k_proj.weight', 'decoder.layers.17.self_attn.o_proj.bias', 'decoder.layers.17.self_attn.o_proj.weight', 'decoder.layers.17.self_attn.q_proj.bias', 'decoder.layers.17.self_attn.q_proj.weight', 'decoder.layers.17.self_attn.scaling', 'decoder.layers.17.self_attn.v_proj.bias', 'decoder.layers.17.self_attn.v_proj.weight', 'decoder.layers.18.input_layernorm.weight', 'decoder.layers.18.mlp.down_proj.bias', 'decoder.layers.18.mlp.down_proj.weight', 'decoder.layers.18.mlp.gate_proj.bias', 'decoder.layers.18.mlp.gate_proj.weight', 'decoder.layers.18.mlp.layer_norm.bias', 'decoder.layers.18.mlp.layer_norm.weight', 'decoder.layers.18.self_attn.k_proj.bias', 'decoder.layers.18.self_attn.k_proj.weight', 'decoder.layers.18.self_attn.o_proj.bias', 'decoder.layers.18.self_attn.o_proj.weight', 'decoder.layers.18.self_attn.q_proj.bias', 'decoder.layers.18.self_attn.q_proj.weight', 'decoder.layers.18.self_attn.scaling', 'decoder.layers.18.self_attn.v_proj.bias', 'decoder.layers.18.self_attn.v_proj.weight', 'decoder.layers.19.input_layernorm.weight', 'decoder.layers.19.mlp.down_proj.bias', 'decoder.layers.19.mlp.down_proj.weight', 'decoder.layers.19.mlp.gate_proj.bias', 'decoder.layers.19.mlp.gate_proj.weight', 'decoder.layers.19.mlp.layer_norm.bias', 'decoder.layers.19.mlp.layer_norm.weight', 'decoder.layers.19.self_attn.k_proj.bias', 'decoder.layers.19.self_attn.k_proj.weight', 'decoder.layers.19.self_attn.o_proj.bias', 'decoder.layers.19.self_attn.o_proj.weight', 'decoder.layers.19.self_attn.q_proj.bias', 'decoder.layers.19.self_attn.q_proj.weight', 'decoder.layers.19.self_attn.scaling', 'decoder.layers.19.self_attn.v_proj.bias', 'decoder.layers.19.self_attn.v_proj.weight', 'decoder.layers.2.input_layernorm.weight', 'decoder.layers.2.mlp.down_proj.bias', 'decoder.layers.2.mlp.down_proj.weight', 'decoder.layers.2.mlp.gate_proj.bias', 'decoder.layers.2.mlp.gate_proj.weight', 'decoder.layers.2.mlp.layer_norm.bias', 'decoder.layers.2.mlp.layer_norm.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.o_proj.bias', 'decoder.layers.2.self_attn.o_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.scaling', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.3.input_layernorm.weight', 'decoder.layers.3.mlp.down_proj.bias', 'decoder.layers.3.mlp.down_proj.weight', 'decoder.layers.3.mlp.gate_proj.bias', 'decoder.layers.3.mlp.gate_proj.weight', 'decoder.layers.3.mlp.layer_norm.bias', 'decoder.layers.3.mlp.layer_norm.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.o_proj.bias', 'decoder.layers.3.self_attn.o_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.scaling', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.4.input_layernorm.weight', 'decoder.layers.4.mlp.down_proj.bias', 'decoder.layers.4.mlp.down_proj.weight', 'decoder.layers.4.mlp.gate_proj.bias', 'decoder.layers.4.mlp.gate_proj.weight', 'decoder.layers.4.mlp.layer_norm.bias', 'decoder.layers.4.mlp.layer_norm.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.o_proj.bias', 'decoder.layers.4.self_attn.o_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.scaling', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.5.input_layernorm.weight', 'decoder.layers.5.mlp.down_proj.bias', 'decoder.layers.5.mlp.down_proj.weight', 'decoder.layers.5.mlp.gate_proj.bias', 'decoder.layers.5.mlp.gate_proj.weight', 'decoder.layers.5.mlp.layer_norm.bias', 'decoder.layers.5.mlp.layer_norm.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.o_proj.bias', 'decoder.layers.5.self_attn.o_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.scaling', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.6.input_layernorm.weight', 'decoder.layers.6.mlp.down_proj.bias', 'decoder.layers.6.mlp.down_proj.weight', 'decoder.layers.6.mlp.gate_proj.bias', 'decoder.layers.6.mlp.gate_proj.weight', 'decoder.layers.6.mlp.layer_norm.bias', 'decoder.layers.6.mlp.layer_norm.weight', 'decoder.layers.6.self_attn.k_proj.bias', 'decoder.layers.6.self_attn.k_proj.weight', 'decoder.layers.6.self_attn.o_proj.bias', 'decoder.layers.6.self_attn.o_proj.weight', 'decoder.layers.6.self_attn.q_proj.bias', 'decoder.layers.6.self_attn.q_proj.weight', 'decoder.layers.6.self_attn.scaling', 'decoder.layers.6.self_attn.v_proj.bias', 'decoder.layers.6.self_attn.v_proj.weight', 'decoder.layers.7.input_layernorm.weight', 'decoder.layers.7.mlp.down_proj.bias', 'decoder.layers.7.mlp.down_proj.weight', 'decoder.layers.7.mlp.gate_proj.bias', 'decoder.layers.7.mlp.gate_proj.weight', 'decoder.layers.7.mlp.layer_norm.bias', 'decoder.layers.7.mlp.layer_norm.weight', 'decoder.layers.7.self_attn.k_proj.bias', 'decoder.layers.7.self_attn.k_proj.weight', 'decoder.layers.7.self_attn.o_proj.bias', 'decoder.layers.7.self_attn.o_proj.weight', 'decoder.layers.7.self_attn.q_proj.bias', 'decoder.layers.7.self_attn.q_proj.weight', 'decoder.layers.7.self_attn.scaling', 'decoder.layers.7.self_attn.v_proj.bias', 'decoder.layers.7.self_attn.v_proj.weight', 'decoder.layers.8.input_layernorm.weight', 'decoder.layers.8.mlp.down_proj.bias', 'decoder.layers.8.mlp.down_proj.weight', 'decoder.layers.8.mlp.gate_proj.bias', 'decoder.layers.8.mlp.gate_proj.weight', 'decoder.layers.8.mlp.layer_norm.bias', 'decoder.layers.8.mlp.layer_norm.weight', 'decoder.layers.8.self_attn.k_proj.bias', 'decoder.layers.8.self_attn.k_proj.weight', 'decoder.layers.8.self_attn.o_proj.bias', 'decoder.layers.8.self_attn.o_proj.weight', 'decoder.layers.8.self_attn.q_proj.bias', 'decoder.layers.8.self_attn.q_proj.weight', 'decoder.layers.8.self_attn.scaling', 'decoder.layers.8.self_attn.v_proj.bias', 'decoder.layers.8.self_attn.v_proj.weight', 'decoder.layers.9.input_layernorm.weight', 'decoder.layers.9.mlp.down_proj.bias', 'decoder.layers.9.mlp.down_proj.weight', 'decoder.layers.9.mlp.gate_proj.bias', 'decoder.layers.9.mlp.gate_proj.weight', 'decoder.layers.9.mlp.layer_norm.bias', 'decoder.layers.9.mlp.layer_norm.weight', 'decoder.layers.9.self_attn.k_proj.bias', 'decoder.layers.9.self_attn.k_proj.weight', 'decoder.layers.9.self_attn.o_proj.bias', 'decoder.layers.9.self_attn.o_proj.weight', 'decoder.layers.9.self_attn.q_proj.bias', 'decoder.layers.9.self_attn.q_proj.weight', 'decoder.layers.9.self_attn.scaling', 'decoder.layers.9.self_attn.v_proj.bias', 'decoder.layers.9.self_attn.v_proj.weight', 'horizon_ff_layer.input_layer.bias', 'horizon_ff_layer.input_layer.weight', 'horizon_ff_layer.output_layer.bias', 'horizon_ff_layer.output_layer.weight', 'horizon_ff_layer.residual_layer.bias', 'horizon_ff_layer.residual_layer.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n",
            "  Epoch 1/100 train_loss=0.7622 train_acc=0.6850 eval_loss=0.7200 eval_acc=0.7013 (best)\n",
            "  Epoch 2/100 train_loss=0.5526 train_acc=0.7675 eval_loss=0.6226 eval_acc=0.7532 (best)\n",
            "  Epoch 3/100 train_loss=0.4189 train_acc=0.8475 eval_loss=0.9040 eval_acc=0.7338 \n",
            "  Epoch 4/100 train_loss=0.3715 train_acc=0.8575 eval_loss=0.9248 eval_acc=0.6429 \n",
            "  Epoch 5/100 train_loss=0.2734 train_acc=0.9025 eval_loss=1.0783 eval_acc=0.7273 \n",
            "  Epoch 6/100 train_loss=0.1799 train_acc=0.9475 eval_loss=1.5381 eval_acc=0.7273 \n",
            "  Epoch 7/100 train_loss=0.1532 train_acc=0.9450 eval_loss=1.8446 eval_acc=0.7403 \n",
            "  Epoch 8/100 train_loss=0.1153 train_acc=0.9675 eval_loss=1.7878 eval_acc=0.7273 \n",
            "  Epoch 9/100 train_loss=0.2902 train_acc=0.8925 eval_loss=2.1106 eval_acc=0.7078 \n",
            "  Epoch 10/100 train_loss=0.3697 train_acc=0.8950 eval_loss=1.7112 eval_acc=0.5844 \n",
            "  Epoch 11/100 train_loss=0.1361 train_acc=0.9350 eval_loss=1.4213 eval_acc=0.7468 \n",
            "  Epoch 12/100 train_loss=0.1108 train_acc=0.9575 eval_loss=1.7003 eval_acc=0.7662 \n",
            "  Early stopping on google/timesfm-2.5-200m-pytorch: no improvement for 10 epochs (best epoch = 2)\n",
            "    tfm[google/timesfm-2.5-200m-pytorch] train_acc=0.7675 eval_acc=0.76623376623376626692873969659558497369289398\n",
            "    mrh_acc=0.7662 mr+h+kg_acc=0.7403 kg_acc=0.7273 ensemble=0.7468 (w=0.60)\n",
            "  Split 1/1 - accuracy=0.7468 time=250.7s\n",
            "Completed MiddlePhalanxOutlineAgeGroup: Mean Acc=0.7468\n",
            "\n",
            "=== 60/109 MiddlePhalanxOutlineCorrect ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n",
            "    Gate split 1/5: baseline_loss=0.8909 adaptive_loss=0.8680\n",
            "    Gate split 2/5: baseline_loss=0.7689 adaptive_loss=0.7147\n",
            "    Gate split 3/5: baseline_loss=0.6520 adaptive_loss=0.6484\n",
            "    Gate split 4/5: baseline_loss=0.7782 adaptive_loss=0.7796\n",
            "    Gate split 5/5: baseline_loss=0.8288 adaptive_loss=0.8467\n",
            "  Decision: Adaptive kept (loss 0.7715 vs baseline 0.7838, delta=-0.0123 <= +0.0200); savgol(window=5, poly=2) - high noise (std_diff)\n",
            "Error processing MiddlePhalanxOutlineCorrect: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n",
            "\n",
            "=== 61/109 MiddlePhalanxTW ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 556, in main\n",
            "    results = evaluate_dataset_per_split(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 429, in evaluate_dataset_per_split\n",
            "    X_train_extra = np.concatenate([X_train_all, all_dec_train], axis=1)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "ValueError: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Gate split 1/5: baseline_loss=1.1897 adaptive_loss=1.1890\n",
            "    Gate split 2/5: baseline_loss=1.0881 adaptive_loss=1.1500\n",
            "    Gate split 3/5: baseline_loss=1.0071 adaptive_loss=1.0017\n",
            "    Gate split 4/5: baseline_loss=1.0249 adaptive_loss=1.0410\n",
            "    Gate split 5/5: baseline_loss=1.0734 adaptive_loss=1.1045\n",
            "  Decision: Adaptive rejected (loss 1.0973 vs baseline 1.0766, delta=+0.0206 > +0.0200); savgol(window=5, poly=2) - high noise (std_diff)\n",
            "\n",
            "=== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at google/timesfm-2.5-200m-pytorch were not used when initializing TimesFmModelForPrediction: ['output_projection_point.hidden_layer.weight', 'output_projection_point.output_layer.weight', 'output_projection_point.residual_layer.weight', 'output_projection_quantiles.hidden_layer.weight', 'output_projection_quantiles.output_layer.weight', 'output_projection_quantiles.residual_layer.weight', 'stacked_xf.0.attn.key_ln.scale', 'stacked_xf.0.attn.out.weight', 'stacked_xf.0.attn.per_dim_scale.per_dim_scale', 'stacked_xf.0.attn.qkv_proj.weight', 'stacked_xf.0.attn.query_ln.scale', 'stacked_xf.0.ff0.weight', 'stacked_xf.0.ff1.weight', 'stacked_xf.0.post_attn_ln.scale', 'stacked_xf.0.post_ff_ln.scale', 'stacked_xf.0.pre_attn_ln.scale', 'stacked_xf.0.pre_ff_ln.scale', 'stacked_xf.1.attn.key_ln.scale', 'stacked_xf.1.attn.out.weight', 'stacked_xf.1.attn.per_dim_scale.per_dim_scale', 'stacked_xf.1.attn.qkv_proj.weight', 'stacked_xf.1.attn.query_ln.scale', 'stacked_xf.1.ff0.weight', 'stacked_xf.1.ff1.weight', 'stacked_xf.1.post_attn_ln.scale', 'stacked_xf.1.post_ff_ln.scale', 'stacked_xf.1.pre_attn_ln.scale', 'stacked_xf.1.pre_ff_ln.scale', 'stacked_xf.10.attn.key_ln.scale', 'stacked_xf.10.attn.out.weight', 'stacked_xf.10.attn.per_dim_scale.per_dim_scale', 'stacked_xf.10.attn.qkv_proj.weight', 'stacked_xf.10.attn.query_ln.scale', 'stacked_xf.10.ff0.weight', 'stacked_xf.10.ff1.weight', 'stacked_xf.10.post_attn_ln.scale', 'stacked_xf.10.post_ff_ln.scale', 'stacked_xf.10.pre_attn_ln.scale', 'stacked_xf.10.pre_ff_ln.scale', 'stacked_xf.11.attn.key_ln.scale', 'stacked_xf.11.attn.out.weight', 'stacked_xf.11.attn.per_dim_scale.per_dim_scale', 'stacked_xf.11.attn.qkv_proj.weight', 'stacked_xf.11.attn.query_ln.scale', 'stacked_xf.11.ff0.weight', 'stacked_xf.11.ff1.weight', 'stacked_xf.11.post_attn_ln.scale', 'stacked_xf.11.post_ff_ln.scale', 'stacked_xf.11.pre_attn_ln.scale', 'stacked_xf.11.pre_ff_ln.scale', 'stacked_xf.12.attn.key_ln.scale', 'stacked_xf.12.attn.out.weight', 'stacked_xf.12.attn.per_dim_scale.per_dim_scale', 'stacked_xf.12.attn.qkv_proj.weight', 'stacked_xf.12.attn.query_ln.scale', 'stacked_xf.12.ff0.weight', 'stacked_xf.12.ff1.weight', 'stacked_xf.12.post_attn_ln.scale', 'stacked_xf.12.post_ff_ln.scale', 'stacked_xf.12.pre_attn_ln.scale', 'stacked_xf.12.pre_ff_ln.scale', 'stacked_xf.13.attn.key_ln.scale', 'stacked_xf.13.attn.out.weight', 'stacked_xf.13.attn.per_dim_scale.per_dim_scale', 'stacked_xf.13.attn.qkv_proj.weight', 'stacked_xf.13.attn.query_ln.scale', 'stacked_xf.13.ff0.weight', 'stacked_xf.13.ff1.weight', 'stacked_xf.13.post_attn_ln.scale', 'stacked_xf.13.post_ff_ln.scale', 'stacked_xf.13.pre_attn_ln.scale', 'stacked_xf.13.pre_ff_ln.scale', 'stacked_xf.14.attn.key_ln.scale', 'stacked_xf.14.attn.out.weight', 'stacked_xf.14.attn.per_dim_scale.per_dim_scale', 'stacked_xf.14.attn.qkv_proj.weight', 'stacked_xf.14.attn.query_ln.scale', 'stacked_xf.14.ff0.weight', 'stacked_xf.14.ff1.weight', 'stacked_xf.14.post_attn_ln.scale', 'stacked_xf.14.post_ff_ln.scale', 'stacked_xf.14.pre_attn_ln.scale', 'stacked_xf.14.pre_ff_ln.scale', 'stacked_xf.15.attn.key_ln.scale', 'stacked_xf.15.attn.out.weight', 'stacked_xf.15.attn.per_dim_scale.per_dim_scale', 'stacked_xf.15.attn.qkv_proj.weight', 'stacked_xf.15.attn.query_ln.scale', 'stacked_xf.15.ff0.weight', 'stacked_xf.15.ff1.weight', 'stacked_xf.15.post_attn_ln.scale', 'stacked_xf.15.post_ff_ln.scale', 'stacked_xf.15.pre_attn_ln.scale', 'stacked_xf.15.pre_ff_ln.scale', 'stacked_xf.16.attn.key_ln.scale', 'stacked_xf.16.attn.out.weight', 'stacked_xf.16.attn.per_dim_scale.per_dim_scale', 'stacked_xf.16.attn.qkv_proj.weight', 'stacked_xf.16.attn.query_ln.scale', 'stacked_xf.16.ff0.weight', 'stacked_xf.16.ff1.weight', 'stacked_xf.16.post_attn_ln.scale', 'stacked_xf.16.post_ff_ln.scale', 'stacked_xf.16.pre_attn_ln.scale', 'stacked_xf.16.pre_ff_ln.scale', 'stacked_xf.17.attn.key_ln.scale', 'stacked_xf.17.attn.out.weight', 'stacked_xf.17.attn.per_dim_scale.per_dim_scale', 'stacked_xf.17.attn.qkv_proj.weight', 'stacked_xf.17.attn.query_ln.scale', 'stacked_xf.17.ff0.weight', 'stacked_xf.17.ff1.weight', 'stacked_xf.17.post_attn_ln.scale', 'stacked_xf.17.post_ff_ln.scale', 'stacked_xf.17.pre_attn_ln.scale', 'stacked_xf.17.pre_ff_ln.scale', 'stacked_xf.18.attn.key_ln.scale', 'stacked_xf.18.attn.out.weight', 'stacked_xf.18.attn.per_dim_scale.per_dim_scale', 'stacked_xf.18.attn.qkv_proj.weight', 'stacked_xf.18.attn.query_ln.scale', 'stacked_xf.18.ff0.weight', 'stacked_xf.18.ff1.weight', 'stacked_xf.18.post_attn_ln.scale', 'stacked_xf.18.post_ff_ln.scale', 'stacked_xf.18.pre_attn_ln.scale', 'stacked_xf.18.pre_ff_ln.scale', 'stacked_xf.19.attn.key_ln.scale', 'stacked_xf.19.attn.out.weight', 'stacked_xf.19.attn.per_dim_scale.per_dim_scale', 'stacked_xf.19.attn.qkv_proj.weight', 'stacked_xf.19.attn.query_ln.scale', 'stacked_xf.19.ff0.weight', 'stacked_xf.19.ff1.weight', 'stacked_xf.19.post_attn_ln.scale', 'stacked_xf.19.post_ff_ln.scale', 'stacked_xf.19.pre_attn_ln.scale', 'stacked_xf.19.pre_ff_ln.scale', 'stacked_xf.2.attn.key_ln.scale', 'stacked_xf.2.attn.out.weight', 'stacked_xf.2.attn.per_dim_scale.per_dim_scale', 'stacked_xf.2.attn.qkv_proj.weight', 'stacked_xf.2.attn.query_ln.scale', 'stacked_xf.2.ff0.weight', 'stacked_xf.2.ff1.weight', 'stacked_xf.2.post_attn_ln.scale', 'stacked_xf.2.post_ff_ln.scale', 'stacked_xf.2.pre_attn_ln.scale', 'stacked_xf.2.pre_ff_ln.scale', 'stacked_xf.3.attn.key_ln.scale', 'stacked_xf.3.attn.out.weight', 'stacked_xf.3.attn.per_dim_scale.per_dim_scale', 'stacked_xf.3.attn.qkv_proj.weight', 'stacked_xf.3.attn.query_ln.scale', 'stacked_xf.3.ff0.weight', 'stacked_xf.3.ff1.weight', 'stacked_xf.3.post_attn_ln.scale', 'stacked_xf.3.post_ff_ln.scale', 'stacked_xf.3.pre_attn_ln.scale', 'stacked_xf.3.pre_ff_ln.scale', 'stacked_xf.4.attn.key_ln.scale', 'stacked_xf.4.attn.out.weight', 'stacked_xf.4.attn.per_dim_scale.per_dim_scale', 'stacked_xf.4.attn.qkv_proj.weight', 'stacked_xf.4.attn.query_ln.scale', 'stacked_xf.4.ff0.weight', 'stacked_xf.4.ff1.weight', 'stacked_xf.4.post_attn_ln.scale', 'stacked_xf.4.post_ff_ln.scale', 'stacked_xf.4.pre_attn_ln.scale', 'stacked_xf.4.pre_ff_ln.scale', 'stacked_xf.5.attn.key_ln.scale', 'stacked_xf.5.attn.out.weight', 'stacked_xf.5.attn.per_dim_scale.per_dim_scale', 'stacked_xf.5.attn.qkv_proj.weight', 'stacked_xf.5.attn.query_ln.scale', 'stacked_xf.5.ff0.weight', 'stacked_xf.5.ff1.weight', 'stacked_xf.5.post_attn_ln.scale', 'stacked_xf.5.post_ff_ln.scale', 'stacked_xf.5.pre_attn_ln.scale', 'stacked_xf.5.pre_ff_ln.scale', 'stacked_xf.6.attn.key_ln.scale', 'stacked_xf.6.attn.out.weight', 'stacked_xf.6.attn.per_dim_scale.per_dim_scale', 'stacked_xf.6.attn.qkv_proj.weight', 'stacked_xf.6.attn.query_ln.scale', 'stacked_xf.6.ff0.weight', 'stacked_xf.6.ff1.weight', 'stacked_xf.6.post_attn_ln.scale', 'stacked_xf.6.post_ff_ln.scale', 'stacked_xf.6.pre_attn_ln.scale', 'stacked_xf.6.pre_ff_ln.scale', 'stacked_xf.7.attn.key_ln.scale', 'stacked_xf.7.attn.out.weight', 'stacked_xf.7.attn.per_dim_scale.per_dim_scale', 'stacked_xf.7.attn.qkv_proj.weight', 'stacked_xf.7.attn.query_ln.scale', 'stacked_xf.7.ff0.weight', 'stacked_xf.7.ff1.weight', 'stacked_xf.7.post_attn_ln.scale', 'stacked_xf.7.post_ff_ln.scale', 'stacked_xf.7.pre_attn_ln.scale', 'stacked_xf.7.pre_ff_ln.scale', 'stacked_xf.8.attn.key_ln.scale', 'stacked_xf.8.attn.out.weight', 'stacked_xf.8.attn.per_dim_scale.per_dim_scale', 'stacked_xf.8.attn.qkv_proj.weight', 'stacked_xf.8.attn.query_ln.scale', 'stacked_xf.8.ff0.weight', 'stacked_xf.8.ff1.weight', 'stacked_xf.8.post_attn_ln.scale', 'stacked_xf.8.post_ff_ln.scale', 'stacked_xf.8.pre_attn_ln.scale', 'stacked_xf.8.pre_ff_ln.scale', 'stacked_xf.9.attn.key_ln.scale', 'stacked_xf.9.attn.out.weight', 'stacked_xf.9.attn.per_dim_scale.per_dim_scale', 'stacked_xf.9.attn.qkv_proj.weight', 'stacked_xf.9.attn.query_ln.scale', 'stacked_xf.9.ff0.weight', 'stacked_xf.9.ff1.weight', 'stacked_xf.9.post_attn_ln.scale', 'stacked_xf.9.post_ff_ln.scale', 'stacked_xf.9.pre_attn_ln.scale', 'stacked_xf.9.pre_ff_ln.scale', 'tokenizer.hidden_layer.bias', 'tokenizer.hidden_layer.weight', 'tokenizer.output_layer.bias', 'tokenizer.output_layer.weight', 'tokenizer.residual_layer.bias', 'tokenizer.residual_layer.weight']\n",
            "- This IS expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of TimesFmModelForPrediction were not initialized from the model checkpoint at google/timesfm-2.5-200m-pytorch and are newly initialized: ['decoder.freq_emb.weight', 'decoder.input_ff_layer.input_layer.bias', 'decoder.input_ff_layer.input_layer.weight', 'decoder.input_ff_layer.output_layer.bias', 'decoder.input_ff_layer.output_layer.weight', 'decoder.input_ff_layer.residual_layer.bias', 'decoder.input_ff_layer.residual_layer.weight', 'decoder.layers.0.input_layernorm.weight', 'decoder.layers.0.mlp.down_proj.bias', 'decoder.layers.0.mlp.down_proj.weight', 'decoder.layers.0.mlp.gate_proj.bias', 'decoder.layers.0.mlp.gate_proj.weight', 'decoder.layers.0.mlp.layer_norm.bias', 'decoder.layers.0.mlp.layer_norm.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.o_proj.bias', 'decoder.layers.0.self_attn.o_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.scaling', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.1.input_layernorm.weight', 'decoder.layers.1.mlp.down_proj.bias', 'decoder.layers.1.mlp.down_proj.weight', 'decoder.layers.1.mlp.gate_proj.bias', 'decoder.layers.1.mlp.gate_proj.weight', 'decoder.layers.1.mlp.layer_norm.bias', 'decoder.layers.1.mlp.layer_norm.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.o_proj.bias', 'decoder.layers.1.self_attn.o_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.scaling', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.10.input_layernorm.weight', 'decoder.layers.10.mlp.down_proj.bias', 'decoder.layers.10.mlp.down_proj.weight', 'decoder.layers.10.mlp.gate_proj.bias', 'decoder.layers.10.mlp.gate_proj.weight', 'decoder.layers.10.mlp.layer_norm.bias', 'decoder.layers.10.mlp.layer_norm.weight', 'decoder.layers.10.self_attn.k_proj.bias', 'decoder.layers.10.self_attn.k_proj.weight', 'decoder.layers.10.self_attn.o_proj.bias', 'decoder.layers.10.self_attn.o_proj.weight', 'decoder.layers.10.self_attn.q_proj.bias', 'decoder.layers.10.self_attn.q_proj.weight', 'decoder.layers.10.self_attn.scaling', 'decoder.layers.10.self_attn.v_proj.bias', 'decoder.layers.10.self_attn.v_proj.weight', 'decoder.layers.11.input_layernorm.weight', 'decoder.layers.11.mlp.down_proj.bias', 'decoder.layers.11.mlp.down_proj.weight', 'decoder.layers.11.mlp.gate_proj.bias', 'decoder.layers.11.mlp.gate_proj.weight', 'decoder.layers.11.mlp.layer_norm.bias', 'decoder.layers.11.mlp.layer_norm.weight', 'decoder.layers.11.self_attn.k_proj.bias', 'decoder.layers.11.self_attn.k_proj.weight', 'decoder.layers.11.self_attn.o_proj.bias', 'decoder.layers.11.self_attn.o_proj.weight', 'decoder.layers.11.self_attn.q_proj.bias', 'decoder.layers.11.self_attn.q_proj.weight', 'decoder.layers.11.self_attn.scaling', 'decoder.layers.11.self_attn.v_proj.bias', 'decoder.layers.11.self_attn.v_proj.weight', 'decoder.layers.12.input_layernorm.weight', 'decoder.layers.12.mlp.down_proj.bias', 'decoder.layers.12.mlp.down_proj.weight', 'decoder.layers.12.mlp.gate_proj.bias', 'decoder.layers.12.mlp.gate_proj.weight', 'decoder.layers.12.mlp.layer_norm.bias', 'decoder.layers.12.mlp.layer_norm.weight', 'decoder.layers.12.self_attn.k_proj.bias', 'decoder.layers.12.self_attn.k_proj.weight', 'decoder.layers.12.self_attn.o_proj.bias', 'decoder.layers.12.self_attn.o_proj.weight', 'decoder.layers.12.self_attn.q_proj.bias', 'decoder.layers.12.self_attn.q_proj.weight', 'decoder.layers.12.self_attn.scaling', 'decoder.layers.12.self_attn.v_proj.bias', 'decoder.layers.12.self_attn.v_proj.weight', 'decoder.layers.13.input_layernorm.weight', 'decoder.layers.13.mlp.down_proj.bias', 'decoder.layers.13.mlp.down_proj.weight', 'decoder.layers.13.mlp.gate_proj.bias', 'decoder.layers.13.mlp.gate_proj.weight', 'decoder.layers.13.mlp.layer_norm.bias', 'decoder.layers.13.mlp.layer_norm.weight', 'decoder.layers.13.self_attn.k_proj.bias', 'decoder.layers.13.self_attn.k_proj.weight', 'decoder.layers.13.self_attn.o_proj.bias', 'decoder.layers.13.self_attn.o_proj.weight', 'decoder.layers.13.self_attn.q_proj.bias', 'decoder.layers.13.self_attn.q_proj.weight', 'decoder.layers.13.self_attn.scaling', 'decoder.layers.13.self_attn.v_proj.bias', 'decoder.layers.13.self_attn.v_proj.weight', 'decoder.layers.14.input_layernorm.weight', 'decoder.layers.14.mlp.down_proj.bias', 'decoder.layers.14.mlp.down_proj.weight', 'decoder.layers.14.mlp.gate_proj.bias', 'decoder.layers.14.mlp.gate_proj.weight', 'decoder.layers.14.mlp.layer_norm.bias', 'decoder.layers.14.mlp.layer_norm.weight', 'decoder.layers.14.self_attn.k_proj.bias', 'decoder.layers.14.self_attn.k_proj.weight', 'decoder.layers.14.self_attn.o_proj.bias', 'decoder.layers.14.self_attn.o_proj.weight', 'decoder.layers.14.self_attn.q_proj.bias', 'decoder.layers.14.self_attn.q_proj.weight', 'decoder.layers.14.self_attn.scaling', 'decoder.layers.14.self_attn.v_proj.bias', 'decoder.layers.14.self_attn.v_proj.weight', 'decoder.layers.15.input_layernorm.weight', 'decoder.layers.15.mlp.down_proj.bias', 'decoder.layers.15.mlp.down_proj.weight', 'decoder.layers.15.mlp.gate_proj.bias', 'decoder.layers.15.mlp.gate_proj.weight', 'decoder.layers.15.mlp.layer_norm.bias', 'decoder.layers.15.mlp.layer_norm.weight', 'decoder.layers.15.self_attn.k_proj.bias', 'decoder.layers.15.self_attn.k_proj.weight', 'decoder.layers.15.self_attn.o_proj.bias', 'decoder.layers.15.self_attn.o_proj.weight', 'decoder.layers.15.self_attn.q_proj.bias', 'decoder.layers.15.self_attn.q_proj.weight', 'decoder.layers.15.self_attn.scaling', 'decoder.layers.15.self_attn.v_proj.bias', 'decoder.layers.15.self_attn.v_proj.weight', 'decoder.layers.16.input_layernorm.weight', 'decoder.layers.16.mlp.down_proj.bias', 'decoder.layers.16.mlp.down_proj.weight', 'decoder.layers.16.mlp.gate_proj.bias', 'decoder.layers.16.mlp.gate_proj.weight', 'decoder.layers.16.mlp.layer_norm.bias', 'decoder.layers.16.mlp.layer_norm.weight', 'decoder.layers.16.self_attn.k_proj.bias', 'decoder.layers.16.self_attn.k_proj.weight', 'decoder.layers.16.self_attn.o_proj.bias', 'decoder.layers.16.self_attn.o_proj.weight', 'decoder.layers.16.self_attn.q_proj.bias', 'decoder.layers.16.self_attn.q_proj.weight', 'decoder.layers.16.self_attn.scaling', 'decoder.layers.16.self_attn.v_proj.bias', 'decoder.layers.16.self_attn.v_proj.weight', 'decoder.layers.17.input_layernorm.weight', 'decoder.layers.17.mlp.down_proj.bias', 'decoder.layers.17.mlp.down_proj.weight', 'decoder.layers.17.mlp.gate_proj.bias', 'decoder.layers.17.mlp.gate_proj.weight', 'decoder.layers.17.mlp.layer_norm.bias', 'decoder.layers.17.mlp.layer_norm.weight', 'decoder.layers.17.self_attn.k_proj.bias', 'decoder.layers.17.self_attn.k_proj.weight', 'decoder.layers.17.self_attn.o_proj.bias', 'decoder.layers.17.self_attn.o_proj.weight', 'decoder.layers.17.self_attn.q_proj.bias', 'decoder.layers.17.self_attn.q_proj.weight', 'decoder.layers.17.self_attn.scaling', 'decoder.layers.17.self_attn.v_proj.bias', 'decoder.layers.17.self_attn.v_proj.weight', 'decoder.layers.18.input_layernorm.weight', 'decoder.layers.18.mlp.down_proj.bias', 'decoder.layers.18.mlp.down_proj.weight', 'decoder.layers.18.mlp.gate_proj.bias', 'decoder.layers.18.mlp.gate_proj.weight', 'decoder.layers.18.mlp.layer_norm.bias', 'decoder.layers.18.mlp.layer_norm.weight', 'decoder.layers.18.self_attn.k_proj.bias', 'decoder.layers.18.self_attn.k_proj.weight', 'decoder.layers.18.self_attn.o_proj.bias', 'decoder.layers.18.self_attn.o_proj.weight', 'decoder.layers.18.self_attn.q_proj.bias', 'decoder.layers.18.self_attn.q_proj.weight', 'decoder.layers.18.self_attn.scaling', 'decoder.layers.18.self_attn.v_proj.bias', 'decoder.layers.18.self_attn.v_proj.weight', 'decoder.layers.19.input_layernorm.weight', 'decoder.layers.19.mlp.down_proj.bias', 'decoder.layers.19.mlp.down_proj.weight', 'decoder.layers.19.mlp.gate_proj.bias', 'decoder.layers.19.mlp.gate_proj.weight', 'decoder.layers.19.mlp.layer_norm.bias', 'decoder.layers.19.mlp.layer_norm.weight', 'decoder.layers.19.self_attn.k_proj.bias', 'decoder.layers.19.self_attn.k_proj.weight', 'decoder.layers.19.self_attn.o_proj.bias', 'decoder.layers.19.self_attn.o_proj.weight', 'decoder.layers.19.self_attn.q_proj.bias', 'decoder.layers.19.self_attn.q_proj.weight', 'decoder.layers.19.self_attn.scaling', 'decoder.layers.19.self_attn.v_proj.bias', 'decoder.layers.19.self_attn.v_proj.weight', 'decoder.layers.2.input_layernorm.weight', 'decoder.layers.2.mlp.down_proj.bias', 'decoder.layers.2.mlp.down_proj.weight', 'decoder.layers.2.mlp.gate_proj.bias', 'decoder.layers.2.mlp.gate_proj.weight', 'decoder.layers.2.mlp.layer_norm.bias', 'decoder.layers.2.mlp.layer_norm.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.o_proj.bias', 'decoder.layers.2.self_attn.o_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.scaling', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.3.input_layernorm.weight', 'decoder.layers.3.mlp.down_proj.bias', 'decoder.layers.3.mlp.down_proj.weight', 'decoder.layers.3.mlp.gate_proj.bias', 'decoder.layers.3.mlp.gate_proj.weight', 'decoder.layers.3.mlp.layer_norm.bias', 'decoder.layers.3.mlp.layer_norm.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.o_proj.bias', 'decoder.layers.3.self_attn.o_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.scaling', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.4.input_layernorm.weight', 'decoder.layers.4.mlp.down_proj.bias', 'decoder.layers.4.mlp.down_proj.weight', 'decoder.layers.4.mlp.gate_proj.bias', 'decoder.layers.4.mlp.gate_proj.weight', 'decoder.layers.4.mlp.layer_norm.bias', 'decoder.layers.4.mlp.layer_norm.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.o_proj.bias', 'decoder.layers.4.self_attn.o_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.scaling', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.5.input_layernorm.weight', 'decoder.layers.5.mlp.down_proj.bias', 'decoder.layers.5.mlp.down_proj.weight', 'decoder.layers.5.mlp.gate_proj.bias', 'decoder.layers.5.mlp.gate_proj.weight', 'decoder.layers.5.mlp.layer_norm.bias', 'decoder.layers.5.mlp.layer_norm.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.o_proj.bias', 'decoder.layers.5.self_attn.o_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.scaling', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.6.input_layernorm.weight', 'decoder.layers.6.mlp.down_proj.bias', 'decoder.layers.6.mlp.down_proj.weight', 'decoder.layers.6.mlp.gate_proj.bias', 'decoder.layers.6.mlp.gate_proj.weight', 'decoder.layers.6.mlp.layer_norm.bias', 'decoder.layers.6.mlp.layer_norm.weight', 'decoder.layers.6.self_attn.k_proj.bias', 'decoder.layers.6.self_attn.k_proj.weight', 'decoder.layers.6.self_attn.o_proj.bias', 'decoder.layers.6.self_attn.o_proj.weight', 'decoder.layers.6.self_attn.q_proj.bias', 'decoder.layers.6.self_attn.q_proj.weight', 'decoder.layers.6.self_attn.scaling', 'decoder.layers.6.self_attn.v_proj.bias', 'decoder.layers.6.self_attn.v_proj.weight', 'decoder.layers.7.input_layernorm.weight', 'decoder.layers.7.mlp.down_proj.bias', 'decoder.layers.7.mlp.down_proj.weight', 'decoder.layers.7.mlp.gate_proj.bias', 'decoder.layers.7.mlp.gate_proj.weight', 'decoder.layers.7.mlp.layer_norm.bias', 'decoder.layers.7.mlp.layer_norm.weight', 'decoder.layers.7.self_attn.k_proj.bias', 'decoder.layers.7.self_attn.k_proj.weight', 'decoder.layers.7.self_attn.o_proj.bias', 'decoder.layers.7.self_attn.o_proj.weight', 'decoder.layers.7.self_attn.q_proj.bias', 'decoder.layers.7.self_attn.q_proj.weight', 'decoder.layers.7.self_attn.scaling', 'decoder.layers.7.self_attn.v_proj.bias', 'decoder.layers.7.self_attn.v_proj.weight', 'decoder.layers.8.input_layernorm.weight', 'decoder.layers.8.mlp.down_proj.bias', 'decoder.layers.8.mlp.down_proj.weight', 'decoder.layers.8.mlp.gate_proj.bias', 'decoder.layers.8.mlp.gate_proj.weight', 'decoder.layers.8.mlp.layer_norm.bias', 'decoder.layers.8.mlp.layer_norm.weight', 'decoder.layers.8.self_attn.k_proj.bias', 'decoder.layers.8.self_attn.k_proj.weight', 'decoder.layers.8.self_attn.o_proj.bias', 'decoder.layers.8.self_attn.o_proj.weight', 'decoder.layers.8.self_attn.q_proj.bias', 'decoder.layers.8.self_attn.q_proj.weight', 'decoder.layers.8.self_attn.scaling', 'decoder.layers.8.self_attn.v_proj.bias', 'decoder.layers.8.self_attn.v_proj.weight', 'decoder.layers.9.input_layernorm.weight', 'decoder.layers.9.mlp.down_proj.bias', 'decoder.layers.9.mlp.down_proj.weight', 'decoder.layers.9.mlp.gate_proj.bias', 'decoder.layers.9.mlp.gate_proj.weight', 'decoder.layers.9.mlp.layer_norm.bias', 'decoder.layers.9.mlp.layer_norm.weight', 'decoder.layers.9.self_attn.k_proj.bias', 'decoder.layers.9.self_attn.k_proj.weight', 'decoder.layers.9.self_attn.o_proj.bias', 'decoder.layers.9.self_attn.o_proj.weight', 'decoder.layers.9.self_attn.q_proj.bias', 'decoder.layers.9.self_attn.q_proj.weight', 'decoder.layers.9.self_attn.scaling', 'decoder.layers.9.self_attn.v_proj.bias', 'decoder.layers.9.self_attn.v_proj.weight', 'horizon_ff_layer.input_layer.bias', 'horizon_ff_layer.input_layer.weight', 'horizon_ff_layer.output_layer.bias', 'horizon_ff_layer.output_layer.weight', 'horizon_ff_layer.residual_layer.bias', 'horizon_ff_layer.residual_layer.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n",
            "  Epoch 1/100 train_loss=1.2018 train_acc=0.5063 eval_loss=1.0766 eval_acc=0.6234 (best)\n",
            "  Epoch 2/100 train_loss=0.8779 train_acc=0.6566 eval_loss=1.0943 eval_acc=0.5779 \n",
            "  Epoch 3/100 train_loss=0.7278 train_acc=0.7093 eval_loss=1.1118 eval_acc=0.6104 \n",
            "  Epoch 4/100 train_loss=0.5530 train_acc=0.7945 eval_loss=1.5209 eval_acc=0.6299 \n",
            "  Epoch 5/100 train_loss=0.3325 train_acc=0.8872 eval_loss=2.0566 eval_acc=0.6039 \n",
            "  Epoch 6/100 train_loss=0.5122 train_acc=0.8170 eval_loss=1.3601 eval_acc=0.5714 \n",
            "  Epoch 7/100 train_loss=0.2681 train_acc=0.9098 eval_loss=2.4571 eval_acc=0.4351 \n",
            "  Epoch 8/100 train_loss=0.3491 train_acc=0.8872 eval_loss=2.4795 eval_acc=0.5195 \n",
            "  Epoch 9/100 train_loss=0.2288 train_acc=0.9148 eval_loss=2.4784 eval_acc=0.5260 \n",
            "  Epoch 10/100 train_loss=0.2834 train_acc=0.9123 eval_loss=3.1791 eval_acc=0.5844 \n",
            "  Epoch 11/100 train_loss=0.1928 train_acc=0.9323 eval_loss=2.6738 eval_acc=0.5844 \n",
            "  Early stopping on google/timesfm-2.5-200m-pytorch: no improvement for 10 epochs (best epoch = 1)\n",
            "    tfm[google/timesfm-2.5-200m-pytorch] train_acc=0.5063 eval_acc=0.58441558441558438818930198976886458694934845\n",
            "    mrh_acc=0.5779 mr+h+kg_acc=0.6104 kg_acc=0.5779 ensemble=0.5974 (w=0.60)\n",
            "  Split 1/1 - accuracy=0.5974 time=232.9s\n",
            "Completed MiddlePhalanxTW: Mean Acc=0.5974\n",
            "\n",
            "=== 62/109 MixedShapesRegularTrain ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  Decision: Heuristic says no filter (clean signal (no filtering))\n",
            "\n",
            "=== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at google/timesfm-2.5-200m-pytorch were not used when initializing TimesFmModelForPrediction: ['output_projection_point.hidden_layer.weight', 'output_projection_point.output_layer.weight', 'output_projection_point.residual_layer.weight', 'output_projection_quantiles.hidden_layer.weight', 'output_projection_quantiles.output_layer.weight', 'output_projection_quantiles.residual_layer.weight', 'stacked_xf.0.attn.key_ln.scale', 'stacked_xf.0.attn.out.weight', 'stacked_xf.0.attn.per_dim_scale.per_dim_scale', 'stacked_xf.0.attn.qkv_proj.weight', 'stacked_xf.0.attn.query_ln.scale', 'stacked_xf.0.ff0.weight', 'stacked_xf.0.ff1.weight', 'stacked_xf.0.post_attn_ln.scale', 'stacked_xf.0.post_ff_ln.scale', 'stacked_xf.0.pre_attn_ln.scale', 'stacked_xf.0.pre_ff_ln.scale', 'stacked_xf.1.attn.key_ln.scale', 'stacked_xf.1.attn.out.weight', 'stacked_xf.1.attn.per_dim_scale.per_dim_scale', 'stacked_xf.1.attn.qkv_proj.weight', 'stacked_xf.1.attn.query_ln.scale', 'stacked_xf.1.ff0.weight', 'stacked_xf.1.ff1.weight', 'stacked_xf.1.post_attn_ln.scale', 'stacked_xf.1.post_ff_ln.scale', 'stacked_xf.1.pre_attn_ln.scale', 'stacked_xf.1.pre_ff_ln.scale', 'stacked_xf.10.attn.key_ln.scale', 'stacked_xf.10.attn.out.weight', 'stacked_xf.10.attn.per_dim_scale.per_dim_scale', 'stacked_xf.10.attn.qkv_proj.weight', 'stacked_xf.10.attn.query_ln.scale', 'stacked_xf.10.ff0.weight', 'stacked_xf.10.ff1.weight', 'stacked_xf.10.post_attn_ln.scale', 'stacked_xf.10.post_ff_ln.scale', 'stacked_xf.10.pre_attn_ln.scale', 'stacked_xf.10.pre_ff_ln.scale', 'stacked_xf.11.attn.key_ln.scale', 'stacked_xf.11.attn.out.weight', 'stacked_xf.11.attn.per_dim_scale.per_dim_scale', 'stacked_xf.11.attn.qkv_proj.weight', 'stacked_xf.11.attn.query_ln.scale', 'stacked_xf.11.ff0.weight', 'stacked_xf.11.ff1.weight', 'stacked_xf.11.post_attn_ln.scale', 'stacked_xf.11.post_ff_ln.scale', 'stacked_xf.11.pre_attn_ln.scale', 'stacked_xf.11.pre_ff_ln.scale', 'stacked_xf.12.attn.key_ln.scale', 'stacked_xf.12.attn.out.weight', 'stacked_xf.12.attn.per_dim_scale.per_dim_scale', 'stacked_xf.12.attn.qkv_proj.weight', 'stacked_xf.12.attn.query_ln.scale', 'stacked_xf.12.ff0.weight', 'stacked_xf.12.ff1.weight', 'stacked_xf.12.post_attn_ln.scale', 'stacked_xf.12.post_ff_ln.scale', 'stacked_xf.12.pre_attn_ln.scale', 'stacked_xf.12.pre_ff_ln.scale', 'stacked_xf.13.attn.key_ln.scale', 'stacked_xf.13.attn.out.weight', 'stacked_xf.13.attn.per_dim_scale.per_dim_scale', 'stacked_xf.13.attn.qkv_proj.weight', 'stacked_xf.13.attn.query_ln.scale', 'stacked_xf.13.ff0.weight', 'stacked_xf.13.ff1.weight', 'stacked_xf.13.post_attn_ln.scale', 'stacked_xf.13.post_ff_ln.scale', 'stacked_xf.13.pre_attn_ln.scale', 'stacked_xf.13.pre_ff_ln.scale', 'stacked_xf.14.attn.key_ln.scale', 'stacked_xf.14.attn.out.weight', 'stacked_xf.14.attn.per_dim_scale.per_dim_scale', 'stacked_xf.14.attn.qkv_proj.weight', 'stacked_xf.14.attn.query_ln.scale', 'stacked_xf.14.ff0.weight', 'stacked_xf.14.ff1.weight', 'stacked_xf.14.post_attn_ln.scale', 'stacked_xf.14.post_ff_ln.scale', 'stacked_xf.14.pre_attn_ln.scale', 'stacked_xf.14.pre_ff_ln.scale', 'stacked_xf.15.attn.key_ln.scale', 'stacked_xf.15.attn.out.weight', 'stacked_xf.15.attn.per_dim_scale.per_dim_scale', 'stacked_xf.15.attn.qkv_proj.weight', 'stacked_xf.15.attn.query_ln.scale', 'stacked_xf.15.ff0.weight', 'stacked_xf.15.ff1.weight', 'stacked_xf.15.post_attn_ln.scale', 'stacked_xf.15.post_ff_ln.scale', 'stacked_xf.15.pre_attn_ln.scale', 'stacked_xf.15.pre_ff_ln.scale', 'stacked_xf.16.attn.key_ln.scale', 'stacked_xf.16.attn.out.weight', 'stacked_xf.16.attn.per_dim_scale.per_dim_scale', 'stacked_xf.16.attn.qkv_proj.weight', 'stacked_xf.16.attn.query_ln.scale', 'stacked_xf.16.ff0.weight', 'stacked_xf.16.ff1.weight', 'stacked_xf.16.post_attn_ln.scale', 'stacked_xf.16.post_ff_ln.scale', 'stacked_xf.16.pre_attn_ln.scale', 'stacked_xf.16.pre_ff_ln.scale', 'stacked_xf.17.attn.key_ln.scale', 'stacked_xf.17.attn.out.weight', 'stacked_xf.17.attn.per_dim_scale.per_dim_scale', 'stacked_xf.17.attn.qkv_proj.weight', 'stacked_xf.17.attn.query_ln.scale', 'stacked_xf.17.ff0.weight', 'stacked_xf.17.ff1.weight', 'stacked_xf.17.post_attn_ln.scale', 'stacked_xf.17.post_ff_ln.scale', 'stacked_xf.17.pre_attn_ln.scale', 'stacked_xf.17.pre_ff_ln.scale', 'stacked_xf.18.attn.key_ln.scale', 'stacked_xf.18.attn.out.weight', 'stacked_xf.18.attn.per_dim_scale.per_dim_scale', 'stacked_xf.18.attn.qkv_proj.weight', 'stacked_xf.18.attn.query_ln.scale', 'stacked_xf.18.ff0.weight', 'stacked_xf.18.ff1.weight', 'stacked_xf.18.post_attn_ln.scale', 'stacked_xf.18.post_ff_ln.scale', 'stacked_xf.18.pre_attn_ln.scale', 'stacked_xf.18.pre_ff_ln.scale', 'stacked_xf.19.attn.key_ln.scale', 'stacked_xf.19.attn.out.weight', 'stacked_xf.19.attn.per_dim_scale.per_dim_scale', 'stacked_xf.19.attn.qkv_proj.weight', 'stacked_xf.19.attn.query_ln.scale', 'stacked_xf.19.ff0.weight', 'stacked_xf.19.ff1.weight', 'stacked_xf.19.post_attn_ln.scale', 'stacked_xf.19.post_ff_ln.scale', 'stacked_xf.19.pre_attn_ln.scale', 'stacked_xf.19.pre_ff_ln.scale', 'stacked_xf.2.attn.key_ln.scale', 'stacked_xf.2.attn.out.weight', 'stacked_xf.2.attn.per_dim_scale.per_dim_scale', 'stacked_xf.2.attn.qkv_proj.weight', 'stacked_xf.2.attn.query_ln.scale', 'stacked_xf.2.ff0.weight', 'stacked_xf.2.ff1.weight', 'stacked_xf.2.post_attn_ln.scale', 'stacked_xf.2.post_ff_ln.scale', 'stacked_xf.2.pre_attn_ln.scale', 'stacked_xf.2.pre_ff_ln.scale', 'stacked_xf.3.attn.key_ln.scale', 'stacked_xf.3.attn.out.weight', 'stacked_xf.3.attn.per_dim_scale.per_dim_scale', 'stacked_xf.3.attn.qkv_proj.weight', 'stacked_xf.3.attn.query_ln.scale', 'stacked_xf.3.ff0.weight', 'stacked_xf.3.ff1.weight', 'stacked_xf.3.post_attn_ln.scale', 'stacked_xf.3.post_ff_ln.scale', 'stacked_xf.3.pre_attn_ln.scale', 'stacked_xf.3.pre_ff_ln.scale', 'stacked_xf.4.attn.key_ln.scale', 'stacked_xf.4.attn.out.weight', 'stacked_xf.4.attn.per_dim_scale.per_dim_scale', 'stacked_xf.4.attn.qkv_proj.weight', 'stacked_xf.4.attn.query_ln.scale', 'stacked_xf.4.ff0.weight', 'stacked_xf.4.ff1.weight', 'stacked_xf.4.post_attn_ln.scale', 'stacked_xf.4.post_ff_ln.scale', 'stacked_xf.4.pre_attn_ln.scale', 'stacked_xf.4.pre_ff_ln.scale', 'stacked_xf.5.attn.key_ln.scale', 'stacked_xf.5.attn.out.weight', 'stacked_xf.5.attn.per_dim_scale.per_dim_scale', 'stacked_xf.5.attn.qkv_proj.weight', 'stacked_xf.5.attn.query_ln.scale', 'stacked_xf.5.ff0.weight', 'stacked_xf.5.ff1.weight', 'stacked_xf.5.post_attn_ln.scale', 'stacked_xf.5.post_ff_ln.scale', 'stacked_xf.5.pre_attn_ln.scale', 'stacked_xf.5.pre_ff_ln.scale', 'stacked_xf.6.attn.key_ln.scale', 'stacked_xf.6.attn.out.weight', 'stacked_xf.6.attn.per_dim_scale.per_dim_scale', 'stacked_xf.6.attn.qkv_proj.weight', 'stacked_xf.6.attn.query_ln.scale', 'stacked_xf.6.ff0.weight', 'stacked_xf.6.ff1.weight', 'stacked_xf.6.post_attn_ln.scale', 'stacked_xf.6.post_ff_ln.scale', 'stacked_xf.6.pre_attn_ln.scale', 'stacked_xf.6.pre_ff_ln.scale', 'stacked_xf.7.attn.key_ln.scale', 'stacked_xf.7.attn.out.weight', 'stacked_xf.7.attn.per_dim_scale.per_dim_scale', 'stacked_xf.7.attn.qkv_proj.weight', 'stacked_xf.7.attn.query_ln.scale', 'stacked_xf.7.ff0.weight', 'stacked_xf.7.ff1.weight', 'stacked_xf.7.post_attn_ln.scale', 'stacked_xf.7.post_ff_ln.scale', 'stacked_xf.7.pre_attn_ln.scale', 'stacked_xf.7.pre_ff_ln.scale', 'stacked_xf.8.attn.key_ln.scale', 'stacked_xf.8.attn.out.weight', 'stacked_xf.8.attn.per_dim_scale.per_dim_scale', 'stacked_xf.8.attn.qkv_proj.weight', 'stacked_xf.8.attn.query_ln.scale', 'stacked_xf.8.ff0.weight', 'stacked_xf.8.ff1.weight', 'stacked_xf.8.post_attn_ln.scale', 'stacked_xf.8.post_ff_ln.scale', 'stacked_xf.8.pre_attn_ln.scale', 'stacked_xf.8.pre_ff_ln.scale', 'stacked_xf.9.attn.key_ln.scale', 'stacked_xf.9.attn.out.weight', 'stacked_xf.9.attn.per_dim_scale.per_dim_scale', 'stacked_xf.9.attn.qkv_proj.weight', 'stacked_xf.9.attn.query_ln.scale', 'stacked_xf.9.ff0.weight', 'stacked_xf.9.ff1.weight', 'stacked_xf.9.post_attn_ln.scale', 'stacked_xf.9.post_ff_ln.scale', 'stacked_xf.9.pre_attn_ln.scale', 'stacked_xf.9.pre_ff_ln.scale', 'tokenizer.hidden_layer.bias', 'tokenizer.hidden_layer.weight', 'tokenizer.output_layer.bias', 'tokenizer.output_layer.weight', 'tokenizer.residual_layer.bias', 'tokenizer.residual_layer.weight']\n",
            "- This IS expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of TimesFmModelForPrediction were not initialized from the model checkpoint at google/timesfm-2.5-200m-pytorch and are newly initialized: ['decoder.freq_emb.weight', 'decoder.input_ff_layer.input_layer.bias', 'decoder.input_ff_layer.input_layer.weight', 'decoder.input_ff_layer.output_layer.bias', 'decoder.input_ff_layer.output_layer.weight', 'decoder.input_ff_layer.residual_layer.bias', 'decoder.input_ff_layer.residual_layer.weight', 'decoder.layers.0.input_layernorm.weight', 'decoder.layers.0.mlp.down_proj.bias', 'decoder.layers.0.mlp.down_proj.weight', 'decoder.layers.0.mlp.gate_proj.bias', 'decoder.layers.0.mlp.gate_proj.weight', 'decoder.layers.0.mlp.layer_norm.bias', 'decoder.layers.0.mlp.layer_norm.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.o_proj.bias', 'decoder.layers.0.self_attn.o_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.scaling', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.1.input_layernorm.weight', 'decoder.layers.1.mlp.down_proj.bias', 'decoder.layers.1.mlp.down_proj.weight', 'decoder.layers.1.mlp.gate_proj.bias', 'decoder.layers.1.mlp.gate_proj.weight', 'decoder.layers.1.mlp.layer_norm.bias', 'decoder.layers.1.mlp.layer_norm.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.o_proj.bias', 'decoder.layers.1.self_attn.o_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.scaling', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.10.input_layernorm.weight', 'decoder.layers.10.mlp.down_proj.bias', 'decoder.layers.10.mlp.down_proj.weight', 'decoder.layers.10.mlp.gate_proj.bias', 'decoder.layers.10.mlp.gate_proj.weight', 'decoder.layers.10.mlp.layer_norm.bias', 'decoder.layers.10.mlp.layer_norm.weight', 'decoder.layers.10.self_attn.k_proj.bias', 'decoder.layers.10.self_attn.k_proj.weight', 'decoder.layers.10.self_attn.o_proj.bias', 'decoder.layers.10.self_attn.o_proj.weight', 'decoder.layers.10.self_attn.q_proj.bias', 'decoder.layers.10.self_attn.q_proj.weight', 'decoder.layers.10.self_attn.scaling', 'decoder.layers.10.self_attn.v_proj.bias', 'decoder.layers.10.self_attn.v_proj.weight', 'decoder.layers.11.input_layernorm.weight', 'decoder.layers.11.mlp.down_proj.bias', 'decoder.layers.11.mlp.down_proj.weight', 'decoder.layers.11.mlp.gate_proj.bias', 'decoder.layers.11.mlp.gate_proj.weight', 'decoder.layers.11.mlp.layer_norm.bias', 'decoder.layers.11.mlp.layer_norm.weight', 'decoder.layers.11.self_attn.k_proj.bias', 'decoder.layers.11.self_attn.k_proj.weight', 'decoder.layers.11.self_attn.o_proj.bias', 'decoder.layers.11.self_attn.o_proj.weight', 'decoder.layers.11.self_attn.q_proj.bias', 'decoder.layers.11.self_attn.q_proj.weight', 'decoder.layers.11.self_attn.scaling', 'decoder.layers.11.self_attn.v_proj.bias', 'decoder.layers.11.self_attn.v_proj.weight', 'decoder.layers.12.input_layernorm.weight', 'decoder.layers.12.mlp.down_proj.bias', 'decoder.layers.12.mlp.down_proj.weight', 'decoder.layers.12.mlp.gate_proj.bias', 'decoder.layers.12.mlp.gate_proj.weight', 'decoder.layers.12.mlp.layer_norm.bias', 'decoder.layers.12.mlp.layer_norm.weight', 'decoder.layers.12.self_attn.k_proj.bias', 'decoder.layers.12.self_attn.k_proj.weight', 'decoder.layers.12.self_attn.o_proj.bias', 'decoder.layers.12.self_attn.o_proj.weight', 'decoder.layers.12.self_attn.q_proj.bias', 'decoder.layers.12.self_attn.q_proj.weight', 'decoder.layers.12.self_attn.scaling', 'decoder.layers.12.self_attn.v_proj.bias', 'decoder.layers.12.self_attn.v_proj.weight', 'decoder.layers.13.input_layernorm.weight', 'decoder.layers.13.mlp.down_proj.bias', 'decoder.layers.13.mlp.down_proj.weight', 'decoder.layers.13.mlp.gate_proj.bias', 'decoder.layers.13.mlp.gate_proj.weight', 'decoder.layers.13.mlp.layer_norm.bias', 'decoder.layers.13.mlp.layer_norm.weight', 'decoder.layers.13.self_attn.k_proj.bias', 'decoder.layers.13.self_attn.k_proj.weight', 'decoder.layers.13.self_attn.o_proj.bias', 'decoder.layers.13.self_attn.o_proj.weight', 'decoder.layers.13.self_attn.q_proj.bias', 'decoder.layers.13.self_attn.q_proj.weight', 'decoder.layers.13.self_attn.scaling', 'decoder.layers.13.self_attn.v_proj.bias', 'decoder.layers.13.self_attn.v_proj.weight', 'decoder.layers.14.input_layernorm.weight', 'decoder.layers.14.mlp.down_proj.bias', 'decoder.layers.14.mlp.down_proj.weight', 'decoder.layers.14.mlp.gate_proj.bias', 'decoder.layers.14.mlp.gate_proj.weight', 'decoder.layers.14.mlp.layer_norm.bias', 'decoder.layers.14.mlp.layer_norm.weight', 'decoder.layers.14.self_attn.k_proj.bias', 'decoder.layers.14.self_attn.k_proj.weight', 'decoder.layers.14.self_attn.o_proj.bias', 'decoder.layers.14.self_attn.o_proj.weight', 'decoder.layers.14.self_attn.q_proj.bias', 'decoder.layers.14.self_attn.q_proj.weight', 'decoder.layers.14.self_attn.scaling', 'decoder.layers.14.self_attn.v_proj.bias', 'decoder.layers.14.self_attn.v_proj.weight', 'decoder.layers.15.input_layernorm.weight', 'decoder.layers.15.mlp.down_proj.bias', 'decoder.layers.15.mlp.down_proj.weight', 'decoder.layers.15.mlp.gate_proj.bias', 'decoder.layers.15.mlp.gate_proj.weight', 'decoder.layers.15.mlp.layer_norm.bias', 'decoder.layers.15.mlp.layer_norm.weight', 'decoder.layers.15.self_attn.k_proj.bias', 'decoder.layers.15.self_attn.k_proj.weight', 'decoder.layers.15.self_attn.o_proj.bias', 'decoder.layers.15.self_attn.o_proj.weight', 'decoder.layers.15.self_attn.q_proj.bias', 'decoder.layers.15.self_attn.q_proj.weight', 'decoder.layers.15.self_attn.scaling', 'decoder.layers.15.self_attn.v_proj.bias', 'decoder.layers.15.self_attn.v_proj.weight', 'decoder.layers.16.input_layernorm.weight', 'decoder.layers.16.mlp.down_proj.bias', 'decoder.layers.16.mlp.down_proj.weight', 'decoder.layers.16.mlp.gate_proj.bias', 'decoder.layers.16.mlp.gate_proj.weight', 'decoder.layers.16.mlp.layer_norm.bias', 'decoder.layers.16.mlp.layer_norm.weight', 'decoder.layers.16.self_attn.k_proj.bias', 'decoder.layers.16.self_attn.k_proj.weight', 'decoder.layers.16.self_attn.o_proj.bias', 'decoder.layers.16.self_attn.o_proj.weight', 'decoder.layers.16.self_attn.q_proj.bias', 'decoder.layers.16.self_attn.q_proj.weight', 'decoder.layers.16.self_attn.scaling', 'decoder.layers.16.self_attn.v_proj.bias', 'decoder.layers.16.self_attn.v_proj.weight', 'decoder.layers.17.input_layernorm.weight', 'decoder.layers.17.mlp.down_proj.bias', 'decoder.layers.17.mlp.down_proj.weight', 'decoder.layers.17.mlp.gate_proj.bias', 'decoder.layers.17.mlp.gate_proj.weight', 'decoder.layers.17.mlp.layer_norm.bias', 'decoder.layers.17.mlp.layer_norm.weight', 'decoder.layers.17.self_attn.k_proj.bias', 'decoder.layers.17.self_attn.k_proj.weight', 'decoder.layers.17.self_attn.o_proj.bias', 'decoder.layers.17.self_attn.o_proj.weight', 'decoder.layers.17.self_attn.q_proj.bias', 'decoder.layers.17.self_attn.q_proj.weight', 'decoder.layers.17.self_attn.scaling', 'decoder.layers.17.self_attn.v_proj.bias', 'decoder.layers.17.self_attn.v_proj.weight', 'decoder.layers.18.input_layernorm.weight', 'decoder.layers.18.mlp.down_proj.bias', 'decoder.layers.18.mlp.down_proj.weight', 'decoder.layers.18.mlp.gate_proj.bias', 'decoder.layers.18.mlp.gate_proj.weight', 'decoder.layers.18.mlp.layer_norm.bias', 'decoder.layers.18.mlp.layer_norm.weight', 'decoder.layers.18.self_attn.k_proj.bias', 'decoder.layers.18.self_attn.k_proj.weight', 'decoder.layers.18.self_attn.o_proj.bias', 'decoder.layers.18.self_attn.o_proj.weight', 'decoder.layers.18.self_attn.q_proj.bias', 'decoder.layers.18.self_attn.q_proj.weight', 'decoder.layers.18.self_attn.scaling', 'decoder.layers.18.self_attn.v_proj.bias', 'decoder.layers.18.self_attn.v_proj.weight', 'decoder.layers.19.input_layernorm.weight', 'decoder.layers.19.mlp.down_proj.bias', 'decoder.layers.19.mlp.down_proj.weight', 'decoder.layers.19.mlp.gate_proj.bias', 'decoder.layers.19.mlp.gate_proj.weight', 'decoder.layers.19.mlp.layer_norm.bias', 'decoder.layers.19.mlp.layer_norm.weight', 'decoder.layers.19.self_attn.k_proj.bias', 'decoder.layers.19.self_attn.k_proj.weight', 'decoder.layers.19.self_attn.o_proj.bias', 'decoder.layers.19.self_attn.o_proj.weight', 'decoder.layers.19.self_attn.q_proj.bias', 'decoder.layers.19.self_attn.q_proj.weight', 'decoder.layers.19.self_attn.scaling', 'decoder.layers.19.self_attn.v_proj.bias', 'decoder.layers.19.self_attn.v_proj.weight', 'decoder.layers.2.input_layernorm.weight', 'decoder.layers.2.mlp.down_proj.bias', 'decoder.layers.2.mlp.down_proj.weight', 'decoder.layers.2.mlp.gate_proj.bias', 'decoder.layers.2.mlp.gate_proj.weight', 'decoder.layers.2.mlp.layer_norm.bias', 'decoder.layers.2.mlp.layer_norm.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.o_proj.bias', 'decoder.layers.2.self_attn.o_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.scaling', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.3.input_layernorm.weight', 'decoder.layers.3.mlp.down_proj.bias', 'decoder.layers.3.mlp.down_proj.weight', 'decoder.layers.3.mlp.gate_proj.bias', 'decoder.layers.3.mlp.gate_proj.weight', 'decoder.layers.3.mlp.layer_norm.bias', 'decoder.layers.3.mlp.layer_norm.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.o_proj.bias', 'decoder.layers.3.self_attn.o_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.scaling', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.4.input_layernorm.weight', 'decoder.layers.4.mlp.down_proj.bias', 'decoder.layers.4.mlp.down_proj.weight', 'decoder.layers.4.mlp.gate_proj.bias', 'decoder.layers.4.mlp.gate_proj.weight', 'decoder.layers.4.mlp.layer_norm.bias', 'decoder.layers.4.mlp.layer_norm.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.o_proj.bias', 'decoder.layers.4.self_attn.o_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.scaling', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.5.input_layernorm.weight', 'decoder.layers.5.mlp.down_proj.bias', 'decoder.layers.5.mlp.down_proj.weight', 'decoder.layers.5.mlp.gate_proj.bias', 'decoder.layers.5.mlp.gate_proj.weight', 'decoder.layers.5.mlp.layer_norm.bias', 'decoder.layers.5.mlp.layer_norm.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.o_proj.bias', 'decoder.layers.5.self_attn.o_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.scaling', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.6.input_layernorm.weight', 'decoder.layers.6.mlp.down_proj.bias', 'decoder.layers.6.mlp.down_proj.weight', 'decoder.layers.6.mlp.gate_proj.bias', 'decoder.layers.6.mlp.gate_proj.weight', 'decoder.layers.6.mlp.layer_norm.bias', 'decoder.layers.6.mlp.layer_norm.weight', 'decoder.layers.6.self_attn.k_proj.bias', 'decoder.layers.6.self_attn.k_proj.weight', 'decoder.layers.6.self_attn.o_proj.bias', 'decoder.layers.6.self_attn.o_proj.weight', 'decoder.layers.6.self_attn.q_proj.bias', 'decoder.layers.6.self_attn.q_proj.weight', 'decoder.layers.6.self_attn.scaling', 'decoder.layers.6.self_attn.v_proj.bias', 'decoder.layers.6.self_attn.v_proj.weight', 'decoder.layers.7.input_layernorm.weight', 'decoder.layers.7.mlp.down_proj.bias', 'decoder.layers.7.mlp.down_proj.weight', 'decoder.layers.7.mlp.gate_proj.bias', 'decoder.layers.7.mlp.gate_proj.weight', 'decoder.layers.7.mlp.layer_norm.bias', 'decoder.layers.7.mlp.layer_norm.weight', 'decoder.layers.7.self_attn.k_proj.bias', 'decoder.layers.7.self_attn.k_proj.weight', 'decoder.layers.7.self_attn.o_proj.bias', 'decoder.layers.7.self_attn.o_proj.weight', 'decoder.layers.7.self_attn.q_proj.bias', 'decoder.layers.7.self_attn.q_proj.weight', 'decoder.layers.7.self_attn.scaling', 'decoder.layers.7.self_attn.v_proj.bias', 'decoder.layers.7.self_attn.v_proj.weight', 'decoder.layers.8.input_layernorm.weight', 'decoder.layers.8.mlp.down_proj.bias', 'decoder.layers.8.mlp.down_proj.weight', 'decoder.layers.8.mlp.gate_proj.bias', 'decoder.layers.8.mlp.gate_proj.weight', 'decoder.layers.8.mlp.layer_norm.bias', 'decoder.layers.8.mlp.layer_norm.weight', 'decoder.layers.8.self_attn.k_proj.bias', 'decoder.layers.8.self_attn.k_proj.weight', 'decoder.layers.8.self_attn.o_proj.bias', 'decoder.layers.8.self_attn.o_proj.weight', 'decoder.layers.8.self_attn.q_proj.bias', 'decoder.layers.8.self_attn.q_proj.weight', 'decoder.layers.8.self_attn.scaling', 'decoder.layers.8.self_attn.v_proj.bias', 'decoder.layers.8.self_attn.v_proj.weight', 'decoder.layers.9.input_layernorm.weight', 'decoder.layers.9.mlp.down_proj.bias', 'decoder.layers.9.mlp.down_proj.weight', 'decoder.layers.9.mlp.gate_proj.bias', 'decoder.layers.9.mlp.gate_proj.weight', 'decoder.layers.9.mlp.layer_norm.bias', 'decoder.layers.9.mlp.layer_norm.weight', 'decoder.layers.9.self_attn.k_proj.bias', 'decoder.layers.9.self_attn.k_proj.weight', 'decoder.layers.9.self_attn.o_proj.bias', 'decoder.layers.9.self_attn.o_proj.weight', 'decoder.layers.9.self_attn.q_proj.bias', 'decoder.layers.9.self_attn.q_proj.weight', 'decoder.layers.9.self_attn.scaling', 'decoder.layers.9.self_attn.v_proj.bias', 'decoder.layers.9.self_attn.v_proj.weight', 'horizon_ff_layer.input_layer.bias', 'horizon_ff_layer.input_layer.weight', 'horizon_ff_layer.output_layer.bias', 'horizon_ff_layer.output_layer.weight', 'horizon_ff_layer.residual_layer.bias', 'horizon_ff_layer.residual_layer.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n",
            "  Epoch 1/100 train_loss=0.5548 train_acc=0.8000 eval_loss=0.1583 eval_acc=0.9522 (best)\n",
            "  Epoch 2/100 train_loss=0.0853 train_acc=0.9740 eval_loss=0.1454 eval_acc=0.9522 (best)\n",
            "  Epoch 3/100 train_loss=0.0424 train_acc=0.9880 eval_loss=0.1193 eval_acc=0.9637 (best)\n",
            "  Epoch 4/100 train_loss=0.0258 train_acc=0.9920 eval_loss=0.1865 eval_acc=0.9579 \n",
            "  Epoch 5/100 train_loss=0.0464 train_acc=0.9860 eval_loss=0.1579 eval_acc=0.9596 \n",
            "  Epoch 6/100 train_loss=0.0087 train_acc=0.9980 eval_loss=0.1204 eval_acc=0.9678 \n",
            "  Epoch 7/100 train_loss=0.0008 train_acc=1.0000 eval_loss=0.1228 eval_acc=0.9753 \n",
            "  Epoch 8/100 train_loss=0.0001 train_acc=1.0000 eval_loss=0.1504 eval_acc=0.9728 \n",
            "  Epoch 9/100 train_loss=0.0001 train_acc=1.0000 eval_loss=0.1510 eval_acc=0.9715 \n",
            "  Epoch 10/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.1485 eval_acc=0.9724 \n",
            "  Epoch 11/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.1471 eval_acc=0.9728 \n",
            "  Epoch 12/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.1458 eval_acc=0.9744 \n",
            "  Epoch 13/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.1450 eval_acc=0.9748 \n",
            "  Early stopping on google/timesfm-2.5-200m-pytorch: no improvement for 10 epochs (best epoch = 3)\n",
            "    tfm[google/timesfm-2.5-200m-pytorch] train_acc=0.9880 eval_acc=0.97484536082474226859062582661863416433334351\n",
            "    mrh_acc=0.9806 mr+h+kg_acc=0.9823 kg_acc=0.9847 ensemble=0.9847 (w=0.30)\n",
            "  Split 1/1 - accuracy=0.9847 time=825.3s\n",
            "Completed MixedShapesRegularTrain: Mean Acc=0.9847\n",
            "\n",
            "=== 63/109 MixedShapesSmallTrain ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  Decision: Heuristic says no filter (clean signal (no filtering))\n",
            "\n",
            "=== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at google/timesfm-2.5-200m-pytorch were not used when initializing TimesFmModelForPrediction: ['output_projection_point.hidden_layer.weight', 'output_projection_point.output_layer.weight', 'output_projection_point.residual_layer.weight', 'output_projection_quantiles.hidden_layer.weight', 'output_projection_quantiles.output_layer.weight', 'output_projection_quantiles.residual_layer.weight', 'stacked_xf.0.attn.key_ln.scale', 'stacked_xf.0.attn.out.weight', 'stacked_xf.0.attn.per_dim_scale.per_dim_scale', 'stacked_xf.0.attn.qkv_proj.weight', 'stacked_xf.0.attn.query_ln.scale', 'stacked_xf.0.ff0.weight', 'stacked_xf.0.ff1.weight', 'stacked_xf.0.post_attn_ln.scale', 'stacked_xf.0.post_ff_ln.scale', 'stacked_xf.0.pre_attn_ln.scale', 'stacked_xf.0.pre_ff_ln.scale', 'stacked_xf.1.attn.key_ln.scale', 'stacked_xf.1.attn.out.weight', 'stacked_xf.1.attn.per_dim_scale.per_dim_scale', 'stacked_xf.1.attn.qkv_proj.weight', 'stacked_xf.1.attn.query_ln.scale', 'stacked_xf.1.ff0.weight', 'stacked_xf.1.ff1.weight', 'stacked_xf.1.post_attn_ln.scale', 'stacked_xf.1.post_ff_ln.scale', 'stacked_xf.1.pre_attn_ln.scale', 'stacked_xf.1.pre_ff_ln.scale', 'stacked_xf.10.attn.key_ln.scale', 'stacked_xf.10.attn.out.weight', 'stacked_xf.10.attn.per_dim_scale.per_dim_scale', 'stacked_xf.10.attn.qkv_proj.weight', 'stacked_xf.10.attn.query_ln.scale', 'stacked_xf.10.ff0.weight', 'stacked_xf.10.ff1.weight', 'stacked_xf.10.post_attn_ln.scale', 'stacked_xf.10.post_ff_ln.scale', 'stacked_xf.10.pre_attn_ln.scale', 'stacked_xf.10.pre_ff_ln.scale', 'stacked_xf.11.attn.key_ln.scale', 'stacked_xf.11.attn.out.weight', 'stacked_xf.11.attn.per_dim_scale.per_dim_scale', 'stacked_xf.11.attn.qkv_proj.weight', 'stacked_xf.11.attn.query_ln.scale', 'stacked_xf.11.ff0.weight', 'stacked_xf.11.ff1.weight', 'stacked_xf.11.post_attn_ln.scale', 'stacked_xf.11.post_ff_ln.scale', 'stacked_xf.11.pre_attn_ln.scale', 'stacked_xf.11.pre_ff_ln.scale', 'stacked_xf.12.attn.key_ln.scale', 'stacked_xf.12.attn.out.weight', 'stacked_xf.12.attn.per_dim_scale.per_dim_scale', 'stacked_xf.12.attn.qkv_proj.weight', 'stacked_xf.12.attn.query_ln.scale', 'stacked_xf.12.ff0.weight', 'stacked_xf.12.ff1.weight', 'stacked_xf.12.post_attn_ln.scale', 'stacked_xf.12.post_ff_ln.scale', 'stacked_xf.12.pre_attn_ln.scale', 'stacked_xf.12.pre_ff_ln.scale', 'stacked_xf.13.attn.key_ln.scale', 'stacked_xf.13.attn.out.weight', 'stacked_xf.13.attn.per_dim_scale.per_dim_scale', 'stacked_xf.13.attn.qkv_proj.weight', 'stacked_xf.13.attn.query_ln.scale', 'stacked_xf.13.ff0.weight', 'stacked_xf.13.ff1.weight', 'stacked_xf.13.post_attn_ln.scale', 'stacked_xf.13.post_ff_ln.scale', 'stacked_xf.13.pre_attn_ln.scale', 'stacked_xf.13.pre_ff_ln.scale', 'stacked_xf.14.attn.key_ln.scale', 'stacked_xf.14.attn.out.weight', 'stacked_xf.14.attn.per_dim_scale.per_dim_scale', 'stacked_xf.14.attn.qkv_proj.weight', 'stacked_xf.14.attn.query_ln.scale', 'stacked_xf.14.ff0.weight', 'stacked_xf.14.ff1.weight', 'stacked_xf.14.post_attn_ln.scale', 'stacked_xf.14.post_ff_ln.scale', 'stacked_xf.14.pre_attn_ln.scale', 'stacked_xf.14.pre_ff_ln.scale', 'stacked_xf.15.attn.key_ln.scale', 'stacked_xf.15.attn.out.weight', 'stacked_xf.15.attn.per_dim_scale.per_dim_scale', 'stacked_xf.15.attn.qkv_proj.weight', 'stacked_xf.15.attn.query_ln.scale', 'stacked_xf.15.ff0.weight', 'stacked_xf.15.ff1.weight', 'stacked_xf.15.post_attn_ln.scale', 'stacked_xf.15.post_ff_ln.scale', 'stacked_xf.15.pre_attn_ln.scale', 'stacked_xf.15.pre_ff_ln.scale', 'stacked_xf.16.attn.key_ln.scale', 'stacked_xf.16.attn.out.weight', 'stacked_xf.16.attn.per_dim_scale.per_dim_scale', 'stacked_xf.16.attn.qkv_proj.weight', 'stacked_xf.16.attn.query_ln.scale', 'stacked_xf.16.ff0.weight', 'stacked_xf.16.ff1.weight', 'stacked_xf.16.post_attn_ln.scale', 'stacked_xf.16.post_ff_ln.scale', 'stacked_xf.16.pre_attn_ln.scale', 'stacked_xf.16.pre_ff_ln.scale', 'stacked_xf.17.attn.key_ln.scale', 'stacked_xf.17.attn.out.weight', 'stacked_xf.17.attn.per_dim_scale.per_dim_scale', 'stacked_xf.17.attn.qkv_proj.weight', 'stacked_xf.17.attn.query_ln.scale', 'stacked_xf.17.ff0.weight', 'stacked_xf.17.ff1.weight', 'stacked_xf.17.post_attn_ln.scale', 'stacked_xf.17.post_ff_ln.scale', 'stacked_xf.17.pre_attn_ln.scale', 'stacked_xf.17.pre_ff_ln.scale', 'stacked_xf.18.attn.key_ln.scale', 'stacked_xf.18.attn.out.weight', 'stacked_xf.18.attn.per_dim_scale.per_dim_scale', 'stacked_xf.18.attn.qkv_proj.weight', 'stacked_xf.18.attn.query_ln.scale', 'stacked_xf.18.ff0.weight', 'stacked_xf.18.ff1.weight', 'stacked_xf.18.post_attn_ln.scale', 'stacked_xf.18.post_ff_ln.scale', 'stacked_xf.18.pre_attn_ln.scale', 'stacked_xf.18.pre_ff_ln.scale', 'stacked_xf.19.attn.key_ln.scale', 'stacked_xf.19.attn.out.weight', 'stacked_xf.19.attn.per_dim_scale.per_dim_scale', 'stacked_xf.19.attn.qkv_proj.weight', 'stacked_xf.19.attn.query_ln.scale', 'stacked_xf.19.ff0.weight', 'stacked_xf.19.ff1.weight', 'stacked_xf.19.post_attn_ln.scale', 'stacked_xf.19.post_ff_ln.scale', 'stacked_xf.19.pre_attn_ln.scale', 'stacked_xf.19.pre_ff_ln.scale', 'stacked_xf.2.attn.key_ln.scale', 'stacked_xf.2.attn.out.weight', 'stacked_xf.2.attn.per_dim_scale.per_dim_scale', 'stacked_xf.2.attn.qkv_proj.weight', 'stacked_xf.2.attn.query_ln.scale', 'stacked_xf.2.ff0.weight', 'stacked_xf.2.ff1.weight', 'stacked_xf.2.post_attn_ln.scale', 'stacked_xf.2.post_ff_ln.scale', 'stacked_xf.2.pre_attn_ln.scale', 'stacked_xf.2.pre_ff_ln.scale', 'stacked_xf.3.attn.key_ln.scale', 'stacked_xf.3.attn.out.weight', 'stacked_xf.3.attn.per_dim_scale.per_dim_scale', 'stacked_xf.3.attn.qkv_proj.weight', 'stacked_xf.3.attn.query_ln.scale', 'stacked_xf.3.ff0.weight', 'stacked_xf.3.ff1.weight', 'stacked_xf.3.post_attn_ln.scale', 'stacked_xf.3.post_ff_ln.scale', 'stacked_xf.3.pre_attn_ln.scale', 'stacked_xf.3.pre_ff_ln.scale', 'stacked_xf.4.attn.key_ln.scale', 'stacked_xf.4.attn.out.weight', 'stacked_xf.4.attn.per_dim_scale.per_dim_scale', 'stacked_xf.4.attn.qkv_proj.weight', 'stacked_xf.4.attn.query_ln.scale', 'stacked_xf.4.ff0.weight', 'stacked_xf.4.ff1.weight', 'stacked_xf.4.post_attn_ln.scale', 'stacked_xf.4.post_ff_ln.scale', 'stacked_xf.4.pre_attn_ln.scale', 'stacked_xf.4.pre_ff_ln.scale', 'stacked_xf.5.attn.key_ln.scale', 'stacked_xf.5.attn.out.weight', 'stacked_xf.5.attn.per_dim_scale.per_dim_scale', 'stacked_xf.5.attn.qkv_proj.weight', 'stacked_xf.5.attn.query_ln.scale', 'stacked_xf.5.ff0.weight', 'stacked_xf.5.ff1.weight', 'stacked_xf.5.post_attn_ln.scale', 'stacked_xf.5.post_ff_ln.scale', 'stacked_xf.5.pre_attn_ln.scale', 'stacked_xf.5.pre_ff_ln.scale', 'stacked_xf.6.attn.key_ln.scale', 'stacked_xf.6.attn.out.weight', 'stacked_xf.6.attn.per_dim_scale.per_dim_scale', 'stacked_xf.6.attn.qkv_proj.weight', 'stacked_xf.6.attn.query_ln.scale', 'stacked_xf.6.ff0.weight', 'stacked_xf.6.ff1.weight', 'stacked_xf.6.post_attn_ln.scale', 'stacked_xf.6.post_ff_ln.scale', 'stacked_xf.6.pre_attn_ln.scale', 'stacked_xf.6.pre_ff_ln.scale', 'stacked_xf.7.attn.key_ln.scale', 'stacked_xf.7.attn.out.weight', 'stacked_xf.7.attn.per_dim_scale.per_dim_scale', 'stacked_xf.7.attn.qkv_proj.weight', 'stacked_xf.7.attn.query_ln.scale', 'stacked_xf.7.ff0.weight', 'stacked_xf.7.ff1.weight', 'stacked_xf.7.post_attn_ln.scale', 'stacked_xf.7.post_ff_ln.scale', 'stacked_xf.7.pre_attn_ln.scale', 'stacked_xf.7.pre_ff_ln.scale', 'stacked_xf.8.attn.key_ln.scale', 'stacked_xf.8.attn.out.weight', 'stacked_xf.8.attn.per_dim_scale.per_dim_scale', 'stacked_xf.8.attn.qkv_proj.weight', 'stacked_xf.8.attn.query_ln.scale', 'stacked_xf.8.ff0.weight', 'stacked_xf.8.ff1.weight', 'stacked_xf.8.post_attn_ln.scale', 'stacked_xf.8.post_ff_ln.scale', 'stacked_xf.8.pre_attn_ln.scale', 'stacked_xf.8.pre_ff_ln.scale', 'stacked_xf.9.attn.key_ln.scale', 'stacked_xf.9.attn.out.weight', 'stacked_xf.9.attn.per_dim_scale.per_dim_scale', 'stacked_xf.9.attn.qkv_proj.weight', 'stacked_xf.9.attn.query_ln.scale', 'stacked_xf.9.ff0.weight', 'stacked_xf.9.ff1.weight', 'stacked_xf.9.post_attn_ln.scale', 'stacked_xf.9.post_ff_ln.scale', 'stacked_xf.9.pre_attn_ln.scale', 'stacked_xf.9.pre_ff_ln.scale', 'tokenizer.hidden_layer.bias', 'tokenizer.hidden_layer.weight', 'tokenizer.output_layer.bias', 'tokenizer.output_layer.weight', 'tokenizer.residual_layer.bias', 'tokenizer.residual_layer.weight']\n",
            "- This IS expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of TimesFmModelForPrediction were not initialized from the model checkpoint at google/timesfm-2.5-200m-pytorch and are newly initialized: ['decoder.freq_emb.weight', 'decoder.input_ff_layer.input_layer.bias', 'decoder.input_ff_layer.input_layer.weight', 'decoder.input_ff_layer.output_layer.bias', 'decoder.input_ff_layer.output_layer.weight', 'decoder.input_ff_layer.residual_layer.bias', 'decoder.input_ff_layer.residual_layer.weight', 'decoder.layers.0.input_layernorm.weight', 'decoder.layers.0.mlp.down_proj.bias', 'decoder.layers.0.mlp.down_proj.weight', 'decoder.layers.0.mlp.gate_proj.bias', 'decoder.layers.0.mlp.gate_proj.weight', 'decoder.layers.0.mlp.layer_norm.bias', 'decoder.layers.0.mlp.layer_norm.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.o_proj.bias', 'decoder.layers.0.self_attn.o_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.scaling', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.1.input_layernorm.weight', 'decoder.layers.1.mlp.down_proj.bias', 'decoder.layers.1.mlp.down_proj.weight', 'decoder.layers.1.mlp.gate_proj.bias', 'decoder.layers.1.mlp.gate_proj.weight', 'decoder.layers.1.mlp.layer_norm.bias', 'decoder.layers.1.mlp.layer_norm.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.o_proj.bias', 'decoder.layers.1.self_attn.o_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.scaling', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.10.input_layernorm.weight', 'decoder.layers.10.mlp.down_proj.bias', 'decoder.layers.10.mlp.down_proj.weight', 'decoder.layers.10.mlp.gate_proj.bias', 'decoder.layers.10.mlp.gate_proj.weight', 'decoder.layers.10.mlp.layer_norm.bias', 'decoder.layers.10.mlp.layer_norm.weight', 'decoder.layers.10.self_attn.k_proj.bias', 'decoder.layers.10.self_attn.k_proj.weight', 'decoder.layers.10.self_attn.o_proj.bias', 'decoder.layers.10.self_attn.o_proj.weight', 'decoder.layers.10.self_attn.q_proj.bias', 'decoder.layers.10.self_attn.q_proj.weight', 'decoder.layers.10.self_attn.scaling', 'decoder.layers.10.self_attn.v_proj.bias', 'decoder.layers.10.self_attn.v_proj.weight', 'decoder.layers.11.input_layernorm.weight', 'decoder.layers.11.mlp.down_proj.bias', 'decoder.layers.11.mlp.down_proj.weight', 'decoder.layers.11.mlp.gate_proj.bias', 'decoder.layers.11.mlp.gate_proj.weight', 'decoder.layers.11.mlp.layer_norm.bias', 'decoder.layers.11.mlp.layer_norm.weight', 'decoder.layers.11.self_attn.k_proj.bias', 'decoder.layers.11.self_attn.k_proj.weight', 'decoder.layers.11.self_attn.o_proj.bias', 'decoder.layers.11.self_attn.o_proj.weight', 'decoder.layers.11.self_attn.q_proj.bias', 'decoder.layers.11.self_attn.q_proj.weight', 'decoder.layers.11.self_attn.scaling', 'decoder.layers.11.self_attn.v_proj.bias', 'decoder.layers.11.self_attn.v_proj.weight', 'decoder.layers.12.input_layernorm.weight', 'decoder.layers.12.mlp.down_proj.bias', 'decoder.layers.12.mlp.down_proj.weight', 'decoder.layers.12.mlp.gate_proj.bias', 'decoder.layers.12.mlp.gate_proj.weight', 'decoder.layers.12.mlp.layer_norm.bias', 'decoder.layers.12.mlp.layer_norm.weight', 'decoder.layers.12.self_attn.k_proj.bias', 'decoder.layers.12.self_attn.k_proj.weight', 'decoder.layers.12.self_attn.o_proj.bias', 'decoder.layers.12.self_attn.o_proj.weight', 'decoder.layers.12.self_attn.q_proj.bias', 'decoder.layers.12.self_attn.q_proj.weight', 'decoder.layers.12.self_attn.scaling', 'decoder.layers.12.self_attn.v_proj.bias', 'decoder.layers.12.self_attn.v_proj.weight', 'decoder.layers.13.input_layernorm.weight', 'decoder.layers.13.mlp.down_proj.bias', 'decoder.layers.13.mlp.down_proj.weight', 'decoder.layers.13.mlp.gate_proj.bias', 'decoder.layers.13.mlp.gate_proj.weight', 'decoder.layers.13.mlp.layer_norm.bias', 'decoder.layers.13.mlp.layer_norm.weight', 'decoder.layers.13.self_attn.k_proj.bias', 'decoder.layers.13.self_attn.k_proj.weight', 'decoder.layers.13.self_attn.o_proj.bias', 'decoder.layers.13.self_attn.o_proj.weight', 'decoder.layers.13.self_attn.q_proj.bias', 'decoder.layers.13.self_attn.q_proj.weight', 'decoder.layers.13.self_attn.scaling', 'decoder.layers.13.self_attn.v_proj.bias', 'decoder.layers.13.self_attn.v_proj.weight', 'decoder.layers.14.input_layernorm.weight', 'decoder.layers.14.mlp.down_proj.bias', 'decoder.layers.14.mlp.down_proj.weight', 'decoder.layers.14.mlp.gate_proj.bias', 'decoder.layers.14.mlp.gate_proj.weight', 'decoder.layers.14.mlp.layer_norm.bias', 'decoder.layers.14.mlp.layer_norm.weight', 'decoder.layers.14.self_attn.k_proj.bias', 'decoder.layers.14.self_attn.k_proj.weight', 'decoder.layers.14.self_attn.o_proj.bias', 'decoder.layers.14.self_attn.o_proj.weight', 'decoder.layers.14.self_attn.q_proj.bias', 'decoder.layers.14.self_attn.q_proj.weight', 'decoder.layers.14.self_attn.scaling', 'decoder.layers.14.self_attn.v_proj.bias', 'decoder.layers.14.self_attn.v_proj.weight', 'decoder.layers.15.input_layernorm.weight', 'decoder.layers.15.mlp.down_proj.bias', 'decoder.layers.15.mlp.down_proj.weight', 'decoder.layers.15.mlp.gate_proj.bias', 'decoder.layers.15.mlp.gate_proj.weight', 'decoder.layers.15.mlp.layer_norm.bias', 'decoder.layers.15.mlp.layer_norm.weight', 'decoder.layers.15.self_attn.k_proj.bias', 'decoder.layers.15.self_attn.k_proj.weight', 'decoder.layers.15.self_attn.o_proj.bias', 'decoder.layers.15.self_attn.o_proj.weight', 'decoder.layers.15.self_attn.q_proj.bias', 'decoder.layers.15.self_attn.q_proj.weight', 'decoder.layers.15.self_attn.scaling', 'decoder.layers.15.self_attn.v_proj.bias', 'decoder.layers.15.self_attn.v_proj.weight', 'decoder.layers.16.input_layernorm.weight', 'decoder.layers.16.mlp.down_proj.bias', 'decoder.layers.16.mlp.down_proj.weight', 'decoder.layers.16.mlp.gate_proj.bias', 'decoder.layers.16.mlp.gate_proj.weight', 'decoder.layers.16.mlp.layer_norm.bias', 'decoder.layers.16.mlp.layer_norm.weight', 'decoder.layers.16.self_attn.k_proj.bias', 'decoder.layers.16.self_attn.k_proj.weight', 'decoder.layers.16.self_attn.o_proj.bias', 'decoder.layers.16.self_attn.o_proj.weight', 'decoder.layers.16.self_attn.q_proj.bias', 'decoder.layers.16.self_attn.q_proj.weight', 'decoder.layers.16.self_attn.scaling', 'decoder.layers.16.self_attn.v_proj.bias', 'decoder.layers.16.self_attn.v_proj.weight', 'decoder.layers.17.input_layernorm.weight', 'decoder.layers.17.mlp.down_proj.bias', 'decoder.layers.17.mlp.down_proj.weight', 'decoder.layers.17.mlp.gate_proj.bias', 'decoder.layers.17.mlp.gate_proj.weight', 'decoder.layers.17.mlp.layer_norm.bias', 'decoder.layers.17.mlp.layer_norm.weight', 'decoder.layers.17.self_attn.k_proj.bias', 'decoder.layers.17.self_attn.k_proj.weight', 'decoder.layers.17.self_attn.o_proj.bias', 'decoder.layers.17.self_attn.o_proj.weight', 'decoder.layers.17.self_attn.q_proj.bias', 'decoder.layers.17.self_attn.q_proj.weight', 'decoder.layers.17.self_attn.scaling', 'decoder.layers.17.self_attn.v_proj.bias', 'decoder.layers.17.self_attn.v_proj.weight', 'decoder.layers.18.input_layernorm.weight', 'decoder.layers.18.mlp.down_proj.bias', 'decoder.layers.18.mlp.down_proj.weight', 'decoder.layers.18.mlp.gate_proj.bias', 'decoder.layers.18.mlp.gate_proj.weight', 'decoder.layers.18.mlp.layer_norm.bias', 'decoder.layers.18.mlp.layer_norm.weight', 'decoder.layers.18.self_attn.k_proj.bias', 'decoder.layers.18.self_attn.k_proj.weight', 'decoder.layers.18.self_attn.o_proj.bias', 'decoder.layers.18.self_attn.o_proj.weight', 'decoder.layers.18.self_attn.q_proj.bias', 'decoder.layers.18.self_attn.q_proj.weight', 'decoder.layers.18.self_attn.scaling', 'decoder.layers.18.self_attn.v_proj.bias', 'decoder.layers.18.self_attn.v_proj.weight', 'decoder.layers.19.input_layernorm.weight', 'decoder.layers.19.mlp.down_proj.bias', 'decoder.layers.19.mlp.down_proj.weight', 'decoder.layers.19.mlp.gate_proj.bias', 'decoder.layers.19.mlp.gate_proj.weight', 'decoder.layers.19.mlp.layer_norm.bias', 'decoder.layers.19.mlp.layer_norm.weight', 'decoder.layers.19.self_attn.k_proj.bias', 'decoder.layers.19.self_attn.k_proj.weight', 'decoder.layers.19.self_attn.o_proj.bias', 'decoder.layers.19.self_attn.o_proj.weight', 'decoder.layers.19.self_attn.q_proj.bias', 'decoder.layers.19.self_attn.q_proj.weight', 'decoder.layers.19.self_attn.scaling', 'decoder.layers.19.self_attn.v_proj.bias', 'decoder.layers.19.self_attn.v_proj.weight', 'decoder.layers.2.input_layernorm.weight', 'decoder.layers.2.mlp.down_proj.bias', 'decoder.layers.2.mlp.down_proj.weight', 'decoder.layers.2.mlp.gate_proj.bias', 'decoder.layers.2.mlp.gate_proj.weight', 'decoder.layers.2.mlp.layer_norm.bias', 'decoder.layers.2.mlp.layer_norm.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.o_proj.bias', 'decoder.layers.2.self_attn.o_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.scaling', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.3.input_layernorm.weight', 'decoder.layers.3.mlp.down_proj.bias', 'decoder.layers.3.mlp.down_proj.weight', 'decoder.layers.3.mlp.gate_proj.bias', 'decoder.layers.3.mlp.gate_proj.weight', 'decoder.layers.3.mlp.layer_norm.bias', 'decoder.layers.3.mlp.layer_norm.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.o_proj.bias', 'decoder.layers.3.self_attn.o_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.scaling', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.4.input_layernorm.weight', 'decoder.layers.4.mlp.down_proj.bias', 'decoder.layers.4.mlp.down_proj.weight', 'decoder.layers.4.mlp.gate_proj.bias', 'decoder.layers.4.mlp.gate_proj.weight', 'decoder.layers.4.mlp.layer_norm.bias', 'decoder.layers.4.mlp.layer_norm.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.o_proj.bias', 'decoder.layers.4.self_attn.o_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.scaling', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.5.input_layernorm.weight', 'decoder.layers.5.mlp.down_proj.bias', 'decoder.layers.5.mlp.down_proj.weight', 'decoder.layers.5.mlp.gate_proj.bias', 'decoder.layers.5.mlp.gate_proj.weight', 'decoder.layers.5.mlp.layer_norm.bias', 'decoder.layers.5.mlp.layer_norm.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.o_proj.bias', 'decoder.layers.5.self_attn.o_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.scaling', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.6.input_layernorm.weight', 'decoder.layers.6.mlp.down_proj.bias', 'decoder.layers.6.mlp.down_proj.weight', 'decoder.layers.6.mlp.gate_proj.bias', 'decoder.layers.6.mlp.gate_proj.weight', 'decoder.layers.6.mlp.layer_norm.bias', 'decoder.layers.6.mlp.layer_norm.weight', 'decoder.layers.6.self_attn.k_proj.bias', 'decoder.layers.6.self_attn.k_proj.weight', 'decoder.layers.6.self_attn.o_proj.bias', 'decoder.layers.6.self_attn.o_proj.weight', 'decoder.layers.6.self_attn.q_proj.bias', 'decoder.layers.6.self_attn.q_proj.weight', 'decoder.layers.6.self_attn.scaling', 'decoder.layers.6.self_attn.v_proj.bias', 'decoder.layers.6.self_attn.v_proj.weight', 'decoder.layers.7.input_layernorm.weight', 'decoder.layers.7.mlp.down_proj.bias', 'decoder.layers.7.mlp.down_proj.weight', 'decoder.layers.7.mlp.gate_proj.bias', 'decoder.layers.7.mlp.gate_proj.weight', 'decoder.layers.7.mlp.layer_norm.bias', 'decoder.layers.7.mlp.layer_norm.weight', 'decoder.layers.7.self_attn.k_proj.bias', 'decoder.layers.7.self_attn.k_proj.weight', 'decoder.layers.7.self_attn.o_proj.bias', 'decoder.layers.7.self_attn.o_proj.weight', 'decoder.layers.7.self_attn.q_proj.bias', 'decoder.layers.7.self_attn.q_proj.weight', 'decoder.layers.7.self_attn.scaling', 'decoder.layers.7.self_attn.v_proj.bias', 'decoder.layers.7.self_attn.v_proj.weight', 'decoder.layers.8.input_layernorm.weight', 'decoder.layers.8.mlp.down_proj.bias', 'decoder.layers.8.mlp.down_proj.weight', 'decoder.layers.8.mlp.gate_proj.bias', 'decoder.layers.8.mlp.gate_proj.weight', 'decoder.layers.8.mlp.layer_norm.bias', 'decoder.layers.8.mlp.layer_norm.weight', 'decoder.layers.8.self_attn.k_proj.bias', 'decoder.layers.8.self_attn.k_proj.weight', 'decoder.layers.8.self_attn.o_proj.bias', 'decoder.layers.8.self_attn.o_proj.weight', 'decoder.layers.8.self_attn.q_proj.bias', 'decoder.layers.8.self_attn.q_proj.weight', 'decoder.layers.8.self_attn.scaling', 'decoder.layers.8.self_attn.v_proj.bias', 'decoder.layers.8.self_attn.v_proj.weight', 'decoder.layers.9.input_layernorm.weight', 'decoder.layers.9.mlp.down_proj.bias', 'decoder.layers.9.mlp.down_proj.weight', 'decoder.layers.9.mlp.gate_proj.bias', 'decoder.layers.9.mlp.gate_proj.weight', 'decoder.layers.9.mlp.layer_norm.bias', 'decoder.layers.9.mlp.layer_norm.weight', 'decoder.layers.9.self_attn.k_proj.bias', 'decoder.layers.9.self_attn.k_proj.weight', 'decoder.layers.9.self_attn.o_proj.bias', 'decoder.layers.9.self_attn.o_proj.weight', 'decoder.layers.9.self_attn.q_proj.bias', 'decoder.layers.9.self_attn.q_proj.weight', 'decoder.layers.9.self_attn.scaling', 'decoder.layers.9.self_attn.v_proj.bias', 'decoder.layers.9.self_attn.v_proj.weight', 'horizon_ff_layer.input_layer.bias', 'horizon_ff_layer.input_layer.weight', 'horizon_ff_layer.output_layer.bias', 'horizon_ff_layer.output_layer.weight', 'horizon_ff_layer.residual_layer.bias', 'horizon_ff_layer.residual_layer.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n",
            "  Epoch 1/100 train_loss=1.4082 train_acc=0.3000 eval_loss=0.3289 eval_acc=0.8924 (best)\n",
            "  Epoch 2/100 train_loss=0.2009 train_acc=0.9500 eval_loss=0.2730 eval_acc=0.9138 (best)\n",
            "  Epoch 3/100 train_loss=0.0537 train_acc=0.9900 eval_loss=0.1906 eval_acc=0.9452 (best)\n",
            "  Epoch 4/100 train_loss=0.0099 train_acc=1.0000 eval_loss=0.1827 eval_acc=0.9509 (best)\n",
            "  Epoch 5/100 train_loss=0.0026 train_acc=1.0000 eval_loss=0.2293 eval_acc=0.9476 \n",
            "  Epoch 6/100 train_loss=0.0010 train_acc=1.0000 eval_loss=0.2382 eval_acc=0.9497 \n",
            "  Epoch 7/100 train_loss=0.0001 train_acc=1.0000 eval_loss=0.2370 eval_acc=0.9518 \n",
            "  Epoch 8/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.2394 eval_acc=0.9551 \n",
            "  Epoch 9/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.2430 eval_acc=0.9563 \n",
            "  Epoch 10/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.2469 eval_acc=0.9571 \n",
            "  Epoch 11/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.2506 eval_acc=0.9584 \n",
            "  Epoch 12/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.2532 eval_acc=0.9584 \n",
            "  Epoch 13/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.2551 eval_acc=0.9584 \n",
            "  Epoch 14/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.2563 eval_acc=0.9575 \n",
            "  Early stopping on google/timesfm-2.5-200m-pytorch: no improvement for 10 epochs (best epoch = 4)\n",
            "    tfm[google/timesfm-2.5-200m-pytorch] train_acc=1.0000 eval_acc=0.95752577319587628412733693039626814424991608\n",
            "    mrh_acc=0.9658 mr+h+kg_acc=0.9678 kg_acc=0.9695 ensemble=0.9670 (w=0.60)\n",
            "  Split 1/1 - accuracy=0.9670 time=625.3s\n",
            "Completed MixedShapesSmallTrain: Mean Acc=0.9670\n",
            "\n",
            "=== 64/109 MoteStrain ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n",
            "    Gate split 1/5: baseline_loss=0.3555 adaptive_loss=0.3791\n",
            "    Gate split 2/5: baseline_loss=0.3863 adaptive_loss=0.4812\n",
            "    Gate split 3/5: baseline_loss=0.3754 adaptive_loss=0.4617\n",
            "    Gate split 4/5: baseline_loss=0.8892 adaptive_loss=0.9556\n",
            "    Gate split 5/5: baseline_loss=0.7529 adaptive_loss=0.7810\n",
            "  Decision: Adaptive rejected (loss 0.6117 vs baseline 0.5519, delta=+0.0599 > +0.0200); savgol(window=5, poly=2) - high noise (std_diff)\n",
            "Error processing MoteStrain: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n",
            "\n",
            "=== 65/109 OliveOil ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 556, in main\n",
            "    results = evaluate_dataset_per_split(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 429, in evaluate_dataset_per_split\n",
            "    X_train_extra = np.concatenate([X_train_all, all_dec_train], axis=1)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "ValueError: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Gate split 1/5: baseline_loss=0.0573 adaptive_loss=0.0211\n",
            "    Gate split 2/5: baseline_loss=0.1877 adaptive_loss=0.0918\n",
            "    Gate split 3/5: baseline_loss=0.2444 adaptive_loss=0.1846\n",
            "    Gate split 4/5: baseline_loss=0.0946 adaptive_loss=0.0285\n",
            "    Gate split 5/5: baseline_loss=0.6461 adaptive_loss=0.5739\n",
            "  Decision: Adaptive kept (loss 0.1800 vs baseline 0.2460, delta=-0.0660 <= +0.0200); savgol(window=15, poly=3) - high noise (std_diff)\n",
            "\n",
            "=== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at google/timesfm-2.5-200m-pytorch were not used when initializing TimesFmModelForPrediction: ['output_projection_point.hidden_layer.weight', 'output_projection_point.output_layer.weight', 'output_projection_point.residual_layer.weight', 'output_projection_quantiles.hidden_layer.weight', 'output_projection_quantiles.output_layer.weight', 'output_projection_quantiles.residual_layer.weight', 'stacked_xf.0.attn.key_ln.scale', 'stacked_xf.0.attn.out.weight', 'stacked_xf.0.attn.per_dim_scale.per_dim_scale', 'stacked_xf.0.attn.qkv_proj.weight', 'stacked_xf.0.attn.query_ln.scale', 'stacked_xf.0.ff0.weight', 'stacked_xf.0.ff1.weight', 'stacked_xf.0.post_attn_ln.scale', 'stacked_xf.0.post_ff_ln.scale', 'stacked_xf.0.pre_attn_ln.scale', 'stacked_xf.0.pre_ff_ln.scale', 'stacked_xf.1.attn.key_ln.scale', 'stacked_xf.1.attn.out.weight', 'stacked_xf.1.attn.per_dim_scale.per_dim_scale', 'stacked_xf.1.attn.qkv_proj.weight', 'stacked_xf.1.attn.query_ln.scale', 'stacked_xf.1.ff0.weight', 'stacked_xf.1.ff1.weight', 'stacked_xf.1.post_attn_ln.scale', 'stacked_xf.1.post_ff_ln.scale', 'stacked_xf.1.pre_attn_ln.scale', 'stacked_xf.1.pre_ff_ln.scale', 'stacked_xf.10.attn.key_ln.scale', 'stacked_xf.10.attn.out.weight', 'stacked_xf.10.attn.per_dim_scale.per_dim_scale', 'stacked_xf.10.attn.qkv_proj.weight', 'stacked_xf.10.attn.query_ln.scale', 'stacked_xf.10.ff0.weight', 'stacked_xf.10.ff1.weight', 'stacked_xf.10.post_attn_ln.scale', 'stacked_xf.10.post_ff_ln.scale', 'stacked_xf.10.pre_attn_ln.scale', 'stacked_xf.10.pre_ff_ln.scale', 'stacked_xf.11.attn.key_ln.scale', 'stacked_xf.11.attn.out.weight', 'stacked_xf.11.attn.per_dim_scale.per_dim_scale', 'stacked_xf.11.attn.qkv_proj.weight', 'stacked_xf.11.attn.query_ln.scale', 'stacked_xf.11.ff0.weight', 'stacked_xf.11.ff1.weight', 'stacked_xf.11.post_attn_ln.scale', 'stacked_xf.11.post_ff_ln.scale', 'stacked_xf.11.pre_attn_ln.scale', 'stacked_xf.11.pre_ff_ln.scale', 'stacked_xf.12.attn.key_ln.scale', 'stacked_xf.12.attn.out.weight', 'stacked_xf.12.attn.per_dim_scale.per_dim_scale', 'stacked_xf.12.attn.qkv_proj.weight', 'stacked_xf.12.attn.query_ln.scale', 'stacked_xf.12.ff0.weight', 'stacked_xf.12.ff1.weight', 'stacked_xf.12.post_attn_ln.scale', 'stacked_xf.12.post_ff_ln.scale', 'stacked_xf.12.pre_attn_ln.scale', 'stacked_xf.12.pre_ff_ln.scale', 'stacked_xf.13.attn.key_ln.scale', 'stacked_xf.13.attn.out.weight', 'stacked_xf.13.attn.per_dim_scale.per_dim_scale', 'stacked_xf.13.attn.qkv_proj.weight', 'stacked_xf.13.attn.query_ln.scale', 'stacked_xf.13.ff0.weight', 'stacked_xf.13.ff1.weight', 'stacked_xf.13.post_attn_ln.scale', 'stacked_xf.13.post_ff_ln.scale', 'stacked_xf.13.pre_attn_ln.scale', 'stacked_xf.13.pre_ff_ln.scale', 'stacked_xf.14.attn.key_ln.scale', 'stacked_xf.14.attn.out.weight', 'stacked_xf.14.attn.per_dim_scale.per_dim_scale', 'stacked_xf.14.attn.qkv_proj.weight', 'stacked_xf.14.attn.query_ln.scale', 'stacked_xf.14.ff0.weight', 'stacked_xf.14.ff1.weight', 'stacked_xf.14.post_attn_ln.scale', 'stacked_xf.14.post_ff_ln.scale', 'stacked_xf.14.pre_attn_ln.scale', 'stacked_xf.14.pre_ff_ln.scale', 'stacked_xf.15.attn.key_ln.scale', 'stacked_xf.15.attn.out.weight', 'stacked_xf.15.attn.per_dim_scale.per_dim_scale', 'stacked_xf.15.attn.qkv_proj.weight', 'stacked_xf.15.attn.query_ln.scale', 'stacked_xf.15.ff0.weight', 'stacked_xf.15.ff1.weight', 'stacked_xf.15.post_attn_ln.scale', 'stacked_xf.15.post_ff_ln.scale', 'stacked_xf.15.pre_attn_ln.scale', 'stacked_xf.15.pre_ff_ln.scale', 'stacked_xf.16.attn.key_ln.scale', 'stacked_xf.16.attn.out.weight', 'stacked_xf.16.attn.per_dim_scale.per_dim_scale', 'stacked_xf.16.attn.qkv_proj.weight', 'stacked_xf.16.attn.query_ln.scale', 'stacked_xf.16.ff0.weight', 'stacked_xf.16.ff1.weight', 'stacked_xf.16.post_attn_ln.scale', 'stacked_xf.16.post_ff_ln.scale', 'stacked_xf.16.pre_attn_ln.scale', 'stacked_xf.16.pre_ff_ln.scale', 'stacked_xf.17.attn.key_ln.scale', 'stacked_xf.17.attn.out.weight', 'stacked_xf.17.attn.per_dim_scale.per_dim_scale', 'stacked_xf.17.attn.qkv_proj.weight', 'stacked_xf.17.attn.query_ln.scale', 'stacked_xf.17.ff0.weight', 'stacked_xf.17.ff1.weight', 'stacked_xf.17.post_attn_ln.scale', 'stacked_xf.17.post_ff_ln.scale', 'stacked_xf.17.pre_attn_ln.scale', 'stacked_xf.17.pre_ff_ln.scale', 'stacked_xf.18.attn.key_ln.scale', 'stacked_xf.18.attn.out.weight', 'stacked_xf.18.attn.per_dim_scale.per_dim_scale', 'stacked_xf.18.attn.qkv_proj.weight', 'stacked_xf.18.attn.query_ln.scale', 'stacked_xf.18.ff0.weight', 'stacked_xf.18.ff1.weight', 'stacked_xf.18.post_attn_ln.scale', 'stacked_xf.18.post_ff_ln.scale', 'stacked_xf.18.pre_attn_ln.scale', 'stacked_xf.18.pre_ff_ln.scale', 'stacked_xf.19.attn.key_ln.scale', 'stacked_xf.19.attn.out.weight', 'stacked_xf.19.attn.per_dim_scale.per_dim_scale', 'stacked_xf.19.attn.qkv_proj.weight', 'stacked_xf.19.attn.query_ln.scale', 'stacked_xf.19.ff0.weight', 'stacked_xf.19.ff1.weight', 'stacked_xf.19.post_attn_ln.scale', 'stacked_xf.19.post_ff_ln.scale', 'stacked_xf.19.pre_attn_ln.scale', 'stacked_xf.19.pre_ff_ln.scale', 'stacked_xf.2.attn.key_ln.scale', 'stacked_xf.2.attn.out.weight', 'stacked_xf.2.attn.per_dim_scale.per_dim_scale', 'stacked_xf.2.attn.qkv_proj.weight', 'stacked_xf.2.attn.query_ln.scale', 'stacked_xf.2.ff0.weight', 'stacked_xf.2.ff1.weight', 'stacked_xf.2.post_attn_ln.scale', 'stacked_xf.2.post_ff_ln.scale', 'stacked_xf.2.pre_attn_ln.scale', 'stacked_xf.2.pre_ff_ln.scale', 'stacked_xf.3.attn.key_ln.scale', 'stacked_xf.3.attn.out.weight', 'stacked_xf.3.attn.per_dim_scale.per_dim_scale', 'stacked_xf.3.attn.qkv_proj.weight', 'stacked_xf.3.attn.query_ln.scale', 'stacked_xf.3.ff0.weight', 'stacked_xf.3.ff1.weight', 'stacked_xf.3.post_attn_ln.scale', 'stacked_xf.3.post_ff_ln.scale', 'stacked_xf.3.pre_attn_ln.scale', 'stacked_xf.3.pre_ff_ln.scale', 'stacked_xf.4.attn.key_ln.scale', 'stacked_xf.4.attn.out.weight', 'stacked_xf.4.attn.per_dim_scale.per_dim_scale', 'stacked_xf.4.attn.qkv_proj.weight', 'stacked_xf.4.attn.query_ln.scale', 'stacked_xf.4.ff0.weight', 'stacked_xf.4.ff1.weight', 'stacked_xf.4.post_attn_ln.scale', 'stacked_xf.4.post_ff_ln.scale', 'stacked_xf.4.pre_attn_ln.scale', 'stacked_xf.4.pre_ff_ln.scale', 'stacked_xf.5.attn.key_ln.scale', 'stacked_xf.5.attn.out.weight', 'stacked_xf.5.attn.per_dim_scale.per_dim_scale', 'stacked_xf.5.attn.qkv_proj.weight', 'stacked_xf.5.attn.query_ln.scale', 'stacked_xf.5.ff0.weight', 'stacked_xf.5.ff1.weight', 'stacked_xf.5.post_attn_ln.scale', 'stacked_xf.5.post_ff_ln.scale', 'stacked_xf.5.pre_attn_ln.scale', 'stacked_xf.5.pre_ff_ln.scale', 'stacked_xf.6.attn.key_ln.scale', 'stacked_xf.6.attn.out.weight', 'stacked_xf.6.attn.per_dim_scale.per_dim_scale', 'stacked_xf.6.attn.qkv_proj.weight', 'stacked_xf.6.attn.query_ln.scale', 'stacked_xf.6.ff0.weight', 'stacked_xf.6.ff1.weight', 'stacked_xf.6.post_attn_ln.scale', 'stacked_xf.6.post_ff_ln.scale', 'stacked_xf.6.pre_attn_ln.scale', 'stacked_xf.6.pre_ff_ln.scale', 'stacked_xf.7.attn.key_ln.scale', 'stacked_xf.7.attn.out.weight', 'stacked_xf.7.attn.per_dim_scale.per_dim_scale', 'stacked_xf.7.attn.qkv_proj.weight', 'stacked_xf.7.attn.query_ln.scale', 'stacked_xf.7.ff0.weight', 'stacked_xf.7.ff1.weight', 'stacked_xf.7.post_attn_ln.scale', 'stacked_xf.7.post_ff_ln.scale', 'stacked_xf.7.pre_attn_ln.scale', 'stacked_xf.7.pre_ff_ln.scale', 'stacked_xf.8.attn.key_ln.scale', 'stacked_xf.8.attn.out.weight', 'stacked_xf.8.attn.per_dim_scale.per_dim_scale', 'stacked_xf.8.attn.qkv_proj.weight', 'stacked_xf.8.attn.query_ln.scale', 'stacked_xf.8.ff0.weight', 'stacked_xf.8.ff1.weight', 'stacked_xf.8.post_attn_ln.scale', 'stacked_xf.8.post_ff_ln.scale', 'stacked_xf.8.pre_attn_ln.scale', 'stacked_xf.8.pre_ff_ln.scale', 'stacked_xf.9.attn.key_ln.scale', 'stacked_xf.9.attn.out.weight', 'stacked_xf.9.attn.per_dim_scale.per_dim_scale', 'stacked_xf.9.attn.qkv_proj.weight', 'stacked_xf.9.attn.query_ln.scale', 'stacked_xf.9.ff0.weight', 'stacked_xf.9.ff1.weight', 'stacked_xf.9.post_attn_ln.scale', 'stacked_xf.9.post_ff_ln.scale', 'stacked_xf.9.pre_attn_ln.scale', 'stacked_xf.9.pre_ff_ln.scale', 'tokenizer.hidden_layer.bias', 'tokenizer.hidden_layer.weight', 'tokenizer.output_layer.bias', 'tokenizer.output_layer.weight', 'tokenizer.residual_layer.bias', 'tokenizer.residual_layer.weight']\n",
            "- This IS expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of TimesFmModelForPrediction were not initialized from the model checkpoint at google/timesfm-2.5-200m-pytorch and are newly initialized: ['decoder.freq_emb.weight', 'decoder.input_ff_layer.input_layer.bias', 'decoder.input_ff_layer.input_layer.weight', 'decoder.input_ff_layer.output_layer.bias', 'decoder.input_ff_layer.output_layer.weight', 'decoder.input_ff_layer.residual_layer.bias', 'decoder.input_ff_layer.residual_layer.weight', 'decoder.layers.0.input_layernorm.weight', 'decoder.layers.0.mlp.down_proj.bias', 'decoder.layers.0.mlp.down_proj.weight', 'decoder.layers.0.mlp.gate_proj.bias', 'decoder.layers.0.mlp.gate_proj.weight', 'decoder.layers.0.mlp.layer_norm.bias', 'decoder.layers.0.mlp.layer_norm.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.o_proj.bias', 'decoder.layers.0.self_attn.o_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.scaling', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.1.input_layernorm.weight', 'decoder.layers.1.mlp.down_proj.bias', 'decoder.layers.1.mlp.down_proj.weight', 'decoder.layers.1.mlp.gate_proj.bias', 'decoder.layers.1.mlp.gate_proj.weight', 'decoder.layers.1.mlp.layer_norm.bias', 'decoder.layers.1.mlp.layer_norm.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.o_proj.bias', 'decoder.layers.1.self_attn.o_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.scaling', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.10.input_layernorm.weight', 'decoder.layers.10.mlp.down_proj.bias', 'decoder.layers.10.mlp.down_proj.weight', 'decoder.layers.10.mlp.gate_proj.bias', 'decoder.layers.10.mlp.gate_proj.weight', 'decoder.layers.10.mlp.layer_norm.bias', 'decoder.layers.10.mlp.layer_norm.weight', 'decoder.layers.10.self_attn.k_proj.bias', 'decoder.layers.10.self_attn.k_proj.weight', 'decoder.layers.10.self_attn.o_proj.bias', 'decoder.layers.10.self_attn.o_proj.weight', 'decoder.layers.10.self_attn.q_proj.bias', 'decoder.layers.10.self_attn.q_proj.weight', 'decoder.layers.10.self_attn.scaling', 'decoder.layers.10.self_attn.v_proj.bias', 'decoder.layers.10.self_attn.v_proj.weight', 'decoder.layers.11.input_layernorm.weight', 'decoder.layers.11.mlp.down_proj.bias', 'decoder.layers.11.mlp.down_proj.weight', 'decoder.layers.11.mlp.gate_proj.bias', 'decoder.layers.11.mlp.gate_proj.weight', 'decoder.layers.11.mlp.layer_norm.bias', 'decoder.layers.11.mlp.layer_norm.weight', 'decoder.layers.11.self_attn.k_proj.bias', 'decoder.layers.11.self_attn.k_proj.weight', 'decoder.layers.11.self_attn.o_proj.bias', 'decoder.layers.11.self_attn.o_proj.weight', 'decoder.layers.11.self_attn.q_proj.bias', 'decoder.layers.11.self_attn.q_proj.weight', 'decoder.layers.11.self_attn.scaling', 'decoder.layers.11.self_attn.v_proj.bias', 'decoder.layers.11.self_attn.v_proj.weight', 'decoder.layers.12.input_layernorm.weight', 'decoder.layers.12.mlp.down_proj.bias', 'decoder.layers.12.mlp.down_proj.weight', 'decoder.layers.12.mlp.gate_proj.bias', 'decoder.layers.12.mlp.gate_proj.weight', 'decoder.layers.12.mlp.layer_norm.bias', 'decoder.layers.12.mlp.layer_norm.weight', 'decoder.layers.12.self_attn.k_proj.bias', 'decoder.layers.12.self_attn.k_proj.weight', 'decoder.layers.12.self_attn.o_proj.bias', 'decoder.layers.12.self_attn.o_proj.weight', 'decoder.layers.12.self_attn.q_proj.bias', 'decoder.layers.12.self_attn.q_proj.weight', 'decoder.layers.12.self_attn.scaling', 'decoder.layers.12.self_attn.v_proj.bias', 'decoder.layers.12.self_attn.v_proj.weight', 'decoder.layers.13.input_layernorm.weight', 'decoder.layers.13.mlp.down_proj.bias', 'decoder.layers.13.mlp.down_proj.weight', 'decoder.layers.13.mlp.gate_proj.bias', 'decoder.layers.13.mlp.gate_proj.weight', 'decoder.layers.13.mlp.layer_norm.bias', 'decoder.layers.13.mlp.layer_norm.weight', 'decoder.layers.13.self_attn.k_proj.bias', 'decoder.layers.13.self_attn.k_proj.weight', 'decoder.layers.13.self_attn.o_proj.bias', 'decoder.layers.13.self_attn.o_proj.weight', 'decoder.layers.13.self_attn.q_proj.bias', 'decoder.layers.13.self_attn.q_proj.weight', 'decoder.layers.13.self_attn.scaling', 'decoder.layers.13.self_attn.v_proj.bias', 'decoder.layers.13.self_attn.v_proj.weight', 'decoder.layers.14.input_layernorm.weight', 'decoder.layers.14.mlp.down_proj.bias', 'decoder.layers.14.mlp.down_proj.weight', 'decoder.layers.14.mlp.gate_proj.bias', 'decoder.layers.14.mlp.gate_proj.weight', 'decoder.layers.14.mlp.layer_norm.bias', 'decoder.layers.14.mlp.layer_norm.weight', 'decoder.layers.14.self_attn.k_proj.bias', 'decoder.layers.14.self_attn.k_proj.weight', 'decoder.layers.14.self_attn.o_proj.bias', 'decoder.layers.14.self_attn.o_proj.weight', 'decoder.layers.14.self_attn.q_proj.bias', 'decoder.layers.14.self_attn.q_proj.weight', 'decoder.layers.14.self_attn.scaling', 'decoder.layers.14.self_attn.v_proj.bias', 'decoder.layers.14.self_attn.v_proj.weight', 'decoder.layers.15.input_layernorm.weight', 'decoder.layers.15.mlp.down_proj.bias', 'decoder.layers.15.mlp.down_proj.weight', 'decoder.layers.15.mlp.gate_proj.bias', 'decoder.layers.15.mlp.gate_proj.weight', 'decoder.layers.15.mlp.layer_norm.bias', 'decoder.layers.15.mlp.layer_norm.weight', 'decoder.layers.15.self_attn.k_proj.bias', 'decoder.layers.15.self_attn.k_proj.weight', 'decoder.layers.15.self_attn.o_proj.bias', 'decoder.layers.15.self_attn.o_proj.weight', 'decoder.layers.15.self_attn.q_proj.bias', 'decoder.layers.15.self_attn.q_proj.weight', 'decoder.layers.15.self_attn.scaling', 'decoder.layers.15.self_attn.v_proj.bias', 'decoder.layers.15.self_attn.v_proj.weight', 'decoder.layers.16.input_layernorm.weight', 'decoder.layers.16.mlp.down_proj.bias', 'decoder.layers.16.mlp.down_proj.weight', 'decoder.layers.16.mlp.gate_proj.bias', 'decoder.layers.16.mlp.gate_proj.weight', 'decoder.layers.16.mlp.layer_norm.bias', 'decoder.layers.16.mlp.layer_norm.weight', 'decoder.layers.16.self_attn.k_proj.bias', 'decoder.layers.16.self_attn.k_proj.weight', 'decoder.layers.16.self_attn.o_proj.bias', 'decoder.layers.16.self_attn.o_proj.weight', 'decoder.layers.16.self_attn.q_proj.bias', 'decoder.layers.16.self_attn.q_proj.weight', 'decoder.layers.16.self_attn.scaling', 'decoder.layers.16.self_attn.v_proj.bias', 'decoder.layers.16.self_attn.v_proj.weight', 'decoder.layers.17.input_layernorm.weight', 'decoder.layers.17.mlp.down_proj.bias', 'decoder.layers.17.mlp.down_proj.weight', 'decoder.layers.17.mlp.gate_proj.bias', 'decoder.layers.17.mlp.gate_proj.weight', 'decoder.layers.17.mlp.layer_norm.bias', 'decoder.layers.17.mlp.layer_norm.weight', 'decoder.layers.17.self_attn.k_proj.bias', 'decoder.layers.17.self_attn.k_proj.weight', 'decoder.layers.17.self_attn.o_proj.bias', 'decoder.layers.17.self_attn.o_proj.weight', 'decoder.layers.17.self_attn.q_proj.bias', 'decoder.layers.17.self_attn.q_proj.weight', 'decoder.layers.17.self_attn.scaling', 'decoder.layers.17.self_attn.v_proj.bias', 'decoder.layers.17.self_attn.v_proj.weight', 'decoder.layers.18.input_layernorm.weight', 'decoder.layers.18.mlp.down_proj.bias', 'decoder.layers.18.mlp.down_proj.weight', 'decoder.layers.18.mlp.gate_proj.bias', 'decoder.layers.18.mlp.gate_proj.weight', 'decoder.layers.18.mlp.layer_norm.bias', 'decoder.layers.18.mlp.layer_norm.weight', 'decoder.layers.18.self_attn.k_proj.bias', 'decoder.layers.18.self_attn.k_proj.weight', 'decoder.layers.18.self_attn.o_proj.bias', 'decoder.layers.18.self_attn.o_proj.weight', 'decoder.layers.18.self_attn.q_proj.bias', 'decoder.layers.18.self_attn.q_proj.weight', 'decoder.layers.18.self_attn.scaling', 'decoder.layers.18.self_attn.v_proj.bias', 'decoder.layers.18.self_attn.v_proj.weight', 'decoder.layers.19.input_layernorm.weight', 'decoder.layers.19.mlp.down_proj.bias', 'decoder.layers.19.mlp.down_proj.weight', 'decoder.layers.19.mlp.gate_proj.bias', 'decoder.layers.19.mlp.gate_proj.weight', 'decoder.layers.19.mlp.layer_norm.bias', 'decoder.layers.19.mlp.layer_norm.weight', 'decoder.layers.19.self_attn.k_proj.bias', 'decoder.layers.19.self_attn.k_proj.weight', 'decoder.layers.19.self_attn.o_proj.bias', 'decoder.layers.19.self_attn.o_proj.weight', 'decoder.layers.19.self_attn.q_proj.bias', 'decoder.layers.19.self_attn.q_proj.weight', 'decoder.layers.19.self_attn.scaling', 'decoder.layers.19.self_attn.v_proj.bias', 'decoder.layers.19.self_attn.v_proj.weight', 'decoder.layers.2.input_layernorm.weight', 'decoder.layers.2.mlp.down_proj.bias', 'decoder.layers.2.mlp.down_proj.weight', 'decoder.layers.2.mlp.gate_proj.bias', 'decoder.layers.2.mlp.gate_proj.weight', 'decoder.layers.2.mlp.layer_norm.bias', 'decoder.layers.2.mlp.layer_norm.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.o_proj.bias', 'decoder.layers.2.self_attn.o_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.scaling', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.3.input_layernorm.weight', 'decoder.layers.3.mlp.down_proj.bias', 'decoder.layers.3.mlp.down_proj.weight', 'decoder.layers.3.mlp.gate_proj.bias', 'decoder.layers.3.mlp.gate_proj.weight', 'decoder.layers.3.mlp.layer_norm.bias', 'decoder.layers.3.mlp.layer_norm.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.o_proj.bias', 'decoder.layers.3.self_attn.o_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.scaling', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.4.input_layernorm.weight', 'decoder.layers.4.mlp.down_proj.bias', 'decoder.layers.4.mlp.down_proj.weight', 'decoder.layers.4.mlp.gate_proj.bias', 'decoder.layers.4.mlp.gate_proj.weight', 'decoder.layers.4.mlp.layer_norm.bias', 'decoder.layers.4.mlp.layer_norm.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.o_proj.bias', 'decoder.layers.4.self_attn.o_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.scaling', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.5.input_layernorm.weight', 'decoder.layers.5.mlp.down_proj.bias', 'decoder.layers.5.mlp.down_proj.weight', 'decoder.layers.5.mlp.gate_proj.bias', 'decoder.layers.5.mlp.gate_proj.weight', 'decoder.layers.5.mlp.layer_norm.bias', 'decoder.layers.5.mlp.layer_norm.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.o_proj.bias', 'decoder.layers.5.self_attn.o_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.scaling', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.6.input_layernorm.weight', 'decoder.layers.6.mlp.down_proj.bias', 'decoder.layers.6.mlp.down_proj.weight', 'decoder.layers.6.mlp.gate_proj.bias', 'decoder.layers.6.mlp.gate_proj.weight', 'decoder.layers.6.mlp.layer_norm.bias', 'decoder.layers.6.mlp.layer_norm.weight', 'decoder.layers.6.self_attn.k_proj.bias', 'decoder.layers.6.self_attn.k_proj.weight', 'decoder.layers.6.self_attn.o_proj.bias', 'decoder.layers.6.self_attn.o_proj.weight', 'decoder.layers.6.self_attn.q_proj.bias', 'decoder.layers.6.self_attn.q_proj.weight', 'decoder.layers.6.self_attn.scaling', 'decoder.layers.6.self_attn.v_proj.bias', 'decoder.layers.6.self_attn.v_proj.weight', 'decoder.layers.7.input_layernorm.weight', 'decoder.layers.7.mlp.down_proj.bias', 'decoder.layers.7.mlp.down_proj.weight', 'decoder.layers.7.mlp.gate_proj.bias', 'decoder.layers.7.mlp.gate_proj.weight', 'decoder.layers.7.mlp.layer_norm.bias', 'decoder.layers.7.mlp.layer_norm.weight', 'decoder.layers.7.self_attn.k_proj.bias', 'decoder.layers.7.self_attn.k_proj.weight', 'decoder.layers.7.self_attn.o_proj.bias', 'decoder.layers.7.self_attn.o_proj.weight', 'decoder.layers.7.self_attn.q_proj.bias', 'decoder.layers.7.self_attn.q_proj.weight', 'decoder.layers.7.self_attn.scaling', 'decoder.layers.7.self_attn.v_proj.bias', 'decoder.layers.7.self_attn.v_proj.weight', 'decoder.layers.8.input_layernorm.weight', 'decoder.layers.8.mlp.down_proj.bias', 'decoder.layers.8.mlp.down_proj.weight', 'decoder.layers.8.mlp.gate_proj.bias', 'decoder.layers.8.mlp.gate_proj.weight', 'decoder.layers.8.mlp.layer_norm.bias', 'decoder.layers.8.mlp.layer_norm.weight', 'decoder.layers.8.self_attn.k_proj.bias', 'decoder.layers.8.self_attn.k_proj.weight', 'decoder.layers.8.self_attn.o_proj.bias', 'decoder.layers.8.self_attn.o_proj.weight', 'decoder.layers.8.self_attn.q_proj.bias', 'decoder.layers.8.self_attn.q_proj.weight', 'decoder.layers.8.self_attn.scaling', 'decoder.layers.8.self_attn.v_proj.bias', 'decoder.layers.8.self_attn.v_proj.weight', 'decoder.layers.9.input_layernorm.weight', 'decoder.layers.9.mlp.down_proj.bias', 'decoder.layers.9.mlp.down_proj.weight', 'decoder.layers.9.mlp.gate_proj.bias', 'decoder.layers.9.mlp.gate_proj.weight', 'decoder.layers.9.mlp.layer_norm.bias', 'decoder.layers.9.mlp.layer_norm.weight', 'decoder.layers.9.self_attn.k_proj.bias', 'decoder.layers.9.self_attn.k_proj.weight', 'decoder.layers.9.self_attn.o_proj.bias', 'decoder.layers.9.self_attn.o_proj.weight', 'decoder.layers.9.self_attn.q_proj.bias', 'decoder.layers.9.self_attn.q_proj.weight', 'decoder.layers.9.self_attn.scaling', 'decoder.layers.9.self_attn.v_proj.bias', 'decoder.layers.9.self_attn.v_proj.weight', 'horizon_ff_layer.input_layer.bias', 'horizon_ff_layer.input_layer.weight', 'horizon_ff_layer.output_layer.bias', 'horizon_ff_layer.output_layer.weight', 'horizon_ff_layer.residual_layer.bias', 'horizon_ff_layer.residual_layer.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n",
            "  Epoch 1/100 train_loss=1.3728 train_acc=0.3333 eval_loss=1.3813 eval_acc=0.2667 (best)\n",
            "  Epoch 2/100 train_loss=1.3902 train_acc=0.4000 eval_loss=0.9209 eval_acc=0.5333 (best)\n",
            "  Epoch 3/100 train_loss=0.2323 train_acc=0.9667 eval_loss=0.8325 eval_acc=0.5333 (best)\n",
            "  Epoch 4/100 train_loss=0.0376 train_acc=1.0000 eval_loss=0.8559 eval_acc=0.6000 \n",
            "  Epoch 5/100 train_loss=0.0090 train_acc=1.0000 eval_loss=0.8636 eval_acc=0.6000 \n",
            "  Epoch 6/100 train_loss=0.0024 train_acc=1.0000 eval_loss=0.8642 eval_acc=0.6000 \n",
            "  Epoch 7/100 train_loss=0.0009 train_acc=1.0000 eval_loss=0.8615 eval_acc=0.6333 \n",
            "  Epoch 8/100 train_loss=0.0003 train_acc=1.0000 eval_loss=0.8603 eval_acc=0.6333 \n",
            "  Epoch 9/100 train_loss=0.0002 train_acc=1.0000 eval_loss=0.8633 eval_acc=0.6333 \n",
            "  Epoch 10/100 train_loss=0.0001 train_acc=1.0000 eval_loss=0.8714 eval_acc=0.6333 \n",
            "  Epoch 11/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.8852 eval_acc=0.6333 \n",
            "  Epoch 12/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.9021 eval_acc=0.6333 \n",
            "  Epoch 13/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.9209 eval_acc=0.6333 \n",
            "  Early stopping on google/timesfm-2.5-200m-pytorch: no improvement for 10 epochs (best epoch = 3)\n",
            "    tfm[google/timesfm-2.5-200m-pytorch] train_acc=0.9667 eval_acc=0.63333333333333330372738600999582558870315552\n",
            "    mrh_acc=0.8667 mr+h+kg_acc=0.9000 kg_acc=0.9333 ensemble=0.9000 (w=0.60)\n",
            "  Split 1/1 - accuracy=0.9000 time=32.1s\n",
            "Completed OliveOil: Mean Acc=0.9000\n",
            "\n",
            "=== 66/109 OSULeaf ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  Decision: Heuristic says no filter (clean signal (no filtering))\n",
            "\n",
            "=== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at google/timesfm-2.5-200m-pytorch were not used when initializing TimesFmModelForPrediction: ['output_projection_point.hidden_layer.weight', 'output_projection_point.output_layer.weight', 'output_projection_point.residual_layer.weight', 'output_projection_quantiles.hidden_layer.weight', 'output_projection_quantiles.output_layer.weight', 'output_projection_quantiles.residual_layer.weight', 'stacked_xf.0.attn.key_ln.scale', 'stacked_xf.0.attn.out.weight', 'stacked_xf.0.attn.per_dim_scale.per_dim_scale', 'stacked_xf.0.attn.qkv_proj.weight', 'stacked_xf.0.attn.query_ln.scale', 'stacked_xf.0.ff0.weight', 'stacked_xf.0.ff1.weight', 'stacked_xf.0.post_attn_ln.scale', 'stacked_xf.0.post_ff_ln.scale', 'stacked_xf.0.pre_attn_ln.scale', 'stacked_xf.0.pre_ff_ln.scale', 'stacked_xf.1.attn.key_ln.scale', 'stacked_xf.1.attn.out.weight', 'stacked_xf.1.attn.per_dim_scale.per_dim_scale', 'stacked_xf.1.attn.qkv_proj.weight', 'stacked_xf.1.attn.query_ln.scale', 'stacked_xf.1.ff0.weight', 'stacked_xf.1.ff1.weight', 'stacked_xf.1.post_attn_ln.scale', 'stacked_xf.1.post_ff_ln.scale', 'stacked_xf.1.pre_attn_ln.scale', 'stacked_xf.1.pre_ff_ln.scale', 'stacked_xf.10.attn.key_ln.scale', 'stacked_xf.10.attn.out.weight', 'stacked_xf.10.attn.per_dim_scale.per_dim_scale', 'stacked_xf.10.attn.qkv_proj.weight', 'stacked_xf.10.attn.query_ln.scale', 'stacked_xf.10.ff0.weight', 'stacked_xf.10.ff1.weight', 'stacked_xf.10.post_attn_ln.scale', 'stacked_xf.10.post_ff_ln.scale', 'stacked_xf.10.pre_attn_ln.scale', 'stacked_xf.10.pre_ff_ln.scale', 'stacked_xf.11.attn.key_ln.scale', 'stacked_xf.11.attn.out.weight', 'stacked_xf.11.attn.per_dim_scale.per_dim_scale', 'stacked_xf.11.attn.qkv_proj.weight', 'stacked_xf.11.attn.query_ln.scale', 'stacked_xf.11.ff0.weight', 'stacked_xf.11.ff1.weight', 'stacked_xf.11.post_attn_ln.scale', 'stacked_xf.11.post_ff_ln.scale', 'stacked_xf.11.pre_attn_ln.scale', 'stacked_xf.11.pre_ff_ln.scale', 'stacked_xf.12.attn.key_ln.scale', 'stacked_xf.12.attn.out.weight', 'stacked_xf.12.attn.per_dim_scale.per_dim_scale', 'stacked_xf.12.attn.qkv_proj.weight', 'stacked_xf.12.attn.query_ln.scale', 'stacked_xf.12.ff0.weight', 'stacked_xf.12.ff1.weight', 'stacked_xf.12.post_attn_ln.scale', 'stacked_xf.12.post_ff_ln.scale', 'stacked_xf.12.pre_attn_ln.scale', 'stacked_xf.12.pre_ff_ln.scale', 'stacked_xf.13.attn.key_ln.scale', 'stacked_xf.13.attn.out.weight', 'stacked_xf.13.attn.per_dim_scale.per_dim_scale', 'stacked_xf.13.attn.qkv_proj.weight', 'stacked_xf.13.attn.query_ln.scale', 'stacked_xf.13.ff0.weight', 'stacked_xf.13.ff1.weight', 'stacked_xf.13.post_attn_ln.scale', 'stacked_xf.13.post_ff_ln.scale', 'stacked_xf.13.pre_attn_ln.scale', 'stacked_xf.13.pre_ff_ln.scale', 'stacked_xf.14.attn.key_ln.scale', 'stacked_xf.14.attn.out.weight', 'stacked_xf.14.attn.per_dim_scale.per_dim_scale', 'stacked_xf.14.attn.qkv_proj.weight', 'stacked_xf.14.attn.query_ln.scale', 'stacked_xf.14.ff0.weight', 'stacked_xf.14.ff1.weight', 'stacked_xf.14.post_attn_ln.scale', 'stacked_xf.14.post_ff_ln.scale', 'stacked_xf.14.pre_attn_ln.scale', 'stacked_xf.14.pre_ff_ln.scale', 'stacked_xf.15.attn.key_ln.scale', 'stacked_xf.15.attn.out.weight', 'stacked_xf.15.attn.per_dim_scale.per_dim_scale', 'stacked_xf.15.attn.qkv_proj.weight', 'stacked_xf.15.attn.query_ln.scale', 'stacked_xf.15.ff0.weight', 'stacked_xf.15.ff1.weight', 'stacked_xf.15.post_attn_ln.scale', 'stacked_xf.15.post_ff_ln.scale', 'stacked_xf.15.pre_attn_ln.scale', 'stacked_xf.15.pre_ff_ln.scale', 'stacked_xf.16.attn.key_ln.scale', 'stacked_xf.16.attn.out.weight', 'stacked_xf.16.attn.per_dim_scale.per_dim_scale', 'stacked_xf.16.attn.qkv_proj.weight', 'stacked_xf.16.attn.query_ln.scale', 'stacked_xf.16.ff0.weight', 'stacked_xf.16.ff1.weight', 'stacked_xf.16.post_attn_ln.scale', 'stacked_xf.16.post_ff_ln.scale', 'stacked_xf.16.pre_attn_ln.scale', 'stacked_xf.16.pre_ff_ln.scale', 'stacked_xf.17.attn.key_ln.scale', 'stacked_xf.17.attn.out.weight', 'stacked_xf.17.attn.per_dim_scale.per_dim_scale', 'stacked_xf.17.attn.qkv_proj.weight', 'stacked_xf.17.attn.query_ln.scale', 'stacked_xf.17.ff0.weight', 'stacked_xf.17.ff1.weight', 'stacked_xf.17.post_attn_ln.scale', 'stacked_xf.17.post_ff_ln.scale', 'stacked_xf.17.pre_attn_ln.scale', 'stacked_xf.17.pre_ff_ln.scale', 'stacked_xf.18.attn.key_ln.scale', 'stacked_xf.18.attn.out.weight', 'stacked_xf.18.attn.per_dim_scale.per_dim_scale', 'stacked_xf.18.attn.qkv_proj.weight', 'stacked_xf.18.attn.query_ln.scale', 'stacked_xf.18.ff0.weight', 'stacked_xf.18.ff1.weight', 'stacked_xf.18.post_attn_ln.scale', 'stacked_xf.18.post_ff_ln.scale', 'stacked_xf.18.pre_attn_ln.scale', 'stacked_xf.18.pre_ff_ln.scale', 'stacked_xf.19.attn.key_ln.scale', 'stacked_xf.19.attn.out.weight', 'stacked_xf.19.attn.per_dim_scale.per_dim_scale', 'stacked_xf.19.attn.qkv_proj.weight', 'stacked_xf.19.attn.query_ln.scale', 'stacked_xf.19.ff0.weight', 'stacked_xf.19.ff1.weight', 'stacked_xf.19.post_attn_ln.scale', 'stacked_xf.19.post_ff_ln.scale', 'stacked_xf.19.pre_attn_ln.scale', 'stacked_xf.19.pre_ff_ln.scale', 'stacked_xf.2.attn.key_ln.scale', 'stacked_xf.2.attn.out.weight', 'stacked_xf.2.attn.per_dim_scale.per_dim_scale', 'stacked_xf.2.attn.qkv_proj.weight', 'stacked_xf.2.attn.query_ln.scale', 'stacked_xf.2.ff0.weight', 'stacked_xf.2.ff1.weight', 'stacked_xf.2.post_attn_ln.scale', 'stacked_xf.2.post_ff_ln.scale', 'stacked_xf.2.pre_attn_ln.scale', 'stacked_xf.2.pre_ff_ln.scale', 'stacked_xf.3.attn.key_ln.scale', 'stacked_xf.3.attn.out.weight', 'stacked_xf.3.attn.per_dim_scale.per_dim_scale', 'stacked_xf.3.attn.qkv_proj.weight', 'stacked_xf.3.attn.query_ln.scale', 'stacked_xf.3.ff0.weight', 'stacked_xf.3.ff1.weight', 'stacked_xf.3.post_attn_ln.scale', 'stacked_xf.3.post_ff_ln.scale', 'stacked_xf.3.pre_attn_ln.scale', 'stacked_xf.3.pre_ff_ln.scale', 'stacked_xf.4.attn.key_ln.scale', 'stacked_xf.4.attn.out.weight', 'stacked_xf.4.attn.per_dim_scale.per_dim_scale', 'stacked_xf.4.attn.qkv_proj.weight', 'stacked_xf.4.attn.query_ln.scale', 'stacked_xf.4.ff0.weight', 'stacked_xf.4.ff1.weight', 'stacked_xf.4.post_attn_ln.scale', 'stacked_xf.4.post_ff_ln.scale', 'stacked_xf.4.pre_attn_ln.scale', 'stacked_xf.4.pre_ff_ln.scale', 'stacked_xf.5.attn.key_ln.scale', 'stacked_xf.5.attn.out.weight', 'stacked_xf.5.attn.per_dim_scale.per_dim_scale', 'stacked_xf.5.attn.qkv_proj.weight', 'stacked_xf.5.attn.query_ln.scale', 'stacked_xf.5.ff0.weight', 'stacked_xf.5.ff1.weight', 'stacked_xf.5.post_attn_ln.scale', 'stacked_xf.5.post_ff_ln.scale', 'stacked_xf.5.pre_attn_ln.scale', 'stacked_xf.5.pre_ff_ln.scale', 'stacked_xf.6.attn.key_ln.scale', 'stacked_xf.6.attn.out.weight', 'stacked_xf.6.attn.per_dim_scale.per_dim_scale', 'stacked_xf.6.attn.qkv_proj.weight', 'stacked_xf.6.attn.query_ln.scale', 'stacked_xf.6.ff0.weight', 'stacked_xf.6.ff1.weight', 'stacked_xf.6.post_attn_ln.scale', 'stacked_xf.6.post_ff_ln.scale', 'stacked_xf.6.pre_attn_ln.scale', 'stacked_xf.6.pre_ff_ln.scale', 'stacked_xf.7.attn.key_ln.scale', 'stacked_xf.7.attn.out.weight', 'stacked_xf.7.attn.per_dim_scale.per_dim_scale', 'stacked_xf.7.attn.qkv_proj.weight', 'stacked_xf.7.attn.query_ln.scale', 'stacked_xf.7.ff0.weight', 'stacked_xf.7.ff1.weight', 'stacked_xf.7.post_attn_ln.scale', 'stacked_xf.7.post_ff_ln.scale', 'stacked_xf.7.pre_attn_ln.scale', 'stacked_xf.7.pre_ff_ln.scale', 'stacked_xf.8.attn.key_ln.scale', 'stacked_xf.8.attn.out.weight', 'stacked_xf.8.attn.per_dim_scale.per_dim_scale', 'stacked_xf.8.attn.qkv_proj.weight', 'stacked_xf.8.attn.query_ln.scale', 'stacked_xf.8.ff0.weight', 'stacked_xf.8.ff1.weight', 'stacked_xf.8.post_attn_ln.scale', 'stacked_xf.8.post_ff_ln.scale', 'stacked_xf.8.pre_attn_ln.scale', 'stacked_xf.8.pre_ff_ln.scale', 'stacked_xf.9.attn.key_ln.scale', 'stacked_xf.9.attn.out.weight', 'stacked_xf.9.attn.per_dim_scale.per_dim_scale', 'stacked_xf.9.attn.qkv_proj.weight', 'stacked_xf.9.attn.query_ln.scale', 'stacked_xf.9.ff0.weight', 'stacked_xf.9.ff1.weight', 'stacked_xf.9.post_attn_ln.scale', 'stacked_xf.9.post_ff_ln.scale', 'stacked_xf.9.pre_attn_ln.scale', 'stacked_xf.9.pre_ff_ln.scale', 'tokenizer.hidden_layer.bias', 'tokenizer.hidden_layer.weight', 'tokenizer.output_layer.bias', 'tokenizer.output_layer.weight', 'tokenizer.residual_layer.bias', 'tokenizer.residual_layer.weight']\n",
            "- This IS expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of TimesFmModelForPrediction were not initialized from the model checkpoint at google/timesfm-2.5-200m-pytorch and are newly initialized: ['decoder.freq_emb.weight', 'decoder.input_ff_layer.input_layer.bias', 'decoder.input_ff_layer.input_layer.weight', 'decoder.input_ff_layer.output_layer.bias', 'decoder.input_ff_layer.output_layer.weight', 'decoder.input_ff_layer.residual_layer.bias', 'decoder.input_ff_layer.residual_layer.weight', 'decoder.layers.0.input_layernorm.weight', 'decoder.layers.0.mlp.down_proj.bias', 'decoder.layers.0.mlp.down_proj.weight', 'decoder.layers.0.mlp.gate_proj.bias', 'decoder.layers.0.mlp.gate_proj.weight', 'decoder.layers.0.mlp.layer_norm.bias', 'decoder.layers.0.mlp.layer_norm.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.o_proj.bias', 'decoder.layers.0.self_attn.o_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.scaling', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.1.input_layernorm.weight', 'decoder.layers.1.mlp.down_proj.bias', 'decoder.layers.1.mlp.down_proj.weight', 'decoder.layers.1.mlp.gate_proj.bias', 'decoder.layers.1.mlp.gate_proj.weight', 'decoder.layers.1.mlp.layer_norm.bias', 'decoder.layers.1.mlp.layer_norm.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.o_proj.bias', 'decoder.layers.1.self_attn.o_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.scaling', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.10.input_layernorm.weight', 'decoder.layers.10.mlp.down_proj.bias', 'decoder.layers.10.mlp.down_proj.weight', 'decoder.layers.10.mlp.gate_proj.bias', 'decoder.layers.10.mlp.gate_proj.weight', 'decoder.layers.10.mlp.layer_norm.bias', 'decoder.layers.10.mlp.layer_norm.weight', 'decoder.layers.10.self_attn.k_proj.bias', 'decoder.layers.10.self_attn.k_proj.weight', 'decoder.layers.10.self_attn.o_proj.bias', 'decoder.layers.10.self_attn.o_proj.weight', 'decoder.layers.10.self_attn.q_proj.bias', 'decoder.layers.10.self_attn.q_proj.weight', 'decoder.layers.10.self_attn.scaling', 'decoder.layers.10.self_attn.v_proj.bias', 'decoder.layers.10.self_attn.v_proj.weight', 'decoder.layers.11.input_layernorm.weight', 'decoder.layers.11.mlp.down_proj.bias', 'decoder.layers.11.mlp.down_proj.weight', 'decoder.layers.11.mlp.gate_proj.bias', 'decoder.layers.11.mlp.gate_proj.weight', 'decoder.layers.11.mlp.layer_norm.bias', 'decoder.layers.11.mlp.layer_norm.weight', 'decoder.layers.11.self_attn.k_proj.bias', 'decoder.layers.11.self_attn.k_proj.weight', 'decoder.layers.11.self_attn.o_proj.bias', 'decoder.layers.11.self_attn.o_proj.weight', 'decoder.layers.11.self_attn.q_proj.bias', 'decoder.layers.11.self_attn.q_proj.weight', 'decoder.layers.11.self_attn.scaling', 'decoder.layers.11.self_attn.v_proj.bias', 'decoder.layers.11.self_attn.v_proj.weight', 'decoder.layers.12.input_layernorm.weight', 'decoder.layers.12.mlp.down_proj.bias', 'decoder.layers.12.mlp.down_proj.weight', 'decoder.layers.12.mlp.gate_proj.bias', 'decoder.layers.12.mlp.gate_proj.weight', 'decoder.layers.12.mlp.layer_norm.bias', 'decoder.layers.12.mlp.layer_norm.weight', 'decoder.layers.12.self_attn.k_proj.bias', 'decoder.layers.12.self_attn.k_proj.weight', 'decoder.layers.12.self_attn.o_proj.bias', 'decoder.layers.12.self_attn.o_proj.weight', 'decoder.layers.12.self_attn.q_proj.bias', 'decoder.layers.12.self_attn.q_proj.weight', 'decoder.layers.12.self_attn.scaling', 'decoder.layers.12.self_attn.v_proj.bias', 'decoder.layers.12.self_attn.v_proj.weight', 'decoder.layers.13.input_layernorm.weight', 'decoder.layers.13.mlp.down_proj.bias', 'decoder.layers.13.mlp.down_proj.weight', 'decoder.layers.13.mlp.gate_proj.bias', 'decoder.layers.13.mlp.gate_proj.weight', 'decoder.layers.13.mlp.layer_norm.bias', 'decoder.layers.13.mlp.layer_norm.weight', 'decoder.layers.13.self_attn.k_proj.bias', 'decoder.layers.13.self_attn.k_proj.weight', 'decoder.layers.13.self_attn.o_proj.bias', 'decoder.layers.13.self_attn.o_proj.weight', 'decoder.layers.13.self_attn.q_proj.bias', 'decoder.layers.13.self_attn.q_proj.weight', 'decoder.layers.13.self_attn.scaling', 'decoder.layers.13.self_attn.v_proj.bias', 'decoder.layers.13.self_attn.v_proj.weight', 'decoder.layers.14.input_layernorm.weight', 'decoder.layers.14.mlp.down_proj.bias', 'decoder.layers.14.mlp.down_proj.weight', 'decoder.layers.14.mlp.gate_proj.bias', 'decoder.layers.14.mlp.gate_proj.weight', 'decoder.layers.14.mlp.layer_norm.bias', 'decoder.layers.14.mlp.layer_norm.weight', 'decoder.layers.14.self_attn.k_proj.bias', 'decoder.layers.14.self_attn.k_proj.weight', 'decoder.layers.14.self_attn.o_proj.bias', 'decoder.layers.14.self_attn.o_proj.weight', 'decoder.layers.14.self_attn.q_proj.bias', 'decoder.layers.14.self_attn.q_proj.weight', 'decoder.layers.14.self_attn.scaling', 'decoder.layers.14.self_attn.v_proj.bias', 'decoder.layers.14.self_attn.v_proj.weight', 'decoder.layers.15.input_layernorm.weight', 'decoder.layers.15.mlp.down_proj.bias', 'decoder.layers.15.mlp.down_proj.weight', 'decoder.layers.15.mlp.gate_proj.bias', 'decoder.layers.15.mlp.gate_proj.weight', 'decoder.layers.15.mlp.layer_norm.bias', 'decoder.layers.15.mlp.layer_norm.weight', 'decoder.layers.15.self_attn.k_proj.bias', 'decoder.layers.15.self_attn.k_proj.weight', 'decoder.layers.15.self_attn.o_proj.bias', 'decoder.layers.15.self_attn.o_proj.weight', 'decoder.layers.15.self_attn.q_proj.bias', 'decoder.layers.15.self_attn.q_proj.weight', 'decoder.layers.15.self_attn.scaling', 'decoder.layers.15.self_attn.v_proj.bias', 'decoder.layers.15.self_attn.v_proj.weight', 'decoder.layers.16.input_layernorm.weight', 'decoder.layers.16.mlp.down_proj.bias', 'decoder.layers.16.mlp.down_proj.weight', 'decoder.layers.16.mlp.gate_proj.bias', 'decoder.layers.16.mlp.gate_proj.weight', 'decoder.layers.16.mlp.layer_norm.bias', 'decoder.layers.16.mlp.layer_norm.weight', 'decoder.layers.16.self_attn.k_proj.bias', 'decoder.layers.16.self_attn.k_proj.weight', 'decoder.layers.16.self_attn.o_proj.bias', 'decoder.layers.16.self_attn.o_proj.weight', 'decoder.layers.16.self_attn.q_proj.bias', 'decoder.layers.16.self_attn.q_proj.weight', 'decoder.layers.16.self_attn.scaling', 'decoder.layers.16.self_attn.v_proj.bias', 'decoder.layers.16.self_attn.v_proj.weight', 'decoder.layers.17.input_layernorm.weight', 'decoder.layers.17.mlp.down_proj.bias', 'decoder.layers.17.mlp.down_proj.weight', 'decoder.layers.17.mlp.gate_proj.bias', 'decoder.layers.17.mlp.gate_proj.weight', 'decoder.layers.17.mlp.layer_norm.bias', 'decoder.layers.17.mlp.layer_norm.weight', 'decoder.layers.17.self_attn.k_proj.bias', 'decoder.layers.17.self_attn.k_proj.weight', 'decoder.layers.17.self_attn.o_proj.bias', 'decoder.layers.17.self_attn.o_proj.weight', 'decoder.layers.17.self_attn.q_proj.bias', 'decoder.layers.17.self_attn.q_proj.weight', 'decoder.layers.17.self_attn.scaling', 'decoder.layers.17.self_attn.v_proj.bias', 'decoder.layers.17.self_attn.v_proj.weight', 'decoder.layers.18.input_layernorm.weight', 'decoder.layers.18.mlp.down_proj.bias', 'decoder.layers.18.mlp.down_proj.weight', 'decoder.layers.18.mlp.gate_proj.bias', 'decoder.layers.18.mlp.gate_proj.weight', 'decoder.layers.18.mlp.layer_norm.bias', 'decoder.layers.18.mlp.layer_norm.weight', 'decoder.layers.18.self_attn.k_proj.bias', 'decoder.layers.18.self_attn.k_proj.weight', 'decoder.layers.18.self_attn.o_proj.bias', 'decoder.layers.18.self_attn.o_proj.weight', 'decoder.layers.18.self_attn.q_proj.bias', 'decoder.layers.18.self_attn.q_proj.weight', 'decoder.layers.18.self_attn.scaling', 'decoder.layers.18.self_attn.v_proj.bias', 'decoder.layers.18.self_attn.v_proj.weight', 'decoder.layers.19.input_layernorm.weight', 'decoder.layers.19.mlp.down_proj.bias', 'decoder.layers.19.mlp.down_proj.weight', 'decoder.layers.19.mlp.gate_proj.bias', 'decoder.layers.19.mlp.gate_proj.weight', 'decoder.layers.19.mlp.layer_norm.bias', 'decoder.layers.19.mlp.layer_norm.weight', 'decoder.layers.19.self_attn.k_proj.bias', 'decoder.layers.19.self_attn.k_proj.weight', 'decoder.layers.19.self_attn.o_proj.bias', 'decoder.layers.19.self_attn.o_proj.weight', 'decoder.layers.19.self_attn.q_proj.bias', 'decoder.layers.19.self_attn.q_proj.weight', 'decoder.layers.19.self_attn.scaling', 'decoder.layers.19.self_attn.v_proj.bias', 'decoder.layers.19.self_attn.v_proj.weight', 'decoder.layers.2.input_layernorm.weight', 'decoder.layers.2.mlp.down_proj.bias', 'decoder.layers.2.mlp.down_proj.weight', 'decoder.layers.2.mlp.gate_proj.bias', 'decoder.layers.2.mlp.gate_proj.weight', 'decoder.layers.2.mlp.layer_norm.bias', 'decoder.layers.2.mlp.layer_norm.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.o_proj.bias', 'decoder.layers.2.self_attn.o_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.scaling', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.3.input_layernorm.weight', 'decoder.layers.3.mlp.down_proj.bias', 'decoder.layers.3.mlp.down_proj.weight', 'decoder.layers.3.mlp.gate_proj.bias', 'decoder.layers.3.mlp.gate_proj.weight', 'decoder.layers.3.mlp.layer_norm.bias', 'decoder.layers.3.mlp.layer_norm.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.o_proj.bias', 'decoder.layers.3.self_attn.o_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.scaling', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.4.input_layernorm.weight', 'decoder.layers.4.mlp.down_proj.bias', 'decoder.layers.4.mlp.down_proj.weight', 'decoder.layers.4.mlp.gate_proj.bias', 'decoder.layers.4.mlp.gate_proj.weight', 'decoder.layers.4.mlp.layer_norm.bias', 'decoder.layers.4.mlp.layer_norm.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.o_proj.bias', 'decoder.layers.4.self_attn.o_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.scaling', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.5.input_layernorm.weight', 'decoder.layers.5.mlp.down_proj.bias', 'decoder.layers.5.mlp.down_proj.weight', 'decoder.layers.5.mlp.gate_proj.bias', 'decoder.layers.5.mlp.gate_proj.weight', 'decoder.layers.5.mlp.layer_norm.bias', 'decoder.layers.5.mlp.layer_norm.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.o_proj.bias', 'decoder.layers.5.self_attn.o_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.scaling', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.6.input_layernorm.weight', 'decoder.layers.6.mlp.down_proj.bias', 'decoder.layers.6.mlp.down_proj.weight', 'decoder.layers.6.mlp.gate_proj.bias', 'decoder.layers.6.mlp.gate_proj.weight', 'decoder.layers.6.mlp.layer_norm.bias', 'decoder.layers.6.mlp.layer_norm.weight', 'decoder.layers.6.self_attn.k_proj.bias', 'decoder.layers.6.self_attn.k_proj.weight', 'decoder.layers.6.self_attn.o_proj.bias', 'decoder.layers.6.self_attn.o_proj.weight', 'decoder.layers.6.self_attn.q_proj.bias', 'decoder.layers.6.self_attn.q_proj.weight', 'decoder.layers.6.self_attn.scaling', 'decoder.layers.6.self_attn.v_proj.bias', 'decoder.layers.6.self_attn.v_proj.weight', 'decoder.layers.7.input_layernorm.weight', 'decoder.layers.7.mlp.down_proj.bias', 'decoder.layers.7.mlp.down_proj.weight', 'decoder.layers.7.mlp.gate_proj.bias', 'decoder.layers.7.mlp.gate_proj.weight', 'decoder.layers.7.mlp.layer_norm.bias', 'decoder.layers.7.mlp.layer_norm.weight', 'decoder.layers.7.self_attn.k_proj.bias', 'decoder.layers.7.self_attn.k_proj.weight', 'decoder.layers.7.self_attn.o_proj.bias', 'decoder.layers.7.self_attn.o_proj.weight', 'decoder.layers.7.self_attn.q_proj.bias', 'decoder.layers.7.self_attn.q_proj.weight', 'decoder.layers.7.self_attn.scaling', 'decoder.layers.7.self_attn.v_proj.bias', 'decoder.layers.7.self_attn.v_proj.weight', 'decoder.layers.8.input_layernorm.weight', 'decoder.layers.8.mlp.down_proj.bias', 'decoder.layers.8.mlp.down_proj.weight', 'decoder.layers.8.mlp.gate_proj.bias', 'decoder.layers.8.mlp.gate_proj.weight', 'decoder.layers.8.mlp.layer_norm.bias', 'decoder.layers.8.mlp.layer_norm.weight', 'decoder.layers.8.self_attn.k_proj.bias', 'decoder.layers.8.self_attn.k_proj.weight', 'decoder.layers.8.self_attn.o_proj.bias', 'decoder.layers.8.self_attn.o_proj.weight', 'decoder.layers.8.self_attn.q_proj.bias', 'decoder.layers.8.self_attn.q_proj.weight', 'decoder.layers.8.self_attn.scaling', 'decoder.layers.8.self_attn.v_proj.bias', 'decoder.layers.8.self_attn.v_proj.weight', 'decoder.layers.9.input_layernorm.weight', 'decoder.layers.9.mlp.down_proj.bias', 'decoder.layers.9.mlp.down_proj.weight', 'decoder.layers.9.mlp.gate_proj.bias', 'decoder.layers.9.mlp.gate_proj.weight', 'decoder.layers.9.mlp.layer_norm.bias', 'decoder.layers.9.mlp.layer_norm.weight', 'decoder.layers.9.self_attn.k_proj.bias', 'decoder.layers.9.self_attn.k_proj.weight', 'decoder.layers.9.self_attn.o_proj.bias', 'decoder.layers.9.self_attn.o_proj.weight', 'decoder.layers.9.self_attn.q_proj.bias', 'decoder.layers.9.self_attn.q_proj.weight', 'decoder.layers.9.self_attn.scaling', 'decoder.layers.9.self_attn.v_proj.bias', 'decoder.layers.9.self_attn.v_proj.weight', 'horizon_ff_layer.input_layer.bias', 'horizon_ff_layer.input_layer.weight', 'horizon_ff_layer.output_layer.bias', 'horizon_ff_layer.output_layer.weight', 'horizon_ff_layer.residual_layer.bias', 'horizon_ff_layer.residual_layer.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n",
            "  Epoch 1/100 train_loss=1.1195 train_acc=0.5650 eval_loss=0.4103 eval_acc=0.8719 (best)\n",
            "  Epoch 2/100 train_loss=0.1552 train_acc=0.9750 eval_loss=0.3082 eval_acc=0.9132 (best)\n",
            "  Epoch 3/100 train_loss=0.0270 train_acc=1.0000 eval_loss=0.2602 eval_acc=0.9380 (best)\n",
            "  Epoch 4/100 train_loss=0.0040 train_acc=1.0000 eval_loss=0.2128 eval_acc=0.9421 (best)\n",
            "  Epoch 5/100 train_loss=0.0007 train_acc=1.0000 eval_loss=0.2156 eval_acc=0.9463 \n",
            "  Epoch 6/100 train_loss=0.0003 train_acc=1.0000 eval_loss=0.2406 eval_acc=0.9421 \n",
            "  Epoch 7/100 train_loss=0.0001 train_acc=1.0000 eval_loss=0.2557 eval_acc=0.9421 \n",
            "  Epoch 8/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.2666 eval_acc=0.9421 \n",
            "  Epoch 9/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.2741 eval_acc=0.9421 \n",
            "  Epoch 10/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.2791 eval_acc=0.9421 \n",
            "  Epoch 11/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.2822 eval_acc=0.9504 \n",
            "  Epoch 12/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.2840 eval_acc=0.9504 \n",
            "  Epoch 13/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.2852 eval_acc=0.9504 \n",
            "  Epoch 14/100 train_loss=0.0000 train_acc=1.0000 eval_loss=0.2861 eval_acc=0.9504 \n",
            "  Early stopping on google/timesfm-2.5-200m-pytorch: no improvement for 10 epochs (best epoch = 4)\n",
            "    tfm[google/timesfm-2.5-200m-pytorch] train_acc=1.0000 eval_acc=0.95041322314049592190343673792085610330104828\n",
            "    mrh_acc=0.9545 mr+h+kg_acc=0.9463 kg_acc=0.9628 ensemble=0.9587 (w=0.60)\n",
            "  Split 1/1 - accuracy=0.9587 time=183.9s\n",
            "Completed OSULeaf: Mean Acc=0.9587\n",
            "\n",
            "=== 67/109 PhalangesOutlinesCorrect ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n",
            "    Gate split 1/5: baseline_loss=0.9075 adaptive_loss=0.9262\n",
            "    Gate split 2/5: baseline_loss=0.6611 adaptive_loss=0.6635\n",
            "    Gate split 3/5: baseline_loss=0.8364 adaptive_loss=0.8132\n",
            "    Gate split 4/5: baseline_loss=0.7293 adaptive_loss=0.7771\n",
            "    Gate split 5/5: baseline_loss=0.9496 adaptive_loss=0.9884\n",
            "  Decision: Adaptive kept (loss 0.8337 vs baseline 0.8168, delta=+0.0169 <= +0.0200); savgol(window=5, poly=2) - high noise (std_diff)\n",
            "Error processing PhalangesOutlinesCorrect: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n",
            "\n",
            "=== 68/109 Phoneme ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 556, in main\n",
            "    results = evaluate_dataset_per_split(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 429, in evaluate_dataset_per_split\n",
            "    X_train_extra = np.concatenate([X_train_all, all_dec_train], axis=1)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "ValueError: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n",
            "    Gate skipped (min class size 1 < 2); savgol(window=21, poly=3) - high noise (std_diff)\n",
            "\n",
            "=== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at google/timesfm-2.5-200m-pytorch were not used when initializing TimesFmModelForPrediction: ['output_projection_point.hidden_layer.weight', 'output_projection_point.output_layer.weight', 'output_projection_point.residual_layer.weight', 'output_projection_quantiles.hidden_layer.weight', 'output_projection_quantiles.output_layer.weight', 'output_projection_quantiles.residual_layer.weight', 'stacked_xf.0.attn.key_ln.scale', 'stacked_xf.0.attn.out.weight', 'stacked_xf.0.attn.per_dim_scale.per_dim_scale', 'stacked_xf.0.attn.qkv_proj.weight', 'stacked_xf.0.attn.query_ln.scale', 'stacked_xf.0.ff0.weight', 'stacked_xf.0.ff1.weight', 'stacked_xf.0.post_attn_ln.scale', 'stacked_xf.0.post_ff_ln.scale', 'stacked_xf.0.pre_attn_ln.scale', 'stacked_xf.0.pre_ff_ln.scale', 'stacked_xf.1.attn.key_ln.scale', 'stacked_xf.1.attn.out.weight', 'stacked_xf.1.attn.per_dim_scale.per_dim_scale', 'stacked_xf.1.attn.qkv_proj.weight', 'stacked_xf.1.attn.query_ln.scale', 'stacked_xf.1.ff0.weight', 'stacked_xf.1.ff1.weight', 'stacked_xf.1.post_attn_ln.scale', 'stacked_xf.1.post_ff_ln.scale', 'stacked_xf.1.pre_attn_ln.scale', 'stacked_xf.1.pre_ff_ln.scale', 'stacked_xf.10.attn.key_ln.scale', 'stacked_xf.10.attn.out.weight', 'stacked_xf.10.attn.per_dim_scale.per_dim_scale', 'stacked_xf.10.attn.qkv_proj.weight', 'stacked_xf.10.attn.query_ln.scale', 'stacked_xf.10.ff0.weight', 'stacked_xf.10.ff1.weight', 'stacked_xf.10.post_attn_ln.scale', 'stacked_xf.10.post_ff_ln.scale', 'stacked_xf.10.pre_attn_ln.scale', 'stacked_xf.10.pre_ff_ln.scale', 'stacked_xf.11.attn.key_ln.scale', 'stacked_xf.11.attn.out.weight', 'stacked_xf.11.attn.per_dim_scale.per_dim_scale', 'stacked_xf.11.attn.qkv_proj.weight', 'stacked_xf.11.attn.query_ln.scale', 'stacked_xf.11.ff0.weight', 'stacked_xf.11.ff1.weight', 'stacked_xf.11.post_attn_ln.scale', 'stacked_xf.11.post_ff_ln.scale', 'stacked_xf.11.pre_attn_ln.scale', 'stacked_xf.11.pre_ff_ln.scale', 'stacked_xf.12.attn.key_ln.scale', 'stacked_xf.12.attn.out.weight', 'stacked_xf.12.attn.per_dim_scale.per_dim_scale', 'stacked_xf.12.attn.qkv_proj.weight', 'stacked_xf.12.attn.query_ln.scale', 'stacked_xf.12.ff0.weight', 'stacked_xf.12.ff1.weight', 'stacked_xf.12.post_attn_ln.scale', 'stacked_xf.12.post_ff_ln.scale', 'stacked_xf.12.pre_attn_ln.scale', 'stacked_xf.12.pre_ff_ln.scale', 'stacked_xf.13.attn.key_ln.scale', 'stacked_xf.13.attn.out.weight', 'stacked_xf.13.attn.per_dim_scale.per_dim_scale', 'stacked_xf.13.attn.qkv_proj.weight', 'stacked_xf.13.attn.query_ln.scale', 'stacked_xf.13.ff0.weight', 'stacked_xf.13.ff1.weight', 'stacked_xf.13.post_attn_ln.scale', 'stacked_xf.13.post_ff_ln.scale', 'stacked_xf.13.pre_attn_ln.scale', 'stacked_xf.13.pre_ff_ln.scale', 'stacked_xf.14.attn.key_ln.scale', 'stacked_xf.14.attn.out.weight', 'stacked_xf.14.attn.per_dim_scale.per_dim_scale', 'stacked_xf.14.attn.qkv_proj.weight', 'stacked_xf.14.attn.query_ln.scale', 'stacked_xf.14.ff0.weight', 'stacked_xf.14.ff1.weight', 'stacked_xf.14.post_attn_ln.scale', 'stacked_xf.14.post_ff_ln.scale', 'stacked_xf.14.pre_attn_ln.scale', 'stacked_xf.14.pre_ff_ln.scale', 'stacked_xf.15.attn.key_ln.scale', 'stacked_xf.15.attn.out.weight', 'stacked_xf.15.attn.per_dim_scale.per_dim_scale', 'stacked_xf.15.attn.qkv_proj.weight', 'stacked_xf.15.attn.query_ln.scale', 'stacked_xf.15.ff0.weight', 'stacked_xf.15.ff1.weight', 'stacked_xf.15.post_attn_ln.scale', 'stacked_xf.15.post_ff_ln.scale', 'stacked_xf.15.pre_attn_ln.scale', 'stacked_xf.15.pre_ff_ln.scale', 'stacked_xf.16.attn.key_ln.scale', 'stacked_xf.16.attn.out.weight', 'stacked_xf.16.attn.per_dim_scale.per_dim_scale', 'stacked_xf.16.attn.qkv_proj.weight', 'stacked_xf.16.attn.query_ln.scale', 'stacked_xf.16.ff0.weight', 'stacked_xf.16.ff1.weight', 'stacked_xf.16.post_attn_ln.scale', 'stacked_xf.16.post_ff_ln.scale', 'stacked_xf.16.pre_attn_ln.scale', 'stacked_xf.16.pre_ff_ln.scale', 'stacked_xf.17.attn.key_ln.scale', 'stacked_xf.17.attn.out.weight', 'stacked_xf.17.attn.per_dim_scale.per_dim_scale', 'stacked_xf.17.attn.qkv_proj.weight', 'stacked_xf.17.attn.query_ln.scale', 'stacked_xf.17.ff0.weight', 'stacked_xf.17.ff1.weight', 'stacked_xf.17.post_attn_ln.scale', 'stacked_xf.17.post_ff_ln.scale', 'stacked_xf.17.pre_attn_ln.scale', 'stacked_xf.17.pre_ff_ln.scale', 'stacked_xf.18.attn.key_ln.scale', 'stacked_xf.18.attn.out.weight', 'stacked_xf.18.attn.per_dim_scale.per_dim_scale', 'stacked_xf.18.attn.qkv_proj.weight', 'stacked_xf.18.attn.query_ln.scale', 'stacked_xf.18.ff0.weight', 'stacked_xf.18.ff1.weight', 'stacked_xf.18.post_attn_ln.scale', 'stacked_xf.18.post_ff_ln.scale', 'stacked_xf.18.pre_attn_ln.scale', 'stacked_xf.18.pre_ff_ln.scale', 'stacked_xf.19.attn.key_ln.scale', 'stacked_xf.19.attn.out.weight', 'stacked_xf.19.attn.per_dim_scale.per_dim_scale', 'stacked_xf.19.attn.qkv_proj.weight', 'stacked_xf.19.attn.query_ln.scale', 'stacked_xf.19.ff0.weight', 'stacked_xf.19.ff1.weight', 'stacked_xf.19.post_attn_ln.scale', 'stacked_xf.19.post_ff_ln.scale', 'stacked_xf.19.pre_attn_ln.scale', 'stacked_xf.19.pre_ff_ln.scale', 'stacked_xf.2.attn.key_ln.scale', 'stacked_xf.2.attn.out.weight', 'stacked_xf.2.attn.per_dim_scale.per_dim_scale', 'stacked_xf.2.attn.qkv_proj.weight', 'stacked_xf.2.attn.query_ln.scale', 'stacked_xf.2.ff0.weight', 'stacked_xf.2.ff1.weight', 'stacked_xf.2.post_attn_ln.scale', 'stacked_xf.2.post_ff_ln.scale', 'stacked_xf.2.pre_attn_ln.scale', 'stacked_xf.2.pre_ff_ln.scale', 'stacked_xf.3.attn.key_ln.scale', 'stacked_xf.3.attn.out.weight', 'stacked_xf.3.attn.per_dim_scale.per_dim_scale', 'stacked_xf.3.attn.qkv_proj.weight', 'stacked_xf.3.attn.query_ln.scale', 'stacked_xf.3.ff0.weight', 'stacked_xf.3.ff1.weight', 'stacked_xf.3.post_attn_ln.scale', 'stacked_xf.3.post_ff_ln.scale', 'stacked_xf.3.pre_attn_ln.scale', 'stacked_xf.3.pre_ff_ln.scale', 'stacked_xf.4.attn.key_ln.scale', 'stacked_xf.4.attn.out.weight', 'stacked_xf.4.attn.per_dim_scale.per_dim_scale', 'stacked_xf.4.attn.qkv_proj.weight', 'stacked_xf.4.attn.query_ln.scale', 'stacked_xf.4.ff0.weight', 'stacked_xf.4.ff1.weight', 'stacked_xf.4.post_attn_ln.scale', 'stacked_xf.4.post_ff_ln.scale', 'stacked_xf.4.pre_attn_ln.scale', 'stacked_xf.4.pre_ff_ln.scale', 'stacked_xf.5.attn.key_ln.scale', 'stacked_xf.5.attn.out.weight', 'stacked_xf.5.attn.per_dim_scale.per_dim_scale', 'stacked_xf.5.attn.qkv_proj.weight', 'stacked_xf.5.attn.query_ln.scale', 'stacked_xf.5.ff0.weight', 'stacked_xf.5.ff1.weight', 'stacked_xf.5.post_attn_ln.scale', 'stacked_xf.5.post_ff_ln.scale', 'stacked_xf.5.pre_attn_ln.scale', 'stacked_xf.5.pre_ff_ln.scale', 'stacked_xf.6.attn.key_ln.scale', 'stacked_xf.6.attn.out.weight', 'stacked_xf.6.attn.per_dim_scale.per_dim_scale', 'stacked_xf.6.attn.qkv_proj.weight', 'stacked_xf.6.attn.query_ln.scale', 'stacked_xf.6.ff0.weight', 'stacked_xf.6.ff1.weight', 'stacked_xf.6.post_attn_ln.scale', 'stacked_xf.6.post_ff_ln.scale', 'stacked_xf.6.pre_attn_ln.scale', 'stacked_xf.6.pre_ff_ln.scale', 'stacked_xf.7.attn.key_ln.scale', 'stacked_xf.7.attn.out.weight', 'stacked_xf.7.attn.per_dim_scale.per_dim_scale', 'stacked_xf.7.attn.qkv_proj.weight', 'stacked_xf.7.attn.query_ln.scale', 'stacked_xf.7.ff0.weight', 'stacked_xf.7.ff1.weight', 'stacked_xf.7.post_attn_ln.scale', 'stacked_xf.7.post_ff_ln.scale', 'stacked_xf.7.pre_attn_ln.scale', 'stacked_xf.7.pre_ff_ln.scale', 'stacked_xf.8.attn.key_ln.scale', 'stacked_xf.8.attn.out.weight', 'stacked_xf.8.attn.per_dim_scale.per_dim_scale', 'stacked_xf.8.attn.qkv_proj.weight', 'stacked_xf.8.attn.query_ln.scale', 'stacked_xf.8.ff0.weight', 'stacked_xf.8.ff1.weight', 'stacked_xf.8.post_attn_ln.scale', 'stacked_xf.8.post_ff_ln.scale', 'stacked_xf.8.pre_attn_ln.scale', 'stacked_xf.8.pre_ff_ln.scale', 'stacked_xf.9.attn.key_ln.scale', 'stacked_xf.9.attn.out.weight', 'stacked_xf.9.attn.per_dim_scale.per_dim_scale', 'stacked_xf.9.attn.qkv_proj.weight', 'stacked_xf.9.attn.query_ln.scale', 'stacked_xf.9.ff0.weight', 'stacked_xf.9.ff1.weight', 'stacked_xf.9.post_attn_ln.scale', 'stacked_xf.9.post_ff_ln.scale', 'stacked_xf.9.pre_attn_ln.scale', 'stacked_xf.9.pre_ff_ln.scale', 'tokenizer.hidden_layer.bias', 'tokenizer.hidden_layer.weight', 'tokenizer.output_layer.bias', 'tokenizer.output_layer.weight', 'tokenizer.residual_layer.bias', 'tokenizer.residual_layer.weight']\n",
            "- This IS expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TimesFmModelForPrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of TimesFmModelForPrediction were not initialized from the model checkpoint at google/timesfm-2.5-200m-pytorch and are newly initialized: ['decoder.freq_emb.weight', 'decoder.input_ff_layer.input_layer.bias', 'decoder.input_ff_layer.input_layer.weight', 'decoder.input_ff_layer.output_layer.bias', 'decoder.input_ff_layer.output_layer.weight', 'decoder.input_ff_layer.residual_layer.bias', 'decoder.input_ff_layer.residual_layer.weight', 'decoder.layers.0.input_layernorm.weight', 'decoder.layers.0.mlp.down_proj.bias', 'decoder.layers.0.mlp.down_proj.weight', 'decoder.layers.0.mlp.gate_proj.bias', 'decoder.layers.0.mlp.gate_proj.weight', 'decoder.layers.0.mlp.layer_norm.bias', 'decoder.layers.0.mlp.layer_norm.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.o_proj.bias', 'decoder.layers.0.self_attn.o_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.scaling', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.1.input_layernorm.weight', 'decoder.layers.1.mlp.down_proj.bias', 'decoder.layers.1.mlp.down_proj.weight', 'decoder.layers.1.mlp.gate_proj.bias', 'decoder.layers.1.mlp.gate_proj.weight', 'decoder.layers.1.mlp.layer_norm.bias', 'decoder.layers.1.mlp.layer_norm.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.o_proj.bias', 'decoder.layers.1.self_attn.o_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.scaling', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.10.input_layernorm.weight', 'decoder.layers.10.mlp.down_proj.bias', 'decoder.layers.10.mlp.down_proj.weight', 'decoder.layers.10.mlp.gate_proj.bias', 'decoder.layers.10.mlp.gate_proj.weight', 'decoder.layers.10.mlp.layer_norm.bias', 'decoder.layers.10.mlp.layer_norm.weight', 'decoder.layers.10.self_attn.k_proj.bias', 'decoder.layers.10.self_attn.k_proj.weight', 'decoder.layers.10.self_attn.o_proj.bias', 'decoder.layers.10.self_attn.o_proj.weight', 'decoder.layers.10.self_attn.q_proj.bias', 'decoder.layers.10.self_attn.q_proj.weight', 'decoder.layers.10.self_attn.scaling', 'decoder.layers.10.self_attn.v_proj.bias', 'decoder.layers.10.self_attn.v_proj.weight', 'decoder.layers.11.input_layernorm.weight', 'decoder.layers.11.mlp.down_proj.bias', 'decoder.layers.11.mlp.down_proj.weight', 'decoder.layers.11.mlp.gate_proj.bias', 'decoder.layers.11.mlp.gate_proj.weight', 'decoder.layers.11.mlp.layer_norm.bias', 'decoder.layers.11.mlp.layer_norm.weight', 'decoder.layers.11.self_attn.k_proj.bias', 'decoder.layers.11.self_attn.k_proj.weight', 'decoder.layers.11.self_attn.o_proj.bias', 'decoder.layers.11.self_attn.o_proj.weight', 'decoder.layers.11.self_attn.q_proj.bias', 'decoder.layers.11.self_attn.q_proj.weight', 'decoder.layers.11.self_attn.scaling', 'decoder.layers.11.self_attn.v_proj.bias', 'decoder.layers.11.self_attn.v_proj.weight', 'decoder.layers.12.input_layernorm.weight', 'decoder.layers.12.mlp.down_proj.bias', 'decoder.layers.12.mlp.down_proj.weight', 'decoder.layers.12.mlp.gate_proj.bias', 'decoder.layers.12.mlp.gate_proj.weight', 'decoder.layers.12.mlp.layer_norm.bias', 'decoder.layers.12.mlp.layer_norm.weight', 'decoder.layers.12.self_attn.k_proj.bias', 'decoder.layers.12.self_attn.k_proj.weight', 'decoder.layers.12.self_attn.o_proj.bias', 'decoder.layers.12.self_attn.o_proj.weight', 'decoder.layers.12.self_attn.q_proj.bias', 'decoder.layers.12.self_attn.q_proj.weight', 'decoder.layers.12.self_attn.scaling', 'decoder.layers.12.self_attn.v_proj.bias', 'decoder.layers.12.self_attn.v_proj.weight', 'decoder.layers.13.input_layernorm.weight', 'decoder.layers.13.mlp.down_proj.bias', 'decoder.layers.13.mlp.down_proj.weight', 'decoder.layers.13.mlp.gate_proj.bias', 'decoder.layers.13.mlp.gate_proj.weight', 'decoder.layers.13.mlp.layer_norm.bias', 'decoder.layers.13.mlp.layer_norm.weight', 'decoder.layers.13.self_attn.k_proj.bias', 'decoder.layers.13.self_attn.k_proj.weight', 'decoder.layers.13.self_attn.o_proj.bias', 'decoder.layers.13.self_attn.o_proj.weight', 'decoder.layers.13.self_attn.q_proj.bias', 'decoder.layers.13.self_attn.q_proj.weight', 'decoder.layers.13.self_attn.scaling', 'decoder.layers.13.self_attn.v_proj.bias', 'decoder.layers.13.self_attn.v_proj.weight', 'decoder.layers.14.input_layernorm.weight', 'decoder.layers.14.mlp.down_proj.bias', 'decoder.layers.14.mlp.down_proj.weight', 'decoder.layers.14.mlp.gate_proj.bias', 'decoder.layers.14.mlp.gate_proj.weight', 'decoder.layers.14.mlp.layer_norm.bias', 'decoder.layers.14.mlp.layer_norm.weight', 'decoder.layers.14.self_attn.k_proj.bias', 'decoder.layers.14.self_attn.k_proj.weight', 'decoder.layers.14.self_attn.o_proj.bias', 'decoder.layers.14.self_attn.o_proj.weight', 'decoder.layers.14.self_attn.q_proj.bias', 'decoder.layers.14.self_attn.q_proj.weight', 'decoder.layers.14.self_attn.scaling', 'decoder.layers.14.self_attn.v_proj.bias', 'decoder.layers.14.self_attn.v_proj.weight', 'decoder.layers.15.input_layernorm.weight', 'decoder.layers.15.mlp.down_proj.bias', 'decoder.layers.15.mlp.down_proj.weight', 'decoder.layers.15.mlp.gate_proj.bias', 'decoder.layers.15.mlp.gate_proj.weight', 'decoder.layers.15.mlp.layer_norm.bias', 'decoder.layers.15.mlp.layer_norm.weight', 'decoder.layers.15.self_attn.k_proj.bias', 'decoder.layers.15.self_attn.k_proj.weight', 'decoder.layers.15.self_attn.o_proj.bias', 'decoder.layers.15.self_attn.o_proj.weight', 'decoder.layers.15.self_attn.q_proj.bias', 'decoder.layers.15.self_attn.q_proj.weight', 'decoder.layers.15.self_attn.scaling', 'decoder.layers.15.self_attn.v_proj.bias', 'decoder.layers.15.self_attn.v_proj.weight', 'decoder.layers.16.input_layernorm.weight', 'decoder.layers.16.mlp.down_proj.bias', 'decoder.layers.16.mlp.down_proj.weight', 'decoder.layers.16.mlp.gate_proj.bias', 'decoder.layers.16.mlp.gate_proj.weight', 'decoder.layers.16.mlp.layer_norm.bias', 'decoder.layers.16.mlp.layer_norm.weight', 'decoder.layers.16.self_attn.k_proj.bias', 'decoder.layers.16.self_attn.k_proj.weight', 'decoder.layers.16.self_attn.o_proj.bias', 'decoder.layers.16.self_attn.o_proj.weight', 'decoder.layers.16.self_attn.q_proj.bias', 'decoder.layers.16.self_attn.q_proj.weight', 'decoder.layers.16.self_attn.scaling', 'decoder.layers.16.self_attn.v_proj.bias', 'decoder.layers.16.self_attn.v_proj.weight', 'decoder.layers.17.input_layernorm.weight', 'decoder.layers.17.mlp.down_proj.bias', 'decoder.layers.17.mlp.down_proj.weight', 'decoder.layers.17.mlp.gate_proj.bias', 'decoder.layers.17.mlp.gate_proj.weight', 'decoder.layers.17.mlp.layer_norm.bias', 'decoder.layers.17.mlp.layer_norm.weight', 'decoder.layers.17.self_attn.k_proj.bias', 'decoder.layers.17.self_attn.k_proj.weight', 'decoder.layers.17.self_attn.o_proj.bias', 'decoder.layers.17.self_attn.o_proj.weight', 'decoder.layers.17.self_attn.q_proj.bias', 'decoder.layers.17.self_attn.q_proj.weight', 'decoder.layers.17.self_attn.scaling', 'decoder.layers.17.self_attn.v_proj.bias', 'decoder.layers.17.self_attn.v_proj.weight', 'decoder.layers.18.input_layernorm.weight', 'decoder.layers.18.mlp.down_proj.bias', 'decoder.layers.18.mlp.down_proj.weight', 'decoder.layers.18.mlp.gate_proj.bias', 'decoder.layers.18.mlp.gate_proj.weight', 'decoder.layers.18.mlp.layer_norm.bias', 'decoder.layers.18.mlp.layer_norm.weight', 'decoder.layers.18.self_attn.k_proj.bias', 'decoder.layers.18.self_attn.k_proj.weight', 'decoder.layers.18.self_attn.o_proj.bias', 'decoder.layers.18.self_attn.o_proj.weight', 'decoder.layers.18.self_attn.q_proj.bias', 'decoder.layers.18.self_attn.q_proj.weight', 'decoder.layers.18.self_attn.scaling', 'decoder.layers.18.self_attn.v_proj.bias', 'decoder.layers.18.self_attn.v_proj.weight', 'decoder.layers.19.input_layernorm.weight', 'decoder.layers.19.mlp.down_proj.bias', 'decoder.layers.19.mlp.down_proj.weight', 'decoder.layers.19.mlp.gate_proj.bias', 'decoder.layers.19.mlp.gate_proj.weight', 'decoder.layers.19.mlp.layer_norm.bias', 'decoder.layers.19.mlp.layer_norm.weight', 'decoder.layers.19.self_attn.k_proj.bias', 'decoder.layers.19.self_attn.k_proj.weight', 'decoder.layers.19.self_attn.o_proj.bias', 'decoder.layers.19.self_attn.o_proj.weight', 'decoder.layers.19.self_attn.q_proj.bias', 'decoder.layers.19.self_attn.q_proj.weight', 'decoder.layers.19.self_attn.scaling', 'decoder.layers.19.self_attn.v_proj.bias', 'decoder.layers.19.self_attn.v_proj.weight', 'decoder.layers.2.input_layernorm.weight', 'decoder.layers.2.mlp.down_proj.bias', 'decoder.layers.2.mlp.down_proj.weight', 'decoder.layers.2.mlp.gate_proj.bias', 'decoder.layers.2.mlp.gate_proj.weight', 'decoder.layers.2.mlp.layer_norm.bias', 'decoder.layers.2.mlp.layer_norm.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.o_proj.bias', 'decoder.layers.2.self_attn.o_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.scaling', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.3.input_layernorm.weight', 'decoder.layers.3.mlp.down_proj.bias', 'decoder.layers.3.mlp.down_proj.weight', 'decoder.layers.3.mlp.gate_proj.bias', 'decoder.layers.3.mlp.gate_proj.weight', 'decoder.layers.3.mlp.layer_norm.bias', 'decoder.layers.3.mlp.layer_norm.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.o_proj.bias', 'decoder.layers.3.self_attn.o_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.scaling', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.4.input_layernorm.weight', 'decoder.layers.4.mlp.down_proj.bias', 'decoder.layers.4.mlp.down_proj.weight', 'decoder.layers.4.mlp.gate_proj.bias', 'decoder.layers.4.mlp.gate_proj.weight', 'decoder.layers.4.mlp.layer_norm.bias', 'decoder.layers.4.mlp.layer_norm.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.o_proj.bias', 'decoder.layers.4.self_attn.o_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.scaling', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.5.input_layernorm.weight', 'decoder.layers.5.mlp.down_proj.bias', 'decoder.layers.5.mlp.down_proj.weight', 'decoder.layers.5.mlp.gate_proj.bias', 'decoder.layers.5.mlp.gate_proj.weight', 'decoder.layers.5.mlp.layer_norm.bias', 'decoder.layers.5.mlp.layer_norm.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.o_proj.bias', 'decoder.layers.5.self_attn.o_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.scaling', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.6.input_layernorm.weight', 'decoder.layers.6.mlp.down_proj.bias', 'decoder.layers.6.mlp.down_proj.weight', 'decoder.layers.6.mlp.gate_proj.bias', 'decoder.layers.6.mlp.gate_proj.weight', 'decoder.layers.6.mlp.layer_norm.bias', 'decoder.layers.6.mlp.layer_norm.weight', 'decoder.layers.6.self_attn.k_proj.bias', 'decoder.layers.6.self_attn.k_proj.weight', 'decoder.layers.6.self_attn.o_proj.bias', 'decoder.layers.6.self_attn.o_proj.weight', 'decoder.layers.6.self_attn.q_proj.bias', 'decoder.layers.6.self_attn.q_proj.weight', 'decoder.layers.6.self_attn.scaling', 'decoder.layers.6.self_attn.v_proj.bias', 'decoder.layers.6.self_attn.v_proj.weight', 'decoder.layers.7.input_layernorm.weight', 'decoder.layers.7.mlp.down_proj.bias', 'decoder.layers.7.mlp.down_proj.weight', 'decoder.layers.7.mlp.gate_proj.bias', 'decoder.layers.7.mlp.gate_proj.weight', 'decoder.layers.7.mlp.layer_norm.bias', 'decoder.layers.7.mlp.layer_norm.weight', 'decoder.layers.7.self_attn.k_proj.bias', 'decoder.layers.7.self_attn.k_proj.weight', 'decoder.layers.7.self_attn.o_proj.bias', 'decoder.layers.7.self_attn.o_proj.weight', 'decoder.layers.7.self_attn.q_proj.bias', 'decoder.layers.7.self_attn.q_proj.weight', 'decoder.layers.7.self_attn.scaling', 'decoder.layers.7.self_attn.v_proj.bias', 'decoder.layers.7.self_attn.v_proj.weight', 'decoder.layers.8.input_layernorm.weight', 'decoder.layers.8.mlp.down_proj.bias', 'decoder.layers.8.mlp.down_proj.weight', 'decoder.layers.8.mlp.gate_proj.bias', 'decoder.layers.8.mlp.gate_proj.weight', 'decoder.layers.8.mlp.layer_norm.bias', 'decoder.layers.8.mlp.layer_norm.weight', 'decoder.layers.8.self_attn.k_proj.bias', 'decoder.layers.8.self_attn.k_proj.weight', 'decoder.layers.8.self_attn.o_proj.bias', 'decoder.layers.8.self_attn.o_proj.weight', 'decoder.layers.8.self_attn.q_proj.bias', 'decoder.layers.8.self_attn.q_proj.weight', 'decoder.layers.8.self_attn.scaling', 'decoder.layers.8.self_attn.v_proj.bias', 'decoder.layers.8.self_attn.v_proj.weight', 'decoder.layers.9.input_layernorm.weight', 'decoder.layers.9.mlp.down_proj.bias', 'decoder.layers.9.mlp.down_proj.weight', 'decoder.layers.9.mlp.gate_proj.bias', 'decoder.layers.9.mlp.gate_proj.weight', 'decoder.layers.9.mlp.layer_norm.bias', 'decoder.layers.9.mlp.layer_norm.weight', 'decoder.layers.9.self_attn.k_proj.bias', 'decoder.layers.9.self_attn.k_proj.weight', 'decoder.layers.9.self_attn.o_proj.bias', 'decoder.layers.9.self_attn.o_proj.weight', 'decoder.layers.9.self_attn.q_proj.bias', 'decoder.layers.9.self_attn.q_proj.weight', 'decoder.layers.9.self_attn.scaling', 'decoder.layers.9.self_attn.v_proj.bias', 'decoder.layers.9.self_attn.v_proj.weight', 'horizon_ff_layer.input_layer.bias', 'horizon_ff_layer.input_layer.weight', 'horizon_ff_layer.output_layer.bias', 'horizon_ff_layer.output_layer.weight', 'horizon_ff_layer.residual_layer.bias', 'horizon_ff_layer.residual_layer.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== Transformer bench: google/timesfm-2.5-200m-pytorch ===\n",
            "!! ERROR for model google/timesfm-2.5-200m-pytorch: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n",
            "    mrh_acc=0.3829 mr+h+kg_acc=0.4008 kg_acc=0.3892 ensemble=0.4008 (w=0.60)\n",
            "  Split 1/1 - accuracy=0.4008 time=62.9s\n",
            "Completed Phoneme: Mean Acc=0.4008\n",
            "\n",
            "=== 69/109 PigAirwayPressure ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n",
            "    Gate split 1/5: baseline_loss=0.9658 adaptive_loss=0.9242\n",
            "    Gate split 2/5: baseline_loss=0.9257 adaptive_loss=0.8772\n",
            "    Gate split 3/5: baseline_loss=0.9832 adaptive_loss=0.9313\n",
            "    Gate split 4/5: baseline_loss=0.9850 adaptive_loss=0.9334\n",
            "    Gate split 5/5: baseline_loss=0.9442 adaptive_loss=0.8726\n",
            "  Decision: Adaptive kept (loss 0.9077 vs baseline 0.9608, delta=-0.0531 <= +0.0200); savgol(window=21, poly=3) - high noise (std_diff)\n",
            "Error processing PigAirwayPressure: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n",
            "\n",
            "=== 70/109 PigArtPressure ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 556, in main\n",
            "    results = evaluate_dataset_per_split(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 376, in evaluate_dataset_per_split\n",
            "    X_train_h_raw, X_test_h_raw = extract_hydra_features(\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/aziz-mrh-final/reference/kg_mtp_rebuild.py\", line 194, in extract_hydra_features\n",
            "    hydra_model = Hydra(\n",
            "                  ^^^^^^\n",
            "  File \"/content/aziz-mrh-final/libs/hydra_basic.py\", line 83, in __init__\n",
            "    torch.manual_seed(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_compile.py\", line 53, in inner\n",
            "    return disable_fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py\", line 1044, in _fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/random.py\", line 46, in manual_seed\n",
            "    torch.cuda.manual_seed_all(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 131, in manual_seed_all\n",
            "    _lazy_call(cb, seed_all=True)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\", line 341, in _lazy_call\n",
            "    callable()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 129, in cb\n",
            "    default_generator.manual_seed(seed)\n",
            "torch.AcceleratorError: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n",
            "    Gate split 1/5: baseline_loss=0.6071 adaptive_loss=0.5472\n",
            "    Gate split 2/5: baseline_loss=0.4730 adaptive_loss=0.4671\n",
            "    Gate split 3/5: baseline_loss=0.5213 adaptive_loss=0.4832\n",
            "    Gate split 4/5: baseline_loss=0.5565 adaptive_loss=0.5068\n",
            "    Gate split 5/5: baseline_loss=0.5295 adaptive_loss=0.5192\n",
            "  Decision: Adaptive kept (loss 0.5047 vs baseline 0.5375, delta=-0.0328 <= +0.0200); savgol(window=21, poly=3) - high noise (std_diff)\n",
            "Error processing PigArtPressure: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n",
            "\n",
            "=== 71/109 PigCVP ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 556, in main\n",
            "    results = evaluate_dataset_per_split(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 376, in evaluate_dataset_per_split\n",
            "    X_train_h_raw, X_test_h_raw = extract_hydra_features(\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/aziz-mrh-final/reference/kg_mtp_rebuild.py\", line 194, in extract_hydra_features\n",
            "    hydra_model = Hydra(\n",
            "                  ^^^^^^\n",
            "  File \"/content/aziz-mrh-final/libs/hydra_basic.py\", line 83, in __init__\n",
            "    torch.manual_seed(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_compile.py\", line 53, in inner\n",
            "    return disable_fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py\", line 1044, in _fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/random.py\", line 46, in manual_seed\n",
            "    torch.cuda.manual_seed_all(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 131, in manual_seed_all\n",
            "    _lazy_call(cb, seed_all=True)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\", line 341, in _lazy_call\n",
            "    callable()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 129, in cb\n",
            "    default_generator.manual_seed(seed)\n",
            "torch.AcceleratorError: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n",
            "    Gate split 1/5: baseline_loss=0.9033 adaptive_loss=0.8288\n",
            "    Gate split 2/5: baseline_loss=0.7371 adaptive_loss=0.6829\n",
            "    Gate split 3/5: baseline_loss=0.8143 adaptive_loss=0.7577\n",
            "    Gate split 4/5: baseline_loss=0.9632 adaptive_loss=0.8401\n",
            "    Gate split 5/5: baseline_loss=0.7513 adaptive_loss=0.6938\n",
            "  Decision: Adaptive kept (loss 0.7607 vs baseline 0.8339, delta=-0.0732 <= +0.0200); savgol(window=21, poly=3) - high noise (std_diff)\n",
            "Error processing PigCVP: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n",
            "\n",
            "=== 72/109 Plane ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  Decision: Heuristic says no filter (clean signal (no filtering))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 556, in main\n",
            "    results = evaluate_dataset_per_split(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 376, in evaluate_dataset_per_split\n",
            "    X_train_h_raw, X_test_h_raw = extract_hydra_features(\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/aziz-mrh-final/reference/kg_mtp_rebuild.py\", line 194, in extract_hydra_features\n",
            "    hydra_model = Hydra(\n",
            "                  ^^^^^^\n",
            "  File \"/content/aziz-mrh-final/libs/hydra_basic.py\", line 83, in __init__\n",
            "    torch.manual_seed(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_compile.py\", line 53, in inner\n",
            "    return disable_fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py\", line 1044, in _fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/random.py\", line 46, in manual_seed\n",
            "    torch.cuda.manual_seed_all(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 131, in manual_seed_all\n",
            "    _lazy_call(cb, seed_all=True)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\", line 341, in _lazy_call\n",
            "    callable()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 129, in cb\n",
            "    default_generator.manual_seed(seed)\n",
            "torch.AcceleratorError: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing Plane: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n",
            "\n",
            "=== 73/109 PowerCons ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 556, in main\n",
            "    results = evaluate_dataset_per_split(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 376, in evaluate_dataset_per_split\n",
            "    X_train_h_raw, X_test_h_raw = extract_hydra_features(\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/aziz-mrh-final/reference/kg_mtp_rebuild.py\", line 194, in extract_hydra_features\n",
            "    hydra_model = Hydra(\n",
            "                  ^^^^^^\n",
            "  File \"/content/aziz-mrh-final/libs/hydra_basic.py\", line 83, in __init__\n",
            "    torch.manual_seed(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_compile.py\", line 53, in inner\n",
            "    return disable_fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py\", line 1044, in _fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/random.py\", line 46, in manual_seed\n",
            "    torch.cuda.manual_seed_all(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 131, in manual_seed_all\n",
            "    _lazy_call(cb, seed_all=True)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\", line 341, in _lazy_call\n",
            "    callable()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 129, in cb\n",
            "    default_generator.manual_seed(seed)\n",
            "torch.AcceleratorError: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Gate split 1/5: baseline_loss=0.3586 adaptive_loss=0.3419\n",
            "    Gate split 2/5: baseline_loss=0.3274 adaptive_loss=0.2719\n",
            "    Gate split 3/5: baseline_loss=0.4219 adaptive_loss=0.4162\n",
            "    Gate split 4/5: baseline_loss=0.4471 adaptive_loss=0.4334\n",
            "    Gate split 5/5: baseline_loss=0.4347 adaptive_loss=0.4432\n",
            "  Decision: Adaptive kept (loss 0.3813 vs baseline 0.3979, delta=-0.0166 <= +0.0200); savgol(window=7, poly=2) - high noise (std_diff)\n",
            "Error processing PowerCons: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n",
            "\n",
            "=== 74/109 ProximalPhalanxOutlineAgeGroup ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  Decision: Heuristic says no filter (clean signal (no filtering))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 556, in main\n",
            "    results = evaluate_dataset_per_split(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 376, in evaluate_dataset_per_split\n",
            "    X_train_h_raw, X_test_h_raw = extract_hydra_features(\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/aziz-mrh-final/reference/kg_mtp_rebuild.py\", line 194, in extract_hydra_features\n",
            "    hydra_model = Hydra(\n",
            "                  ^^^^^^\n",
            "  File \"/content/aziz-mrh-final/libs/hydra_basic.py\", line 83, in __init__\n",
            "    torch.manual_seed(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_compile.py\", line 53, in inner\n",
            "    return disable_fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py\", line 1044, in _fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/random.py\", line 46, in manual_seed\n",
            "    torch.cuda.manual_seed_all(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 131, in manual_seed_all\n",
            "    _lazy_call(cb, seed_all=True)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\", line 341, in _lazy_call\n",
            "    callable()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 129, in cb\n",
            "    default_generator.manual_seed(seed)\n",
            "torch.AcceleratorError: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing ProximalPhalanxOutlineAgeGroup: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n",
            "\n",
            "=== 75/109 ProximalPhalanxOutlineCorrect ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  Decision: Heuristic says no filter (clean signal (no filtering))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 556, in main\n",
            "    results = evaluate_dataset_per_split(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 376, in evaluate_dataset_per_split\n",
            "    X_train_h_raw, X_test_h_raw = extract_hydra_features(\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/aziz-mrh-final/reference/kg_mtp_rebuild.py\", line 194, in extract_hydra_features\n",
            "    hydra_model = Hydra(\n",
            "                  ^^^^^^\n",
            "  File \"/content/aziz-mrh-final/libs/hydra_basic.py\", line 83, in __init__\n",
            "    torch.manual_seed(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_compile.py\", line 53, in inner\n",
            "    return disable_fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py\", line 1044, in _fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/random.py\", line 46, in manual_seed\n",
            "    torch.cuda.manual_seed_all(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 131, in manual_seed_all\n",
            "    _lazy_call(cb, seed_all=True)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\", line 341, in _lazy_call\n",
            "    callable()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 129, in cb\n",
            "    default_generator.manual_seed(seed)\n",
            "torch.AcceleratorError: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing ProximalPhalanxOutlineCorrect: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n",
            "\n",
            "=== 76/109 ProximalPhalanxTW ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  Decision: Heuristic says no filter (clean signal (no filtering))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 556, in main\n",
            "    results = evaluate_dataset_per_split(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 376, in evaluate_dataset_per_split\n",
            "    X_train_h_raw, X_test_h_raw = extract_hydra_features(\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/aziz-mrh-final/reference/kg_mtp_rebuild.py\", line 194, in extract_hydra_features\n",
            "    hydra_model = Hydra(\n",
            "                  ^^^^^^\n",
            "  File \"/content/aziz-mrh-final/libs/hydra_basic.py\", line 83, in __init__\n",
            "    torch.manual_seed(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_compile.py\", line 53, in inner\n",
            "    return disable_fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py\", line 1044, in _fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/random.py\", line 46, in manual_seed\n",
            "    torch.cuda.manual_seed_all(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 131, in manual_seed_all\n",
            "    _lazy_call(cb, seed_all=True)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\", line 341, in _lazy_call\n",
            "    callable()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 129, in cb\n",
            "    default_generator.manual_seed(seed)\n",
            "torch.AcceleratorError: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing ProximalPhalanxTW: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n",
            "\n",
            "=== 77/109 RefrigerationDevices ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 556, in main\n",
            "    results = evaluate_dataset_per_split(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 376, in evaluate_dataset_per_split\n",
            "    X_train_h_raw, X_test_h_raw = extract_hydra_features(\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/aziz-mrh-final/reference/kg_mtp_rebuild.py\", line 194, in extract_hydra_features\n",
            "    hydra_model = Hydra(\n",
            "                  ^^^^^^\n",
            "  File \"/content/aziz-mrh-final/libs/hydra_basic.py\", line 83, in __init__\n",
            "    torch.manual_seed(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_compile.py\", line 53, in inner\n",
            "    return disable_fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py\", line 1044, in _fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/random.py\", line 46, in manual_seed\n",
            "    torch.cuda.manual_seed_all(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 131, in manual_seed_all\n",
            "    _lazy_call(cb, seed_all=True)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\", line 341, in _lazy_call\n",
            "    callable()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 129, in cb\n",
            "    default_generator.manual_seed(seed)\n",
            "torch.AcceleratorError: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n",
            "    Gate split 1/5: baseline_loss=0.6853 adaptive_loss=0.8130\n",
            "    Gate split 2/5: baseline_loss=0.9662 adaptive_loss=0.9399\n",
            "    Gate split 3/5: baseline_loss=0.8967 adaptive_loss=0.8498\n",
            "    Gate split 4/5: baseline_loss=1.0547 adaptive_loss=1.1644\n",
            "    Gate split 5/5: baseline_loss=0.7575 adaptive_loss=0.9136\n",
            "  Decision: Adaptive rejected (loss 0.9361 vs baseline 0.8721, delta=+0.0640 > +0.0200); savgol(window=15, poly=3) - high noise (std_diff)\n",
            "Error processing RefrigerationDevices: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n",
            "\n",
            "=== 78/109 Rock ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 556, in main\n",
            "    results = evaluate_dataset_per_split(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 376, in evaluate_dataset_per_split\n",
            "    X_train_h_raw, X_test_h_raw = extract_hydra_features(\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/aziz-mrh-final/reference/kg_mtp_rebuild.py\", line 194, in extract_hydra_features\n",
            "    hydra_model = Hydra(\n",
            "                  ^^^^^^\n",
            "  File \"/content/aziz-mrh-final/libs/hydra_basic.py\", line 83, in __init__\n",
            "    torch.manual_seed(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_compile.py\", line 53, in inner\n",
            "    return disable_fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py\", line 1044, in _fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/random.py\", line 46, in manual_seed\n",
            "    torch.cuda.manual_seed_all(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 131, in manual_seed_all\n",
            "    _lazy_call(cb, seed_all=True)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\", line 341, in _lazy_call\n",
            "    callable()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 129, in cb\n",
            "    default_generator.manual_seed(seed)\n",
            "torch.AcceleratorError: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n",
            "    Gate split 1/5: baseline_loss=0.6364 adaptive_loss=0.7455\n",
            "    Gate split 2/5: baseline_loss=0.6136 adaptive_loss=0.6840\n",
            "    Gate split 3/5: baseline_loss=0.6450 adaptive_loss=0.6352\n",
            "    Gate split 4/5: baseline_loss=0.6955 adaptive_loss=0.7649\n",
            "    Gate split 5/5: baseline_loss=1.0116 adaptive_loss=1.0192\n",
            "  Decision: Adaptive rejected (loss 0.7697 vs baseline 0.7204, delta=+0.0493 > +0.0200); savgol(window=21, poly=3) - high noise (std_diff)\n",
            "Error processing Rock: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n",
            "\n",
            "=== 79/109 ScreenType ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 556, in main\n",
            "    results = evaluate_dataset_per_split(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 376, in evaluate_dataset_per_split\n",
            "    X_train_h_raw, X_test_h_raw = extract_hydra_features(\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/aziz-mrh-final/reference/kg_mtp_rebuild.py\", line 194, in extract_hydra_features\n",
            "    hydra_model = Hydra(\n",
            "                  ^^^^^^\n",
            "  File \"/content/aziz-mrh-final/libs/hydra_basic.py\", line 83, in __init__\n",
            "    torch.manual_seed(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_compile.py\", line 53, in inner\n",
            "    return disable_fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py\", line 1044, in _fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/random.py\", line 46, in manual_seed\n",
            "    torch.cuda.manual_seed_all(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 131, in manual_seed_all\n",
            "    _lazy_call(cb, seed_all=True)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\", line 341, in _lazy_call\n",
            "    callable()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 129, in cb\n",
            "    default_generator.manual_seed(seed)\n",
            "torch.AcceleratorError: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n",
            "    Gate split 1/5: baseline_loss=1.1584 adaptive_loss=1.2881\n",
            "    Gate split 2/5: baseline_loss=1.3012 adaptive_loss=1.2292\n",
            "    Gate split 3/5: baseline_loss=1.2526 adaptive_loss=1.3246\n",
            "    Gate split 4/5: baseline_loss=1.6581 adaptive_loss=1.5544\n",
            "    Gate split 5/5: baseline_loss=1.1956 adaptive_loss=0.9851\n",
            "  Decision: Adaptive kept (loss 1.2763 vs baseline 1.3132, delta=-0.0369 <= +0.0200); savgol(window=15, poly=3) - high noise (std_diff)\n",
            "Error processing ScreenType: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n",
            "\n",
            "=== 80/109 SemgHandGenderCh2 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 556, in main\n",
            "    results = evaluate_dataset_per_split(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 376, in evaluate_dataset_per_split\n",
            "    X_train_h_raw, X_test_h_raw = extract_hydra_features(\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/aziz-mrh-final/reference/kg_mtp_rebuild.py\", line 194, in extract_hydra_features\n",
            "    hydra_model = Hydra(\n",
            "                  ^^^^^^\n",
            "  File \"/content/aziz-mrh-final/libs/hydra_basic.py\", line 83, in __init__\n",
            "    torch.manual_seed(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_compile.py\", line 53, in inner\n",
            "    return disable_fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py\", line 1044, in _fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/random.py\", line 46, in manual_seed\n",
            "    torch.cuda.manual_seed_all(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 131, in manual_seed_all\n",
            "    _lazy_call(cb, seed_all=True)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\", line 341, in _lazy_call\n",
            "    callable()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 129, in cb\n",
            "    default_generator.manual_seed(seed)\n",
            "torch.AcceleratorError: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n",
            "    Gate split 1/5: baseline_loss=0.6805 adaptive_loss=0.6924\n",
            "    Gate split 2/5: baseline_loss=0.4532 adaptive_loss=0.4886\n",
            "    Gate split 3/5: baseline_loss=0.5034 adaptive_loss=0.5906\n",
            "    Gate split 4/5: baseline_loss=0.5469 adaptive_loss=0.5960\n",
            "    Gate split 5/5: baseline_loss=0.5994 adaptive_loss=0.4953\n",
            "  Decision: Adaptive kept (loss 0.5726 vs baseline 0.5567, delta=+0.0159 <= +0.0200); savgol(window=21, poly=3) - high noise (std_diff)\n",
            "Error processing SemgHandGenderCh2: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n",
            "\n",
            "=== 81/109 SemgHandMovementCh2 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 556, in main\n",
            "    results = evaluate_dataset_per_split(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 376, in evaluate_dataset_per_split\n",
            "    X_train_h_raw, X_test_h_raw = extract_hydra_features(\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/aziz-mrh-final/reference/kg_mtp_rebuild.py\", line 194, in extract_hydra_features\n",
            "    hydra_model = Hydra(\n",
            "                  ^^^^^^\n",
            "  File \"/content/aziz-mrh-final/libs/hydra_basic.py\", line 83, in __init__\n",
            "    torch.manual_seed(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_compile.py\", line 53, in inner\n",
            "    return disable_fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py\", line 1044, in _fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/random.py\", line 46, in manual_seed\n",
            "    torch.cuda.manual_seed_all(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 131, in manual_seed_all\n",
            "    _lazy_call(cb, seed_all=True)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\", line 341, in _lazy_call\n",
            "    callable()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 129, in cb\n",
            "    default_generator.manual_seed(seed)\n",
            "torch.AcceleratorError: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n",
            "    Gate split 1/5: baseline_loss=0.6068 adaptive_loss=0.5319\n",
            "    Gate split 2/5: baseline_loss=0.7888 adaptive_loss=0.8076\n",
            "    Gate split 3/5: baseline_loss=0.7173 adaptive_loss=0.6515\n",
            "    Gate split 4/5: baseline_loss=0.7222 adaptive_loss=0.6219\n",
            "    Gate split 5/5: baseline_loss=0.6575 adaptive_loss=0.6250\n",
            "  Decision: Adaptive kept (loss 0.6476 vs baseline 0.6985, delta=-0.0510 <= +0.0200); savgol(window=21, poly=3) - high noise (std_diff)\n",
            "Error processing SemgHandMovementCh2: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n",
            "\n",
            "=== 82/109 SemgHandSubjectCh2 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 556, in main\n",
            "    results = evaluate_dataset_per_split(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 376, in evaluate_dataset_per_split\n",
            "    X_train_h_raw, X_test_h_raw = extract_hydra_features(\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/aziz-mrh-final/reference/kg_mtp_rebuild.py\", line 194, in extract_hydra_features\n",
            "    hydra_model = Hydra(\n",
            "                  ^^^^^^\n",
            "  File \"/content/aziz-mrh-final/libs/hydra_basic.py\", line 83, in __init__\n",
            "    torch.manual_seed(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_compile.py\", line 53, in inner\n",
            "    return disable_fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py\", line 1044, in _fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/random.py\", line 46, in manual_seed\n",
            "    torch.cuda.manual_seed_all(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 131, in manual_seed_all\n",
            "    _lazy_call(cb, seed_all=True)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\", line 341, in _lazy_call\n",
            "    callable()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 129, in cb\n",
            "    default_generator.manual_seed(seed)\n",
            "torch.AcceleratorError: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n",
            "    Gate split 1/5: baseline_loss=0.5259 adaptive_loss=0.4792\n",
            "    Gate split 2/5: baseline_loss=0.4879 adaptive_loss=0.3939\n",
            "    Gate split 3/5: baseline_loss=0.4985 adaptive_loss=0.4235\n",
            "    Gate split 4/5: baseline_loss=0.5003 adaptive_loss=0.4025\n",
            "    Gate split 5/5: baseline_loss=0.6284 adaptive_loss=0.5541\n",
            "  Decision: Adaptive kept (loss 0.4506 vs baseline 0.5282, delta=-0.0776 <= +0.0200); savgol(window=21, poly=3) - high noise (std_diff)\n",
            "Error processing SemgHandSubjectCh2: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n",
            "\n",
            "=== 83/109 ShapeletSim ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  Decision: Heuristic says no filter (clean signal (no filtering))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 556, in main\n",
            "    results = evaluate_dataset_per_split(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 376, in evaluate_dataset_per_split\n",
            "    X_train_h_raw, X_test_h_raw = extract_hydra_features(\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/aziz-mrh-final/reference/kg_mtp_rebuild.py\", line 194, in extract_hydra_features\n",
            "    hydra_model = Hydra(\n",
            "                  ^^^^^^\n",
            "  File \"/content/aziz-mrh-final/libs/hydra_basic.py\", line 83, in __init__\n",
            "    torch.manual_seed(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_compile.py\", line 53, in inner\n",
            "    return disable_fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py\", line 1044, in _fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/random.py\", line 46, in manual_seed\n",
            "    torch.cuda.manual_seed_all(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 131, in manual_seed_all\n",
            "    _lazy_call(cb, seed_all=True)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\", line 341, in _lazy_call\n",
            "    callable()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 129, in cb\n",
            "    default_generator.manual_seed(seed)\n",
            "torch.AcceleratorError: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing ShapeletSim: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n",
            "\n",
            "=== 84/109 ShapesAll ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 556, in main\n",
            "    results = evaluate_dataset_per_split(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 376, in evaluate_dataset_per_split\n",
            "    X_train_h_raw, X_test_h_raw = extract_hydra_features(\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/aziz-mrh-final/reference/kg_mtp_rebuild.py\", line 194, in extract_hydra_features\n",
            "    hydra_model = Hydra(\n",
            "                  ^^^^^^\n",
            "  File \"/content/aziz-mrh-final/libs/hydra_basic.py\", line 83, in __init__\n",
            "    torch.manual_seed(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_compile.py\", line 53, in inner\n",
            "    return disable_fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py\", line 1044, in _fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/random.py\", line 46, in manual_seed\n",
            "    torch.cuda.manual_seed_all(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 131, in manual_seed_all\n",
            "    _lazy_call(cb, seed_all=True)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\", line 341, in _lazy_call\n",
            "    callable()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 129, in cb\n",
            "    default_generator.manual_seed(seed)\n",
            "torch.AcceleratorError: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Split 1/1 ---\n",
            "  Decision: Heuristic says no filter (clean signal (no filtering))\n",
            "Error processing ShapesAll: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n",
            "\n",
            "=== 85/109 SmallKitchenAppliances ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 556, in main\n",
            "    results = evaluate_dataset_per_split(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 376, in evaluate_dataset_per_split\n",
            "    X_train_h_raw, X_test_h_raw = extract_hydra_features(\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/aziz-mrh-final/reference/kg_mtp_rebuild.py\", line 194, in extract_hydra_features\n",
            "    hydra_model = Hydra(\n",
            "                  ^^^^^^\n",
            "  File \"/content/aziz-mrh-final/libs/hydra_basic.py\", line 83, in __init__\n",
            "    torch.manual_seed(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_compile.py\", line 53, in inner\n",
            "    return disable_fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py\", line 1044, in _fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/random.py\", line 46, in manual_seed\n",
            "    torch.cuda.manual_seed_all(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 131, in manual_seed_all\n",
            "    _lazy_call(cb, seed_all=True)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\", line 341, in _lazy_call\n",
            "    callable()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 129, in cb\n",
            "    default_generator.manual_seed(seed)\n",
            "torch.AcceleratorError: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n",
            "    Gate split 1/5: baseline_loss=0.5331 adaptive_loss=0.5132\n",
            "    Gate split 2/5: baseline_loss=0.6533 adaptive_loss=0.4961\n",
            "    Gate split 3/5: baseline_loss=0.7002 adaptive_loss=0.6993\n",
            "    Gate split 4/5: baseline_loss=0.5405 adaptive_loss=0.5968\n",
            "    Gate split 5/5: baseline_loss=0.8447 adaptive_loss=0.7399\n",
            "  Decision: Adaptive kept (loss 0.6091 vs baseline 0.6543, delta=-0.0453 <= +0.0200); savgol(window=15, poly=3) - high noise (std_diff)\n",
            "Error processing SmallKitchenAppliances: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n",
            "\n",
            "=== 86/109 SmoothSubspace ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  Decision: Heuristic says no filter (too short to filter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 556, in main\n",
            "    results = evaluate_dataset_per_split(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 376, in evaluate_dataset_per_split\n",
            "    X_train_h_raw, X_test_h_raw = extract_hydra_features(\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/aziz-mrh-final/reference/kg_mtp_rebuild.py\", line 194, in extract_hydra_features\n",
            "    hydra_model = Hydra(\n",
            "                  ^^^^^^\n",
            "  File \"/content/aziz-mrh-final/libs/hydra_basic.py\", line 83, in __init__\n",
            "    torch.manual_seed(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_compile.py\", line 53, in inner\n",
            "    return disable_fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py\", line 1044, in _fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/random.py\", line 46, in manual_seed\n",
            "    torch.cuda.manual_seed_all(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 131, in manual_seed_all\n",
            "    _lazy_call(cb, seed_all=True)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\", line 341, in _lazy_call\n",
            "    callable()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 129, in cb\n",
            "    default_generator.manual_seed(seed)\n",
            "torch.AcceleratorError: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing SmoothSubspace: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n",
            "\n",
            "=== 87/109 SonyAIBORobotSurface1 ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 556, in main\n",
            "    results = evaluate_dataset_per_split(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 376, in evaluate_dataset_per_split\n",
            "    X_train_h_raw, X_test_h_raw = extract_hydra_features(\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/aziz-mrh-final/reference/kg_mtp_rebuild.py\", line 194, in extract_hydra_features\n",
            "    hydra_model = Hydra(\n",
            "                  ^^^^^^\n",
            "  File \"/content/aziz-mrh-final/libs/hydra_basic.py\", line 83, in __init__\n",
            "    torch.manual_seed(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_compile.py\", line 53, in inner\n",
            "    return disable_fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py\", line 1044, in _fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/random.py\", line 46, in manual_seed\n",
            "    torch.cuda.manual_seed_all(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 131, in manual_seed_all\n",
            "    _lazy_call(cb, seed_all=True)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\", line 341, in _lazy_call\n",
            "    callable()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 129, in cb\n",
            "    default_generator.manual_seed(seed)\n",
            "torch.AcceleratorError: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Gate split 1/5: baseline_loss=0.3845 adaptive_loss=0.3876\n",
            "    Gate split 2/5: baseline_loss=0.5051 adaptive_loss=0.5521\n",
            "    Gate split 3/5: baseline_loss=0.2069 adaptive_loss=0.2921\n",
            "    Gate split 4/5: baseline_loss=0.3281 adaptive_loss=0.3615\n",
            "    Gate split 5/5: baseline_loss=0.1431 adaptive_loss=0.1639\n",
            "  Decision: Adaptive rejected (loss 0.3515 vs baseline 0.3136, delta=+0.0379 > +0.0200); savgol(window=5, poly=2) - high noise (std_diff)\n",
            "Error processing SonyAIBORobotSurface1: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n",
            "\n",
            "=== 88/109 SonyAIBORobotSurface2 ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 556, in main\n",
            "    results = evaluate_dataset_per_split(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 376, in evaluate_dataset_per_split\n",
            "    X_train_h_raw, X_test_h_raw = extract_hydra_features(\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/aziz-mrh-final/reference/kg_mtp_rebuild.py\", line 194, in extract_hydra_features\n",
            "    hydra_model = Hydra(\n",
            "                  ^^^^^^\n",
            "  File \"/content/aziz-mrh-final/libs/hydra_basic.py\", line 83, in __init__\n",
            "    torch.manual_seed(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_compile.py\", line 53, in inner\n",
            "    return disable_fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py\", line 1044, in _fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/random.py\", line 46, in manual_seed\n",
            "    torch.cuda.manual_seed_all(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 131, in manual_seed_all\n",
            "    _lazy_call(cb, seed_all=True)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\", line 341, in _lazy_call\n",
            "    callable()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 129, in cb\n",
            "    default_generator.manual_seed(seed)\n",
            "torch.AcceleratorError: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Gate split 1/5: baseline_loss=0.3982 adaptive_loss=0.4156\n",
            "    Gate split 2/5: baseline_loss=0.4268 adaptive_loss=0.3821\n",
            "    Gate split 3/5: baseline_loss=0.4317 adaptive_loss=0.4147\n",
            "    Gate split 4/5: baseline_loss=0.3471 adaptive_loss=0.3371\n",
            "    Gate split 5/5: baseline_loss=0.3623 adaptive_loss=0.3616\n",
            "  Decision: Adaptive kept (loss 0.3823 vs baseline 0.3932, delta=-0.0110 <= +0.0200); savgol(window=5, poly=2) - high noise (std_diff)\n",
            "Error processing SonyAIBORobotSurface2: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n",
            "\n",
            "=== 89/109 StarLightCurves ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 556, in main\n",
            "    results = evaluate_dataset_per_split(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 376, in evaluate_dataset_per_split\n",
            "    X_train_h_raw, X_test_h_raw = extract_hydra_features(\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/aziz-mrh-final/reference/kg_mtp_rebuild.py\", line 194, in extract_hydra_features\n",
            "    hydra_model = Hydra(\n",
            "                  ^^^^^^\n",
            "  File \"/content/aziz-mrh-final/libs/hydra_basic.py\", line 83, in __init__\n",
            "    torch.manual_seed(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_compile.py\", line 53, in inner\n",
            "    return disable_fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py\", line 1044, in _fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/random.py\", line 46, in manual_seed\n",
            "    torch.cuda.manual_seed_all(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 131, in manual_seed_all\n",
            "    _lazy_call(cb, seed_all=True)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\", line 341, in _lazy_call\n",
            "    callable()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 129, in cb\n",
            "    default_generator.manual_seed(seed)\n",
            "torch.AcceleratorError: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n",
            "    Gate split 1/5: baseline_loss=0.3052 adaptive_loss=0.3040\n",
            "    Gate split 2/5: baseline_loss=0.2265 adaptive_loss=0.0327\n",
            "    Gate split 3/5: baseline_loss=0.1504 adaptive_loss=0.0215\n",
            "    Gate split 4/5: baseline_loss=0.1820 adaptive_loss=0.1950\n",
            "    Gate split 5/5: baseline_loss=0.3227 adaptive_loss=0.0317\n",
            "  Decision: Adaptive kept (loss 0.1170 vs baseline 0.2374, delta=-0.1204 <= +0.0200); savgol(window=21, poly=3) - high noise (std_diff)\n",
            "Error processing StarLightCurves: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n",
            "\n",
            "=== 90/109 Strawberry ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 556, in main\n",
            "    results = evaluate_dataset_per_split(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 376, in evaluate_dataset_per_split\n",
            "    X_train_h_raw, X_test_h_raw = extract_hydra_features(\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/aziz-mrh-final/reference/kg_mtp_rebuild.py\", line 194, in extract_hydra_features\n",
            "    hydra_model = Hydra(\n",
            "                  ^^^^^^\n",
            "  File \"/content/aziz-mrh-final/libs/hydra_basic.py\", line 83, in __init__\n",
            "    torch.manual_seed(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_compile.py\", line 53, in inner\n",
            "    return disable_fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py\", line 1044, in _fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/random.py\", line 46, in manual_seed\n",
            "    torch.cuda.manual_seed_all(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 131, in manual_seed_all\n",
            "    _lazy_call(cb, seed_all=True)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\", line 341, in _lazy_call\n",
            "    callable()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 129, in cb\n",
            "    default_generator.manual_seed(seed)\n",
            "torch.AcceleratorError: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n",
            "    Gate split 1/5: baseline_loss=0.4128 adaptive_loss=0.3935\n",
            "    Gate split 2/5: baseline_loss=0.3909 adaptive_loss=0.3838\n",
            "    Gate split 3/5: baseline_loss=0.4312 adaptive_loss=0.3587\n",
            "    Gate split 4/5: baseline_loss=0.5065 adaptive_loss=0.4378\n",
            "    Gate split 5/5: baseline_loss=0.5217 adaptive_loss=0.5098\n",
            "  Decision: Adaptive kept (loss 0.4167 vs baseline 0.4526, delta=-0.0359 <= +0.0200); savgol(window=11, poly=2) - high noise (std_diff)\n",
            "Error processing Strawberry: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n",
            "\n",
            "=== 91/109 SwedishLeaf ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  Decision: Heuristic says no filter (clean signal (no filtering))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 556, in main\n",
            "    results = evaluate_dataset_per_split(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 376, in evaluate_dataset_per_split\n",
            "    X_train_h_raw, X_test_h_raw = extract_hydra_features(\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/aziz-mrh-final/reference/kg_mtp_rebuild.py\", line 194, in extract_hydra_features\n",
            "    hydra_model = Hydra(\n",
            "                  ^^^^^^\n",
            "  File \"/content/aziz-mrh-final/libs/hydra_basic.py\", line 83, in __init__\n",
            "    torch.manual_seed(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_compile.py\", line 53, in inner\n",
            "    return disable_fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py\", line 1044, in _fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/random.py\", line 46, in manual_seed\n",
            "    torch.cuda.manual_seed_all(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 131, in manual_seed_all\n",
            "    _lazy_call(cb, seed_all=True)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\", line 341, in _lazy_call\n",
            "    callable()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 129, in cb\n",
            "    default_generator.manual_seed(seed)\n",
            "torch.AcceleratorError: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing SwedishLeaf: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n",
            "\n",
            "=== 92/109 Symbols ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 556, in main\n",
            "    results = evaluate_dataset_per_split(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 376, in evaluate_dataset_per_split\n",
            "    X_train_h_raw, X_test_h_raw = extract_hydra_features(\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/aziz-mrh-final/reference/kg_mtp_rebuild.py\", line 194, in extract_hydra_features\n",
            "    hydra_model = Hydra(\n",
            "                  ^^^^^^\n",
            "  File \"/content/aziz-mrh-final/libs/hydra_basic.py\", line 83, in __init__\n",
            "    torch.manual_seed(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_compile.py\", line 53, in inner\n",
            "    return disable_fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py\", line 1044, in _fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/random.py\", line 46, in manual_seed\n",
            "    torch.cuda.manual_seed_all(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 131, in manual_seed_all\n",
            "    _lazy_call(cb, seed_all=True)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\", line 341, in _lazy_call\n",
            "    callable()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 129, in cb\n",
            "    default_generator.manual_seed(seed)\n",
            "torch.AcceleratorError: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n",
            "    Gate split 1/5: baseline_loss=0.0000 adaptive_loss=0.0000\n",
            "    Gate split 2/5: baseline_loss=0.0000 adaptive_loss=0.0000\n",
            "    Gate split 3/5: baseline_loss=0.1092 adaptive_loss=0.1067\n",
            "    Gate split 4/5: baseline_loss=0.0185 adaptive_loss=0.0516\n",
            "    Gate split 5/5: baseline_loss=0.1312 adaptive_loss=0.0838\n",
            "  Decision: Adaptive kept (loss 0.0484 vs baseline 0.0518, delta=-0.0034 <= +0.0200); savgol(window=11, poly=2) - high noise (std_diff)\n",
            "Error processing Symbols: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n",
            "\n",
            "=== 93/109 SyntheticControl ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 556, in main\n",
            "    results = evaluate_dataset_per_split(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 376, in evaluate_dataset_per_split\n",
            "    X_train_h_raw, X_test_h_raw = extract_hydra_features(\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/aziz-mrh-final/reference/kg_mtp_rebuild.py\", line 194, in extract_hydra_features\n",
            "    hydra_model = Hydra(\n",
            "                  ^^^^^^\n",
            "  File \"/content/aziz-mrh-final/libs/hydra_basic.py\", line 83, in __init__\n",
            "    torch.manual_seed(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_compile.py\", line 53, in inner\n",
            "    return disable_fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py\", line 1044, in _fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/random.py\", line 46, in manual_seed\n",
            "    torch.cuda.manual_seed_all(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 131, in manual_seed_all\n",
            "    _lazy_call(cb, seed_all=True)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\", line 341, in _lazy_call\n",
            "    callable()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 129, in cb\n",
            "    default_generator.manual_seed(seed)\n",
            "torch.AcceleratorError: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Gate split 1/5: baseline_loss=0.0356 adaptive_loss=0.0253\n",
            "    Gate split 2/5: baseline_loss=0.0940 adaptive_loss=0.0756\n",
            "    Gate split 3/5: baseline_loss=0.1080 adaptive_loss=0.0948\n",
            "    Gate split 4/5: baseline_loss=0.0872 adaptive_loss=0.1022\n",
            "    Gate split 5/5: baseline_loss=0.1476 adaptive_loss=0.1318\n",
            "  Decision: Adaptive kept (loss 0.0859 vs baseline 0.0945, delta=-0.0085 <= +0.0200); savgol(window=5, poly=2) - high noise (std_diff)\n",
            "Error processing SyntheticControl: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n",
            "\n",
            "=== 94/109 ToeSegmentation1 ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 556, in main\n",
            "    results = evaluate_dataset_per_split(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 376, in evaluate_dataset_per_split\n",
            "    X_train_h_raw, X_test_h_raw = extract_hydra_features(\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/aziz-mrh-final/reference/kg_mtp_rebuild.py\", line 194, in extract_hydra_features\n",
            "    hydra_model = Hydra(\n",
            "                  ^^^^^^\n",
            "  File \"/content/aziz-mrh-final/libs/hydra_basic.py\", line 83, in __init__\n",
            "    torch.manual_seed(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_compile.py\", line 53, in inner\n",
            "    return disable_fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py\", line 1044, in _fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/random.py\", line 46, in manual_seed\n",
            "    torch.cuda.manual_seed_all(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 131, in manual_seed_all\n",
            "    _lazy_call(cb, seed_all=True)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\", line 341, in _lazy_call\n",
            "    callable()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 129, in cb\n",
            "    default_generator.manual_seed(seed)\n",
            "torch.AcceleratorError: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Gate split 1/5: baseline_loss=0.4176 adaptive_loss=0.4352\n",
            "    Gate split 2/5: baseline_loss=0.4578 adaptive_loss=0.4561\n",
            "    Gate split 3/5: baseline_loss=0.4136 adaptive_loss=0.4182\n",
            "    Gate split 4/5: baseline_loss=0.4789 adaptive_loss=0.4314\n",
            "    Gate split 5/5: baseline_loss=0.3444 adaptive_loss=0.2718\n",
            "  Decision: Adaptive kept (loss 0.4026 vs baseline 0.4225, delta=-0.0199 <= +0.0200); savgol(window=11, poly=2) - high noise (std_diff)\n",
            "Error processing ToeSegmentation1: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n",
            "\n",
            "=== 95/109 ToeSegmentation2 ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 556, in main\n",
            "    results = evaluate_dataset_per_split(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 376, in evaluate_dataset_per_split\n",
            "    X_train_h_raw, X_test_h_raw = extract_hydra_features(\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/aziz-mrh-final/reference/kg_mtp_rebuild.py\", line 194, in extract_hydra_features\n",
            "    hydra_model = Hydra(\n",
            "                  ^^^^^^\n",
            "  File \"/content/aziz-mrh-final/libs/hydra_basic.py\", line 83, in __init__\n",
            "    torch.manual_seed(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_compile.py\", line 53, in inner\n",
            "    return disable_fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py\", line 1044, in _fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/random.py\", line 46, in manual_seed\n",
            "    torch.cuda.manual_seed_all(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 131, in manual_seed_all\n",
            "    _lazy_call(cb, seed_all=True)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\", line 341, in _lazy_call\n",
            "    callable()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 129, in cb\n",
            "    default_generator.manual_seed(seed)\n",
            "torch.AcceleratorError: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Gate split 1/5: baseline_loss=0.2785 adaptive_loss=0.2226\n",
            "    Gate split 2/5: baseline_loss=0.2126 adaptive_loss=0.2234\n",
            "    Gate split 3/5: baseline_loss=0.2836 adaptive_loss=0.2656\n",
            "    Gate split 4/5: baseline_loss=0.5197 adaptive_loss=0.4790\n",
            "    Gate split 5/5: baseline_loss=0.3469 adaptive_loss=0.2842\n",
            "  Decision: Adaptive kept (loss 0.2950 vs baseline 0.3283, delta=-0.0333 <= +0.0200); savgol(window=11, poly=2) - high noise (std_diff)\n",
            "Error processing ToeSegmentation2: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n",
            "\n",
            "=== 96/109 Trace ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 556, in main\n",
            "    results = evaluate_dataset_per_split(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 376, in evaluate_dataset_per_split\n",
            "    X_train_h_raw, X_test_h_raw = extract_hydra_features(\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/aziz-mrh-final/reference/kg_mtp_rebuild.py\", line 194, in extract_hydra_features\n",
            "    hydra_model = Hydra(\n",
            "                  ^^^^^^\n",
            "  File \"/content/aziz-mrh-final/libs/hydra_basic.py\", line 83, in __init__\n",
            "    torch.manual_seed(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_compile.py\", line 53, in inner\n",
            "    return disable_fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py\", line 1044, in _fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/random.py\", line 46, in manual_seed\n",
            "    torch.cuda.manual_seed_all(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 131, in manual_seed_all\n",
            "    _lazy_call(cb, seed_all=True)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\", line 341, in _lazy_call\n",
            "    callable()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 129, in cb\n",
            "    default_generator.manual_seed(seed)\n",
            "torch.AcceleratorError: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Gate split 1/5: baseline_loss=0.0000 adaptive_loss=0.0000\n",
            "    Gate split 2/5: baseline_loss=0.0000 adaptive_loss=0.0000\n",
            "    Gate split 3/5: baseline_loss=0.0000 adaptive_loss=0.0000\n",
            "    Gate split 4/5: baseline_loss=0.0000 adaptive_loss=0.0000\n",
            "    Gate split 5/5: baseline_loss=0.0000 adaptive_loss=0.0000\n",
            "  Decision: Adaptive kept (loss 0.0000 vs baseline 0.0000, delta=+0.0000 <= +0.0200); savgol(window=11, poly=2) - high noise (std_diff)\n",
            "Error processing Trace: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n",
            "\n",
            "=== 97/109 TwoLeadECG ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 556, in main\n",
            "    results = evaluate_dataset_per_split(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 376, in evaluate_dataset_per_split\n",
            "    X_train_h_raw, X_test_h_raw = extract_hydra_features(\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/aziz-mrh-final/reference/kg_mtp_rebuild.py\", line 194, in extract_hydra_features\n",
            "    hydra_model = Hydra(\n",
            "                  ^^^^^^\n",
            "  File \"/content/aziz-mrh-final/libs/hydra_basic.py\", line 83, in __init__\n",
            "    torch.manual_seed(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_compile.py\", line 53, in inner\n",
            "    return disable_fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py\", line 1044, in _fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/random.py\", line 46, in manual_seed\n",
            "    torch.cuda.manual_seed_all(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 131, in manual_seed_all\n",
            "    _lazy_call(cb, seed_all=True)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\", line 341, in _lazy_call\n",
            "    callable()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 129, in cb\n",
            "    default_generator.manual_seed(seed)\n",
            "torch.AcceleratorError: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Gate split 1/5: baseline_loss=0.2563 adaptive_loss=0.2311\n",
            "    Gate split 2/5: baseline_loss=0.3493 adaptive_loss=0.3175\n",
            "    Gate split 3/5: baseline_loss=0.2599 adaptive_loss=0.2705\n",
            "    Gate split 4/5: baseline_loss=0.3260 adaptive_loss=0.3021\n",
            "    Gate split 5/5: baseline_loss=0.2716 adaptive_loss=0.2474\n",
            "  Decision: Adaptive kept (loss 0.2737 vs baseline 0.2926, delta=-0.0189 <= +0.0200); savgol(window=5, poly=2) - high noise (std_diff)\n",
            "Error processing TwoLeadECG: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n",
            "\n",
            "=== 98/109 TwoPatterns ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 556, in main\n",
            "    results = evaluate_dataset_per_split(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 376, in evaluate_dataset_per_split\n",
            "    X_train_h_raw, X_test_h_raw = extract_hydra_features(\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/aziz-mrh-final/reference/kg_mtp_rebuild.py\", line 194, in extract_hydra_features\n",
            "    hydra_model = Hydra(\n",
            "                  ^^^^^^\n",
            "  File \"/content/aziz-mrh-final/libs/hydra_basic.py\", line 83, in __init__\n",
            "    torch.manual_seed(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_compile.py\", line 53, in inner\n",
            "    return disable_fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py\", line 1044, in _fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/random.py\", line 46, in manual_seed\n",
            "    torch.cuda.manual_seed_all(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 131, in manual_seed_all\n",
            "    _lazy_call(cb, seed_all=True)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\", line 341, in _lazy_call\n",
            "    callable()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 129, in cb\n",
            "    default_generator.manual_seed(seed)\n",
            "torch.AcceleratorError: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n",
            "    Gate split 1/5: baseline_loss=0.1223 adaptive_loss=0.0912\n",
            "    Gate split 2/5: baseline_loss=0.2020 adaptive_loss=0.1611\n",
            "    Gate split 3/5: baseline_loss=0.2413 adaptive_loss=0.1613\n",
            "    Gate split 4/5: baseline_loss=0.2950 adaptive_loss=0.1820\n",
            "    Gate split 5/5: baseline_loss=0.2936 adaptive_loss=0.1941\n",
            "  Decision: Adaptive kept (loss 0.1579 vs baseline 0.2308, delta=-0.0729 <= +0.0200); savgol(window=7, poly=2) - high noise (std_diff)\n",
            "Error processing TwoPatterns: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n",
            "\n",
            "=== 99/109 UMD ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 556, in main\n",
            "    results = evaluate_dataset_per_split(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 376, in evaluate_dataset_per_split\n",
            "    X_train_h_raw, X_test_h_raw = extract_hydra_features(\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/aziz-mrh-final/reference/kg_mtp_rebuild.py\", line 194, in extract_hydra_features\n",
            "    hydra_model = Hydra(\n",
            "                  ^^^^^^\n",
            "  File \"/content/aziz-mrh-final/libs/hydra_basic.py\", line 83, in __init__\n",
            "    torch.manual_seed(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_compile.py\", line 53, in inner\n",
            "    return disable_fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py\", line 1044, in _fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/random.py\", line 46, in manual_seed\n",
            "    torch.cuda.manual_seed_all(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 131, in manual_seed_all\n",
            "    _lazy_call(cb, seed_all=True)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\", line 341, in _lazy_call\n",
            "    callable()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 129, in cb\n",
            "    default_generator.manual_seed(seed)\n",
            "torch.AcceleratorError: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Gate split 1/5: baseline_loss=0.0016 adaptive_loss=0.0049\n",
            "    Gate split 2/5: baseline_loss=0.1574 adaptive_loss=0.1022\n",
            "    Gate split 3/5: baseline_loss=0.1861 adaptive_loss=0.1947\n",
            "    Gate split 4/5: baseline_loss=0.1819 adaptive_loss=0.1925\n",
            "    Gate split 5/5: baseline_loss=0.3321 adaptive_loss=0.3237\n",
            "  Decision: Adaptive kept (loss 0.1636 vs baseline 0.1718, delta=-0.0082 <= +0.0200); savgol(window=7, poly=2) - high noise (std_diff)\n",
            "Error processing UMD: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n",
            "\n",
            "=== 100/109 UWaveGestureLibraryAll ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 556, in main\n",
            "    results = evaluate_dataset_per_split(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 376, in evaluate_dataset_per_split\n",
            "    X_train_h_raw, X_test_h_raw = extract_hydra_features(\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/aziz-mrh-final/reference/kg_mtp_rebuild.py\", line 194, in extract_hydra_features\n",
            "    hydra_model = Hydra(\n",
            "                  ^^^^^^\n",
            "  File \"/content/aziz-mrh-final/libs/hydra_basic.py\", line 83, in __init__\n",
            "    torch.manual_seed(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_compile.py\", line 53, in inner\n",
            "    return disable_fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py\", line 1044, in _fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/random.py\", line 46, in manual_seed\n",
            "    torch.cuda.manual_seed_all(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 131, in manual_seed_all\n",
            "    _lazy_call(cb, seed_all=True)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\", line 341, in _lazy_call\n",
            "    callable()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 129, in cb\n",
            "    default_generator.manual_seed(seed)\n",
            "torch.AcceleratorError: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n",
            "    Gate split 1/5: baseline_loss=0.1422 adaptive_loss=0.1420\n",
            "    Gate split 2/5: baseline_loss=0.2905 adaptive_loss=0.2896\n",
            "    Gate split 3/5: baseline_loss=0.1939 adaptive_loss=0.1835\n",
            "    Gate split 4/5: baseline_loss=0.1974 adaptive_loss=0.1963\n",
            "    Gate split 5/5: baseline_loss=0.1589 adaptive_loss=0.1876\n",
            "  Decision: Adaptive kept (loss 0.1998 vs baseline 0.1966, delta=+0.0032 <= +0.0200); savgol(window=15, poly=3) - high noise (std_diff)\n",
            "Error processing UWaveGestureLibraryAll: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n",
            "\n",
            "=== 101/109 UWaveGestureLibraryX ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 556, in main\n",
            "    results = evaluate_dataset_per_split(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 376, in evaluate_dataset_per_split\n",
            "    X_train_h_raw, X_test_h_raw = extract_hydra_features(\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/aziz-mrh-final/reference/kg_mtp_rebuild.py\", line 194, in extract_hydra_features\n",
            "    hydra_model = Hydra(\n",
            "                  ^^^^^^\n",
            "  File \"/content/aziz-mrh-final/libs/hydra_basic.py\", line 83, in __init__\n",
            "    torch.manual_seed(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_compile.py\", line 53, in inner\n",
            "    return disable_fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py\", line 1044, in _fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/random.py\", line 46, in manual_seed\n",
            "    torch.cuda.manual_seed_all(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 131, in manual_seed_all\n",
            "    _lazy_call(cb, seed_all=True)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\", line 341, in _lazy_call\n",
            "    callable()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 129, in cb\n",
            "    default_generator.manual_seed(seed)\n",
            "torch.AcceleratorError: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n",
            "    Gate split 1/5: baseline_loss=0.4934 adaptive_loss=0.5139\n",
            "    Gate split 2/5: baseline_loss=0.5365 adaptive_loss=0.5409\n",
            "    Gate split 3/5: baseline_loss=0.4614 adaptive_loss=0.4594\n",
            "    Gate split 4/5: baseline_loss=0.4354 adaptive_loss=0.4510\n",
            "    Gate split 5/5: baseline_loss=0.3732 adaptive_loss=0.4209\n",
            "  Decision: Adaptive kept (loss 0.4772 vs baseline 0.4600, delta=+0.0172 <= +0.0200); savgol(window=11, poly=2) - high noise (std_diff)\n",
            "Error processing UWaveGestureLibraryX: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n",
            "\n",
            "=== 102/109 UWaveGestureLibraryY ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 556, in main\n",
            "    results = evaluate_dataset_per_split(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 376, in evaluate_dataset_per_split\n",
            "    X_train_h_raw, X_test_h_raw = extract_hydra_features(\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/aziz-mrh-final/reference/kg_mtp_rebuild.py\", line 194, in extract_hydra_features\n",
            "    hydra_model = Hydra(\n",
            "                  ^^^^^^\n",
            "  File \"/content/aziz-mrh-final/libs/hydra_basic.py\", line 83, in __init__\n",
            "    torch.manual_seed(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_compile.py\", line 53, in inner\n",
            "    return disable_fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py\", line 1044, in _fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/random.py\", line 46, in manual_seed\n",
            "    torch.cuda.manual_seed_all(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 131, in manual_seed_all\n",
            "    _lazy_call(cb, seed_all=True)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\", line 341, in _lazy_call\n",
            "    callable()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 129, in cb\n",
            "    default_generator.manual_seed(seed)\n",
            "torch.AcceleratorError: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n",
            "    Gate split 1/5: baseline_loss=0.6013 adaptive_loss=0.6353\n",
            "    Gate split 2/5: baseline_loss=0.8607 adaptive_loss=0.8613\n",
            "    Gate split 3/5: baseline_loss=0.7202 adaptive_loss=0.7445\n",
            "    Gate split 4/5: baseline_loss=0.7301 adaptive_loss=0.7564\n",
            "    Gate split 5/5: baseline_loss=0.6546 adaptive_loss=0.6822\n",
            "  Decision: Adaptive rejected (loss 0.7359 vs baseline 0.7134, delta=+0.0226 > +0.0200); savgol(window=11, poly=2) - high noise (std_diff)\n",
            "Error processing UWaveGestureLibraryY: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n",
            "\n",
            "=== 103/109 UWaveGestureLibraryZ ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 556, in main\n",
            "    results = evaluate_dataset_per_split(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 376, in evaluate_dataset_per_split\n",
            "    X_train_h_raw, X_test_h_raw = extract_hydra_features(\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/aziz-mrh-final/reference/kg_mtp_rebuild.py\", line 194, in extract_hydra_features\n",
            "    hydra_model = Hydra(\n",
            "                  ^^^^^^\n",
            "  File \"/content/aziz-mrh-final/libs/hydra_basic.py\", line 83, in __init__\n",
            "    torch.manual_seed(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_compile.py\", line 53, in inner\n",
            "    return disable_fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py\", line 1044, in _fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/random.py\", line 46, in manual_seed\n",
            "    torch.cuda.manual_seed_all(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 131, in manual_seed_all\n",
            "    _lazy_call(cb, seed_all=True)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\", line 341, in _lazy_call\n",
            "    callable()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 129, in cb\n",
            "    default_generator.manual_seed(seed)\n",
            "torch.AcceleratorError: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n",
            "    Gate split 1/5: baseline_loss=0.5960 adaptive_loss=0.5792\n",
            "    Gate split 2/5: baseline_loss=0.6593 adaptive_loss=0.6821\n",
            "    Gate split 3/5: baseline_loss=0.6105 adaptive_loss=0.6156\n",
            "    Gate split 4/5: baseline_loss=0.6070 adaptive_loss=0.6422\n",
            "    Gate split 5/5: baseline_loss=0.6659 adaptive_loss=0.6827\n",
            "  Decision: Adaptive kept (loss 0.6404 vs baseline 0.6277, delta=+0.0126 <= +0.0200); savgol(window=11, poly=2) - high noise (std_diff)\n",
            "Error processing UWaveGestureLibraryZ: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n",
            "\n",
            "=== 104/109 Wafer ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 556, in main\n",
            "    results = evaluate_dataset_per_split(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 376, in evaluate_dataset_per_split\n",
            "    X_train_h_raw, X_test_h_raw = extract_hydra_features(\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/aziz-mrh-final/reference/kg_mtp_rebuild.py\", line 194, in extract_hydra_features\n",
            "    hydra_model = Hydra(\n",
            "                  ^^^^^^\n",
            "  File \"/content/aziz-mrh-final/libs/hydra_basic.py\", line 83, in __init__\n",
            "    torch.manual_seed(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_compile.py\", line 53, in inner\n",
            "    return disable_fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py\", line 1044, in _fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/random.py\", line 46, in manual_seed\n",
            "    torch.cuda.manual_seed_all(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 131, in manual_seed_all\n",
            "    _lazy_call(cb, seed_all=True)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\", line 341, in _lazy_call\n",
            "    callable()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 129, in cb\n",
            "    default_generator.manual_seed(seed)\n",
            "torch.AcceleratorError: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n",
            "    Gate split 1/5: baseline_loss=0.1710 adaptive_loss=0.1842\n",
            "    Gate split 2/5: baseline_loss=0.0964 adaptive_loss=0.1032\n",
            "    Gate split 3/5: baseline_loss=0.1785 adaptive_loss=0.2322\n",
            "    Gate split 4/5: baseline_loss=0.1597 adaptive_loss=0.2125\n",
            "    Gate split 5/5: baseline_loss=0.0917 adaptive_loss=0.1268\n",
            "  Decision: Adaptive rejected (loss 0.1718 vs baseline 0.1394, delta=+0.0323 > +0.0200); savgol(window=7, poly=2) - high noise (std_diff)\n",
            "Error processing Wafer: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n",
            "\n",
            "=== 105/109 Wine ===\n",
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 556, in main\n",
            "    results = evaluate_dataset_per_split(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 376, in evaluate_dataset_per_split\n",
            "    X_train_h_raw, X_test_h_raw = extract_hydra_features(\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/aziz-mrh-final/reference/kg_mtp_rebuild.py\", line 194, in extract_hydra_features\n",
            "    hydra_model = Hydra(\n",
            "                  ^^^^^^\n",
            "  File \"/content/aziz-mrh-final/libs/hydra_basic.py\", line 83, in __init__\n",
            "    torch.manual_seed(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_compile.py\", line 53, in inner\n",
            "    return disable_fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py\", line 1044, in _fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/random.py\", line 46, in manual_seed\n",
            "    torch.cuda.manual_seed_all(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 131, in manual_seed_all\n",
            "    _lazy_call(cb, seed_all=True)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\", line 341, in _lazy_call\n",
            "    callable()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 129, in cb\n",
            "    default_generator.manual_seed(seed)\n",
            "torch.AcceleratorError: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Gate split 1/5: baseline_loss=0.5563 adaptive_loss=0.5104\n",
            "    Gate split 2/5: baseline_loss=0.4635 adaptive_loss=0.3972\n",
            "    Gate split 3/5: baseline_loss=0.3909 adaptive_loss=0.3366\n",
            "    Gate split 4/5: baseline_loss=0.3829 adaptive_loss=0.3055\n",
            "    Gate split 5/5: baseline_loss=0.3483 adaptive_loss=0.2667\n",
            "  Decision: Adaptive kept (loss 0.3633 vs baseline 0.4284, delta=-0.0651 <= +0.0200); savgol(window=11, poly=2) - high noise (std_diff)\n",
            "Error processing Wine: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n",
            "\n",
            "=== 106/109 WordSynonyms ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 556, in main\n",
            "    results = evaluate_dataset_per_split(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 376, in evaluate_dataset_per_split\n",
            "    X_train_h_raw, X_test_h_raw = extract_hydra_features(\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/aziz-mrh-final/reference/kg_mtp_rebuild.py\", line 194, in extract_hydra_features\n",
            "    hydra_model = Hydra(\n",
            "                  ^^^^^^\n",
            "  File \"/content/aziz-mrh-final/libs/hydra_basic.py\", line 83, in __init__\n",
            "    torch.manual_seed(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_compile.py\", line 53, in inner\n",
            "    return disable_fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py\", line 1044, in _fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/random.py\", line 46, in manual_seed\n",
            "    torch.cuda.manual_seed_all(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 131, in manual_seed_all\n",
            "    _lazy_call(cb, seed_all=True)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\", line 341, in _lazy_call\n",
            "    callable()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 129, in cb\n",
            "    default_generator.manual_seed(seed)\n",
            "torch.AcceleratorError: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n",
            "    Gate split 1/5: baseline_loss=0.5352 adaptive_loss=0.5438\n",
            "    Gate split 2/5: baseline_loss=0.6534 adaptive_loss=0.6553\n",
            "    Gate split 3/5: baseline_loss=0.6346 adaptive_loss=0.6415\n",
            "    Gate split 4/5: baseline_loss=0.6633 adaptive_loss=0.6821\n",
            "    Gate split 5/5: baseline_loss=0.6612 adaptive_loss=0.6811\n",
            "  Decision: Adaptive kept (loss 0.6408 vs baseline 0.6295, delta=+0.0112 <= +0.0200); savgol(window=11, poly=2) - high noise (std_diff)\n",
            "Error processing WordSynonyms: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n",
            "\n",
            "=== 107/109 Worms ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 556, in main\n",
            "    results = evaluate_dataset_per_split(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 376, in evaluate_dataset_per_split\n",
            "    X_train_h_raw, X_test_h_raw = extract_hydra_features(\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/aziz-mrh-final/reference/kg_mtp_rebuild.py\", line 194, in extract_hydra_features\n",
            "    hydra_model = Hydra(\n",
            "                  ^^^^^^\n",
            "  File \"/content/aziz-mrh-final/libs/hydra_basic.py\", line 83, in __init__\n",
            "    torch.manual_seed(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_compile.py\", line 53, in inner\n",
            "    return disable_fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py\", line 1044, in _fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/random.py\", line 46, in manual_seed\n",
            "    torch.cuda.manual_seed_all(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 131, in manual_seed_all\n",
            "    _lazy_call(cb, seed_all=True)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\", line 341, in _lazy_call\n",
            "    callable()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 129, in cb\n",
            "    default_generator.manual_seed(seed)\n",
            "torch.AcceleratorError: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n",
            "    Gate split 1/5: baseline_loss=0.8574 adaptive_loss=0.7993\n",
            "    Gate split 2/5: baseline_loss=0.6488 adaptive_loss=0.6439\n",
            "    Gate split 3/5: baseline_loss=0.9033 adaptive_loss=0.9449\n",
            "    Gate split 4/5: baseline_loss=0.8801 adaptive_loss=0.9467\n",
            "    Gate split 5/5: baseline_loss=0.8063 adaptive_loss=0.7783\n",
            "  Decision: Adaptive kept (loss 0.8226 vs baseline 0.8192, delta=+0.0035 <= +0.0200); savgol(window=15, poly=3) - high noise (std_diff)\n",
            "Error processing Worms: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n",
            "\n",
            "=== 108/109 WormsTwoClass ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 556, in main\n",
            "    results = evaluate_dataset_per_split(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 376, in evaluate_dataset_per_split\n",
            "    X_train_h_raw, X_test_h_raw = extract_hydra_features(\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/aziz-mrh-final/reference/kg_mtp_rebuild.py\", line 194, in extract_hydra_features\n",
            "    hydra_model = Hydra(\n",
            "                  ^^^^^^\n",
            "  File \"/content/aziz-mrh-final/libs/hydra_basic.py\", line 83, in __init__\n",
            "    torch.manual_seed(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_compile.py\", line 53, in inner\n",
            "    return disable_fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py\", line 1044, in _fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/random.py\", line 46, in manual_seed\n",
            "    torch.cuda.manual_seed_all(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 131, in manual_seed_all\n",
            "    _lazy_call(cb, seed_all=True)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\", line 341, in _lazy_call\n",
            "    callable()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 129, in cb\n",
            "    default_generator.manual_seed(seed)\n",
            "torch.AcceleratorError: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Split 1/1 ---\n",
            "  [Loss Gate] Running subset simulations...\n",
            "    Gate split 1/5: baseline_loss=0.5788 adaptive_loss=0.6306\n",
            "    Gate split 2/5: baseline_loss=0.8530 adaptive_loss=0.8648\n",
            "    Gate split 3/5: baseline_loss=0.8750 adaptive_loss=0.8910\n",
            "    Gate split 4/5: baseline_loss=0.8202 adaptive_loss=0.8277\n",
            "    Gate split 5/5: baseline_loss=1.0398 adaptive_loss=0.9007\n",
            "  Decision: Adaptive kept (loss 0.8230 vs baseline 0.8333, delta=-0.0104 <= +0.0200); savgol(window=15, poly=3) - high noise (std_diff)\n",
            "Error processing WormsTwoClass: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n",
            "\n",
            "=== 109/109 Yoga ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 556, in main\n",
            "    results = evaluate_dataset_per_split(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 376, in evaluate_dataset_per_split\n",
            "    X_train_h_raw, X_test_h_raw = extract_hydra_features(\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/aziz-mrh-final/reference/kg_mtp_rebuild.py\", line 194, in extract_hydra_features\n",
            "    hydra_model = Hydra(\n",
            "                  ^^^^^^\n",
            "  File \"/content/aziz-mrh-final/libs/hydra_basic.py\", line 83, in __init__\n",
            "    torch.manual_seed(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_compile.py\", line 53, in inner\n",
            "    return disable_fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py\", line 1044, in _fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/random.py\", line 46, in manual_seed\n",
            "    torch.cuda.manual_seed_all(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 131, in manual_seed_all\n",
            "    _lazy_call(cb, seed_all=True)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\", line 341, in _lazy_call\n",
            "    callable()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 129, in cb\n",
            "    default_generator.manual_seed(seed)\n",
            "torch.AcceleratorError: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Split 1/1 ---\n",
            "  Decision: Heuristic says no filter (clean signal (no filtering))\n",
            "Error processing Yoga: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n",
            "\n",
            "Running final aggregation...\n",
            "Aggregation complete.\n",
            "time: 8h 58min 39s (started: 2025-11-23 04:18:23 +00:00)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 556, in main\n",
            "    results = evaluate_dataset_per_split(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-968560981.py\", line 376, in evaluate_dataset_per_split\n",
            "    X_train_h_raw, X_test_h_raw = extract_hydra_features(\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/aziz-mrh-final/reference/kg_mtp_rebuild.py\", line 194, in extract_hydra_features\n",
            "    hydra_model = Hydra(\n",
            "                  ^^^^^^\n",
            "  File \"/content/aziz-mrh-final/libs/hydra_basic.py\", line 83, in __init__\n",
            "    torch.manual_seed(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_compile.py\", line 53, in inner\n",
            "    return disable_fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py\", line 1044, in _fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/random.py\", line 46, in manual_seed\n",
            "    torch.cuda.manual_seed_all(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 131, in manual_seed_all\n",
            "    _lazy_call(cb, seed_all=True)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\", line 341, in _lazy_call\n",
            "    callable()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 129, in cb\n",
            "    default_generator.manual_seed(seed)\n",
            "torch.AcceleratorError: CUDA error: device-side assert triggered\n",
            "Search for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!timestamp=\"`date -Iseconds`\" ; for a in  results/*csv ; do basename=\"$(basename \"$a\" .csv)\"; dirname=\"/content/drive/MyDrive/sota2025/aziz_final\"; dest_path=\"${dirname}/experiment_TStransformer_${basename}_${timestamp}.csv\"; cp \"$a\" \"${dest_path}\"; echo \"${dest_path}\"; done"
      ],
      "metadata": {
        "id": "Dco1CMcBXDE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2jTocEMRe6Hq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6THqNiUimuUn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}